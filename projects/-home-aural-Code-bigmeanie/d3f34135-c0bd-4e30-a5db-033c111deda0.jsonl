{"type":"summary","summary":"Claude Templates: Sync, Customize, Manage Projects","leafUuid":"494898af-57f9-4d47-9dd2-8d2fd607bce7"}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":"/god review /back/.docs/code files for acurracy and gaps"},"uuid":"a5a5018a-5cf5-4afb-97ed-3487678b5909","timestamp":"2025-08-13T09:58:37.509Z"}
{"parentUuid":"a5a5018a-5cf5-4afb-97ed-3487678b5909","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01JtUuinH9jCDm635hcN2YRv","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"I'll use the god agent to review the code documentation files for accuracy and gaps."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":36355,"cache_read_input_tokens":0,"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CS5WehJM9SQkdnjveY4vv","type":"assistant","uuid":"c2aae76a-dadf-4c32-8f31-f7b9de7a0b06","timestamp":"2025-08-13T09:58:41.338Z"}
{"parentUuid":"c2aae76a-dadf-4c32-8f31-f7b9de7a0b06","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01JtUuinH9jCDm635hcN2YRv","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01Bd6KCouHcoi937jkuqmkcQ","name":"Task","input":{"description":"Review code docs accuracy","prompt":"Review all files in /home/aural/Code/bigmeanie/back/.docs/code/ for accuracy and identify any gaps or inconsistencies. \n\nFocus on:\n1. Technical accuracy of the documented patterns and practices\n2. Completeness of coverage for the codebase\n3. Any outdated or incorrect information\n4. Missing important topics that should be documented\n5. Consistency between different documentation files\n\nRead all files in that directory and provide a comprehensive review highlighting:\n- What's accurate and well-documented\n- What needs correction or updating\n- What important topics are missing\n- Specific recommendations for improvements\n\nBe thorough but concise in your analysis.","subagent_type":"god"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":36355,"cache_read_input_tokens":0,"output_tokens":253,"service_tier":"standard"}},"requestId":"req_011CS5WehJM9SQkdnjveY4vv","type":"assistant","uuid":"c80f1bfc-0e27-49cb-86b7-72beb62abe58","timestamp":"2025-08-13T09:58:46.915Z"}
{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":"Review all files in /home/aural/Code/bigmeanie/back/.docs/code/ for accuracy and identify any gaps or inconsistencies. \n\nFocus on:\n1. Technical accuracy of the documented patterns and practices\n2. Completeness of coverage for the codebase\n3. Any outdated or incorrect information\n4. Missing important topics that should be documented\n5. Consistency between different documentation files\n\nRead all files in that directory and provide a comprehensive review highlighting:\n- What's accurate and well-documented\n- What needs correction or updating\n- What important topics are missing\n- Specific recommendations for improvements\n\nBe thorough but concise in your analysis."},"uuid":"a2ceb058-11f0-428b-9921-d16dd02e1024","timestamp":"2025-08-13T09:58:46.941Z"}
{"parentUuid":"a2ceb058-11f0-428b-9921-d16dd02e1024","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01XXVdK4VBnBP3bPwvTDCsgH","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"I'll review all the documentation files in `/home/aural/Code/bigmeanie/back/.docs/code/` to assess their accuracy, completeness, and identify any gaps or inconsistencies."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":32490,"cache_read_input_tokens":0,"output_tokens":153,"service_tier":"standard"}},"requestId":"req_011CS5WfNtqapGDSQoBcB8DP","type":"assistant","uuid":"614c5d3e-0d84-434d-af91-5869026ae76b","timestamp":"2025-08-13T09:58:50.968Z"}
{"parentUuid":"614c5d3e-0d84-434d-af91-5869026ae76b","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01XXVdK4VBnBP3bPwvTDCsgH","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_018nE6SQqx479wPHiHGgQXXV","name":"Bash","input":{"command":"find /home/aural/Code/bigmeanie/back/.docs/code/ -type f -name \"*.md\" | head -20","description":"List all markdown files in the code docs directory"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":32490,"cache_read_input_tokens":0,"output_tokens":153,"service_tier":"standard"}},"requestId":"req_011CS5WfNtqapGDSQoBcB8DP","type":"assistant","uuid":"9cf03fe7-10e7-4b7c-88f9-e8c4d7c30f36","timestamp":"2025-08-13T09:58:52.562Z"}
{"parentUuid":"9cf03fe7-10e7-4b7c-88f9-e8c4d7c30f36","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018nE6SQqx479wPHiHGgQXXV","type":"tool_result","content":"/home/aural/Code/bigmeanie/back/.docs/code/errors.md\n/home/aural/Code/bigmeanie/back/.docs/code/fundamentals.md\n/home/aural/Code/bigmeanie/back/.docs/code/design-patterns.md\n/home/aural/Code/bigmeanie/back/.docs/code/packages.md\n/home/aural/Code/bigmeanie/back/.docs/code/concurrency.md\n/home/aural/Code/bigmeanie/back/.docs/code/testing.md\n/home/aural/Code/bigmeanie/back/.docs/code/performance.md","is_error":false}]},"uuid":"22c6ec92-b632-4b01-bc49-877f862511fb","timestamp":"2025-08-13T09:58:52.597Z","toolUseResult":{"stdout":"/home/aural/Code/bigmeanie/back/.docs/code/errors.md\n/home/aural/Code/bigmeanie/back/.docs/code/fundamentals.md\n/home/aural/Code/bigmeanie/back/.docs/code/design-patterns.md\n/home/aural/Code/bigmeanie/back/.docs/code/packages.md\n/home/aural/Code/bigmeanie/back/.docs/code/concurrency.md\n/home/aural/Code/bigmeanie/back/.docs/code/testing.md\n/home/aural/Code/bigmeanie/back/.docs/code/performance.md","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"22c6ec92-b632-4b01-bc49-877f862511fb","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_012cfKPAxYA1pPjT9dKw5151","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Now let me read each of these documentation files to review their content:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":486,"cache_read_input_tokens":32490,"output_tokens":88,"service_tier":"standard"}},"requestId":"req_011CS5WfowizT1VeHZuFWeRE","type":"assistant","uuid":"a57ad979-132b-40a5-93d3-605822cba171","timestamp":"2025-08-13T09:58:55.776Z"}
{"parentUuid":"a57ad979-132b-40a5-93d3-605822cba171","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_012cfKPAxYA1pPjT9dKw5151","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_015W3xWXAu53fCaBgXCgYFdH","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/errors.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":486,"cache_read_input_tokens":32490,"output_tokens":88,"service_tier":"standard"}},"requestId":"req_011CS5WfowizT1VeHZuFWeRE","type":"assistant","uuid":"31d125c0-49de-4605-95c2-5ac4f04d444e","timestamp":"2025-08-13T09:58:56.503Z"}
{"parentUuid":"31d125c0-49de-4605-95c2-5ac4f04d444e","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015W3xWXAu53fCaBgXCgYFdH","type":"tool_result","content":"     1→# Go Error Handling - Excellence in Error Management\n     2→\n     3→## Table of Contents\n     4→1. [Error Basics](#error-basics)\n     5→2. [Error Types](#error-types)\n     6→3. [Error Wrapping](#error-wrapping)\n     7→4. [Sentinel Errors](#sentinel-errors)\n     8→5. [Custom Errors](#custom-errors)\n     9→6. [Error Design Patterns](#error-design-patterns)\n    10→7. [Panic and Recover](#panic-and-recover)\n    11→8. [Error Handling Strategies](#error-handling-strategies)\n    12→9. [Testing Errors](#testing-errors)\n    13→10. [Best Practices](#best-practices)\n    14→\n    15→## Error Basics\n    16→\n    17→### The Error Interface\n    18→```go\n    19→// Built-in error interface\n    20→type error interface {\n    21→    Error() string\n    22→}\n    23→\n    24→// Basic error creation\n    25→import \"errors\"\n    26→\n    27→err := errors.New(\"something went wrong\")\n    28→\n    29→// Formatted errors\n    30→err := fmt.Errorf(\"failed to process item %d: %s\", id, reason)\n    31→\n    32→// Checking errors\n    33→result, err := doSomething()\n    34→if err != nil {\n    35→    // Handle error\n    36→    return err\n    37→}\n    38→\n    39→// Multiple return values with error\n    40→func divide(a, b float64) (float64, error) {\n    41→    if b == 0 {\n    42→        return 0, errors.New(\"division by zero\")\n    43→    }\n    44→    return a / b, nil\n    45→}\n    46→\n    47→// Named returns with error\n    48→func readFile(path string) (data []byte, err error) {\n    49→    data, err = os.ReadFile(path)\n    50→    if err != nil {\n    51→        return nil, err // Explicit return preferred\n    52→    }\n    53→    return data, nil\n    54→}\n    55→\n    56→// Defer with error handling\n    57→func writeFile(path string, data []byte) (err error) {\n    58→    f, err := os.Create(path)\n    59→    if err != nil {\n    60→        return err\n    61→    }\n    62→    defer func() {\n    63→        if cerr := f.Close(); cerr != nil && err == nil {\n    64→            err = cerr // Capture close error if no other error\n    65→        }\n    66→    }()\n    67→    \n    68→    _, err = f.Write(data)\n    69→    return err\n    70→}\n    71→```\n    72→\n    73→### Error Checking Patterns\n    74→```go\n    75→// Immediate return pattern\n    76→if err := doSomething(); err != nil {\n    77→    return fmt.Errorf(\"doSomething failed: %w\", err)\n    78→}\n    79→\n    80→// Guard clause pattern\n    81→func process(input string) error {\n    82→    if input == \"\" {\n    83→        return errors.New(\"input cannot be empty\")\n    84→    }\n    85→    \n    86→    if len(input) > 100 {\n    87→        return errors.New(\"input too long\")\n    88→    }\n    89→    \n    90→    // Main logic here\n    91→    return nil\n    92→}\n    93→\n    94→// Error accumulation\n    95→func processMultiple(items []Item) error {\n    96→    var errs []error\n    97→    \n    98→    for _, item := range items {\n    99→        if err := processItem(item); err != nil {\n   100→            errs = append(errs, fmt.Errorf(\"item %v: %w\", item.ID, err))\n   101→        }\n   102→    }\n   103→    \n   104→    if len(errs) > 0 {\n   105→        return fmt.Errorf(\"multiple errors: %v\", errs)\n   106→    }\n   107→    \n   108→    return nil\n   109→}\n   110→\n   111→// First error wins\n   112→func firstErrorWins(tasks []func() error) error {\n   113→    for _, task := range tasks {\n   114→        if err := task(); err != nil {\n   115→            return err\n   116→        }\n   117→    }\n   118→    return nil\n   119→}\n   120→\n   121→// All errors matter\n   122→import \"golang.org/x/sync/errgroup\"\n   123→\n   124→func allErrorsMatter(ctx context.Context) error {\n   125→    g, ctx := errgroup.WithContext(ctx)\n   126→    \n   127→    g.Go(func() error {\n   128→        return task1(ctx)\n   129→    })\n   130→    \n   131→    g.Go(func() error {\n   132→        return task2(ctx)\n   133→    })\n   134→    \n   135→    g.Go(func() error {\n   136→        return task3(ctx)\n   137→    })\n   138→    \n   139→    return g.Wait() // Returns first error\n   140→}\n   141→```\n   142→\n   143→## Error Types\n   144→\n   145→### Implementing Error Types\n   146→```go\n   147→// Simple error type\n   148→type ValidationError struct {\n   149→    Field string\n   150→    Value interface{}\n   151→    Msg   string\n   152→}\n   153→\n   154→func (e ValidationError) Error() string {\n   155→    return fmt.Sprintf(\"validation failed for %s with value %v: %s\", \n   156→        e.Field, e.Value, e.Msg)\n   157→}\n   158→\n   159→// Error type with code\n   160→type APIError struct {\n   161→    Code    int\n   162→    Message string\n   163→    Details map[string]interface{}\n   164→}\n   165→\n   166→func (e APIError) Error() string {\n   167→    return fmt.Sprintf(\"API error %d: %s\", e.Code, e.Message)\n   168→}\n   169→\n   170→// Temporary error interface\n   171→type temporary interface {\n   172→    Temporary() bool\n   173→}\n   174→\n   175→type NetworkError struct {\n   176→    Op         string\n   177→    Err        error\n   178→    Temporary  bool\n   179→    Timeout    bool\n   180→}\n   181→\n   182→func (e NetworkError) Error() string {\n   183→    return fmt.Sprintf(\"network error during %s: %v\", e.Op, e.Err)\n   184→}\n   185→\n   186→func (e NetworkError) Unwrap() error {\n   187→    return e.Err\n   188→}\n   189→\n   190→func (e NetworkError) IsTemporary() bool {\n   191→    return e.Temporary\n   192→}\n   193→\n   194→func (e NetworkError) IsTimeout() bool {\n   195→    return e.Timeout\n   196→}\n   197→\n   198→// Rich error type\n   199→type RichError struct {\n   200→    Op         string                 // Operation\n   201→    Kind       ErrorKind              // Category\n   202→    Err        error                  // Wrapped error\n   203→    Severity   Severity               // Error severity\n   204→    Context    map[string]interface{} // Additional context\n   205→    StackTrace string                 // Stack trace\n   206→    Timestamp  time.Time              // When it occurred\n   207→}\n   208→\n   209→type ErrorKind int\n   210→\n   211→const (\n   212→    KindOther ErrorKind = iota\n   213→    KindInvalid\n   214→    KindPermission\n   215→    KindIO\n   216→    KindExist\n   217→    KindNotExist\n   218→    KindNetwork\n   219→)\n   220→\n   221→type Severity int\n   222→\n   223→const (\n   224→    SeverityLow Severity = iota\n   225→    SeverityMedium\n   226→    SeverityHigh\n   227→    SeverityCritical\n   228→)\n   229→\n   230→func (e *RichError) Error() string {\n   231→    var b strings.Builder\n   232→    b.WriteString(e.Op)\n   233→    b.WriteString(\": \")\n   234→    b.WriteString(e.Kind.String())\n   235→    if e.Err != nil {\n   236→        b.WriteString(\": \")\n   237→        b.WriteString(e.Err.Error())\n   238→    }\n   239→    return b.String()\n   240→}\n   241→\n   242→func (e *RichError) Unwrap() error {\n   243→    return e.Err\n   244→}\n   245→```\n   246→\n   247→### Structured Errors\n   248→```go\n   249→// Multi-error type\n   250→type MultiError struct {\n   251→    Errors []error\n   252→}\n   253→\n   254→func (m *MultiError) Error() string {\n   255→    var msgs []string\n   256→    for _, err := range m.Errors {\n   257→        msgs = append(msgs, err.Error())\n   258→    }\n   259→    return strings.Join(msgs, \"; \")\n   260→}\n   261→\n   262→func (m *MultiError) Add(err error) {\n   263→    if err != nil {\n   264→        m.Errors = append(m.Errors, err)\n   265→    }\n   266→}\n   267→\n   268→func (m *MultiError) HasErrors() bool {\n   269→    return len(m.Errors) > 0\n   270→}\n   271→\n   272→// Causal error chain\n   273→type CausalError struct {\n   274→    Op    string\n   275→    Cause error\n   276→}\n   277→\n   278→func (e *CausalError) Error() string {\n   279→    if e.Cause != nil {\n   280→        return fmt.Sprintf(\"%s: %v\", e.Op, e.Cause)\n   281→    }\n   282→    return e.Op\n   283→}\n   284→\n   285→func (e *CausalError) Unwrap() error {\n   286→    return e.Cause\n   287→}\n   288→\n   289→// HTTP error response\n   290→type HTTPError struct {\n   291→    Status  int         `json:\"status\"`\n   292→    Code    string      `json:\"code\"`\n   293→    Message string      `json:\"message\"`\n   294→    Details interface{} `json:\"details,omitempty\"`\n   295→    TraceID string      `json:\"trace_id,omitempty\"`\n   296→}\n   297→\n   298→func (e HTTPError) Error() string {\n   299→    return fmt.Sprintf(\"HTTP %d: %s\", e.Status, e.Message)\n   300→}\n   301→\n   302→func (e HTTPError) StatusCode() int {\n   303→    return e.Status\n   304→}\n   305→```\n   306→\n   307→## Error Wrapping\n   308→\n   309→### Wrapping with fmt.Errorf\n   310→```go\n   311→// Basic wrapping (Go 1.13+)\n   312→func readConfig(path string) (*Config, error) {\n   313→    data, err := os.ReadFile(path)\n   314→    if err != nil {\n   315→        return nil, fmt.Errorf(\"failed to read config file %s: %w\", path, err)\n   316→    }\n   317→    \n   318→    var config Config\n   319→    if err := json.Unmarshal(data, &config); err != nil {\n   320→        return nil, fmt.Errorf(\"failed to parse config: %w\", err)\n   321→    }\n   322→    \n   323→    return &config, nil\n   324→}\n   325→\n   326→// Multiple wrapping layers\n   327→func highlevel() error {\n   328→    if err := midlevel(); err != nil {\n   329→        return fmt.Errorf(\"highlevel failed: %w\", err)\n   330→    }\n   331→    return nil\n   332→}\n   333→\n   334→func midlevel() error {\n   335→    if err := lowlevel(); err != nil {\n   336→        return fmt.Errorf(\"midlevel failed: %w\", err)\n   337→    }\n   338→    return nil\n   339→}\n   340→\n   341→func lowlevel() error {\n   342→    return errors.New(\"disk full\")\n   343→}\n   344→\n   345→// Result: \"highlevel failed: midlevel failed: disk full\"\n   346→\n   347→// Wrapping with additional context\n   348→type contextError struct {\n   349→    op      string\n   350→    path    string\n   351→    user    string\n   352→    wrapped error\n   353→}\n   354→\n   355→func (e *contextError) Error() string {\n   356→    return fmt.Sprintf(\"op=%s path=%s user=%s: %v\", \n   357→        e.op, e.path, e.user, e.wrapped)\n   358→}\n   359→\n   360→func (e *contextError) Unwrap() error {\n   361→    return e.wrapped\n   362→}\n   363→\n   364→func wrapWithContext(op, path, user string, err error) error {\n   365→    if err == nil {\n   366→        return nil\n   367→    }\n   368→    return &contextError{\n   369→        op:      op,\n   370→        path:    path,\n   371→        user:    user,\n   372→        wrapped: err,\n   373→    }\n   374→}\n   375→```\n   376→\n   377→### Unwrapping Errors\n   378→```go\n   379→// Using errors.Is (Go 1.13+)\n   380→var ErrPermission = errors.New(\"permission denied\")\n   381→\n   382→func checkPermission() error {\n   383→    // Some checks...\n   384→    return fmt.Errorf(\"user %s: %w\", username, ErrPermission)\n   385→}\n   386→\n   387→func main() {\n   388→    err := checkPermission()\n   389→    if errors.Is(err, ErrPermission) {\n   390→        // Handle permission error\n   391→    }\n   392→}\n   393→\n   394→// Using errors.As (Go 1.13+)\n   395→type PathError struct {\n   396→    Op   string\n   397→    Path string\n   398→    Err  error\n   399→}\n   400→\n   401→func (e *PathError) Error() string {\n   402→    return fmt.Sprintf(\"%s %s: %v\", e.Op, e.Path, e.Err)\n   403→}\n   404→\n   405→func handleError(err error) {\n   406→    var pathErr *PathError\n   407→    if errors.As(err, &pathErr) {\n   408→        fmt.Printf(\"Path error: %s\\n\", pathErr.Path)\n   409→    }\n   410→}\n   411→\n   412→// Custom Is implementation\n   413→type MyError struct {\n   414→    Code string\n   415→    Msg  string\n   416→}\n   417→\n   418→func (e MyError) Error() string {\n   419→    return fmt.Sprintf(\"%s: %s\", e.Code, e.Msg)\n   420→}\n   421→\n   422→func (e MyError) Is(target error) bool {\n   423→    t, ok := target.(MyError)\n   424→    if !ok {\n   425→        return false\n   426→    }\n   427→    return e.Code == t.Code\n   428→}\n   429→\n   430→// Custom As implementation\n   431→func (e *MyError) As(target interface{}) bool {\n   432→    switch v := target.(type) {\n   433→    case **MyError:\n   434→        *v = e\n   435→        return true\n   436→    case *MyError:\n   437→        *v = *e\n   438→        return true\n   439→    default:\n   440→        return false\n   441→    }\n   442→}\n   443→```\n   444→\n   445→## Sentinel Errors\n   446→\n   447→### Defining Sentinel Errors\n   448→```go\n   449→// Package-level sentinel errors\n   450→package mypackage\n   451→\n   452→var (\n   453→    // ErrNotFound is returned when a requested resource is not found.\n   454→    ErrNotFound = errors.New(\"not found\")\n   455→    \n   456→    // ErrAlreadyExists is returned when attempting to create a resource that already exists.\n   457→    ErrAlreadyExists = errors.New(\"already exists\")\n   458→    \n   459→    // ErrInvalidInput is returned when input validation fails.\n   460→    ErrInvalidInput = errors.New(\"invalid input\")\n   461→    \n   462→    // ErrUnauthorized is returned when authentication fails.\n   463→    ErrUnauthorized = errors.New(\"unauthorized\")\n   464→    \n   465→    // ErrForbidden is returned when the user lacks permission.\n   466→    ErrForbidden = errors.New(\"forbidden\")\n   467→    \n   468→    // ErrTimeout is returned when an operation times out.\n   469→    ErrTimeout = errors.New(\"operation timeout\")\n   470→    \n   471→    // ErrCanceled is returned when an operation is canceled.\n   472→    ErrCanceled = errors.New(\"operation canceled\")\n   473→)\n   474→\n   475→// Using sentinel errors\n   476→func GetUser(id string) (*User, error) {\n   477→    user, err := db.Query(id)\n   478→    if err != nil {\n   479→        if errors.Is(err, sql.ErrNoRows) {\n   480→            return nil, ErrNotFound\n   481→        }\n   482→        return nil, fmt.Errorf(\"database query failed: %w\", err)\n   483→    }\n   484→    return user, nil\n   485→}\n   486→\n   487→// Checking sentinel errors\n   488→user, err := GetUser(id)\n   489→if err != nil {\n   490→    if errors.Is(err, ErrNotFound) {\n   491→        // Handle not found case\n   492→        return http.StatusNotFound\n   493→    }\n   494→    // Handle other errors\n   495→    return http.StatusInternalServerError\n   496→}\n   497→\n   498→// Sentinel errors with types\n   499→type NotFoundError struct {\n   500→    Resource string\n   501→    ID       string\n   502→}\n   503→\n   504→func (e NotFoundError) Error() string {\n   505→    return fmt.Sprintf(\"%s with ID %s not found\", e.Resource, e.ID)\n   506→}\n   507→\n   508→var errNotFoundSentinel = NotFoundError{}\n   509→\n   510→func (e NotFoundError) Is(target error) bool {\n   511→    _, ok := target.(NotFoundError)\n   512→    return ok\n   513→}\n   514→```\n   515→\n   516→### Sentinel Error Best Practices\n   517→```go\n   518→// DO: Export sentinel errors that callers need to check\n   519→var ErrInvalidFormat = errors.New(\"invalid format\")\n   520→\n   521→// DON'T: Export errors that are implementation details\n   522→var errInternalState = errors.New(\"internal state corrupted\") // unexported\n   523→\n   524→// DO: Use descriptive names\n   525→var ErrUserNotFound = errors.New(\"user not found\")\n   526→var ErrInsufficientFunds = errors.New(\"insufficient funds\")\n   527→\n   528→// DON'T: Use generic names\n   529→var ErrBad = errors.New(\"bad\")\n   530→var ErrFail = errors.New(\"fail\")\n   531→\n   532→// DO: Document sentinel errors\n   533→// ErrRateLimitExceeded is returned when the rate limit is exceeded.\n   534→// Callers should implement exponential backoff when receiving this error.\n   535→var ErrRateLimitExceeded = errors.New(\"rate limit exceeded\")\n   536→\n   537→// DO: Group related errors\n   538→var (\n   539→    // Database errors\n   540→    ErrDBConnection = errors.New(\"database connection failed\")\n   541→    ErrDBTimeout    = errors.New(\"database timeout\")\n   542→    ErrDBLocked     = errors.New(\"database locked\")\n   543→    \n   544→    // Validation errors\n   545→    ErrValidationFailed = errors.New(\"validation failed\")\n   546→    ErrMissingField     = errors.New(\"required field missing\")\n   547→    ErrInvalidFormat    = errors.New(\"invalid format\")\n   548→)\n   549→```\n   550→\n   551→## Custom Errors\n   552→\n   553→### Domain-Specific Errors\n   554→```go\n   555→// Business logic errors\n   556→type InsufficientFundsError struct {\n   557→    Account   string\n   558→    Available decimal.Decimal\n   559→    Required  decimal.Decimal\n   560→}\n   561→\n   562→func (e InsufficientFundsError) Error() string {\n   563→    return fmt.Sprintf(\"insufficient funds in account %s: available %s, required %s\",\n   564→        e.Account, e.Available, e.Required)\n   565→}\n   566→\n   567→// Validation errors\n   568→type ValidationErrors struct {\n   569→    Errors map[string][]string\n   570→}\n   571→\n   572→func (v ValidationErrors) Error() string {\n   573→    var msgs []string\n   574→    for field, errors := range v.Errors {\n   575→        msgs = append(msgs, fmt.Sprintf(\"%s: %s\", field, strings.Join(errors, \", \")))\n   576→    }\n   577→    return \"validation failed: \" + strings.Join(msgs, \"; \")\n   578→}\n   579→\n   580→func (v *ValidationErrors) Add(field, message string) {\n   581→    if v.Errors == nil {\n   582→        v.Errors = make(map[string][]string)\n   583→    }\n   584→    v.Errors[field] = append(v.Errors[field], message)\n   585→}\n   586→\n   587→func (v ValidationErrors) HasErrors() bool {\n   588→    return len(v.Errors) > 0\n   589→}\n   590→\n   591→// State machine errors\n   592→type StateTransitionError struct {\n   593→    From  State\n   594→    To    State\n   595→    Event Event\n   596→}\n   597→\n   598→func (e StateTransitionError) Error() string {\n   599→    return fmt.Sprintf(\"invalid state transition from %s to %s on event %s\",\n   600→        e.From, e.To, e.Event)\n   601→}\n   602→\n   603→// Configuration errors\n   604→type ConfigError struct {\n   605→    File    string\n   606→    Section string\n   607→    Key     string\n   608→    Value   interface{}\n   609→    Reason  string\n   610→}\n   611→\n   612→func (e ConfigError) Error() string {\n   613→    return fmt.Sprintf(\"config error in %s [%s] %s=%v: %s\",\n   614→        e.File, e.Section, e.Key, e.Value, e.Reason)\n   615→}\n   616→```\n   617→\n   618→### Error Builders\n   619→```go\n   620→// Fluent error builder\n   621→type ErrorBuilder struct {\n   622→    err      error\n   623→    code     string\n   624→    message  string\n   625→    details  map[string]interface{}\n   626→    wrapped  error\n   627→}\n   628→\n   629→func NewError() *ErrorBuilder {\n   630→    return &ErrorBuilder{\n   631→        details: make(map[string]interface{}),\n   632→    }\n   633→}\n   634→\n   635→func (b *ErrorBuilder) WithCode(code string) *ErrorBuilder {\n   636→    b.code = code\n   637→    return b\n   638→}\n   639→\n   640→func (b *ErrorBuilder) WithMessage(msg string) *ErrorBuilder {\n   641→    b.message = msg\n   642→    return b\n   643→}\n   644→\n   645→func (b *ErrorBuilder) WithDetail(key string, value interface{}) *ErrorBuilder {\n   646→    b.details[key] = value\n   647→    return b\n   648→}\n   649→\n   650→func (b *ErrorBuilder) Wrap(err error) *ErrorBuilder {\n   651→    b.wrapped = err\n   652→    return b\n   653→}\n   654→\n   655→func (b *ErrorBuilder) Build() error {\n   656→    return &builtError{\n   657→        code:    b.code,\n   658→        message: b.message,\n   659→        details: b.details,\n   660→        wrapped: b.wrapped,\n   661→    }\n   662→}\n   663→\n   664→type builtError struct {\n   665→    code    string\n   666→    message string\n   667→    details map[string]interface{}\n   668→    wrapped error\n   669→}\n   670→\n   671→func (e builtError) Error() string {\n   672→    if e.wrapped != nil {\n   673→        return fmt.Sprintf(\"[%s] %s: %v\", e.code, e.message, e.wrapped)\n   674→    }\n   675→    return fmt.Sprintf(\"[%s] %s\", e.code, e.message)\n   676→}\n   677→\n   678→func (e builtError) Unwrap() error {\n   679→    return e.wrapped\n   680→}\n   681→\n   682→// Usage\n   683→err := NewError().\n   684→    WithCode(\"VALIDATION_ERROR\").\n   685→    WithMessage(\"Invalid user input\").\n   686→    WithDetail(\"field\", \"email\").\n   687→    WithDetail(\"value\", userEmail).\n   688→    Wrap(originalErr).\n   689→    Build()\n   690→```\n   691→\n   692→## Error Design Patterns\n   693→\n   694→### Error Handler Pattern\n   695→```go\n   696→// Centralized error handler\n   697→type ErrorHandler interface {\n   698→    Handle(error) error\n   699→}\n   700→\n   701→type errorHandler struct {\n   702→    logger    Logger\n   703→    metrics   Metrics\n   704→    notifier  Notifier\n   705→}\n   706→\n   707→func (h *errorHandler) Handle(err error) error {\n   708→    // Log error\n   709→    h.logger.Error(\"error occurred\", \"error\", err)\n   710→    \n   711→    // Record metrics\n   712→    h.metrics.IncrementErrorCount(errorType(err))\n   713→    \n   714→    // Notify if critical\n   715→    if isCritical(err) {\n   716→        h.notifier.NotifyCritical(err)\n   717→    }\n   718→    \n   719→    // Transform for client\n   720→    return transformError(err)\n   721→}\n   722→\n   723→func errorType(err error) string {\n   724→    switch {\n   725→    case errors.Is(err, ErrNotFound):\n   726→        return \"not_found\"\n   727→    case errors.Is(err, ErrUnauthorized):\n   728→        return \"unauthorized\"\n   729→    default:\n   730→        return \"internal\"\n   731→    }\n   732→}\n   733→\n   734→func isCritical(err error) bool {\n   735→    var criticalErr CriticalError\n   736→    return errors.As(err, &criticalErr)\n   737→}\n   738→\n   739→func transformError(err error) error {\n   740→    // Hide internal details from client\n   741→    switch {\n   742→    case errors.Is(err, ErrNotFound):\n   743→        return NewHTTPError(404, \"Resource not found\")\n   744→    case errors.Is(err, ErrUnauthorized):\n   745→        return NewHTTPError(401, \"Unauthorized\")\n   746→    default:\n   747→        return NewHTTPError(500, \"Internal server error\")\n   748→    }\n   749→}\n   750→```\n   751→\n   752→### Result Type Pattern\n   753→```go\n   754→// Result type for explicit error handling\n   755→type Result[T any] struct {\n   756→    value T\n   757→    err   error\n   758→}\n   759→\n   760→func Ok[T any](value T) Result[T] {\n   761→    return Result[T]{value: value}\n   762→}\n   763→\n   764→func Err[T any](err error) Result[T] {\n   765→    return Result[T]{err: err}\n   766→}\n   767→\n   768→func (r Result[T]) IsOk() bool {\n   769→    return r.err == nil\n   770→}\n   771→\n   772→func (r Result[T]) IsErr() bool {\n   773→    return r.err != nil\n   774→}\n   775→\n   776→func (r Result[T]) Unwrap() (T, error) {\n   777→    return r.value, r.err\n   778→}\n   779→\n   780→func (r Result[T]) UnwrapOr(defaultValue T) T {\n   781→    if r.err != nil {\n   782→        return defaultValue\n   783→    }\n   784→    return r.value\n   785→}\n   786→\n   787→func (r Result[T]) Map(fn func(T) T) Result[T] {\n   788→    if r.err != nil {\n   789→        return r\n   790→    }\n   791→    return Ok(fn(r.value))\n   792→}\n   793→\n   794→// Usage\n   795→func divide(a, b float64) Result[float64] {\n   796→    if b == 0 {\n   797→        return Err[float64](errors.New(\"division by zero\"))\n   798→    }\n   799→    return Ok(a / b)\n   800→}\n   801→\n   802→result := divide(10, 2)\n   803→if result.IsOk() {\n   804→    value, _ := result.Unwrap()\n   805→    fmt.Println(value)\n   806→}\n   807→```\n   808→\n   809→### Error Recovery Pattern\n   810→```go\n   811→// Retry with exponential backoff\n   812→func retryWithBackoff(fn func() error, maxRetries int) error {\n   813→    var err error\n   814→    backoff := 100 * time.Millisecond\n   815→    \n   816→    for i := 0; i < maxRetries; i++ {\n   817→        err = fn()\n   818→        if err == nil {\n   819→            return nil\n   820→        }\n   821→        \n   822→        // Check if error is retryable\n   823→        if !isRetryable(err) {\n   824→            return err\n   825→        }\n   826→        \n   827→        if i < maxRetries-1 {\n   828→            time.Sleep(backoff)\n   829→            backoff *= 2\n   830→            if backoff > 10*time.Second {\n   831→                backoff = 10 * time.Second\n   832→            }\n   833→        }\n   834→    }\n   835→    \n   836→    return fmt.Errorf(\"failed after %d retries: %w\", maxRetries, err)\n   837→}\n   838→\n   839→func isRetryable(err error) bool {\n   840→    // Check for temporary errors\n   841→    var tempErr interface{ Temporary() bool }\n   842→    if errors.As(err, &tempErr) && tempErr.Temporary() {\n   843→        return true\n   844→    }\n   845→    \n   846→    // Check for specific retryable errors\n   847→    return errors.Is(err, ErrTimeout) || \n   848→           errors.Is(err, ErrRateLimited) ||\n   849→           errors.Is(err, ErrServiceUnavailable)\n   850→}\n   851→\n   852→// Circuit breaker pattern\n   853→type CircuitBreaker struct {\n   854→    mu           sync.RWMutex\n   855→    failureCount int\n   856→    lastFailTime time.Time\n   857→    state        string // \"closed\", \"open\", \"half-open\"\n   858→    threshold    int\n   859→    timeout      time.Duration\n   860→}\n   861→\n   862→func (cb *CircuitBreaker) Call(fn func() error) error {\n   863→    cb.mu.RLock()\n   864→    state := cb.state\n   865→    cb.mu.RUnlock()\n   866→    \n   867→    if state == \"open\" {\n   868→        cb.mu.RLock()\n   869→        if time.Since(cb.lastFailTime) > cb.timeout {\n   870→            cb.mu.RUnlock()\n   871→            cb.mu.Lock()\n   872→            cb.state = \"half-open\"\n   873→            cb.mu.Unlock()\n   874→        } else {\n   875→            cb.mu.RUnlock()\n   876→            return ErrCircuitBreakerOpen\n   877→        }\n   878→    }\n   879→    \n   880→    err := fn()\n   881→    \n   882→    cb.mu.Lock()\n   883→    defer cb.mu.Unlock()\n   884→    \n   885→    if err != nil {\n   886→        cb.failureCount++\n   887→        cb.lastFailTime = time.Now()\n   888→        \n   889→        if cb.failureCount >= cb.threshold {\n   890→            cb.state = \"open\"\n   891→        }\n   892→        return err\n   893→    }\n   894→    \n   895→    if cb.state == \"half-open\" {\n   896→        cb.state = \"closed\"\n   897→    }\n   898→    cb.failureCount = 0\n   899→    return nil\n   900→}\n   901→```\n   902→\n   903→## Panic and Recover\n   904→\n   905→### When to Panic\n   906→```go\n   907→// Panic for unrecoverable errors during initialization\n   908→func MustConnect(dsn string) *sql.DB {\n   909→    db, err := sql.Open(\"postgres\", dsn)\n   910→    if err != nil {\n   911→        panic(fmt.Sprintf(\"failed to connect to database: %v\", err))\n   912→    }\n   913→    return db\n   914→}\n   915→\n   916→// Panic for programming errors\n   917→func (s *Stack) Pop() interface{} {\n   918→    if len(s.items) == 0 {\n   919→        panic(\"pop from empty stack\") // Programming error\n   920→    }\n   921→    item := s.items[len(s.items)-1]\n   922→    s.items = s.items[:len(s.items)-1]\n   923→    return item\n   924→}\n   925→\n   926→// Panic for impossible conditions\n   927→func processValue(v interface{}) {\n   928→    switch v := v.(type) {\n   929→    case int:\n   930→        // handle int\n   931→    case string:\n   932→        // handle string\n   933→    default:\n   934→        panic(fmt.Sprintf(\"unexpected type %T\", v))\n   935→    }\n   936→}\n   937→\n   938→// DON'T panic for normal errors\n   939→func badExample(input string) {\n   940→    if input == \"\" {\n   941→        panic(\"input is empty\") // Bad! Use error return instead\n   942→    }\n   943→}\n   944→\n   945→func goodExample(input string) error {\n   946→    if input == \"\" {\n   947→        return errors.New(\"input is empty\")\n   948→    }\n   949→    return nil\n   950→}\n   951→```\n   952→\n   953→### Recover Pattern\n   954→```go\n   955→// Basic recover\n   956→func safeCall(fn func()) (err error) {\n   957→    defer func() {\n   958→        if r := recover(); r != nil {\n   959→            err = fmt.Errorf(\"panic recovered: %v\", r)\n   960→        }\n   961→    }()\n   962→    \n   963→    fn()\n   964→    return nil\n   965→}\n   966→\n   967→// Recover with stack trace\n   968→import \"runtime/debug\"\n   969→\n   970→func recoverWithStack() {\n   971→    if r := recover(); r != nil {\n   972→        log.Printf(\"Panic: %v\\nStack: %s\", r, debug.Stack())\n   973→    }\n   974→}\n   975→\n   976→// HTTP middleware with recover\n   977→func RecoverMiddleware(next http.Handler) http.Handler {\n   978→    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n   979→        defer func() {\n   980→            if err := recover(); err != nil {\n   981→                log.Printf(\"Panic in handler: %v\\nStack: %s\", err, debug.Stack())\n   982→                http.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n   983→            }\n   984→        }()\n   985→        \n   986→        next.ServeHTTP(w, r)\n   987→    })\n   988→}\n   989→\n   990→// Goroutine with recover\n   991→func SafeGo(fn func()) {\n   992→    go func() {\n   993→        defer func() {\n   994→            if r := recover(); r != nil {\n   995→                log.Printf(\"Panic in goroutine: %v\\nStack: %s\", r, debug.Stack())\n   996→            }\n   997→        }()\n   998→        \n   999→        fn()\n  1000→    }()\n  1001→}\n  1002→\n  1003→// Convert panic to error\n  1004→func callExternalLibrary() (err error) {\n  1005→    defer func() {\n  1006→        if r := recover(); r != nil {\n  1007→            err = fmt.Errorf(\"external library panicked: %v\", r)\n  1008→        }\n  1009→    }()\n  1010→    \n  1011→    // Call potentially panicking external code\n  1012→    externalLibrary.DangerousOperation()\n  1013→    \n  1014→    return nil\n  1015→}\n  1016→```\n  1017→\n  1018→## Error Handling Strategies\n  1019→\n  1020→### Fail Fast\n  1021→```go\n  1022→// Fail fast on critical errors\n  1023→func Initialize() error {\n  1024→    // Check prerequisites first\n  1025→    if err := checkDependencies(); err != nil {\n  1026→        return fmt.Errorf(\"dependency check failed: %w\", err)\n  1027→    }\n  1028→    \n  1029→    if err := validateConfig(); err != nil {\n  1030→        return fmt.Errorf(\"config validation failed: %w\", err)\n  1031→    }\n  1032→    \n  1033→    // Only proceed if everything is valid\n  1034→    return startServices()\n  1035→}\n  1036→\n  1037→// Validate early\n  1038→func ProcessRequest(req Request) error {\n  1039→    // Validate input immediately\n  1040→    if err := req.Validate(); err != nil {\n  1041→        return fmt.Errorf(\"invalid request: %w\", err)\n  1042→    }\n  1043→    \n  1044→    // Check permissions early\n  1045→    if err := checkPermissions(req.UserID); err != nil {\n  1046→        return fmt.Errorf(\"permission denied: %w\", err)\n  1047→    }\n  1048→    \n  1049→    // Process only after validation\n  1050→    return process(req)\n  1051→}\n  1052→```\n  1053→\n  1054→### Graceful Degradation\n  1055→```go\n  1056→// Fallback on error\n  1057→func GetUserPreferences(userID string) (*Preferences, error) {\n  1058→    // Try to get from cache\n  1059→    prefs, err := cache.Get(userID)\n  1060→    if err == nil {\n  1061→        return prefs, nil\n  1062→    }\n  1063→    \n  1064→    // Fallback to database\n  1065→    prefs, err = db.GetPreferences(userID)\n  1066→    if err == nil {\n  1067→        // Update cache for next time\n  1068→        go cache.Set(userID, prefs)\n  1069→        return prefs, nil\n  1070→    }\n  1071→    \n  1072→    // Return defaults if all fails\n  1073→    log.Printf(\"Failed to get preferences for %s: %v\", userID, err)\n  1074→    return DefaultPreferences(), nil\n  1075→}\n  1076→\n  1077→// Partial success\n  1078→func ProcessBatch(items []Item) error {\n  1079→    var successCount int\n  1080→    var errors []error\n  1081→    \n  1082→    for _, item := range items {\n  1083→        if err := processItem(item); err != nil {\n  1084→            errors = append(errors, fmt.Errorf(\"item %v: %w\", item.ID, err))\n  1085→            continue\n  1086→        }\n  1087→        successCount++\n  1088→    }\n  1089→    \n  1090→    if len(errors) > 0 {\n  1091→        log.Printf(\"Processed %d/%d items successfully\", successCount, len(items))\n  1092→        return &PartialError{\n  1093→            Successful: successCount,\n  1094→            Failed:     len(errors),\n  1095→            Errors:     errors,\n  1096→        }\n  1097→    }\n  1098→    \n  1099→    return nil\n  1100→}\n  1101→```\n  1102→\n  1103→### Error Aggregation\n  1104→```go\n  1105→// Collect all errors\n  1106→type ErrorCollector struct {\n  1107→    mu     sync.Mutex\n  1108→    errors []error\n  1109→}\n  1110→\n  1111→func (c *ErrorCollector) Add(err error) {\n  1112→    if err == nil {\n  1113→        return\n  1114→    }\n  1115→    \n  1116→    c.mu.Lock()\n  1117→    defer c.mu.Unlock()\n  1118→    c.errors = append(c.errors, err)\n  1119→}\n  1120→\n  1121→func (c *ErrorCollector) Error() error {\n  1122→    c.mu.Lock()\n  1123→    defer c.mu.Unlock()\n  1124→    \n  1125→    switch len(c.errors) {\n  1126→    case 0:\n  1127→        return nil\n  1128→    case 1:\n  1129→        return c.errors[0]\n  1130→    default:\n  1131→        return &MultiError{Errors: c.errors}\n  1132→    }\n  1133→}\n  1134→\n  1135→// Usage with goroutines\n  1136→func ProcessConcurrently(items []Item) error {\n  1137→    var wg sync.WaitGroup\n  1138→    collector := &ErrorCollector{}\n  1139→    \n  1140→    for _, item := range items {\n  1141→        wg.Add(1)\n  1142→        go func(i Item) {\n  1143→            defer wg.Done()\n  1144→            if err := processItem(i); err != nil {\n  1145→                collector.Add(fmt.Errorf(\"item %v: %w\", i.ID, err))\n  1146→            }\n  1147→        }(item)\n  1148→    }\n  1149→    \n  1150→    wg.Wait()\n  1151→    return collector.Error()\n  1152→}\n  1153→```\n  1154→\n  1155→## Testing Errors\n  1156→\n  1157→### Testing Error Cases\n  1158→```go\n  1159→func TestDivide(t *testing.T) {\n  1160→    tests := []struct {\n  1161→        name    string\n  1162→        a, b    float64\n  1163→        want    float64\n  1164→        wantErr bool\n  1165→        errMsg  string\n  1166→    }{\n  1167→        {\n  1168→            name: \"normal division\",\n  1169→            a:    10,\n  1170→            b:    2,\n  1171→            want: 5,\n  1172→        },\n  1173→        {\n  1174→            name:    \"divide by zero\",\n  1175→            a:       10,\n  1176→            b:       0,\n  1177→            wantErr: true,\n  1178→            errMsg:  \"division by zero\",\n  1179→        },\n  1180→    }\n  1181→    \n  1182→    for _, tt := range tests {\n  1183→        t.Run(tt.name, func(t *testing.T) {\n  1184→            got, err := Divide(tt.a, tt.b)\n  1185→            \n  1186→            if (err != nil) != tt.wantErr {\n  1187→                t.Errorf(\"Divide() error = %v, wantErr %v\", err, tt.wantErr)\n  1188→                return\n  1189→            }\n  1190→            \n  1191→            if tt.wantErr {\n  1192→                if !strings.Contains(err.Error(), tt.errMsg) {\n  1193→                    t.Errorf(\"Divide() error = %v, want error containing %v\", \n  1194→                        err, tt.errMsg)\n  1195→                }\n  1196→                return\n  1197→            }\n  1198→            \n  1199→            if got != tt.want {\n  1200→                t.Errorf(\"Divide() = %v, want %v\", got, tt.want)\n  1201→            }\n  1202→        })\n  1203→    }\n  1204→}\n  1205→\n  1206→// Testing sentinel errors\n  1207→func TestGetUser_NotFound(t *testing.T) {\n  1208→    repo := NewMockRepository()\n  1209→    repo.ReturnError = sql.ErrNoRows\n  1210→    \n  1211→    service := NewService(repo)\n  1212→    _, err := service.GetUser(\"123\")\n  1213→    \n  1214→    if !errors.Is(err, ErrNotFound) {\n  1215→        t.Errorf(\"expected ErrNotFound, got %v\", err)\n  1216→    }\n  1217→}\n  1218→\n  1219→// Testing error types\n  1220→func TestValidationError(t *testing.T) {\n  1221→    err := ValidateUser(User{})\n  1222→    \n  1223→    var validationErr ValidationError\n  1224→    if !errors.As(err, &validationErr) {\n  1225→        t.Fatalf(\"expected ValidationError, got %T\", err)\n  1226→    }\n  1227→    \n  1228→    if validationErr.Field != \"email\" {\n  1229→        t.Errorf(\"expected field 'email', got %s\", validationErr.Field)\n  1230→    }\n  1231→}\n  1232→\n  1233→// Testing error wrapping\n  1234→func TestErrorWrapping(t *testing.T) {\n  1235→    rootErr := errors.New(\"root cause\")\n  1236→    wrappedErr := fmt.Errorf(\"wrapped: %w\", rootErr)\n  1237→    \n  1238→    if !errors.Is(wrappedErr, rootErr) {\n  1239→        t.Error(\"expected wrapped error to contain root cause\")\n  1240→    }\n  1241→}\n  1242→```\n  1243→\n  1244→### Mocking Errors\n  1245→```go\n  1246→// Error injection for testing\n  1247→type ErrorInjector struct {\n  1248→    errors map[string]error\n  1249→    calls  map[string]int\n  1250→}\n  1251→\n  1252→func (e *ErrorInjector) ShouldFail(operation string) error {\n  1253→    e.calls[operation]++\n  1254→    \n  1255→    if err, ok := e.errors[operation]; ok {\n  1256→        // Return error on specific call count\n  1257→        if callErr, ok := err.(*CallCountError); ok {\n  1258→            if e.calls[operation] == callErr.OnCall {\n  1259→                return callErr.Err\n  1260→            }\n  1261→            return nil\n  1262→        }\n  1263→        return err\n  1264→    }\n  1265→    \n  1266→    return nil\n  1267→}\n  1268→\n  1269→type CallCountError struct {\n  1270→    OnCall int\n  1271→    Err    error\n  1272→}\n  1273→\n  1274→// Usage in tests\n  1275→func TestRetry(t *testing.T) {\n  1276→    injector := &ErrorInjector{\n  1277→        errors: map[string]error{\n  1278→            \"connect\": &CallCountError{\n  1279→                OnCall: 1, // Fail on first call\n  1280→                Err:    errors.New(\"connection failed\"),\n  1281→            },\n  1282→        },\n  1283→        calls: make(map[string]int),\n  1284→    }\n  1285→    \n  1286→    service := NewService(injector)\n  1287→    err := service.ConnectWithRetry()\n  1288→    \n  1289→    if err != nil {\n  1290→        t.Errorf(\"expected success after retry, got %v\", err)\n  1291→    }\n  1292→    \n  1293→    if injector.calls[\"connect\"] != 2 {\n  1294→        t.Errorf(\"expected 2 connection attempts, got %d\", \n  1295→            injector.calls[\"connect\"])\n  1296→    }\n  1297→}\n  1298→```\n  1299→\n  1300→## Best Practices\n  1301→\n  1302→### Error Design Guidelines\n  1303→```go\n  1304→// 1. Return error as last value\n  1305→func Good() (Result, error)\n  1306→func Bad() (error, Result)  // Don't do this\n  1307→\n  1308→// 2. Check errors immediately\n  1309→result, err := doSomething()\n  1310→if err != nil {\n  1311→    return err\n  1312→}\n  1313→\n  1314→// 3. Add context when wrapping\n  1315→if err != nil {\n  1316→    return fmt.Errorf(\"failed to process user %s: %w\", userID, err)\n  1317→}\n  1318→\n  1319→// 4. Use sentinel errors for known conditions\n  1320→var ErrNotFound = errors.New(\"not found\")\n  1321→\n  1322→// 5. Create specific error types for rich information\n  1323→type ValidationError struct {\n  1324→    Field string\n  1325→    Value interface{}\n  1326→}\n  1327→\n  1328→// 6. Don't ignore errors\n  1329→_ = os.Remove(tempFile)  // Bad\n  1330→if err := os.Remove(tempFile); err != nil {\n  1331→    log.Printf(\"failed to remove temp file: %v\", err)\n  1332→}\n  1333→\n  1334→// 7. Handle errors once\n  1335→// Don't log AND return - let caller decide\n  1336→\n  1337→// 8. Use errors.Is and errors.As for checking\n  1338→if errors.Is(err, ErrNotFound) { }\n  1339→var validErr ValidationError\n  1340→if errors.As(err, &validErr) { }\n  1341→\n  1342→// 9. Keep error messages lowercase\n  1343→errors.New(\"not found\")  // Good\n  1344→errors.New(\"Not Found\")  // Bad\n  1345→\n  1346→// 10. Include relevant context\n  1347→fmt.Errorf(\"user %s: %w\", userID, err)  // Good\n  1348→fmt.Errorf(\"error: %w\", err)  // Too generic\n  1349→```\n  1350→\n  1351→### Common Pitfalls\n  1352→```go\n  1353→// Shadowing err variable\n  1354→err := doFirst()\n  1355→if err != nil {\n  1356→    err := doSecond()  // Shadows outer err!\n  1357→    if err != nil {\n  1358→        return err\n  1359→    }\n  1360→}\n  1361→\n  1362→// Checking wrong error\n  1363→result, err := doSomething()\n  1364→if err != nil {\n  1365→    anotherResult, err := doAnother()  // Reuses err\n  1366→    if err != nil {  // Might be checking wrong error\n  1367→        return err\n  1368→    }\n  1369→}\n  1370→\n  1371→// Nil interface gotcha\n  1372→func returnsError() error {\n  1373→    var err *MyError  // nil pointer\n  1374→    return err        // Returns non-nil error interface!\n  1375→}\n  1376→\n  1377→// Fix:\n  1378→func returnsError() error {\n  1379→    var err *MyError\n  1380→    if someCondition {\n  1381→        err = &MyError{}\n  1382→    }\n  1383→    if err != nil {\n  1384→        return err\n  1385→    }\n  1386→    return nil  // Explicitly return nil\n  1387→}\n  1388→```\n  1389→\n  1390→## Best Practices Summary\n  1391→\n  1392→1. **Always check errors** - Never ignore returned errors\n  1393→2. **Add context when wrapping** - Help debugging with good messages\n  1394→3. **Use sentinel errors wisely** - For known, actionable conditions\n  1395→4. **Create custom error types** - When you need rich error information\n  1396→5. **Fail fast** - Return early on errors\n  1397→6. **Don't panic** - Reserve for truly exceptional cases\n  1398→7. **Test error paths** - Ensure error handling works correctly\n  1399→8. **Use errors.Is/As** - For robust error checking\n  1400→9. **Keep errors actionable** - Help users understand what went wrong\n  1401→10. **Document error behavior** - Specify what errors functions can return\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"da72b4b3-807c-4ec8-961e-2046ec58ff7a","timestamp":"2025-08-13T09:58:56.643Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/errors.md","content":"# Go Error Handling - Excellence in Error Management\n\n## Table of Contents\n1. [Error Basics](#error-basics)\n2. [Error Types](#error-types)\n3. [Error Wrapping](#error-wrapping)\n4. [Sentinel Errors](#sentinel-errors)\n5. [Custom Errors](#custom-errors)\n6. [Error Design Patterns](#error-design-patterns)\n7. [Panic and Recover](#panic-and-recover)\n8. [Error Handling Strategies](#error-handling-strategies)\n9. [Testing Errors](#testing-errors)\n10. [Best Practices](#best-practices)\n\n## Error Basics\n\n### The Error Interface\n```go\n// Built-in error interface\ntype error interface {\n    Error() string\n}\n\n// Basic error creation\nimport \"errors\"\n\nerr := errors.New(\"something went wrong\")\n\n// Formatted errors\nerr := fmt.Errorf(\"failed to process item %d: %s\", id, reason)\n\n// Checking errors\nresult, err := doSomething()\nif err != nil {\n    // Handle error\n    return err\n}\n\n// Multiple return values with error\nfunc divide(a, b float64) (float64, error) {\n    if b == 0 {\n        return 0, errors.New(\"division by zero\")\n    }\n    return a / b, nil\n}\n\n// Named returns with error\nfunc readFile(path string) (data []byte, err error) {\n    data, err = os.ReadFile(path)\n    if err != nil {\n        return nil, err // Explicit return preferred\n    }\n    return data, nil\n}\n\n// Defer with error handling\nfunc writeFile(path string, data []byte) (err error) {\n    f, err := os.Create(path)\n    if err != nil {\n        return err\n    }\n    defer func() {\n        if cerr := f.Close(); cerr != nil && err == nil {\n            err = cerr // Capture close error if no other error\n        }\n    }()\n    \n    _, err = f.Write(data)\n    return err\n}\n```\n\n### Error Checking Patterns\n```go\n// Immediate return pattern\nif err := doSomething(); err != nil {\n    return fmt.Errorf(\"doSomething failed: %w\", err)\n}\n\n// Guard clause pattern\nfunc process(input string) error {\n    if input == \"\" {\n        return errors.New(\"input cannot be empty\")\n    }\n    \n    if len(input) > 100 {\n        return errors.New(\"input too long\")\n    }\n    \n    // Main logic here\n    return nil\n}\n\n// Error accumulation\nfunc processMultiple(items []Item) error {\n    var errs []error\n    \n    for _, item := range items {\n        if err := processItem(item); err != nil {\n            errs = append(errs, fmt.Errorf(\"item %v: %w\", item.ID, err))\n        }\n    }\n    \n    if len(errs) > 0 {\n        return fmt.Errorf(\"multiple errors: %v\", errs)\n    }\n    \n    return nil\n}\n\n// First error wins\nfunc firstErrorWins(tasks []func() error) error {\n    for _, task := range tasks {\n        if err := task(); err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\n// All errors matter\nimport \"golang.org/x/sync/errgroup\"\n\nfunc allErrorsMatter(ctx context.Context) error {\n    g, ctx := errgroup.WithContext(ctx)\n    \n    g.Go(func() error {\n        return task1(ctx)\n    })\n    \n    g.Go(func() error {\n        return task2(ctx)\n    })\n    \n    g.Go(func() error {\n        return task3(ctx)\n    })\n    \n    return g.Wait() // Returns first error\n}\n```\n\n## Error Types\n\n### Implementing Error Types\n```go\n// Simple error type\ntype ValidationError struct {\n    Field string\n    Value interface{}\n    Msg   string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"validation failed for %s with value %v: %s\", \n        e.Field, e.Value, e.Msg)\n}\n\n// Error type with code\ntype APIError struct {\n    Code    int\n    Message string\n    Details map[string]interface{}\n}\n\nfunc (e APIError) Error() string {\n    return fmt.Sprintf(\"API error %d: %s\", e.Code, e.Message)\n}\n\n// Temporary error interface\ntype temporary interface {\n    Temporary() bool\n}\n\ntype NetworkError struct {\n    Op         string\n    Err        error\n    Temporary  bool\n    Timeout    bool\n}\n\nfunc (e NetworkError) Error() string {\n    return fmt.Sprintf(\"network error during %s: %v\", e.Op, e.Err)\n}\n\nfunc (e NetworkError) Unwrap() error {\n    return e.Err\n}\n\nfunc (e NetworkError) IsTemporary() bool {\n    return e.Temporary\n}\n\nfunc (e NetworkError) IsTimeout() bool {\n    return e.Timeout\n}\n\n// Rich error type\ntype RichError struct {\n    Op         string                 // Operation\n    Kind       ErrorKind              // Category\n    Err        error                  // Wrapped error\n    Severity   Severity               // Error severity\n    Context    map[string]interface{} // Additional context\n    StackTrace string                 // Stack trace\n    Timestamp  time.Time              // When it occurred\n}\n\ntype ErrorKind int\n\nconst (\n    KindOther ErrorKind = iota\n    KindInvalid\n    KindPermission\n    KindIO\n    KindExist\n    KindNotExist\n    KindNetwork\n)\n\ntype Severity int\n\nconst (\n    SeverityLow Severity = iota\n    SeverityMedium\n    SeverityHigh\n    SeverityCritical\n)\n\nfunc (e *RichError) Error() string {\n    var b strings.Builder\n    b.WriteString(e.Op)\n    b.WriteString(\": \")\n    b.WriteString(e.Kind.String())\n    if e.Err != nil {\n        b.WriteString(\": \")\n        b.WriteString(e.Err.Error())\n    }\n    return b.String()\n}\n\nfunc (e *RichError) Unwrap() error {\n    return e.Err\n}\n```\n\n### Structured Errors\n```go\n// Multi-error type\ntype MultiError struct {\n    Errors []error\n}\n\nfunc (m *MultiError) Error() string {\n    var msgs []string\n    for _, err := range m.Errors {\n        msgs = append(msgs, err.Error())\n    }\n    return strings.Join(msgs, \"; \")\n}\n\nfunc (m *MultiError) Add(err error) {\n    if err != nil {\n        m.Errors = append(m.Errors, err)\n    }\n}\n\nfunc (m *MultiError) HasErrors() bool {\n    return len(m.Errors) > 0\n}\n\n// Causal error chain\ntype CausalError struct {\n    Op    string\n    Cause error\n}\n\nfunc (e *CausalError) Error() string {\n    if e.Cause != nil {\n        return fmt.Sprintf(\"%s: %v\", e.Op, e.Cause)\n    }\n    return e.Op\n}\n\nfunc (e *CausalError) Unwrap() error {\n    return e.Cause\n}\n\n// HTTP error response\ntype HTTPError struct {\n    Status  int         `json:\"status\"`\n    Code    string      `json:\"code\"`\n    Message string      `json:\"message\"`\n    Details interface{} `json:\"details,omitempty\"`\n    TraceID string      `json:\"trace_id,omitempty\"`\n}\n\nfunc (e HTTPError) Error() string {\n    return fmt.Sprintf(\"HTTP %d: %s\", e.Status, e.Message)\n}\n\nfunc (e HTTPError) StatusCode() int {\n    return e.Status\n}\n```\n\n## Error Wrapping\n\n### Wrapping with fmt.Errorf\n```go\n// Basic wrapping (Go 1.13+)\nfunc readConfig(path string) (*Config, error) {\n    data, err := os.ReadFile(path)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to read config file %s: %w\", path, err)\n    }\n    \n    var config Config\n    if err := json.Unmarshal(data, &config); err != nil {\n        return nil, fmt.Errorf(\"failed to parse config: %w\", err)\n    }\n    \n    return &config, nil\n}\n\n// Multiple wrapping layers\nfunc highlevel() error {\n    if err := midlevel(); err != nil {\n        return fmt.Errorf(\"highlevel failed: %w\", err)\n    }\n    return nil\n}\n\nfunc midlevel() error {\n    if err := lowlevel(); err != nil {\n        return fmt.Errorf(\"midlevel failed: %w\", err)\n    }\n    return nil\n}\n\nfunc lowlevel() error {\n    return errors.New(\"disk full\")\n}\n\n// Result: \"highlevel failed: midlevel failed: disk full\"\n\n// Wrapping with additional context\ntype contextError struct {\n    op      string\n    path    string\n    user    string\n    wrapped error\n}\n\nfunc (e *contextError) Error() string {\n    return fmt.Sprintf(\"op=%s path=%s user=%s: %v\", \n        e.op, e.path, e.user, e.wrapped)\n}\n\nfunc (e *contextError) Unwrap() error {\n    return e.wrapped\n}\n\nfunc wrapWithContext(op, path, user string, err error) error {\n    if err == nil {\n        return nil\n    }\n    return &contextError{\n        op:      op,\n        path:    path,\n        user:    user,\n        wrapped: err,\n    }\n}\n```\n\n### Unwrapping Errors\n```go\n// Using errors.Is (Go 1.13+)\nvar ErrPermission = errors.New(\"permission denied\")\n\nfunc checkPermission() error {\n    // Some checks...\n    return fmt.Errorf(\"user %s: %w\", username, ErrPermission)\n}\n\nfunc main() {\n    err := checkPermission()\n    if errors.Is(err, ErrPermission) {\n        // Handle permission error\n    }\n}\n\n// Using errors.As (Go 1.13+)\ntype PathError struct {\n    Op   string\n    Path string\n    Err  error\n}\n\nfunc (e *PathError) Error() string {\n    return fmt.Sprintf(\"%s %s: %v\", e.Op, e.Path, e.Err)\n}\n\nfunc handleError(err error) {\n    var pathErr *PathError\n    if errors.As(err, &pathErr) {\n        fmt.Printf(\"Path error: %s\\n\", pathErr.Path)\n    }\n}\n\n// Custom Is implementation\ntype MyError struct {\n    Code string\n    Msg  string\n}\n\nfunc (e MyError) Error() string {\n    return fmt.Sprintf(\"%s: %s\", e.Code, e.Msg)\n}\n\nfunc (e MyError) Is(target error) bool {\n    t, ok := target.(MyError)\n    if !ok {\n        return false\n    }\n    return e.Code == t.Code\n}\n\n// Custom As implementation\nfunc (e *MyError) As(target interface{}) bool {\n    switch v := target.(type) {\n    case **MyError:\n        *v = e\n        return true\n    case *MyError:\n        *v = *e\n        return true\n    default:\n        return false\n    }\n}\n```\n\n## Sentinel Errors\n\n### Defining Sentinel Errors\n```go\n// Package-level sentinel errors\npackage mypackage\n\nvar (\n    // ErrNotFound is returned when a requested resource is not found.\n    ErrNotFound = errors.New(\"not found\")\n    \n    // ErrAlreadyExists is returned when attempting to create a resource that already exists.\n    ErrAlreadyExists = errors.New(\"already exists\")\n    \n    // ErrInvalidInput is returned when input validation fails.\n    ErrInvalidInput = errors.New(\"invalid input\")\n    \n    // ErrUnauthorized is returned when authentication fails.\n    ErrUnauthorized = errors.New(\"unauthorized\")\n    \n    // ErrForbidden is returned when the user lacks permission.\n    ErrForbidden = errors.New(\"forbidden\")\n    \n    // ErrTimeout is returned when an operation times out.\n    ErrTimeout = errors.New(\"operation timeout\")\n    \n    // ErrCanceled is returned when an operation is canceled.\n    ErrCanceled = errors.New(\"operation canceled\")\n)\n\n// Using sentinel errors\nfunc GetUser(id string) (*User, error) {\n    user, err := db.Query(id)\n    if err != nil {\n        if errors.Is(err, sql.ErrNoRows) {\n            return nil, ErrNotFound\n        }\n        return nil, fmt.Errorf(\"database query failed: %w\", err)\n    }\n    return user, nil\n}\n\n// Checking sentinel errors\nuser, err := GetUser(id)\nif err != nil {\n    if errors.Is(err, ErrNotFound) {\n        // Handle not found case\n        return http.StatusNotFound\n    }\n    // Handle other errors\n    return http.StatusInternalServerError\n}\n\n// Sentinel errors with types\ntype NotFoundError struct {\n    Resource string\n    ID       string\n}\n\nfunc (e NotFoundError) Error() string {\n    return fmt.Sprintf(\"%s with ID %s not found\", e.Resource, e.ID)\n}\n\nvar errNotFoundSentinel = NotFoundError{}\n\nfunc (e NotFoundError) Is(target error) bool {\n    _, ok := target.(NotFoundError)\n    return ok\n}\n```\n\n### Sentinel Error Best Practices\n```go\n// DO: Export sentinel errors that callers need to check\nvar ErrInvalidFormat = errors.New(\"invalid format\")\n\n// DON'T: Export errors that are implementation details\nvar errInternalState = errors.New(\"internal state corrupted\") // unexported\n\n// DO: Use descriptive names\nvar ErrUserNotFound = errors.New(\"user not found\")\nvar ErrInsufficientFunds = errors.New(\"insufficient funds\")\n\n// DON'T: Use generic names\nvar ErrBad = errors.New(\"bad\")\nvar ErrFail = errors.New(\"fail\")\n\n// DO: Document sentinel errors\n// ErrRateLimitExceeded is returned when the rate limit is exceeded.\n// Callers should implement exponential backoff when receiving this error.\nvar ErrRateLimitExceeded = errors.New(\"rate limit exceeded\")\n\n// DO: Group related errors\nvar (\n    // Database errors\n    ErrDBConnection = errors.New(\"database connection failed\")\n    ErrDBTimeout    = errors.New(\"database timeout\")\n    ErrDBLocked     = errors.New(\"database locked\")\n    \n    // Validation errors\n    ErrValidationFailed = errors.New(\"validation failed\")\n    ErrMissingField     = errors.New(\"required field missing\")\n    ErrInvalidFormat    = errors.New(\"invalid format\")\n)\n```\n\n## Custom Errors\n\n### Domain-Specific Errors\n```go\n// Business logic errors\ntype InsufficientFundsError struct {\n    Account   string\n    Available decimal.Decimal\n    Required  decimal.Decimal\n}\n\nfunc (e InsufficientFundsError) Error() string {\n    return fmt.Sprintf(\"insufficient funds in account %s: available %s, required %s\",\n        e.Account, e.Available, e.Required)\n}\n\n// Validation errors\ntype ValidationErrors struct {\n    Errors map[string][]string\n}\n\nfunc (v ValidationErrors) Error() string {\n    var msgs []string\n    for field, errors := range v.Errors {\n        msgs = append(msgs, fmt.Sprintf(\"%s: %s\", field, strings.Join(errors, \", \")))\n    }\n    return \"validation failed: \" + strings.Join(msgs, \"; \")\n}\n\nfunc (v *ValidationErrors) Add(field, message string) {\n    if v.Errors == nil {\n        v.Errors = make(map[string][]string)\n    }\n    v.Errors[field] = append(v.Errors[field], message)\n}\n\nfunc (v ValidationErrors) HasErrors() bool {\n    return len(v.Errors) > 0\n}\n\n// State machine errors\ntype StateTransitionError struct {\n    From  State\n    To    State\n    Event Event\n}\n\nfunc (e StateTransitionError) Error() string {\n    return fmt.Sprintf(\"invalid state transition from %s to %s on event %s\",\n        e.From, e.To, e.Event)\n}\n\n// Configuration errors\ntype ConfigError struct {\n    File    string\n    Section string\n    Key     string\n    Value   interface{}\n    Reason  string\n}\n\nfunc (e ConfigError) Error() string {\n    return fmt.Sprintf(\"config error in %s [%s] %s=%v: %s\",\n        e.File, e.Section, e.Key, e.Value, e.Reason)\n}\n```\n\n### Error Builders\n```go\n// Fluent error builder\ntype ErrorBuilder struct {\n    err      error\n    code     string\n    message  string\n    details  map[string]interface{}\n    wrapped  error\n}\n\nfunc NewError() *ErrorBuilder {\n    return &ErrorBuilder{\n        details: make(map[string]interface{}),\n    }\n}\n\nfunc (b *ErrorBuilder) WithCode(code string) *ErrorBuilder {\n    b.code = code\n    return b\n}\n\nfunc (b *ErrorBuilder) WithMessage(msg string) *ErrorBuilder {\n    b.message = msg\n    return b\n}\n\nfunc (b *ErrorBuilder) WithDetail(key string, value interface{}) *ErrorBuilder {\n    b.details[key] = value\n    return b\n}\n\nfunc (b *ErrorBuilder) Wrap(err error) *ErrorBuilder {\n    b.wrapped = err\n    return b\n}\n\nfunc (b *ErrorBuilder) Build() error {\n    return &builtError{\n        code:    b.code,\n        message: b.message,\n        details: b.details,\n        wrapped: b.wrapped,\n    }\n}\n\ntype builtError struct {\n    code    string\n    message string\n    details map[string]interface{}\n    wrapped error\n}\n\nfunc (e builtError) Error() string {\n    if e.wrapped != nil {\n        return fmt.Sprintf(\"[%s] %s: %v\", e.code, e.message, e.wrapped)\n    }\n    return fmt.Sprintf(\"[%s] %s\", e.code, e.message)\n}\n\nfunc (e builtError) Unwrap() error {\n    return e.wrapped\n}\n\n// Usage\nerr := NewError().\n    WithCode(\"VALIDATION_ERROR\").\n    WithMessage(\"Invalid user input\").\n    WithDetail(\"field\", \"email\").\n    WithDetail(\"value\", userEmail).\n    Wrap(originalErr).\n    Build()\n```\n\n## Error Design Patterns\n\n### Error Handler Pattern\n```go\n// Centralized error handler\ntype ErrorHandler interface {\n    Handle(error) error\n}\n\ntype errorHandler struct {\n    logger    Logger\n    metrics   Metrics\n    notifier  Notifier\n}\n\nfunc (h *errorHandler) Handle(err error) error {\n    // Log error\n    h.logger.Error(\"error occurred\", \"error\", err)\n    \n    // Record metrics\n    h.metrics.IncrementErrorCount(errorType(err))\n    \n    // Notify if critical\n    if isCritical(err) {\n        h.notifier.NotifyCritical(err)\n    }\n    \n    // Transform for client\n    return transformError(err)\n}\n\nfunc errorType(err error) string {\n    switch {\n    case errors.Is(err, ErrNotFound):\n        return \"not_found\"\n    case errors.Is(err, ErrUnauthorized):\n        return \"unauthorized\"\n    default:\n        return \"internal\"\n    }\n}\n\nfunc isCritical(err error) bool {\n    var criticalErr CriticalError\n    return errors.As(err, &criticalErr)\n}\n\nfunc transformError(err error) error {\n    // Hide internal details from client\n    switch {\n    case errors.Is(err, ErrNotFound):\n        return NewHTTPError(404, \"Resource not found\")\n    case errors.Is(err, ErrUnauthorized):\n        return NewHTTPError(401, \"Unauthorized\")\n    default:\n        return NewHTTPError(500, \"Internal server error\")\n    }\n}\n```\n\n### Result Type Pattern\n```go\n// Result type for explicit error handling\ntype Result[T any] struct {\n    value T\n    err   error\n}\n\nfunc Ok[T any](value T) Result[T] {\n    return Result[T]{value: value}\n}\n\nfunc Err[T any](err error) Result[T] {\n    return Result[T]{err: err}\n}\n\nfunc (r Result[T]) IsOk() bool {\n    return r.err == nil\n}\n\nfunc (r Result[T]) IsErr() bool {\n    return r.err != nil\n}\n\nfunc (r Result[T]) Unwrap() (T, error) {\n    return r.value, r.err\n}\n\nfunc (r Result[T]) UnwrapOr(defaultValue T) T {\n    if r.err != nil {\n        return defaultValue\n    }\n    return r.value\n}\n\nfunc (r Result[T]) Map(fn func(T) T) Result[T] {\n    if r.err != nil {\n        return r\n    }\n    return Ok(fn(r.value))\n}\n\n// Usage\nfunc divide(a, b float64) Result[float64] {\n    if b == 0 {\n        return Err[float64](errors.New(\"division by zero\"))\n    }\n    return Ok(a / b)\n}\n\nresult := divide(10, 2)\nif result.IsOk() {\n    value, _ := result.Unwrap()\n    fmt.Println(value)\n}\n```\n\n### Error Recovery Pattern\n```go\n// Retry with exponential backoff\nfunc retryWithBackoff(fn func() error, maxRetries int) error {\n    var err error\n    backoff := 100 * time.Millisecond\n    \n    for i := 0; i < maxRetries; i++ {\n        err = fn()\n        if err == nil {\n            return nil\n        }\n        \n        // Check if error is retryable\n        if !isRetryable(err) {\n            return err\n        }\n        \n        if i < maxRetries-1 {\n            time.Sleep(backoff)\n            backoff *= 2\n            if backoff > 10*time.Second {\n                backoff = 10 * time.Second\n            }\n        }\n    }\n    \n    return fmt.Errorf(\"failed after %d retries: %w\", maxRetries, err)\n}\n\nfunc isRetryable(err error) bool {\n    // Check for temporary errors\n    var tempErr interface{ Temporary() bool }\n    if errors.As(err, &tempErr) && tempErr.Temporary() {\n        return true\n    }\n    \n    // Check for specific retryable errors\n    return errors.Is(err, ErrTimeout) || \n           errors.Is(err, ErrRateLimited) ||\n           errors.Is(err, ErrServiceUnavailable)\n}\n\n// Circuit breaker pattern\ntype CircuitBreaker struct {\n    mu           sync.RWMutex\n    failureCount int\n    lastFailTime time.Time\n    state        string // \"closed\", \"open\", \"half-open\"\n    threshold    int\n    timeout      time.Duration\n}\n\nfunc (cb *CircuitBreaker) Call(fn func() error) error {\n    cb.mu.RLock()\n    state := cb.state\n    cb.mu.RUnlock()\n    \n    if state == \"open\" {\n        cb.mu.RLock()\n        if time.Since(cb.lastFailTime) > cb.timeout {\n            cb.mu.RUnlock()\n            cb.mu.Lock()\n            cb.state = \"half-open\"\n            cb.mu.Unlock()\n        } else {\n            cb.mu.RUnlock()\n            return ErrCircuitBreakerOpen\n        }\n    }\n    \n    err := fn()\n    \n    cb.mu.Lock()\n    defer cb.mu.Unlock()\n    \n    if err != nil {\n        cb.failureCount++\n        cb.lastFailTime = time.Now()\n        \n        if cb.failureCount >= cb.threshold {\n            cb.state = \"open\"\n        }\n        return err\n    }\n    \n    if cb.state == \"half-open\" {\n        cb.state = \"closed\"\n    }\n    cb.failureCount = 0\n    return nil\n}\n```\n\n## Panic and Recover\n\n### When to Panic\n```go\n// Panic for unrecoverable errors during initialization\nfunc MustConnect(dsn string) *sql.DB {\n    db, err := sql.Open(\"postgres\", dsn)\n    if err != nil {\n        panic(fmt.Sprintf(\"failed to connect to database: %v\", err))\n    }\n    return db\n}\n\n// Panic for programming errors\nfunc (s *Stack) Pop() interface{} {\n    if len(s.items) == 0 {\n        panic(\"pop from empty stack\") // Programming error\n    }\n    item := s.items[len(s.items)-1]\n    s.items = s.items[:len(s.items)-1]\n    return item\n}\n\n// Panic for impossible conditions\nfunc processValue(v interface{}) {\n    switch v := v.(type) {\n    case int:\n        // handle int\n    case string:\n        // handle string\n    default:\n        panic(fmt.Sprintf(\"unexpected type %T\", v))\n    }\n}\n\n// DON'T panic for normal errors\nfunc badExample(input string) {\n    if input == \"\" {\n        panic(\"input is empty\") // Bad! Use error return instead\n    }\n}\n\nfunc goodExample(input string) error {\n    if input == \"\" {\n        return errors.New(\"input is empty\")\n    }\n    return nil\n}\n```\n\n### Recover Pattern\n```go\n// Basic recover\nfunc safeCall(fn func()) (err error) {\n    defer func() {\n        if r := recover(); r != nil {\n            err = fmt.Errorf(\"panic recovered: %v\", r)\n        }\n    }()\n    \n    fn()\n    return nil\n}\n\n// Recover with stack trace\nimport \"runtime/debug\"\n\nfunc recoverWithStack() {\n    if r := recover(); r != nil {\n        log.Printf(\"Panic: %v\\nStack: %s\", r, debug.Stack())\n    }\n}\n\n// HTTP middleware with recover\nfunc RecoverMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        defer func() {\n            if err := recover(); err != nil {\n                log.Printf(\"Panic in handler: %v\\nStack: %s\", err, debug.Stack())\n                http.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n            }\n        }()\n        \n        next.ServeHTTP(w, r)\n    })\n}\n\n// Goroutine with recover\nfunc SafeGo(fn func()) {\n    go func() {\n        defer func() {\n            if r := recover(); r != nil {\n                log.Printf(\"Panic in goroutine: %v\\nStack: %s\", r, debug.Stack())\n            }\n        }()\n        \n        fn()\n    }()\n}\n\n// Convert panic to error\nfunc callExternalLibrary() (err error) {\n    defer func() {\n        if r := recover(); r != nil {\n            err = fmt.Errorf(\"external library panicked: %v\", r)\n        }\n    }()\n    \n    // Call potentially panicking external code\n    externalLibrary.DangerousOperation()\n    \n    return nil\n}\n```\n\n## Error Handling Strategies\n\n### Fail Fast\n```go\n// Fail fast on critical errors\nfunc Initialize() error {\n    // Check prerequisites first\n    if err := checkDependencies(); err != nil {\n        return fmt.Errorf(\"dependency check failed: %w\", err)\n    }\n    \n    if err := validateConfig(); err != nil {\n        return fmt.Errorf(\"config validation failed: %w\", err)\n    }\n    \n    // Only proceed if everything is valid\n    return startServices()\n}\n\n// Validate early\nfunc ProcessRequest(req Request) error {\n    // Validate input immediately\n    if err := req.Validate(); err != nil {\n        return fmt.Errorf(\"invalid request: %w\", err)\n    }\n    \n    // Check permissions early\n    if err := checkPermissions(req.UserID); err != nil {\n        return fmt.Errorf(\"permission denied: %w\", err)\n    }\n    \n    // Process only after validation\n    return process(req)\n}\n```\n\n### Graceful Degradation\n```go\n// Fallback on error\nfunc GetUserPreferences(userID string) (*Preferences, error) {\n    // Try to get from cache\n    prefs, err := cache.Get(userID)\n    if err == nil {\n        return prefs, nil\n    }\n    \n    // Fallback to database\n    prefs, err = db.GetPreferences(userID)\n    if err == nil {\n        // Update cache for next time\n        go cache.Set(userID, prefs)\n        return prefs, nil\n    }\n    \n    // Return defaults if all fails\n    log.Printf(\"Failed to get preferences for %s: %v\", userID, err)\n    return DefaultPreferences(), nil\n}\n\n// Partial success\nfunc ProcessBatch(items []Item) error {\n    var successCount int\n    var errors []error\n    \n    for _, item := range items {\n        if err := processItem(item); err != nil {\n            errors = append(errors, fmt.Errorf(\"item %v: %w\", item.ID, err))\n            continue\n        }\n        successCount++\n    }\n    \n    if len(errors) > 0 {\n        log.Printf(\"Processed %d/%d items successfully\", successCount, len(items))\n        return &PartialError{\n            Successful: successCount,\n            Failed:     len(errors),\n            Errors:     errors,\n        }\n    }\n    \n    return nil\n}\n```\n\n### Error Aggregation\n```go\n// Collect all errors\ntype ErrorCollector struct {\n    mu     sync.Mutex\n    errors []error\n}\n\nfunc (c *ErrorCollector) Add(err error) {\n    if err == nil {\n        return\n    }\n    \n    c.mu.Lock()\n    defer c.mu.Unlock()\n    c.errors = append(c.errors, err)\n}\n\nfunc (c *ErrorCollector) Error() error {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    switch len(c.errors) {\n    case 0:\n        return nil\n    case 1:\n        return c.errors[0]\n    default:\n        return &MultiError{Errors: c.errors}\n    }\n}\n\n// Usage with goroutines\nfunc ProcessConcurrently(items []Item) error {\n    var wg sync.WaitGroup\n    collector := &ErrorCollector{}\n    \n    for _, item := range items {\n        wg.Add(1)\n        go func(i Item) {\n            defer wg.Done()\n            if err := processItem(i); err != nil {\n                collector.Add(fmt.Errorf(\"item %v: %w\", i.ID, err))\n            }\n        }(item)\n    }\n    \n    wg.Wait()\n    return collector.Error()\n}\n```\n\n## Testing Errors\n\n### Testing Error Cases\n```go\nfunc TestDivide(t *testing.T) {\n    tests := []struct {\n        name    string\n        a, b    float64\n        want    float64\n        wantErr bool\n        errMsg  string\n    }{\n        {\n            name: \"normal division\",\n            a:    10,\n            b:    2,\n            want: 5,\n        },\n        {\n            name:    \"divide by zero\",\n            a:       10,\n            b:       0,\n            wantErr: true,\n            errMsg:  \"division by zero\",\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got, err := Divide(tt.a, tt.b)\n            \n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Divide() error = %v, wantErr %v\", err, tt.wantErr)\n                return\n            }\n            \n            if tt.wantErr {\n                if !strings.Contains(err.Error(), tt.errMsg) {\n                    t.Errorf(\"Divide() error = %v, want error containing %v\", \n                        err, tt.errMsg)\n                }\n                return\n            }\n            \n            if got != tt.want {\n                t.Errorf(\"Divide() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n\n// Testing sentinel errors\nfunc TestGetUser_NotFound(t *testing.T) {\n    repo := NewMockRepository()\n    repo.ReturnError = sql.ErrNoRows\n    \n    service := NewService(repo)\n    _, err := service.GetUser(\"123\")\n    \n    if !errors.Is(err, ErrNotFound) {\n        t.Errorf(\"expected ErrNotFound, got %v\", err)\n    }\n}\n\n// Testing error types\nfunc TestValidationError(t *testing.T) {\n    err := ValidateUser(User{})\n    \n    var validationErr ValidationError\n    if !errors.As(err, &validationErr) {\n        t.Fatalf(\"expected ValidationError, got %T\", err)\n    }\n    \n    if validationErr.Field != \"email\" {\n        t.Errorf(\"expected field 'email', got %s\", validationErr.Field)\n    }\n}\n\n// Testing error wrapping\nfunc TestErrorWrapping(t *testing.T) {\n    rootErr := errors.New(\"root cause\")\n    wrappedErr := fmt.Errorf(\"wrapped: %w\", rootErr)\n    \n    if !errors.Is(wrappedErr, rootErr) {\n        t.Error(\"expected wrapped error to contain root cause\")\n    }\n}\n```\n\n### Mocking Errors\n```go\n// Error injection for testing\ntype ErrorInjector struct {\n    errors map[string]error\n    calls  map[string]int\n}\n\nfunc (e *ErrorInjector) ShouldFail(operation string) error {\n    e.calls[operation]++\n    \n    if err, ok := e.errors[operation]; ok {\n        // Return error on specific call count\n        if callErr, ok := err.(*CallCountError); ok {\n            if e.calls[operation] == callErr.OnCall {\n                return callErr.Err\n            }\n            return nil\n        }\n        return err\n    }\n    \n    return nil\n}\n\ntype CallCountError struct {\n    OnCall int\n    Err    error\n}\n\n// Usage in tests\nfunc TestRetry(t *testing.T) {\n    injector := &ErrorInjector{\n        errors: map[string]error{\n            \"connect\": &CallCountError{\n                OnCall: 1, // Fail on first call\n                Err:    errors.New(\"connection failed\"),\n            },\n        },\n        calls: make(map[string]int),\n    }\n    \n    service := NewService(injector)\n    err := service.ConnectWithRetry()\n    \n    if err != nil {\n        t.Errorf(\"expected success after retry, got %v\", err)\n    }\n    \n    if injector.calls[\"connect\"] != 2 {\n        t.Errorf(\"expected 2 connection attempts, got %d\", \n            injector.calls[\"connect\"])\n    }\n}\n```\n\n## Best Practices\n\n### Error Design Guidelines\n```go\n// 1. Return error as last value\nfunc Good() (Result, error)\nfunc Bad() (error, Result)  // Don't do this\n\n// 2. Check errors immediately\nresult, err := doSomething()\nif err != nil {\n    return err\n}\n\n// 3. Add context when wrapping\nif err != nil {\n    return fmt.Errorf(\"failed to process user %s: %w\", userID, err)\n}\n\n// 4. Use sentinel errors for known conditions\nvar ErrNotFound = errors.New(\"not found\")\n\n// 5. Create specific error types for rich information\ntype ValidationError struct {\n    Field string\n    Value interface{}\n}\n\n// 6. Don't ignore errors\n_ = os.Remove(tempFile)  // Bad\nif err := os.Remove(tempFile); err != nil {\n    log.Printf(\"failed to remove temp file: %v\", err)\n}\n\n// 7. Handle errors once\n// Don't log AND return - let caller decide\n\n// 8. Use errors.Is and errors.As for checking\nif errors.Is(err, ErrNotFound) { }\nvar validErr ValidationError\nif errors.As(err, &validErr) { }\n\n// 9. Keep error messages lowercase\nerrors.New(\"not found\")  // Good\nerrors.New(\"Not Found\")  // Bad\n\n// 10. Include relevant context\nfmt.Errorf(\"user %s: %w\", userID, err)  // Good\nfmt.Errorf(\"error: %w\", err)  // Too generic\n```\n\n### Common Pitfalls\n```go\n// Shadowing err variable\nerr := doFirst()\nif err != nil {\n    err := doSecond()  // Shadows outer err!\n    if err != nil {\n        return err\n    }\n}\n\n// Checking wrong error\nresult, err := doSomething()\nif err != nil {\n    anotherResult, err := doAnother()  // Reuses err\n    if err != nil {  // Might be checking wrong error\n        return err\n    }\n}\n\n// Nil interface gotcha\nfunc returnsError() error {\n    var err *MyError  // nil pointer\n    return err        // Returns non-nil error interface!\n}\n\n// Fix:\nfunc returnsError() error {\n    var err *MyError\n    if someCondition {\n        err = &MyError{}\n    }\n    if err != nil {\n        return err\n    }\n    return nil  // Explicitly return nil\n}\n```\n\n## Best Practices Summary\n\n1. **Always check errors** - Never ignore returned errors\n2. **Add context when wrapping** - Help debugging with good messages\n3. **Use sentinel errors wisely** - For known, actionable conditions\n4. **Create custom error types** - When you need rich error information\n5. **Fail fast** - Return early on errors\n6. **Don't panic** - Reserve for truly exceptional cases\n7. **Test error paths** - Ensure error handling works correctly\n8. **Use errors.Is/As** - For robust error checking\n9. **Keep errors actionable** - Help users understand what went wrong\n10. **Document error behavior** - Specify what errors functions can return","numLines":1401,"startLine":1,"totalLines":1401}}}
{"parentUuid":"da72b4b3-807c-4ec8-961e-2046ec58ff7a","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_012ZyZSwjEPiGi7G9aYL6Lke","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_018kADaqSSoZAb443k9vLLEc","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/fundamentals.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":14763,"cache_read_input_tokens":32976,"output_tokens":74,"service_tier":"standard"}},"requestId":"req_011CS5Wg646ainjnSJDzfJ7E","type":"assistant","uuid":"309dd556-4762-49bb-9c8a-97ff1de65097","timestamp":"2025-08-13T09:59:00.743Z"}
{"parentUuid":"309dd556-4762-49bb-9c8a-97ff1de65097","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018kADaqSSoZAb443k9vLLEc","type":"tool_result","content":"     1→# Go Language Fundamentals - Complete Reference\n     2→\n     3→## Table of Contents\n     4→1. [Introduction](#introduction)\n     5→2. [Basic Syntax](#basic-syntax)\n     6→3. [Variables and Constants](#variables-and-constants)\n     7→4. [Data Types](#data-types)\n     8→5. [Control Flow](#control-flow)\n     9→6. [Functions](#functions)\n    10→7. [Methods](#methods)\n    11→8. [Structs](#structs)\n    12→9. [Interfaces](#interfaces)\n    13→10. [Pointers](#pointers)\n    14→11. [Arrays and Slices](#arrays-and-slices)\n    15→12. [Maps](#maps)\n    16→13. [Error Handling](#error-handling)\n    17→14. [Packages and Modules](#packages-and-modules)\n    18→15. [Type Assertions and Type Switches](#type-assertions-and-type-switches)\n    19→16. [Embedding and Composition](#embedding-and-composition)\n    20→17. [Generics](#generics)\n    21→\n    22→## Introduction\n    23→\n    24→Go is a statically typed, compiled language designed for simplicity, efficiency, and reliable software. Created at Google in 2007 by Robert Griesemer, Rob Pike, and Ken Thompson, Go combines the performance of compiled languages with the ease of programming of dynamic languages.\n    25→\n    26→### Core Philosophy\n    27→- **Simplicity**: Less is exponentially more\n    28→- **Readability**: Code is read more often than written\n    29→- **Efficiency**: Fast compilation, fast execution\n    30→- **Concurrency**: Built-in primitives for concurrent programming\n    31→- **Pragmatism**: Solve real problems with practical solutions\n    32→\n    33→## Basic Syntax\n    34→\n    35→### Program Structure\n    36→\n    37→Every Go program starts with a package declaration and imports:\n    38→\n    39→```go\n    40→package main\n    41→\n    42→import (\n    43→    \"fmt\"\n    44→    \"strings\"\n    45→    \"time\"\n    46→)\n    47→\n    48→func main() {\n    49→    fmt.Println(\"Hello, Go!\")\n    50→}\n    51→```\n    52→\n    53→### Comments\n    54→\n    55→```go\n    56→// Single-line comment\n    57→\n    58→/*\n    59→   Multi-line comment\n    60→   Can span multiple lines\n    61→*/\n    62→\n    63→// Package documentation comment (must precede package declaration)\n    64→// Package math provides basic mathematical functions.\n    65→package math\n    66→\n    67→// Function documentation (must precede function declaration)\n    68→// Add returns the sum of two integers.\n    69→func Add(a, b int) int {\n    70→    return a + b\n    71→}\n    72→```\n    73→\n    74→### Naming Conventions\n    75→\n    76→```go\n    77→// Exported (public) - starts with uppercase\n    78→type Strategy struct{}\n    79→func CalculateProfit() {}\n    80→const MaxRetries = 3\n    81→var DefaultTimeout = 5 * time.Second\n    82→\n    83→// Unexported (private) - starts with lowercase\n    84→type position struct{}\n    85→func calculateLoss() {}\n    86→const maxAttempts = 5\n    87→var defaultBuffer = 1024\n    88→\n    89→// Package names - lowercase, single word\n    90→package trading  // Good\n    91→package tradingEngine  // Bad - use trading or engine\n    92→\n    93→// Interface names - typically end with -er\n    94→type Reader interface{}\n    95→type Writer interface{}\n    96→type Closer interface{}\n    97→type ReadWriteCloser interface{}  // Composition\n    98→\n    99→// Acronyms - keep consistent case\n   100→var httpClient HTTP  // Bad\n   101→var HTTPClient HTTP  // Good\n   102→var xmlParser XML    // Bad\n   103→var XMLParser XML    // Good\n   104→```\n   105→\n   106→## Variables and Constants\n   107→\n   108→### Variable Declaration\n   109→\n   110→```go\n   111→// var declaration with type\n   112→var name string\n   113→var age int\n   114→var balance float64\n   115→\n   116→// var declaration with initialization\n   117→var name string = \"John\"\n   118→var age int = 30\n   119→var balance = 1000.50  // Type inferred\n   120→\n   121→// Short variable declaration (only inside functions)\n   122→name := \"John\"\n   123→age := 30\n   124→balance := 1000.50\n   125→\n   126→// Multiple variable declaration\n   127→var (\n   128→    firstName string = \"John\"\n   129→    lastName  string = \"Doe\"\n   130→    age       int    = 30\n   131→)\n   132→\n   133→// Multiple assignment\n   134→x, y := 10, 20\n   135→a, b = b, a  // Swap values\n   136→\n   137→// Blank identifier for unused values\n   138→_, err := someFunction()  // Ignore first return value\n   139→```\n   140→\n   141→### Constants\n   142→\n   143→```go\n   144→// Single constant\n   145→const Pi = 3.14159\n   146→const MaxRetries = 3\n   147→const Message = \"Hello\"\n   148→\n   149→// Typed constants\n   150→const MaxInt int = 1000\n   151→const Timeout time.Duration = 5 * time.Second\n   152→\n   153→// Multiple constants\n   154→const (\n   155→    StatusOK       = 200\n   156→    StatusNotFound = 404\n   157→    StatusError    = 500\n   158→)\n   159→\n   160→// iota - constant generator\n   161→const (\n   162→    Sunday = iota  // 0\n   163→    Monday         // 1\n   164→    Tuesday        // 2\n   165→    Wednesday      // 3\n   166→    Thursday       // 4\n   167→    Friday         // 5\n   168→    Saturday       // 6\n   169→)\n   170→\n   171→// iota with expressions\n   172→const (\n   173→    _  = iota             // 0 (ignored)\n   174→    KB = 1 << (10 * iota) // 1024\n   175→    MB                    // 1048576\n   176→    GB                    // 1073741824\n   177→    TB                    // 1099511627776\n   178→)\n   179→\n   180→// Bit flags with iota\n   181→const (\n   182→    ReadPermission = 1 << iota  // 1\n   183→    WritePermission              // 2\n   184→    ExecutePermission            // 4\n   185→)\n   186→```\n   187→\n   188→## Data Types\n   189→\n   190→### Basic Types\n   191→\n   192→```go\n   193→// Boolean\n   194→var isActive bool = true\n   195→var isComplete bool  // Zero value: false\n   196→\n   197→// Integers\n   198→var i8 int8 = 127                    // -128 to 127\n   199→var i16 int16 = 32767                // -32768 to 32767\n   200→var i32 int32 = 2147483647           // -2147483648 to 2147483647\n   201→var i64 int64 = 9223372036854775807  // -9223372036854775808 to 9223372036854775807\n   202→var i int = 42                       // Platform dependent (32 or 64 bit)\n   203→\n   204→// Unsigned integers\n   205→var ui8 uint8 = 255                  // 0 to 255 (byte is alias)\n   206→var ui16 uint16 = 65535              // 0 to 65535\n   207→var ui32 uint32 = 4294967295         // 0 to 4294967295\n   208→var ui64 uint64 = 18446744073709551615  // 0 to 18446744073709551615\n   209→var ui uint = 42                     // Platform dependent\n   210→\n   211→// Floating point\n   212→var f32 float32 = 3.14               // IEEE-754 32-bit\n   213→var f64 float64 = 3.141592653589793  // IEEE-754 64-bit\n   214→\n   215→// Complex numbers\n   216→var c64 complex64 = 1 + 2i           // float32 real and imaginary\n   217→var c128 complex128 = 1 + 2i         // float64 real and imaginary\n   218→\n   219→// Strings\n   220→var str string = \"Hello, Go!\"        // UTF-8 encoded\n   221→var multiline = `This is\n   222→a multiline\n   223→string`                               // Raw string literal\n   224→\n   225→// Rune (Unicode code point)\n   226→var r rune = 'A'                     // int32 alias\n   227→var emoji rune = '😀'\n   228→\n   229→// Byte\n   230→var b byte = 65                      // uint8 alias\n   231→```\n   232→\n   233→### Type Conversions\n   234→\n   235→```go\n   236→// Explicit type conversion required\n   237→var i int = 42\n   238→var f float64 = float64(i)\n   239→var u uint = uint(i)\n   240→\n   241→// String conversions\n   242→import \"strconv\"\n   243→\n   244→// Int to string\n   245→s := strconv.Itoa(42)\n   246→s := strconv.FormatInt(42, 10)  // base 10\n   247→\n   248→// String to int\n   249→i, err := strconv.Atoi(\"42\")\n   250→i64, err := strconv.ParseInt(\"42\", 10, 64)\n   251→\n   252→// Float to string\n   253→s := strconv.FormatFloat(3.14, 'f', 2, 64)  // 2 decimal places\n   254→\n   255→// String to float\n   256→f, err := strconv.ParseFloat(\"3.14\", 64)\n   257→\n   258→// Type assertions (for interfaces)\n   259→var x interface{} = \"hello\"\n   260→s := x.(string)  // Panics if x is not string\n   261→s, ok := x.(string)  // Safe assertion with ok check\n   262→```\n   263→\n   264→### Zero Values\n   265→\n   266→```go\n   267→// All types have zero values\n   268→var b bool        // false\n   269→var i int         // 0\n   270→var f float64     // 0.0\n   271→var s string      // \"\"\n   272→var p *int        // nil\n   273→var a []int       // nil\n   274→var m map[string]int  // nil\n   275→var c chan int    // nil\n   276→var fn func()     // nil\n   277→var iface error   // nil\n   278→```\n   279→\n   280→## Control Flow\n   281→\n   282→### If Statements\n   283→\n   284→```go\n   285→// Basic if\n   286→if x > 0 {\n   287→    fmt.Println(\"Positive\")\n   288→}\n   289→\n   290→// If-else\n   291→if x > 0 {\n   292→    fmt.Println(\"Positive\")\n   293→} else {\n   294→    fmt.Println(\"Non-positive\")\n   295→}\n   296→\n   297→// If-else if-else\n   298→if x > 0 {\n   299→    fmt.Println(\"Positive\")\n   300→} else if x < 0 {\n   301→    fmt.Println(\"Negative\")\n   302→} else {\n   303→    fmt.Println(\"Zero\")\n   304→}\n   305→\n   306→// If with initialization\n   307→if err := doSomething(); err != nil {\n   308→    return err  // err is scoped to if block\n   309→}\n   310→\n   311→// Common patterns\n   312→// Check error immediately\n   313→if err != nil {\n   314→    return fmt.Errorf(\"failed to process: %w\", err)\n   315→}\n   316→\n   317→// Check boolean\n   318→if !isValid {\n   319→    return errors.New(\"invalid input\")\n   320→}\n   321→\n   322→// Check nil\n   323→if data == nil {\n   324→    return errors.New(\"data is nil\")\n   325→}\n   326→```\n   327→\n   328→### Switch Statements\n   329→\n   330→```go\n   331→// Basic switch\n   332→switch day {\n   333→case \"Monday\":\n   334→    fmt.Println(\"Start of work week\")\n   335→case \"Friday\":\n   336→    fmt.Println(\"TGIF!\")\n   337→case \"Saturday\", \"Sunday\":\n   338→    fmt.Println(\"Weekend!\")\n   339→default:\n   340→    fmt.Println(\"Midweek\")\n   341→}\n   342→\n   343→// Switch with no expression (like if-else chain)\n   344→switch {\n   345→case x < 0:\n   346→    fmt.Println(\"Negative\")\n   347→case x == 0:\n   348→    fmt.Println(\"Zero\")\n   349→case x > 0:\n   350→    fmt.Println(\"Positive\")\n   351→}\n   352→\n   353→// Switch with initialization\n   354→switch os := runtime.GOOS; os {\n   355→case \"darwin\":\n   356→    fmt.Println(\"macOS\")\n   357→case \"linux\":\n   358→    fmt.Println(\"Linux\")\n   359→default:\n   360→    fmt.Printf(\"Unknown OS: %s\\n\", os)\n   361→}\n   362→\n   363→// Type switch\n   364→func describe(i interface{}) {\n   365→    switch v := i.(type) {\n   366→    case int:\n   367→        fmt.Printf(\"Integer: %d\\n\", v)\n   368→    case string:\n   369→        fmt.Printf(\"String: %s\\n\", v)\n   370→    case bool:\n   371→        fmt.Printf(\"Boolean: %t\\n\", v)\n   372→    case nil:\n   373→        fmt.Println(\"nil value\")\n   374→    default:\n   375→        fmt.Printf(\"Unknown type: %T\\n\", v)\n   376→    }\n   377→}\n   378→\n   379→// Fallthrough (rarely used)\n   380→switch num {\n   381→case 1:\n   382→    fmt.Println(\"One\")\n   383→    fallthrough  // Continue to next case\n   384→case 2:\n   385→    fmt.Println(\"One or Two\")\n   386→}\n   387→```\n   388→\n   389→### Loops\n   390→\n   391→```go\n   392→// For loop - traditional\n   393→for i := 0; i < 10; i++ {\n   394→    fmt.Println(i)\n   395→}\n   396→\n   397→// For loop - while style\n   398→count := 0\n   399→for count < 10 {\n   400→    fmt.Println(count)\n   401→    count++\n   402→}\n   403→\n   404→// Infinite loop\n   405→for {\n   406→    // Break or return to exit\n   407→    if condition {\n   408→        break\n   409→    }\n   410→}\n   411→\n   412→// Range over slice\n   413→numbers := []int{1, 2, 3, 4, 5}\n   414→for index, value := range numbers {\n   415→    fmt.Printf(\"%d: %d\\n\", index, value)\n   416→}\n   417→\n   418→// Range over slice - values only\n   419→for _, value := range numbers {\n   420→    fmt.Println(value)\n   421→}\n   422→\n   423→// Range over slice - indices only\n   424→for index := range numbers {\n   425→    fmt.Println(index)\n   426→}\n   427→\n   428→// Range over map\n   429→ages := map[string]int{\"Alice\": 30, \"Bob\": 25}\n   430→for name, age := range ages {\n   431→    fmt.Printf(\"%s is %d years old\\n\", name, age)\n   432→}\n   433→\n   434→// Range over string (gives runes)\n   435→for index, runeValue := range \"Hello, 世界\" {\n   436→    fmt.Printf(\"%d: %c\\n\", index, runeValue)\n   437→}\n   438→\n   439→// Range over channel\n   440→ch := make(chan int)\n   441→go func() {\n   442→    for i := 0; i < 5; i++ {\n   443→        ch <- i\n   444→    }\n   445→    close(ch)\n   446→}()\n   447→for value := range ch {\n   448→    fmt.Println(value)\n   449→}\n   450→\n   451→// Continue and break with labels\n   452→outer:\n   453→for i := 0; i < 3; i++ {\n   454→    for j := 0; j < 3; j++ {\n   455→        if i == 1 && j == 1 {\n   456→            break outer  // Break outer loop\n   457→        }\n   458→        fmt.Printf(\"(%d, %d) \", i, j)\n   459→    }\n   460→}\n   461→```\n   462→\n   463→### Defer, Panic, and Recover\n   464→\n   465→```go\n   466→// Defer - executes when function returns\n   467→func readFile(filename string) error {\n   468→    file, err := os.Open(filename)\n   469→    if err != nil {\n   470→        return err\n   471→    }\n   472→    defer file.Close()  // Executed when function returns\n   473→    \n   474→    // Read file...\n   475→    return nil\n   476→}\n   477→\n   478→// Multiple defers - LIFO order\n   479→func example() {\n   480→    defer fmt.Println(\"Third\")\n   481→    defer fmt.Println(\"Second\")\n   482→    defer fmt.Println(\"First\")\n   483→    // Prints: First, Second, Third\n   484→}\n   485→\n   486→// Defer with arguments - evaluated immediately\n   487→func deferArgs() {\n   488→    i := 0\n   489→    defer fmt.Println(i)  // Prints 0, not 1\n   490→    i++\n   491→}\n   492→\n   493→// Defer with closure - captures variables\n   494→func deferClosure() {\n   495→    i := 0\n   496→    defer func() {\n   497→        fmt.Println(i)  // Prints 1\n   498→    }()\n   499→    i++\n   500→}\n   501→\n   502→// Panic - runtime error\n   503→func divide(a, b int) int {\n   504→    if b == 0 {\n   505→        panic(\"division by zero\")\n   506→    }\n   507→    return a / b\n   508→}\n   509→\n   510→// Recover - catch panic\n   511→func safeFunction() {\n   512→    defer func() {\n   513→        if r := recover(); r != nil {\n   514→            fmt.Printf(\"Recovered from panic: %v\\n\", r)\n   515→        }\n   516→    }()\n   517→    \n   518→    // Code that might panic\n   519→    panic(\"something went wrong\")\n   520→}\n   521→\n   522→// Practical error recovery pattern\n   523→func robustFunction() (err error) {\n   524→    defer func() {\n   525→        if r := recover(); r != nil {\n   526→            err = fmt.Errorf(\"panic recovered: %v\", r)\n   527→        }\n   528→    }()\n   529→    \n   530→    // Potentially panicking code\n   531→    return nil\n   532→}\n   533→```\n   534→\n   535→## Functions\n   536→\n   537→### Function Declaration\n   538→\n   539→```go\n   540→// Basic function\n   541→func greet() {\n   542→    fmt.Println(\"Hello!\")\n   543→}\n   544→\n   545→// Function with parameters\n   546→func add(a int, b int) int {\n   547→    return a + b\n   548→}\n   549→\n   550→// Shorthand for same type parameters\n   551→func add(a, b int) int {\n   552→    return a + b\n   553→}\n   554→\n   555→// Multiple return values\n   556→func divide(a, b float64) (float64, error) {\n   557→    if b == 0 {\n   558→        return 0, errors.New(\"division by zero\")\n   559→    }\n   560→    return a / b, nil\n   561→}\n   562→\n   563→// Named return values\n   564→func getCoordinates() (x, y int) {\n   565→    x = 10\n   566→    y = 20\n   567→    return  // Naked return\n   568→}\n   569→\n   570→// Named returns with explicit values\n   571→func calculate(a, b int) (sum, product int) {\n   572→    sum = a + b\n   573→    product = a * b\n   574→    return sum, product  // Can be explicit\n   575→}\n   576→\n   577→// Variadic functions\n   578→func sum(numbers ...int) int {\n   579→    total := 0\n   580→    for _, n := range numbers {\n   581→        total += n\n   582→    }\n   583→    return total\n   584→}\n   585→\n   586→// Calling variadic functions\n   587→result := sum(1, 2, 3, 4, 5)\n   588→nums := []int{1, 2, 3}\n   589→result := sum(nums...)  // Spread slice\n   590→```\n   591→\n   592→### Function Types and Values\n   593→\n   594→```go\n   595→// Function as type\n   596→type Operation func(int, int) int\n   597→\n   598→func add(a, b int) int { return a + b }\n   599→func multiply(a, b int) int { return a * b }\n   600→\n   601→var op Operation = add\n   602→result := op(5, 3)  // 8\n   603→\n   604→// Function as parameter\n   605→func apply(op Operation, a, b int) int {\n   606→    return op(a, b)\n   607→}\n   608→\n   609→result := apply(add, 5, 3)\n   610→result = apply(multiply, 5, 3)\n   611→\n   612→// Function returning function\n   613→func makeAdder(x int) func(int) int {\n   614→    return func(y int) int {\n   615→        return x + y\n   616→    }\n   617→}\n   618→\n   619→add5 := makeAdder(5)\n   620→result := add5(3)  // 8\n   621→\n   622→// Anonymous functions\n   623→func() {\n   624→    fmt.Println(\"Anonymous function\")\n   625→}()  // Immediately invoked\n   626→\n   627→// Assign to variable\n   628→greet := func(name string) {\n   629→    fmt.Printf(\"Hello, %s!\\n\", name)\n   630→}\n   631→greet(\"World\")\n   632→```\n   633→\n   634→### Closures\n   635→\n   636→```go\n   637→// Closure captures variables\n   638→func counter() func() int {\n   639→    count := 0\n   640→    return func() int {\n   641→        count++\n   642→        return count\n   643→    }\n   644→}\n   645→\n   646→c := counter()\n   647→fmt.Println(c())  // 1\n   648→fmt.Println(c())  // 2\n   649→fmt.Println(c())  // 3\n   650→\n   651→// Closure in loop (common pitfall)\n   652→// Wrong way\n   653→funcs := []func(){}\n   654→for i := 0; i < 3; i++ {\n   655→    funcs = append(funcs, func() {\n   656→        fmt.Println(i)  // All print 3\n   657→    })\n   658→}\n   659→\n   660→// Correct way\n   661→for i := 0; i < 3; i++ {\n   662→    i := i  // Shadow variable\n   663→    funcs = append(funcs, func() {\n   664→        fmt.Println(i)  // Prints 0, 1, 2\n   665→    })\n   666→}\n   667→\n   668→// Alternative correct way\n   669→for i := 0; i < 3; i++ {\n   670→    func(n int) {\n   671→        funcs = append(funcs, func() {\n   672→            fmt.Println(n)\n   673→        })\n   674→    }(i)\n   675→}\n   676→```\n   677→\n   678→## Methods\n   679→\n   680→### Method Declaration\n   681→\n   682→```go\n   683→// Method on struct\n   684→type Rectangle struct {\n   685→    Width, Height float64\n   686→}\n   687→\n   688→// Value receiver\n   689→func (r Rectangle) Area() float64 {\n   690→    return r.Width * r.Height\n   691→}\n   692→\n   693→// Pointer receiver\n   694→func (r *Rectangle) Scale(factor float64) {\n   695→    r.Width *= factor\n   696→    r.Height *= factor\n   697→}\n   698→\n   699→// Using methods\n   700→rect := Rectangle{Width: 10, Height: 5}\n   701→area := rect.Area()        // 50\n   702→rect.Scale(2)              // Width=20, Height=10\n   703→\n   704→// Method on non-struct types\n   705→type MyInt int\n   706→\n   707→func (m MyInt) IsEven() bool {\n   708→    return m%2 == 0\n   709→}\n   710→\n   711→var num MyInt = 42\n   712→if num.IsEven() {\n   713→    fmt.Println(\"Even number\")\n   714→}\n   715→\n   716→// Method on pointer vs value\n   717→type Counter struct {\n   718→    value int\n   719→}\n   720→\n   721→// Value receiver - cannot modify\n   722→func (c Counter) GetValue() int {\n   723→    return c.value\n   724→}\n   725→\n   726→// Pointer receiver - can modify\n   727→func (c *Counter) Increment() {\n   728→    c.value++\n   729→}\n   730→\n   731→// Pointer receiver - can handle nil\n   732→func (c *Counter) SafeIncrement() {\n   733→    if c == nil {\n   734→        return\n   735→    }\n   736→    c.value++\n   737→}\n   738→```\n   739→\n   740→### Method Sets\n   741→\n   742→```go\n   743→// Method set rules:\n   744→// - Type T has method set of all methods with receiver T\n   745→// - Type *T has method set of all methods with receiver T or *T\n   746→\n   747→type Shape struct {\n   748→    Name string\n   749→}\n   750→\n   751→func (s Shape) GetName() string {\n   752→    return s.Name\n   753→}\n   754→\n   755→func (s *Shape) SetName(name string) {\n   756→    s.Name = name\n   757→}\n   758→\n   759→// Value type can call value receiver methods\n   760→shape := Shape{Name: \"Circle\"}\n   761→name := shape.GetName()  // OK\n   762→\n   763→// Value type automatically gets address for pointer receiver\n   764→shape.SetName(\"Square\")  // OK (Go converts to (&shape).SetName())\n   765→\n   766→// Pointer type can call both\n   767→shapePtr := &Shape{Name: \"Triangle\"}\n   768→name = shapePtr.GetName()  // OK\n   769→shapePtr.SetName(\"Pentagon\")  // OK\n   770→```\n   771→\n   772→## Structs\n   773→\n   774→### Struct Declaration and Usage\n   775→\n   776→```go\n   777→// Basic struct\n   778→type Person struct {\n   779→    FirstName string\n   780→    LastName  string\n   781→    Age       int\n   782→}\n   783→\n   784→// Creating structs\n   785→p1 := Person{\n   786→    FirstName: \"John\",\n   787→    LastName:  \"Doe\",\n   788→    Age:       30,\n   789→}\n   790→\n   791→// Positional initialization (not recommended)\n   792→p2 := Person{\"Jane\", \"Doe\", 25}\n   793→\n   794→// Zero value struct\n   795→var p3 Person  // All fields have zero values\n   796→\n   797→// Accessing fields\n   798→fmt.Println(p1.FirstName)\n   799→p1.Age = 31\n   800→\n   801→// Struct pointer\n   802→ptr := &Person{FirstName: \"Bob\"}\n   803→ptr.Age = 40  // Automatic dereferencing\n   804→\n   805→// Anonymous struct\n   806→point := struct {\n   807→    X, Y int\n   808→}{X: 10, Y: 20}\n   809→\n   810→// Struct tags\n   811→type User struct {\n   812→    ID        int    `json:\"id\" db:\"user_id\"`\n   813→    Email     string `json:\"email\" validate:\"required,email\"`\n   814→    Password  string `json:\"-\"`  // Omit from JSON\n   815→    CreatedAt time.Time `json:\"created_at,omitempty\"`\n   816→}\n   817→\n   818→// Accessing tags via reflection\n   819→import \"reflect\"\n   820→\n   821→t := reflect.TypeOf(User{})\n   822→field, _ := t.FieldByName(\"Email\")\n   823→fmt.Println(field.Tag.Get(\"json\"))     // \"email\"\n   824→fmt.Println(field.Tag.Get(\"validate\")) // \"required,email\"\n   825→```\n   826→\n   827→### Struct Embedding\n   828→\n   829→```go\n   830→// Embedding for composition\n   831→type Address struct {\n   832→    Street  string\n   833→    City    string\n   834→    Country string\n   835→}\n   836→\n   837→type Employee struct {\n   838→    Person  // Embedded struct\n   839→    Address // Another embedded struct\n   840→    Salary  float64\n   841→}\n   842→\n   843→emp := Employee{\n   844→    Person: Person{\n   845→        FirstName: \"Alice\",\n   846→        LastName:  \"Smith\",\n   847→        Age:       28,\n   848→    },\n   849→    Address: Address{\n   850→        City:    \"New York\",\n   851→        Country: \"USA\",\n   852→    },\n   853→    Salary: 75000,\n   854→}\n   855→\n   856→// Promoted fields\n   857→fmt.Println(emp.FirstName)  // Promoted from Person\n   858→fmt.Println(emp.City)       // Promoted from Address\n   859→\n   860→// Explicit access\n   861→fmt.Println(emp.Person.FirstName)\n   862→\n   863→// Method promotion\n   864→type Writer struct{}\n   865→\n   866→func (w Writer) Write(data []byte) (int, error) {\n   867→    return len(data), nil\n   868→}\n   869→\n   870→type Logger struct {\n   871→    Writer  // Embedded\n   872→    prefix string\n   873→}\n   874→\n   875→log := Logger{prefix: \"[INFO]\"}\n   876→log.Write([]byte(\"message\"))  // Promoted method\n   877→```\n   878→\n   879→### Struct Comparison\n   880→\n   881→```go\n   882→// Structs are comparable if all fields are comparable\n   883→type Point struct {\n   884→    X, Y int\n   885→}\n   886→\n   887→p1 := Point{1, 2}\n   888→p2 := Point{1, 2}\n   889→p3 := Point{2, 3}\n   890→\n   891→fmt.Println(p1 == p2)  // true\n   892→fmt.Println(p1 == p3)  // false\n   893→\n   894→// Non-comparable structs (contain slices, maps, functions)\n   895→type Data struct {\n   896→    Values []int  // Slices are not comparable\n   897→}\n   898→\n   899→// This won't compile:\n   900→// d1 := Data{Values: []int{1, 2}}\n   901→// d2 := Data{Values: []int{1, 2}}\n   902→// fmt.Println(d1 == d2)  // Compile error\n   903→```\n   904→\n   905→## Interfaces\n   906→\n   907→### Interface Declaration and Implementation\n   908→\n   909→```go\n   910→// Interface declaration\n   911→type Writer interface {\n   912→    Write([]byte) (int, error)\n   913→}\n   914→\n   915→// Interface with multiple methods\n   916→type ReadWriter interface {\n   917→    Read([]byte) (int, error)\n   918→    Write([]byte) (int, error)\n   919→}\n   920→\n   921→// Empty interface (any type)\n   922→type Any interface{}  // Pre Go 1.18\n   923→type Any = any        // Go 1.18+\n   924→\n   925→// Implicit implementation\n   926→type FileWriter struct {\n   927→    filename string\n   928→}\n   929→\n   930→func (f FileWriter) Write(data []byte) (int, error) {\n   931→    // Implementation\n   932→    return len(data), nil\n   933→}\n   934→\n   935→// FileWriter implements Writer implicitly\n   936→var w Writer = FileWriter{filename: \"test.txt\"}\n   937→```\n   938→\n   939→### Interface Composition\n   940→\n   941→```go\n   942→// Composing interfaces\n   943→type Reader interface {\n   944→    Read([]byte) (int, error)\n   945→}\n   946→\n   947→type Writer interface {\n   948→    Write([]byte) (int, error)\n   949→}\n   950→\n   951→type Closer interface {\n   952→    Close() error\n   953→}\n   954→\n   955→// Composed interface\n   956→type ReadWriteCloser interface {\n   957→    Reader\n   958→    Writer\n   959→    Closer\n   960→}\n   961→\n   962→// Alternative inline composition\n   963→type ReadWriter interface {\n   964→    Read([]byte) (int, error)\n   965→    Write([]byte) (int, error)\n   966→}\n   967→```\n   968→\n   969→### Interface Values and nil\n   970→\n   971→```go\n   972→// Interface values have two components: type and value\n   973→var w Writer\n   974→fmt.Printf(\"Type: %T, Value: %v\\n\", w, w)  // Type: <nil>, Value: <nil>\n   975→\n   976→// nil interface vs interface with nil value\n   977→type MyWriter struct{}\n   978→\n   979→func (m *MyWriter) Write(data []byte) (int, error) {\n   980→    if m == nil {\n   981→        return 0, errors.New(\"nil writer\")\n   982→    }\n   983→    return len(data), nil\n   984→}\n   985→\n   986→var mw *MyWriter = nil\n   987→var w Writer = mw\n   988→// w is not nil (has type *MyWriter), but its value is nil\n   989→\n   990→if w == nil {\n   991→    fmt.Println(\"w is nil\")  // Won't print\n   992→}\n   993→\n   994→// Check for nil value\n   995→if mw == nil {\n   996→    fmt.Println(\"mw is nil\")  // Will print\n   997→}\n   998→```\n   999→\n  1000→### Type Assertions and Type Switches\n  1001→\n  1002→```go\n  1003→// Type assertion\n  1004→var i interface{} = \"hello\"\n  1005→\n  1006→// Direct assertion (panics if wrong type)\n  1007→s := i.(string)\n  1008→fmt.Println(s)\n  1009→\n  1010→// Safe assertion with comma-ok\n  1011→s, ok := i.(string)\n  1012→if ok {\n  1013→    fmt.Println(\"String:\", s)\n  1014→}\n  1015→\n  1016→// Check interface implementation\n  1017→var w io.Writer = &bytes.Buffer{}\n  1018→if buf, ok := w.(*bytes.Buffer); ok {\n  1019→    fmt.Println(\"It's a buffer:\", buf)\n  1020→}\n  1021→\n  1022→// Type switch\n  1023→func describe(i interface{}) {\n  1024→    switch v := i.(type) {\n  1025→    case int:\n  1026→        fmt.Printf(\"Integer: %d\\n\", v)\n  1027→    case string:\n  1028→        fmt.Printf(\"String: %s\\n\", v)\n  1029→    case io.Reader:\n  1030→        fmt.Println(\"It's a reader\")\n  1031→    case nil:\n  1032→        fmt.Println(\"It's nil\")\n  1033→    default:\n  1034→        fmt.Printf(\"Unknown type: %T\\n\", v)\n  1035→    }\n  1036→}\n  1037→```\n  1038→\n  1039→### Common Interface Patterns\n  1040→\n  1041→```go\n  1042→// Stringer interface\n  1043→type Stringer interface {\n  1044→    String() string\n  1045→}\n  1046→\n  1047→type Point struct {\n  1048→    X, Y int\n  1049→}\n  1050→\n  1051→func (p Point) String() string {\n  1052→    return fmt.Sprintf(\"(%d, %d)\", p.X, p.Y)\n  1053→}\n  1054→\n  1055→// Error interface\n  1056→type error interface {\n  1057→    Error() string\n  1058→}\n  1059→\n  1060→type ValidationError struct {\n  1061→    Field string\n  1062→    Value string\n  1063→}\n  1064→\n  1065→func (e ValidationError) Error() string {\n  1066→    return fmt.Sprintf(\"validation failed for field %s: %s\", e.Field, e.Value)\n  1067→}\n  1068→\n  1069→// Sort interface\n  1070→type Interface interface {\n  1071→    Len() int\n  1072→    Less(i, j int) bool\n  1073→    Swap(i, j int)\n  1074→}\n  1075→\n  1076→// Custom sort implementation\n  1077→type ByAge []Person\n  1078→\n  1079→func (a ByAge) Len() int           { return len(a) }\n  1080→func (a ByAge) Less(i, j int) bool { return a[i].Age < a[j].Age }\n  1081→func (a ByAge) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }\n  1082→\n  1083→// Usage\n  1084→people := []Person{{Name: \"Alice\", Age: 30}, {Name: \"Bob\", Age: 25}}\n  1085→sort.Sort(ByAge(people))\n  1086→```\n  1087→\n  1088→## Pointers\n  1089→\n  1090→### Pointer Basics\n  1091→\n  1092→```go\n  1093→// Declare pointer\n  1094→var p *int\n  1095→\n  1096→// Get address of variable\n  1097→x := 42\n  1098→p = &x\n  1099→\n  1100→// Dereference pointer\n  1101→fmt.Println(*p)  // 42\n  1102→*p = 100\n  1103→fmt.Println(x)   // 100\n  1104→\n  1105→// Pointer zero value is nil\n  1106→var ptr *string\n  1107→if ptr == nil {\n  1108→    fmt.Println(\"ptr is nil\")\n  1109→}\n  1110→\n  1111→// New function allocates memory\n  1112→ptr = new(string)\n  1113→*ptr = \"Hello\"\n  1114→\n  1115→// Pointer to struct\n  1116→type Person struct {\n  1117→    Name string\n  1118→    Age  int\n  1119→}\n  1120→\n  1121→person := &Person{Name: \"Alice\", Age: 30}\n  1122→person.Age = 31  // Automatic dereferencing\n  1123→\n  1124→// Pointer arithmetic is NOT allowed in Go\n  1125→// p++  // This won't compile\n  1126→```\n  1127→\n  1128→### Pointers vs Values\n  1129→\n  1130→```go\n  1131→// Pass by value\n  1132→func modifyValue(x int) {\n  1133→    x = 100  // Doesn't affect original\n  1134→}\n  1135→\n  1136→// Pass by pointer\n  1137→func modifyPointer(x *int) {\n  1138→    *x = 100  // Modifies original\n  1139→}\n  1140→\n  1141→value := 42\n  1142→modifyValue(value)\n  1143→fmt.Println(value)  // Still 42\n  1144→\n  1145→modifyPointer(&value)\n  1146→fmt.Println(value)  // Now 100\n  1147→\n  1148→// Slices, maps, channels are reference types\n  1149→func modifySlice(s []int) {\n  1150→    s[0] = 100  // Modifies original\n  1151→}\n  1152→\n  1153→slice := []int{1, 2, 3}\n  1154→modifySlice(slice)\n  1155→fmt.Println(slice)  // [100, 2, 3]\n  1156→\n  1157→// But reassigning doesn't affect original\n  1158→func reassignSlice(s []int) {\n  1159→    s = []int{4, 5, 6}  // Doesn't affect original\n  1160→}\n  1161→\n  1162→// To modify slice itself, use pointer\n  1163→func replaceSlice(s *[]int) {\n  1164→    *s = []int{4, 5, 6}\n  1165→}\n  1166→```\n  1167→\n  1168→## Arrays and Slices\n  1169→\n  1170→### Arrays\n  1171→\n  1172→```go\n  1173→// Array declaration\n  1174→var arr [5]int              // [0 0 0 0 0]\n  1175→arr[0] = 10\n  1176→arr[4] = 50\n  1177→\n  1178→// Array initialization\n  1179→arr := [5]int{1, 2, 3, 4, 5}\n  1180→arr := [...]int{1, 2, 3}    // Compiler counts elements\n  1181→arr := [5]int{0: 10, 4: 50} // Index:value pairs\n  1182→\n  1183→// Arrays are values (copied on assignment)\n  1184→arr1 := [3]int{1, 2, 3}\n  1185→arr2 := arr1\n  1186→arr2[0] = 100\n  1187→fmt.Println(arr1)  // [1 2 3] - unchanged\n  1188→fmt.Println(arr2)  // [100 2 3]\n  1189→\n  1190→// Array size is part of type\n  1191→var a [5]int\n  1192→var b [10]int\n  1193→// a = b  // Won't compile - different types\n  1194→\n  1195→// Multidimensional arrays\n  1196→var matrix [3][3]int\n  1197→matrix[1][1] = 5\n  1198→\n  1199→// Array iteration\n  1200→for i := 0; i < len(arr); i++ {\n  1201→    fmt.Println(arr[i])\n  1202→}\n  1203→\n  1204→for index, value := range arr {\n  1205→    fmt.Printf(\"%d: %d\\n\", index, value)\n  1206→}\n  1207→```\n  1208→\n  1209→### Slices\n  1210→\n  1211→```go\n  1212→// Slice declaration\n  1213→var slice []int            // nil slice\n  1214→slice = []int{}           // Empty slice\n  1215→slice = []int{1, 2, 3}    // Initialized slice\n  1216→\n  1217→// Make function\n  1218→slice = make([]int, 5)    // Length 5, capacity 5\n  1219→slice = make([]int, 5, 10) // Length 5, capacity 10\n  1220→\n  1221→// Slice from array\n  1222→arr := [5]int{1, 2, 3, 4, 5}\n  1223→slice = arr[1:4]  // [2 3 4]\n  1224→slice = arr[:3]   // [1 2 3]\n  1225→slice = arr[2:]   // [3 4 5]\n  1226→slice = arr[:]    // [1 2 3 4 5]\n  1227→\n  1228→// Slice properties\n  1229→fmt.Println(len(slice))  // Length\n  1230→fmt.Println(cap(slice))  // Capacity\n  1231→\n  1232→// Append\n  1233→slice = []int{1, 2, 3}\n  1234→slice = append(slice, 4)\n  1235→slice = append(slice, 5, 6, 7)\n  1236→slice = append(slice, []int{8, 9}...)\n  1237→\n  1238→// Copy\n  1239→src := []int{1, 2, 3}\n  1240→dst := make([]int, len(src))\n  1241→n := copy(dst, src)  // Returns number copied\n  1242→\n  1243→// Slice tricks\n  1244→// Remove element at index i\n  1245→slice = append(slice[:i], slice[i+1:]...)\n  1246→\n  1247→// Insert element at index i\n  1248→slice = append(slice[:i], append([]int{x}, slice[i:]...)...)\n  1249→\n  1250→// Pop from end\n  1251→x := slice[len(slice)-1]\n  1252→slice = slice[:len(slice)-1]\n  1253→\n  1254→// Push to front\n  1255→slice = append([]int{x}, slice...)\n  1256→\n  1257→// Filter in place\n  1258→n := 0\n  1259→for _, x := range slice {\n  1260→    if keepElement(x) {\n  1261→        slice[n] = x\n  1262→        n++\n  1263→    }\n  1264→}\n  1265→slice = slice[:n]\n  1266→```\n  1267→\n  1268→### Slice Internals\n  1269→\n  1270→```go\n  1271→// Slice header (conceptual)\n  1272→type SliceHeader struct {\n  1273→    Data uintptr  // Pointer to underlying array\n  1274→    Len  int      // Current length\n  1275→    Cap  int      // Capacity\n  1276→}\n  1277→\n  1278→// Slices share underlying array\n  1279→original := []int{1, 2, 3, 4, 5}\n  1280→slice1 := original[1:4]  // [2 3 4]\n  1281→slice2 := original[2:5]  // [3 4 5]\n  1282→\n  1283→slice1[1] = 100  // Modifies shared array\n  1284→fmt.Println(slice2)  // [100 4 5]\n  1285→\n  1286→// Full slice expression controls capacity\n  1287→slice := original[1:3:4]  // [low:high:max]\n  1288→// len = high - low = 2\n  1289→// cap = max - low = 3\n  1290→\n  1291→// nil vs empty slice\n  1292→var nilSlice []int        // nil\n  1293→emptySlice := []int{}     // Not nil, but empty\n  1294→madeSlice := make([]int, 0) // Not nil, but empty\n  1295→\n  1296→fmt.Println(nilSlice == nil)    // true\n  1297→fmt.Println(emptySlice == nil)  // false\n  1298→fmt.Println(len(nilSlice))      // 0\n  1299→fmt.Println(len(emptySlice))    // 0\n  1300→\n  1301→// Both work with append\n  1302→nilSlice = append(nilSlice, 1)\n  1303→emptySlice = append(emptySlice, 1)\n  1304→```\n  1305→\n  1306→## Maps\n  1307→\n  1308→### Map Basics\n  1309→\n  1310→```go\n  1311→// Map declaration\n  1312→var m map[string]int      // nil map\n  1313→m = make(map[string]int)  // Initialize\n  1314→\n  1315→// Map literal\n  1316→m = map[string]int{\n  1317→    \"Alice\": 30,\n  1318→    \"Bob\":   25,\n  1319→}\n  1320→\n  1321→// Operations\n  1322→m[\"Charlie\"] = 35         // Insert/Update\n  1323→age := m[\"Alice\"]         // Retrieve\n  1324→delete(m, \"Bob\")          // Delete\n  1325→\n  1326→// Check if key exists\n  1327→age, exists := m[\"David\"]\n  1328→if exists {\n  1329→    fmt.Printf(\"David is %d years old\\n\", age)\n  1330→}\n  1331→\n  1332→// Zero value for missing key\n  1333→fmt.Println(m[\"Unknown\"])  // 0 (zero value for int)\n  1334→\n  1335→// Iteration (order is random)\n  1336→for key, value := range m {\n  1337→    fmt.Printf(\"%s: %d\\n\", key, value)\n  1338→}\n  1339→\n  1340→// Keys only\n  1341→for key := range m {\n  1342→    fmt.Println(key)\n  1343→}\n  1344→\n  1345→// Values only\n  1346→for _, value := range m {\n  1347→    fmt.Println(value)\n  1348→}\n  1349→```\n  1350→\n  1351→### Map Patterns\n  1352→\n  1353→```go\n  1354→// Map as set\n  1355→set := make(map[string]bool)\n  1356→set[\"apple\"] = true\n  1357→set[\"banana\"] = true\n  1358→\n  1359→if set[\"apple\"] {\n  1360→    fmt.Println(\"apple is in the set\")\n  1361→}\n  1362→\n  1363→// Alternative set using empty struct (memory efficient)\n  1364→type void struct{}\n  1365→var member void\n  1366→\n  1367→set := make(map[string]void)\n  1368→set[\"apple\"] = member\n  1369→set[\"banana\"] = member\n  1370→\n  1371→if _, exists := set[\"apple\"]; exists {\n  1372→    fmt.Println(\"apple is in the set\")\n  1373→}\n  1374→\n  1375→// Counting with maps\n  1376→counts := make(map[string]int)\n  1377→words := []string{\"apple\", \"banana\", \"apple\", \"orange\", \"banana\", \"apple\"}\n  1378→\n  1379→for _, word := range words {\n  1380→    counts[word]++  // Works even if key doesn't exist\n  1381→}\n  1382→\n  1383→// Grouping with maps\n  1384→type Person struct {\n  1385→    Name string\n  1386→    Age  int\n  1387→}\n  1388→\n  1389→people := []Person{\n  1390→    {\"Alice\", 30},\n  1391→    {\"Bob\", 25},\n  1392→    {\"Charlie\", 30},\n  1393→    {\"David\", 25},\n  1394→}\n  1395→\n  1396→ageGroups := make(map[int][]Person)\n  1397→for _, person := range people {\n  1398→    ageGroups[person.Age] = append(ageGroups[person.Age], person)\n  1399→}\n  1400→\n  1401→// Map of maps\n  1402→nested := make(map[string]map[string]int)\n  1403→nested[\"scores\"] = make(map[string]int)\n  1404→nested[\"scores\"][\"Alice\"] = 95\n  1405→nested[\"scores\"][\"Bob\"] = 87\n  1406→\n  1407→// Safe nested access\n  1408→if scores, ok := nested[\"scores\"]; ok {\n  1409→    if score, ok := scores[\"Alice\"]; ok {\n  1410→        fmt.Printf(\"Alice's score: %d\\n\", score)\n  1411→    }\n  1412→}\n  1413→```\n  1414→\n  1415→### Maps and Concurrency\n  1416→\n  1417→```go\n  1418→// Maps are not safe for concurrent access\n  1419→// Use sync.Map or mutex\n  1420→\n  1421→import \"sync\"\n  1422→\n  1423→// With mutex\n  1424→type SafeMap struct {\n  1425→    mu sync.RWMutex\n  1426→    m  map[string]int\n  1427→}\n  1428→\n  1429→func (sm *SafeMap) Set(key string, value int) {\n  1430→    sm.mu.Lock()\n  1431→    defer sm.mu.Unlock()\n  1432→    sm.m[key] = value\n  1433→}\n  1434→\n  1435→func (sm *SafeMap) Get(key string) (int, bool) {\n  1436→    sm.mu.RLock()\n  1437→    defer sm.mu.RUnlock()\n  1438→    value, exists := sm.m[key]\n  1439→    return value, exists\n  1440→}\n  1441→\n  1442→// Using sync.Map (for specific use cases)\n  1443→var m sync.Map\n  1444→\n  1445→// Store\n  1446→m.Store(\"key\", \"value\")\n  1447→\n  1448→// Load\n  1449→value, ok := m.Load(\"key\")\n  1450→\n  1451→// LoadOrStore\n  1452→actual, loaded := m.LoadOrStore(\"key\", \"new-value\")\n  1453→\n  1454→// Delete\n  1455→m.Delete(\"key\")\n  1456→\n  1457→// Range\n  1458→m.Range(func(key, value interface{}) bool {\n  1459→    fmt.Printf(\"%v: %v\\n\", key, value)\n  1460→    return true  // Continue iteration\n  1461→})\n  1462→```\n  1463→\n  1464→## Error Handling\n  1465→\n  1466→### Error Interface\n  1467→\n  1468→```go\n  1469→// Error interface\n  1470→type error interface {\n  1471→    Error() string\n  1472→}\n  1473→\n  1474→// Creating errors\n  1475→import \"errors\"\n  1476→\n  1477→err := errors.New(\"something went wrong\")\n  1478→err := fmt.Errorf(\"failed to process %s: %v\", filename, originalErr)\n  1479→\n  1480→// Custom error types\n  1481→type ValidationError struct {\n  1482→    Field string\n  1483→    Value interface{}\n  1484→    Msg   string\n  1485→}\n  1486→\n  1487→func (e ValidationError) Error() string {\n  1488→    return fmt.Sprintf(\"validation error: field=%s value=%v msg=%s\", \n  1489→        e.Field, e.Value, e.Msg)\n  1490→}\n  1491→\n  1492→// Sentinel errors\n  1493→var (\n  1494→    ErrNotFound   = errors.New(\"not found\")\n  1495→    ErrPermission = errors.New(\"permission denied\")\n  1496→    ErrTimeout    = errors.New(\"operation timed out\")\n  1497→)\n  1498→\n  1499→// Error wrapping (Go 1.13+)\n  1500→originalErr := errors.New(\"original error\")\n  1501→wrappedErr := fmt.Errorf(\"wrapped: %w\", originalErr)\n  1502→\n  1503→// Unwrap errors\n  1504→if errors.Is(wrappedErr, originalErr) {\n  1505→    fmt.Println(\"Error is originalErr\")\n  1506→}\n  1507→\n  1508→var validationErr ValidationError\n  1509→if errors.As(wrappedErr, &validationErr) {\n  1510→    fmt.Printf(\"Validation error: %s\\n\", validationErr.Field)\n  1511→}\n  1512→```\n  1513→\n  1514→### Error Handling Patterns\n  1515→\n  1516→```go\n  1517→// Immediate error checking\n  1518→result, err := doSomething()\n  1519→if err != nil {\n  1520→    return fmt.Errorf(\"doSomething failed: %w\", err)\n  1521→}\n  1522→\n  1523→// Multiple error sources\n  1524→func processFile(filename string) error {\n  1525→    file, err := os.Open(filename)\n  1526→    if err != nil {\n  1527→        return fmt.Errorf(\"open file: %w\", err)\n  1528→    }\n  1529→    defer file.Close()\n  1530→    \n  1531→    data, err := io.ReadAll(file)\n  1532→    if err != nil {\n  1533→        return fmt.Errorf(\"read file: %w\", err)\n  1534→    }\n  1535→    \n  1536→    if err := processData(data); err != nil {\n  1537→        return fmt.Errorf(\"process data: %w\", err)\n  1538→    }\n  1539→    \n  1540→    return nil\n  1541→}\n  1542→\n  1543→// Error accumulation\n  1544→var errs []error\n  1545→\n  1546→for _, item := range items {\n  1547→    if err := process(item); err != nil {\n  1548→        errs = append(errs, err)\n  1549→    }\n  1550→}\n  1551→\n  1552→if len(errs) > 0 {\n  1553→    return fmt.Errorf(\"processing failed with %d errors\", len(errs))\n  1554→}\n  1555→\n  1556→// Retry pattern\n  1557→func retryOperation(maxAttempts int) error {\n  1558→    var lastErr error\n  1559→    \n  1560→    for i := 0; i < maxAttempts; i++ {\n  1561→        if err := attemptOperation(); err != nil {\n  1562→            lastErr = err\n  1563→            time.Sleep(time.Second * time.Duration(i+1))\n  1564→            continue\n  1565→        }\n  1566→        return nil  // Success\n  1567→    }\n  1568→    \n  1569→    return fmt.Errorf(\"failed after %d attempts: %w\", maxAttempts, lastErr)\n  1570→}\n  1571→\n  1572→// Cleanup on error\n  1573→func createResources() (err error) {\n  1574→    resource1, err := createResource1()\n  1575→    if err != nil {\n  1576→        return err\n  1577→    }\n  1578→    defer func() {\n  1579→        if err != nil {\n  1580→            resource1.Cleanup()\n  1581→        }\n  1582→    }()\n  1583→    \n  1584→    resource2, err := createResource2()\n  1585→    if err != nil {\n  1586→        return err  // resource1 cleaned up by defer\n  1587→    }\n  1588→    \n  1589→    return nil\n  1590→}\n  1591→```\n  1592→\n  1593→## Packages and Modules\n  1594→\n  1595→### Package Organization\n  1596→\n  1597→```go\n  1598→// Package declaration (first non-comment line)\n  1599→package mypackage\n  1600→\n  1601→// Package documentation\n  1602→// Package mypackage provides utilities for data processing.\n  1603→// It includes functions for parsing, validation, and transformation.\n  1604→package mypackage\n  1605→\n  1606→// Import statements\n  1607→import (\n  1608→    \"fmt\"           // Standard library\n  1609→    \"time\"\n  1610→    \n  1611→    \"github.com/pkg/errors\"  // External packages\n  1612→    \n  1613→    \"myproject/internal/utils\"  // Internal packages\n  1614→)\n  1615→\n  1616→// Import aliasing\n  1617→import (\n  1618→    \"context\"\n  1619→    stdlog \"log\"  // Alias to avoid conflicts\n  1620→    . \"math\"      // Dot import (use sparingly)\n  1621→    _ \"image/png\" // Import for side effects only\n  1622→)\n  1623→\n  1624→// Package initialization\n  1625→func init() {\n  1626→    // Runs when package is imported\n  1627→    // Can have multiple init functions\n  1628→    fmt.Println(\"Package initialized\")\n  1629→}\n  1630→\n  1631→// Exported (public) - uppercase\n  1632→func PublicFunction() {}\n  1633→type PublicType struct{}\n  1634→const PublicConst = 42\n  1635→var PublicVar = \"hello\"\n  1636→\n  1637→// Unexported (private) - lowercase\n  1638→func privateFunction() {}\n  1639→type privateType struct{}\n  1640→const privateConst = 42\n  1641→var privateVar = \"hello\"\n  1642→```\n  1643→\n  1644→### Module Management\n  1645→\n  1646→```bash\n  1647→# Initialize module\n  1648→go mod init github.com/username/projectname\n  1649→\n  1650→# Add dependencies\n  1651→go get github.com/pkg/errors\n  1652→go get github.com/stretchr/testify@v1.8.0\n  1653→\n  1654→# Update dependencies\n  1655→go get -u ./...              # Update all\n  1656→go get -u github.com/pkg/errors  # Update specific\n  1657→\n  1658→# Clean up\n  1659→go mod tidy  # Remove unused dependencies\n  1660→\n  1661→# Vendor dependencies\n  1662→go mod vendor  # Copy dependencies to vendor/\n  1663→\n  1664→# Module directives in go.mod\n  1665→module github.com/username/project\n  1666→\n  1667→go 1.21\n  1668→\n  1669→require (\n  1670→    github.com/pkg/errors v0.9.1\n  1671→    github.com/stretchr/testify v1.8.0\n  1672→)\n  1673→\n  1674→replace github.com/old/package => github.com/new/package v1.0.0\n  1675→\n  1676→exclude github.com/bad/package v1.0.0\n  1677→```\n  1678→\n  1679→### Internal Packages\n  1680→\n  1681→```go\n  1682→// Internal packages can only be imported by nearby code\n  1683→myproject/\n  1684→├── cmd/\n  1685→│   └── app/\n  1686→│       └── main.go  // Can import internal/\n  1687→├── internal/\n  1688→│   ├── database/    // Only accessible within myproject\n  1689→│   └── utils/\n  1690→├── pkg/             // Public packages\n  1691→│   └── api/\n  1692→└── go.mod\n  1693→\n  1694→// This import works in myproject\n  1695→import \"myproject/internal/database\"\n  1696→\n  1697→// This import fails outside myproject\n  1698→import \"github.com/other/project/internal/database\"  // Error\n  1699→```\n  1700→\n  1701→## Type Assertions and Type Switches\n  1702→\n  1703→### Type Assertions\n  1704→\n  1705→```go\n  1706→// Basic type assertion\n  1707→var i interface{} = \"hello\"\n  1708→s := i.(string)  // Panics if not string\n  1709→fmt.Println(s)\n  1710→\n  1711→// Safe type assertion\n  1712→s, ok := i.(string)\n  1713→if !ok {\n  1714→    fmt.Println(\"Not a string\")\n  1715→}\n  1716→\n  1717→// Common patterns\n  1718→func processValue(v interface{}) {\n  1719→    // Try multiple types\n  1720→    switch value := v.(type) {\n  1721→    case string:\n  1722→        fmt.Printf(\"String: %s\\n\", value)\n  1723→    case int:\n  1724→        fmt.Printf(\"Integer: %d\\n\", value)\n  1725→    case []byte:\n  1726→        fmt.Printf(\"Bytes: %s\\n\", string(value))\n  1727→    default:\n  1728→        fmt.Printf(\"Unknown: %T\\n\", value)\n  1729→    }\n  1730→}\n  1731→\n  1732→// Check for interface implementation\n  1733→type Stringer interface {\n  1734→    String() string\n  1735→}\n  1736→\n  1737→func toString(v interface{}) string {\n  1738→    if s, ok := v.(Stringer); ok {\n  1739→        return s.String()\n  1740→    }\n  1741→    return fmt.Sprintf(\"%v\", v)\n  1742→}\n  1743→\n  1744→// Nil interface gotcha\n  1745→var p *Person  // nil pointer\n  1746→var i interface{} = p\n  1747→\n  1748→if i == nil {\n  1749→    fmt.Println(\"i is nil\")  // Won't print!\n  1750→}\n  1751→\n  1752→if p == nil {\n  1753→    fmt.Println(\"p is nil\")  // Will print\n  1754→}\n  1755→```\n  1756→\n  1757→## Embedding and Composition\n  1758→\n  1759→### Struct Embedding\n  1760→\n  1761→```go\n  1762→// Base types\n  1763→type Person struct {\n  1764→    Name string\n  1765→    Age  int\n  1766→}\n  1767→\n  1768→type Address struct {\n  1769→    Street string\n  1770→    City   string\n  1771→}\n  1772→\n  1773→// Embedding\n  1774→type Employee struct {\n  1775→    Person      // Anonymous field\n  1776→    Address     // Another anonymous field\n  1777→    Department string\n  1778→    Salary     float64\n  1779→}\n  1780→\n  1781→emp := Employee{\n  1782→    Person:     Person{Name: \"Alice\", Age: 30},\n  1783→    Address:    Address{City: \"New York\"},\n  1784→    Department: \"Engineering\",\n  1785→}\n  1786→\n  1787→// Field promotion\n  1788→fmt.Println(emp.Name)  // Accessed directly\n  1789→fmt.Println(emp.City)\n  1790→\n  1791→// Method promotion\n  1792→func (p Person) Introduce() {\n  1793→    fmt.Printf(\"Hi, I'm %s\\n\", p.Name)\n  1794→}\n  1795→\n  1796→emp.Introduce()  // Method promoted from Person\n  1797→\n  1798→// Shadowing\n  1799→type Manager struct {\n  1800→    Employee\n  1801→    Name string  // Shadows Person.Name\n  1802→}\n  1803→\n  1804→mgr := Manager{\n  1805→    Employee: emp,\n  1806→    Name:     \"Manager Name\",  // This shadows Employee.Person.Name\n  1807→}\n  1808→\n  1809→fmt.Println(mgr.Name)              // \"Manager Name\"\n  1810→fmt.Println(mgr.Employee.Name)     // \"Alice\"\n  1811→fmt.Println(mgr.Employee.Person.Name)  // \"Alice\"\n  1812→```\n  1813→\n  1814→### Interface Embedding\n  1815→\n  1816→```go\n  1817→// Base interfaces\n  1818→type Reader interface {\n  1819→    Read([]byte) (int, error)\n  1820→}\n  1821→\n  1822→type Writer interface {\n  1823→    Write([]byte) (int, error)\n  1824→}\n  1825→\n  1826→type Closer interface {\n  1827→    Close() error\n  1828→}\n  1829→\n  1830→// Embedded interfaces\n  1831→type ReadWriter interface {\n  1832→    Reader\n  1833→    Writer\n  1834→}\n  1835→\n  1836→type ReadWriteCloser interface {\n  1837→    Reader\n  1838→    Writer\n  1839→    Closer\n  1840→}\n  1841→\n  1842→// Alternative syntax\n  1843→type ReadWriteCloser interface {\n  1844→    Read([]byte) (int, error)\n  1845→    Write([]byte) (int, error)\n  1846→    Close() error\n  1847→}\n  1848→\n  1849→// Implementation\n  1850→type File struct {\n  1851→    // fields\n  1852→}\n  1853→\n  1854→func (f *File) Read(p []byte) (int, error) {\n  1855→    // implementation\n  1856→}\n  1857→\n  1858→func (f *File) Write(p []byte) (int, error) {\n  1859→    // implementation\n  1860→}\n  1861→\n  1862→func (f *File) Close() error {\n  1863→    // implementation\n  1864→}\n  1865→\n  1866→// File now implements ReadWriteCloser\n  1867→var rwc ReadWriteCloser = &File{}\n  1868→```\n  1869→\n  1870→## Generics\n  1871→\n  1872→### Generic Functions\n  1873→\n  1874→```go\n  1875→// Generic function with type parameter\n  1876→func Max[T comparable](a, b T) T {\n  1877→    if a > b {\n  1878→        return a\n  1879→    }\n  1880→    return b\n  1881→}\n  1882→\n  1883→// Usage\n  1884→maxInt := Max(10, 20)           // Type inferred\n  1885→maxFloat := Max[float64](3.14, 2.71)  // Explicit type\n  1886→\n  1887→// Multiple type parameters\n  1888→func Swap[T, U any](a T, b U) (U, T) {\n  1889→    return b, a\n  1890→}\n  1891→\n  1892→// Type constraints\n  1893→type Number interface {\n  1894→    int | int32 | int64 | float32 | float64\n  1895→}\n  1896→\n  1897→func Sum[T Number](numbers []T) T {\n  1898→    var sum T\n  1899→    for _, n := range numbers {\n  1900→        sum += n\n  1901→    }\n  1902→    return sum\n  1903→}\n  1904→\n  1905→// Using standard constraints\n  1906→import \"golang.org/x/exp/constraints\"\n  1907→\n  1908→func Min[T constraints.Ordered](a, b T) T {\n  1909→    if a < b {\n  1910→        return a\n  1911→    }\n  1912→    return b\n  1913→}\n  1914→```\n  1915→\n  1916→### Generic Types\n  1917→\n  1918→```go\n  1919→// Generic struct\n  1920→type Stack[T any] struct {\n  1921→    items []T\n  1922→}\n  1923→\n  1924→func (s *Stack[T]) Push(item T) {\n  1925→    s.items = append(s.items, item)\n  1926→}\n  1927→\n  1928→func (s *Stack[T]) Pop() (T, bool) {\n  1929→    var zero T\n  1930→    if len(s.items) == 0 {\n  1931→        return zero, false\n  1932→    }\n  1933→    item := s.items[len(s.items)-1]\n  1934→    s.items = s.items[:len(s.items)-1]\n  1935→    return item, true\n  1936→}\n  1937→\n  1938→// Usage\n  1939→intStack := Stack[int]{}\n  1940→intStack.Push(42)\n  1941→value, ok := intStack.Pop()\n  1942→\n  1943→// Generic interface\n  1944→type Container[T any] interface {\n  1945→    Add(T)\n  1946→    Get(int) T\n  1947→    Size() int\n  1948→}\n  1949→\n  1950→// Type inference with generics\n  1951→type Pair[T, U any] struct {\n  1952→    First  T\n  1953→    Second U\n  1954→}\n  1955→\n  1956→// Constructor function\n  1957→func NewPair[T, U any](first T, second U) Pair[T, U] {\n  1958→    return Pair[T, U]{First: first, Second: second}\n  1959→}\n  1960→\n  1961→// Type inference in use\n  1962→p := NewPair(1, \"hello\")  // Pair[int, string] inferred\n  1963→```\n  1964→\n  1965→### Type Constraints\n  1966→\n  1967→```go\n  1968→// Custom constraints\n  1969→type Signed interface {\n  1970→    ~int | ~int8 | ~int16 | ~int32 | ~int64\n  1971→}\n  1972→\n  1973→type Unsigned interface {\n  1974→    ~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64\n  1975→}\n  1976→\n  1977→type Integer interface {\n  1978→    Signed | Unsigned\n  1979→}\n  1980→\n  1981→// Tilde (~) allows underlying types\n  1982→type MyInt int\n  1983→\n  1984→func Double[T ~int](x T) T {\n  1985→    return x * 2\n  1986→}\n  1987→\n  1988→var mi MyInt = 5\n  1989→result := Double(mi)  // Works because MyInt's underlying type is int\n  1990→\n  1991→// Constraint with methods\n  1992→type Stringer interface {\n  1993→    String() string\n  1994→}\n  1995→\n  1996→func PrintAll[T Stringer](items []T) {\n  1997→    for _, item := range items {\n  1998→        fmt.Println(item.String())\n  1999→    }\n  2000→}\n  2001→\n  2002→// Complex constraints\n  2003→type Number interface {\n  2004→    ~int | ~int8 | ~int16 | ~int32 | ~int64 |\n  2005→    ~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64 |\n  2006→    ~float32 | ~float64\n  2007→}\n  2008→\n  2009→type Addable[T any] interface {\n  2010→    Add(T) T\n  2011→}\n  2012→\n  2013→type AddableNumber[T Number] interface {\n  2014→    Number\n  2015→    Addable[T]\n  2016→}\n  2017→```\n  2018→\n  2019→## Best Practices Summary\n  2020→\n  2021→### Code Organization\n  2022→- Keep packages small and focused\n  2023→- Use clear, descriptive names\n  2024→- Group related functionality\n  2025→- Minimize package dependencies\n  2026→- Use internal packages for private code\n  2027→\n  2028→### Error Handling\n  2029→- Always check errors\n  2030→- Wrap errors with context\n  2031→- Use sentinel errors for known conditions\n  2032→- Create custom error types when needed\n  2033→- Handle errors at the appropriate level\n  2034→\n  2035→### Concurrency\n  2036→- Don't communicate by sharing memory; share memory by communicating\n  2037→- Use channels for coordination\n  2038→- Keep goroutines simple\n  2039→- Always handle goroutine cleanup\n  2040→- Use context for cancellation\n  2041→\n  2042→### Performance\n  2043→- Measure before optimizing\n  2044→- Preallocate slices when size is known\n  2045→- Use string.Builder for string concatenation\n  2046→- Be aware of memory allocations\n  2047→- Profile your code\n  2048→\n  2049→### Testing\n  2050→- Write table-driven tests\n  2051→- Test edge cases\n  2052→- Use subtests for better organization\n  2053→- Mock external dependencies\n  2054→- Aim for high test coverage\n  2055→\n  2056→### Documentation\n  2057→- Document all exported items\n  2058→- Write clear package documentation\n  2059→- Include examples in documentation\n  2060→- Keep comments up to date\n  2061→- Use godoc format\n  2062→\n  2063→This comprehensive guide covers the fundamental aspects of Go programming. Each topic includes practical examples and best practices to help write idiomatic, efficient Go code.\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"ec955ed0-c137-4fb1-b409-b9a3eb89e0a8","timestamp":"2025-08-13T09:59:00.955Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/fundamentals.md","content":"# Go Language Fundamentals - Complete Reference\n\n## Table of Contents\n1. [Introduction](#introduction)\n2. [Basic Syntax](#basic-syntax)\n3. [Variables and Constants](#variables-and-constants)\n4. [Data Types](#data-types)\n5. [Control Flow](#control-flow)\n6. [Functions](#functions)\n7. [Methods](#methods)\n8. [Structs](#structs)\n9. [Interfaces](#interfaces)\n10. [Pointers](#pointers)\n11. [Arrays and Slices](#arrays-and-slices)\n12. [Maps](#maps)\n13. [Error Handling](#error-handling)\n14. [Packages and Modules](#packages-and-modules)\n15. [Type Assertions and Type Switches](#type-assertions-and-type-switches)\n16. [Embedding and Composition](#embedding-and-composition)\n17. [Generics](#generics)\n\n## Introduction\n\nGo is a statically typed, compiled language designed for simplicity, efficiency, and reliable software. Created at Google in 2007 by Robert Griesemer, Rob Pike, and Ken Thompson, Go combines the performance of compiled languages with the ease of programming of dynamic languages.\n\n### Core Philosophy\n- **Simplicity**: Less is exponentially more\n- **Readability**: Code is read more often than written\n- **Efficiency**: Fast compilation, fast execution\n- **Concurrency**: Built-in primitives for concurrent programming\n- **Pragmatism**: Solve real problems with practical solutions\n\n## Basic Syntax\n\n### Program Structure\n\nEvery Go program starts with a package declaration and imports:\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"strings\"\n    \"time\"\n)\n\nfunc main() {\n    fmt.Println(\"Hello, Go!\")\n}\n```\n\n### Comments\n\n```go\n// Single-line comment\n\n/*\n   Multi-line comment\n   Can span multiple lines\n*/\n\n// Package documentation comment (must precede package declaration)\n// Package math provides basic mathematical functions.\npackage math\n\n// Function documentation (must precede function declaration)\n// Add returns the sum of two integers.\nfunc Add(a, b int) int {\n    return a + b\n}\n```\n\n### Naming Conventions\n\n```go\n// Exported (public) - starts with uppercase\ntype Strategy struct{}\nfunc CalculateProfit() {}\nconst MaxRetries = 3\nvar DefaultTimeout = 5 * time.Second\n\n// Unexported (private) - starts with lowercase\ntype position struct{}\nfunc calculateLoss() {}\nconst maxAttempts = 5\nvar defaultBuffer = 1024\n\n// Package names - lowercase, single word\npackage trading  // Good\npackage tradingEngine  // Bad - use trading or engine\n\n// Interface names - typically end with -er\ntype Reader interface{}\ntype Writer interface{}\ntype Closer interface{}\ntype ReadWriteCloser interface{}  // Composition\n\n// Acronyms - keep consistent case\nvar httpClient HTTP  // Bad\nvar HTTPClient HTTP  // Good\nvar xmlParser XML    // Bad\nvar XMLParser XML    // Good\n```\n\n## Variables and Constants\n\n### Variable Declaration\n\n```go\n// var declaration with type\nvar name string\nvar age int\nvar balance float64\n\n// var declaration with initialization\nvar name string = \"John\"\nvar age int = 30\nvar balance = 1000.50  // Type inferred\n\n// Short variable declaration (only inside functions)\nname := \"John\"\nage := 30\nbalance := 1000.50\n\n// Multiple variable declaration\nvar (\n    firstName string = \"John\"\n    lastName  string = \"Doe\"\n    age       int    = 30\n)\n\n// Multiple assignment\nx, y := 10, 20\na, b = b, a  // Swap values\n\n// Blank identifier for unused values\n_, err := someFunction()  // Ignore first return value\n```\n\n### Constants\n\n```go\n// Single constant\nconst Pi = 3.14159\nconst MaxRetries = 3\nconst Message = \"Hello\"\n\n// Typed constants\nconst MaxInt int = 1000\nconst Timeout time.Duration = 5 * time.Second\n\n// Multiple constants\nconst (\n    StatusOK       = 200\n    StatusNotFound = 404\n    StatusError    = 500\n)\n\n// iota - constant generator\nconst (\n    Sunday = iota  // 0\n    Monday         // 1\n    Tuesday        // 2\n    Wednesday      // 3\n    Thursday       // 4\n    Friday         // 5\n    Saturday       // 6\n)\n\n// iota with expressions\nconst (\n    _  = iota             // 0 (ignored)\n    KB = 1 << (10 * iota) // 1024\n    MB                    // 1048576\n    GB                    // 1073741824\n    TB                    // 1099511627776\n)\n\n// Bit flags with iota\nconst (\n    ReadPermission = 1 << iota  // 1\n    WritePermission              // 2\n    ExecutePermission            // 4\n)\n```\n\n## Data Types\n\n### Basic Types\n\n```go\n// Boolean\nvar isActive bool = true\nvar isComplete bool  // Zero value: false\n\n// Integers\nvar i8 int8 = 127                    // -128 to 127\nvar i16 int16 = 32767                // -32768 to 32767\nvar i32 int32 = 2147483647           // -2147483648 to 2147483647\nvar i64 int64 = 9223372036854775807  // -9223372036854775808 to 9223372036854775807\nvar i int = 42                       // Platform dependent (32 or 64 bit)\n\n// Unsigned integers\nvar ui8 uint8 = 255                  // 0 to 255 (byte is alias)\nvar ui16 uint16 = 65535              // 0 to 65535\nvar ui32 uint32 = 4294967295         // 0 to 4294967295\nvar ui64 uint64 = 18446744073709551615  // 0 to 18446744073709551615\nvar ui uint = 42                     // Platform dependent\n\n// Floating point\nvar f32 float32 = 3.14               // IEEE-754 32-bit\nvar f64 float64 = 3.141592653589793  // IEEE-754 64-bit\n\n// Complex numbers\nvar c64 complex64 = 1 + 2i           // float32 real and imaginary\nvar c128 complex128 = 1 + 2i         // float64 real and imaginary\n\n// Strings\nvar str string = \"Hello, Go!\"        // UTF-8 encoded\nvar multiline = `This is\na multiline\nstring`                               // Raw string literal\n\n// Rune (Unicode code point)\nvar r rune = 'A'                     // int32 alias\nvar emoji rune = '😀'\n\n// Byte\nvar b byte = 65                      // uint8 alias\n```\n\n### Type Conversions\n\n```go\n// Explicit type conversion required\nvar i int = 42\nvar f float64 = float64(i)\nvar u uint = uint(i)\n\n// String conversions\nimport \"strconv\"\n\n// Int to string\ns := strconv.Itoa(42)\ns := strconv.FormatInt(42, 10)  // base 10\n\n// String to int\ni, err := strconv.Atoi(\"42\")\ni64, err := strconv.ParseInt(\"42\", 10, 64)\n\n// Float to string\ns := strconv.FormatFloat(3.14, 'f', 2, 64)  // 2 decimal places\n\n// String to float\nf, err := strconv.ParseFloat(\"3.14\", 64)\n\n// Type assertions (for interfaces)\nvar x interface{} = \"hello\"\ns := x.(string)  // Panics if x is not string\ns, ok := x.(string)  // Safe assertion with ok check\n```\n\n### Zero Values\n\n```go\n// All types have zero values\nvar b bool        // false\nvar i int         // 0\nvar f float64     // 0.0\nvar s string      // \"\"\nvar p *int        // nil\nvar a []int       // nil\nvar m map[string]int  // nil\nvar c chan int    // nil\nvar fn func()     // nil\nvar iface error   // nil\n```\n\n## Control Flow\n\n### If Statements\n\n```go\n// Basic if\nif x > 0 {\n    fmt.Println(\"Positive\")\n}\n\n// If-else\nif x > 0 {\n    fmt.Println(\"Positive\")\n} else {\n    fmt.Println(\"Non-positive\")\n}\n\n// If-else if-else\nif x > 0 {\n    fmt.Println(\"Positive\")\n} else if x < 0 {\n    fmt.Println(\"Negative\")\n} else {\n    fmt.Println(\"Zero\")\n}\n\n// If with initialization\nif err := doSomething(); err != nil {\n    return err  // err is scoped to if block\n}\n\n// Common patterns\n// Check error immediately\nif err != nil {\n    return fmt.Errorf(\"failed to process: %w\", err)\n}\n\n// Check boolean\nif !isValid {\n    return errors.New(\"invalid input\")\n}\n\n// Check nil\nif data == nil {\n    return errors.New(\"data is nil\")\n}\n```\n\n### Switch Statements\n\n```go\n// Basic switch\nswitch day {\ncase \"Monday\":\n    fmt.Println(\"Start of work week\")\ncase \"Friday\":\n    fmt.Println(\"TGIF!\")\ncase \"Saturday\", \"Sunday\":\n    fmt.Println(\"Weekend!\")\ndefault:\n    fmt.Println(\"Midweek\")\n}\n\n// Switch with no expression (like if-else chain)\nswitch {\ncase x < 0:\n    fmt.Println(\"Negative\")\ncase x == 0:\n    fmt.Println(\"Zero\")\ncase x > 0:\n    fmt.Println(\"Positive\")\n}\n\n// Switch with initialization\nswitch os := runtime.GOOS; os {\ncase \"darwin\":\n    fmt.Println(\"macOS\")\ncase \"linux\":\n    fmt.Println(\"Linux\")\ndefault:\n    fmt.Printf(\"Unknown OS: %s\\n\", os)\n}\n\n// Type switch\nfunc describe(i interface{}) {\n    switch v := i.(type) {\n    case int:\n        fmt.Printf(\"Integer: %d\\n\", v)\n    case string:\n        fmt.Printf(\"String: %s\\n\", v)\n    case bool:\n        fmt.Printf(\"Boolean: %t\\n\", v)\n    case nil:\n        fmt.Println(\"nil value\")\n    default:\n        fmt.Printf(\"Unknown type: %T\\n\", v)\n    }\n}\n\n// Fallthrough (rarely used)\nswitch num {\ncase 1:\n    fmt.Println(\"One\")\n    fallthrough  // Continue to next case\ncase 2:\n    fmt.Println(\"One or Two\")\n}\n```\n\n### Loops\n\n```go\n// For loop - traditional\nfor i := 0; i < 10; i++ {\n    fmt.Println(i)\n}\n\n// For loop - while style\ncount := 0\nfor count < 10 {\n    fmt.Println(count)\n    count++\n}\n\n// Infinite loop\nfor {\n    // Break or return to exit\n    if condition {\n        break\n    }\n}\n\n// Range over slice\nnumbers := []int{1, 2, 3, 4, 5}\nfor index, value := range numbers {\n    fmt.Printf(\"%d: %d\\n\", index, value)\n}\n\n// Range over slice - values only\nfor _, value := range numbers {\n    fmt.Println(value)\n}\n\n// Range over slice - indices only\nfor index := range numbers {\n    fmt.Println(index)\n}\n\n// Range over map\nages := map[string]int{\"Alice\": 30, \"Bob\": 25}\nfor name, age := range ages {\n    fmt.Printf(\"%s is %d years old\\n\", name, age)\n}\n\n// Range over string (gives runes)\nfor index, runeValue := range \"Hello, 世界\" {\n    fmt.Printf(\"%d: %c\\n\", index, runeValue)\n}\n\n// Range over channel\nch := make(chan int)\ngo func() {\n    for i := 0; i < 5; i++ {\n        ch <- i\n    }\n    close(ch)\n}()\nfor value := range ch {\n    fmt.Println(value)\n}\n\n// Continue and break with labels\nouter:\nfor i := 0; i < 3; i++ {\n    for j := 0; j < 3; j++ {\n        if i == 1 && j == 1 {\n            break outer  // Break outer loop\n        }\n        fmt.Printf(\"(%d, %d) \", i, j)\n    }\n}\n```\n\n### Defer, Panic, and Recover\n\n```go\n// Defer - executes when function returns\nfunc readFile(filename string) error {\n    file, err := os.Open(filename)\n    if err != nil {\n        return err\n    }\n    defer file.Close()  // Executed when function returns\n    \n    // Read file...\n    return nil\n}\n\n// Multiple defers - LIFO order\nfunc example() {\n    defer fmt.Println(\"Third\")\n    defer fmt.Println(\"Second\")\n    defer fmt.Println(\"First\")\n    // Prints: First, Second, Third\n}\n\n// Defer with arguments - evaluated immediately\nfunc deferArgs() {\n    i := 0\n    defer fmt.Println(i)  // Prints 0, not 1\n    i++\n}\n\n// Defer with closure - captures variables\nfunc deferClosure() {\n    i := 0\n    defer func() {\n        fmt.Println(i)  // Prints 1\n    }()\n    i++\n}\n\n// Panic - runtime error\nfunc divide(a, b int) int {\n    if b == 0 {\n        panic(\"division by zero\")\n    }\n    return a / b\n}\n\n// Recover - catch panic\nfunc safeFunction() {\n    defer func() {\n        if r := recover(); r != nil {\n            fmt.Printf(\"Recovered from panic: %v\\n\", r)\n        }\n    }()\n    \n    // Code that might panic\n    panic(\"something went wrong\")\n}\n\n// Practical error recovery pattern\nfunc robustFunction() (err error) {\n    defer func() {\n        if r := recover(); r != nil {\n            err = fmt.Errorf(\"panic recovered: %v\", r)\n        }\n    }()\n    \n    // Potentially panicking code\n    return nil\n}\n```\n\n## Functions\n\n### Function Declaration\n\n```go\n// Basic function\nfunc greet() {\n    fmt.Println(\"Hello!\")\n}\n\n// Function with parameters\nfunc add(a int, b int) int {\n    return a + b\n}\n\n// Shorthand for same type parameters\nfunc add(a, b int) int {\n    return a + b\n}\n\n// Multiple return values\nfunc divide(a, b float64) (float64, error) {\n    if b == 0 {\n        return 0, errors.New(\"division by zero\")\n    }\n    return a / b, nil\n}\n\n// Named return values\nfunc getCoordinates() (x, y int) {\n    x = 10\n    y = 20\n    return  // Naked return\n}\n\n// Named returns with explicit values\nfunc calculate(a, b int) (sum, product int) {\n    sum = a + b\n    product = a * b\n    return sum, product  // Can be explicit\n}\n\n// Variadic functions\nfunc sum(numbers ...int) int {\n    total := 0\n    for _, n := range numbers {\n        total += n\n    }\n    return total\n}\n\n// Calling variadic functions\nresult := sum(1, 2, 3, 4, 5)\nnums := []int{1, 2, 3}\nresult := sum(nums...)  // Spread slice\n```\n\n### Function Types and Values\n\n```go\n// Function as type\ntype Operation func(int, int) int\n\nfunc add(a, b int) int { return a + b }\nfunc multiply(a, b int) int { return a * b }\n\nvar op Operation = add\nresult := op(5, 3)  // 8\n\n// Function as parameter\nfunc apply(op Operation, a, b int) int {\n    return op(a, b)\n}\n\nresult := apply(add, 5, 3)\nresult = apply(multiply, 5, 3)\n\n// Function returning function\nfunc makeAdder(x int) func(int) int {\n    return func(y int) int {\n        return x + y\n    }\n}\n\nadd5 := makeAdder(5)\nresult := add5(3)  // 8\n\n// Anonymous functions\nfunc() {\n    fmt.Println(\"Anonymous function\")\n}()  // Immediately invoked\n\n// Assign to variable\ngreet := func(name string) {\n    fmt.Printf(\"Hello, %s!\\n\", name)\n}\ngreet(\"World\")\n```\n\n### Closures\n\n```go\n// Closure captures variables\nfunc counter() func() int {\n    count := 0\n    return func() int {\n        count++\n        return count\n    }\n}\n\nc := counter()\nfmt.Println(c())  // 1\nfmt.Println(c())  // 2\nfmt.Println(c())  // 3\n\n// Closure in loop (common pitfall)\n// Wrong way\nfuncs := []func(){}\nfor i := 0; i < 3; i++ {\n    funcs = append(funcs, func() {\n        fmt.Println(i)  // All print 3\n    })\n}\n\n// Correct way\nfor i := 0; i < 3; i++ {\n    i := i  // Shadow variable\n    funcs = append(funcs, func() {\n        fmt.Println(i)  // Prints 0, 1, 2\n    })\n}\n\n// Alternative correct way\nfor i := 0; i < 3; i++ {\n    func(n int) {\n        funcs = append(funcs, func() {\n            fmt.Println(n)\n        })\n    }(i)\n}\n```\n\n## Methods\n\n### Method Declaration\n\n```go\n// Method on struct\ntype Rectangle struct {\n    Width, Height float64\n}\n\n// Value receiver\nfunc (r Rectangle) Area() float64 {\n    return r.Width * r.Height\n}\n\n// Pointer receiver\nfunc (r *Rectangle) Scale(factor float64) {\n    r.Width *= factor\n    r.Height *= factor\n}\n\n// Using methods\nrect := Rectangle{Width: 10, Height: 5}\narea := rect.Area()        // 50\nrect.Scale(2)              // Width=20, Height=10\n\n// Method on non-struct types\ntype MyInt int\n\nfunc (m MyInt) IsEven() bool {\n    return m%2 == 0\n}\n\nvar num MyInt = 42\nif num.IsEven() {\n    fmt.Println(\"Even number\")\n}\n\n// Method on pointer vs value\ntype Counter struct {\n    value int\n}\n\n// Value receiver - cannot modify\nfunc (c Counter) GetValue() int {\n    return c.value\n}\n\n// Pointer receiver - can modify\nfunc (c *Counter) Increment() {\n    c.value++\n}\n\n// Pointer receiver - can handle nil\nfunc (c *Counter) SafeIncrement() {\n    if c == nil {\n        return\n    }\n    c.value++\n}\n```\n\n### Method Sets\n\n```go\n// Method set rules:\n// - Type T has method set of all methods with receiver T\n// - Type *T has method set of all methods with receiver T or *T\n\ntype Shape struct {\n    Name string\n}\n\nfunc (s Shape) GetName() string {\n    return s.Name\n}\n\nfunc (s *Shape) SetName(name string) {\n    s.Name = name\n}\n\n// Value type can call value receiver methods\nshape := Shape{Name: \"Circle\"}\nname := shape.GetName()  // OK\n\n// Value type automatically gets address for pointer receiver\nshape.SetName(\"Square\")  // OK (Go converts to (&shape).SetName())\n\n// Pointer type can call both\nshapePtr := &Shape{Name: \"Triangle\"}\nname = shapePtr.GetName()  // OK\nshapePtr.SetName(\"Pentagon\")  // OK\n```\n\n## Structs\n\n### Struct Declaration and Usage\n\n```go\n// Basic struct\ntype Person struct {\n    FirstName string\n    LastName  string\n    Age       int\n}\n\n// Creating structs\np1 := Person{\n    FirstName: \"John\",\n    LastName:  \"Doe\",\n    Age:       30,\n}\n\n// Positional initialization (not recommended)\np2 := Person{\"Jane\", \"Doe\", 25}\n\n// Zero value struct\nvar p3 Person  // All fields have zero values\n\n// Accessing fields\nfmt.Println(p1.FirstName)\np1.Age = 31\n\n// Struct pointer\nptr := &Person{FirstName: \"Bob\"}\nptr.Age = 40  // Automatic dereferencing\n\n// Anonymous struct\npoint := struct {\n    X, Y int\n}{X: 10, Y: 20}\n\n// Struct tags\ntype User struct {\n    ID        int    `json:\"id\" db:\"user_id\"`\n    Email     string `json:\"email\" validate:\"required,email\"`\n    Password  string `json:\"-\"`  // Omit from JSON\n    CreatedAt time.Time `json:\"created_at,omitempty\"`\n}\n\n// Accessing tags via reflection\nimport \"reflect\"\n\nt := reflect.TypeOf(User{})\nfield, _ := t.FieldByName(\"Email\")\nfmt.Println(field.Tag.Get(\"json\"))     // \"email\"\nfmt.Println(field.Tag.Get(\"validate\")) // \"required,email\"\n```\n\n### Struct Embedding\n\n```go\n// Embedding for composition\ntype Address struct {\n    Street  string\n    City    string\n    Country string\n}\n\ntype Employee struct {\n    Person  // Embedded struct\n    Address // Another embedded struct\n    Salary  float64\n}\n\nemp := Employee{\n    Person: Person{\n        FirstName: \"Alice\",\n        LastName:  \"Smith\",\n        Age:       28,\n    },\n    Address: Address{\n        City:    \"New York\",\n        Country: \"USA\",\n    },\n    Salary: 75000,\n}\n\n// Promoted fields\nfmt.Println(emp.FirstName)  // Promoted from Person\nfmt.Println(emp.City)       // Promoted from Address\n\n// Explicit access\nfmt.Println(emp.Person.FirstName)\n\n// Method promotion\ntype Writer struct{}\n\nfunc (w Writer) Write(data []byte) (int, error) {\n    return len(data), nil\n}\n\ntype Logger struct {\n    Writer  // Embedded\n    prefix string\n}\n\nlog := Logger{prefix: \"[INFO]\"}\nlog.Write([]byte(\"message\"))  // Promoted method\n```\n\n### Struct Comparison\n\n```go\n// Structs are comparable if all fields are comparable\ntype Point struct {\n    X, Y int\n}\n\np1 := Point{1, 2}\np2 := Point{1, 2}\np3 := Point{2, 3}\n\nfmt.Println(p1 == p2)  // true\nfmt.Println(p1 == p3)  // false\n\n// Non-comparable structs (contain slices, maps, functions)\ntype Data struct {\n    Values []int  // Slices are not comparable\n}\n\n// This won't compile:\n// d1 := Data{Values: []int{1, 2}}\n// d2 := Data{Values: []int{1, 2}}\n// fmt.Println(d1 == d2)  // Compile error\n```\n\n## Interfaces\n\n### Interface Declaration and Implementation\n\n```go\n// Interface declaration\ntype Writer interface {\n    Write([]byte) (int, error)\n}\n\n// Interface with multiple methods\ntype ReadWriter interface {\n    Read([]byte) (int, error)\n    Write([]byte) (int, error)\n}\n\n// Empty interface (any type)\ntype Any interface{}  // Pre Go 1.18\ntype Any = any        // Go 1.18+\n\n// Implicit implementation\ntype FileWriter struct {\n    filename string\n}\n\nfunc (f FileWriter) Write(data []byte) (int, error) {\n    // Implementation\n    return len(data), nil\n}\n\n// FileWriter implements Writer implicitly\nvar w Writer = FileWriter{filename: \"test.txt\"}\n```\n\n### Interface Composition\n\n```go\n// Composing interfaces\ntype Reader interface {\n    Read([]byte) (int, error)\n}\n\ntype Writer interface {\n    Write([]byte) (int, error)\n}\n\ntype Closer interface {\n    Close() error\n}\n\n// Composed interface\ntype ReadWriteCloser interface {\n    Reader\n    Writer\n    Closer\n}\n\n// Alternative inline composition\ntype ReadWriter interface {\n    Read([]byte) (int, error)\n    Write([]byte) (int, error)\n}\n```\n\n### Interface Values and nil\n\n```go\n// Interface values have two components: type and value\nvar w Writer\nfmt.Printf(\"Type: %T, Value: %v\\n\", w, w)  // Type: <nil>, Value: <nil>\n\n// nil interface vs interface with nil value\ntype MyWriter struct{}\n\nfunc (m *MyWriter) Write(data []byte) (int, error) {\n    if m == nil {\n        return 0, errors.New(\"nil writer\")\n    }\n    return len(data), nil\n}\n\nvar mw *MyWriter = nil\nvar w Writer = mw\n// w is not nil (has type *MyWriter), but its value is nil\n\nif w == nil {\n    fmt.Println(\"w is nil\")  // Won't print\n}\n\n// Check for nil value\nif mw == nil {\n    fmt.Println(\"mw is nil\")  // Will print\n}\n```\n\n### Type Assertions and Type Switches\n\n```go\n// Type assertion\nvar i interface{} = \"hello\"\n\n// Direct assertion (panics if wrong type)\ns := i.(string)\nfmt.Println(s)\n\n// Safe assertion with comma-ok\ns, ok := i.(string)\nif ok {\n    fmt.Println(\"String:\", s)\n}\n\n// Check interface implementation\nvar w io.Writer = &bytes.Buffer{}\nif buf, ok := w.(*bytes.Buffer); ok {\n    fmt.Println(\"It's a buffer:\", buf)\n}\n\n// Type switch\nfunc describe(i interface{}) {\n    switch v := i.(type) {\n    case int:\n        fmt.Printf(\"Integer: %d\\n\", v)\n    case string:\n        fmt.Printf(\"String: %s\\n\", v)\n    case io.Reader:\n        fmt.Println(\"It's a reader\")\n    case nil:\n        fmt.Println(\"It's nil\")\n    default:\n        fmt.Printf(\"Unknown type: %T\\n\", v)\n    }\n}\n```\n\n### Common Interface Patterns\n\n```go\n// Stringer interface\ntype Stringer interface {\n    String() string\n}\n\ntype Point struct {\n    X, Y int\n}\n\nfunc (p Point) String() string {\n    return fmt.Sprintf(\"(%d, %d)\", p.X, p.Y)\n}\n\n// Error interface\ntype error interface {\n    Error() string\n}\n\ntype ValidationError struct {\n    Field string\n    Value string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"validation failed for field %s: %s\", e.Field, e.Value)\n}\n\n// Sort interface\ntype Interface interface {\n    Len() int\n    Less(i, j int) bool\n    Swap(i, j int)\n}\n\n// Custom sort implementation\ntype ByAge []Person\n\nfunc (a ByAge) Len() int           { return len(a) }\nfunc (a ByAge) Less(i, j int) bool { return a[i].Age < a[j].Age }\nfunc (a ByAge) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }\n\n// Usage\npeople := []Person{{Name: \"Alice\", Age: 30}, {Name: \"Bob\", Age: 25}}\nsort.Sort(ByAge(people))\n```\n\n## Pointers\n\n### Pointer Basics\n\n```go\n// Declare pointer\nvar p *int\n\n// Get address of variable\nx := 42\np = &x\n\n// Dereference pointer\nfmt.Println(*p)  // 42\n*p = 100\nfmt.Println(x)   // 100\n\n// Pointer zero value is nil\nvar ptr *string\nif ptr == nil {\n    fmt.Println(\"ptr is nil\")\n}\n\n// New function allocates memory\nptr = new(string)\n*ptr = \"Hello\"\n\n// Pointer to struct\ntype Person struct {\n    Name string\n    Age  int\n}\n\nperson := &Person{Name: \"Alice\", Age: 30}\nperson.Age = 31  // Automatic dereferencing\n\n// Pointer arithmetic is NOT allowed in Go\n// p++  // This won't compile\n```\n\n### Pointers vs Values\n\n```go\n// Pass by value\nfunc modifyValue(x int) {\n    x = 100  // Doesn't affect original\n}\n\n// Pass by pointer\nfunc modifyPointer(x *int) {\n    *x = 100  // Modifies original\n}\n\nvalue := 42\nmodifyValue(value)\nfmt.Println(value)  // Still 42\n\nmodifyPointer(&value)\nfmt.Println(value)  // Now 100\n\n// Slices, maps, channels are reference types\nfunc modifySlice(s []int) {\n    s[0] = 100  // Modifies original\n}\n\nslice := []int{1, 2, 3}\nmodifySlice(slice)\nfmt.Println(slice)  // [100, 2, 3]\n\n// But reassigning doesn't affect original\nfunc reassignSlice(s []int) {\n    s = []int{4, 5, 6}  // Doesn't affect original\n}\n\n// To modify slice itself, use pointer\nfunc replaceSlice(s *[]int) {\n    *s = []int{4, 5, 6}\n}\n```\n\n## Arrays and Slices\n\n### Arrays\n\n```go\n// Array declaration\nvar arr [5]int              // [0 0 0 0 0]\narr[0] = 10\narr[4] = 50\n\n// Array initialization\narr := [5]int{1, 2, 3, 4, 5}\narr := [...]int{1, 2, 3}    // Compiler counts elements\narr := [5]int{0: 10, 4: 50} // Index:value pairs\n\n// Arrays are values (copied on assignment)\narr1 := [3]int{1, 2, 3}\narr2 := arr1\narr2[0] = 100\nfmt.Println(arr1)  // [1 2 3] - unchanged\nfmt.Println(arr2)  // [100 2 3]\n\n// Array size is part of type\nvar a [5]int\nvar b [10]int\n// a = b  // Won't compile - different types\n\n// Multidimensional arrays\nvar matrix [3][3]int\nmatrix[1][1] = 5\n\n// Array iteration\nfor i := 0; i < len(arr); i++ {\n    fmt.Println(arr[i])\n}\n\nfor index, value := range arr {\n    fmt.Printf(\"%d: %d\\n\", index, value)\n}\n```\n\n### Slices\n\n```go\n// Slice declaration\nvar slice []int            // nil slice\nslice = []int{}           // Empty slice\nslice = []int{1, 2, 3}    // Initialized slice\n\n// Make function\nslice = make([]int, 5)    // Length 5, capacity 5\nslice = make([]int, 5, 10) // Length 5, capacity 10\n\n// Slice from array\narr := [5]int{1, 2, 3, 4, 5}\nslice = arr[1:4]  // [2 3 4]\nslice = arr[:3]   // [1 2 3]\nslice = arr[2:]   // [3 4 5]\nslice = arr[:]    // [1 2 3 4 5]\n\n// Slice properties\nfmt.Println(len(slice))  // Length\nfmt.Println(cap(slice))  // Capacity\n\n// Append\nslice = []int{1, 2, 3}\nslice = append(slice, 4)\nslice = append(slice, 5, 6, 7)\nslice = append(slice, []int{8, 9}...)\n\n// Copy\nsrc := []int{1, 2, 3}\ndst := make([]int, len(src))\nn := copy(dst, src)  // Returns number copied\n\n// Slice tricks\n// Remove element at index i\nslice = append(slice[:i], slice[i+1:]...)\n\n// Insert element at index i\nslice = append(slice[:i], append([]int{x}, slice[i:]...)...)\n\n// Pop from end\nx := slice[len(slice)-1]\nslice = slice[:len(slice)-1]\n\n// Push to front\nslice = append([]int{x}, slice...)\n\n// Filter in place\nn := 0\nfor _, x := range slice {\n    if keepElement(x) {\n        slice[n] = x\n        n++\n    }\n}\nslice = slice[:n]\n```\n\n### Slice Internals\n\n```go\n// Slice header (conceptual)\ntype SliceHeader struct {\n    Data uintptr  // Pointer to underlying array\n    Len  int      // Current length\n    Cap  int      // Capacity\n}\n\n// Slices share underlying array\noriginal := []int{1, 2, 3, 4, 5}\nslice1 := original[1:4]  // [2 3 4]\nslice2 := original[2:5]  // [3 4 5]\n\nslice1[1] = 100  // Modifies shared array\nfmt.Println(slice2)  // [100 4 5]\n\n// Full slice expression controls capacity\nslice := original[1:3:4]  // [low:high:max]\n// len = high - low = 2\n// cap = max - low = 3\n\n// nil vs empty slice\nvar nilSlice []int        // nil\nemptySlice := []int{}     // Not nil, but empty\nmadeSlice := make([]int, 0) // Not nil, but empty\n\nfmt.Println(nilSlice == nil)    // true\nfmt.Println(emptySlice == nil)  // false\nfmt.Println(len(nilSlice))      // 0\nfmt.Println(len(emptySlice))    // 0\n\n// Both work with append\nnilSlice = append(nilSlice, 1)\nemptySlice = append(emptySlice, 1)\n```\n\n## Maps\n\n### Map Basics\n\n```go\n// Map declaration\nvar m map[string]int      // nil map\nm = make(map[string]int)  // Initialize\n\n// Map literal\nm = map[string]int{\n    \"Alice\": 30,\n    \"Bob\":   25,\n}\n\n// Operations\nm[\"Charlie\"] = 35         // Insert/Update\nage := m[\"Alice\"]         // Retrieve\ndelete(m, \"Bob\")          // Delete\n\n// Check if key exists\nage, exists := m[\"David\"]\nif exists {\n    fmt.Printf(\"David is %d years old\\n\", age)\n}\n\n// Zero value for missing key\nfmt.Println(m[\"Unknown\"])  // 0 (zero value for int)\n\n// Iteration (order is random)\nfor key, value := range m {\n    fmt.Printf(\"%s: %d\\n\", key, value)\n}\n\n// Keys only\nfor key := range m {\n    fmt.Println(key)\n}\n\n// Values only\nfor _, value := range m {\n    fmt.Println(value)\n}\n```\n\n### Map Patterns\n\n```go\n// Map as set\nset := make(map[string]bool)\nset[\"apple\"] = true\nset[\"banana\"] = true\n\nif set[\"apple\"] {\n    fmt.Println(\"apple is in the set\")\n}\n\n// Alternative set using empty struct (memory efficient)\ntype void struct{}\nvar member void\n\nset := make(map[string]void)\nset[\"apple\"] = member\nset[\"banana\"] = member\n\nif _, exists := set[\"apple\"]; exists {\n    fmt.Println(\"apple is in the set\")\n}\n\n// Counting with maps\ncounts := make(map[string]int)\nwords := []string{\"apple\", \"banana\", \"apple\", \"orange\", \"banana\", \"apple\"}\n\nfor _, word := range words {\n    counts[word]++  // Works even if key doesn't exist\n}\n\n// Grouping with maps\ntype Person struct {\n    Name string\n    Age  int\n}\n\npeople := []Person{\n    {\"Alice\", 30},\n    {\"Bob\", 25},\n    {\"Charlie\", 30},\n    {\"David\", 25},\n}\n\nageGroups := make(map[int][]Person)\nfor _, person := range people {\n    ageGroups[person.Age] = append(ageGroups[person.Age], person)\n}\n\n// Map of maps\nnested := make(map[string]map[string]int)\nnested[\"scores\"] = make(map[string]int)\nnested[\"scores\"][\"Alice\"] = 95\nnested[\"scores\"][\"Bob\"] = 87\n\n// Safe nested access\nif scores, ok := nested[\"scores\"]; ok {\n    if score, ok := scores[\"Alice\"]; ok {\n        fmt.Printf(\"Alice's score: %d\\n\", score)\n    }\n}\n```\n\n### Maps and Concurrency\n\n```go\n// Maps are not safe for concurrent access\n// Use sync.Map or mutex\n\nimport \"sync\"\n\n// With mutex\ntype SafeMap struct {\n    mu sync.RWMutex\n    m  map[string]int\n}\n\nfunc (sm *SafeMap) Set(key string, value int) {\n    sm.mu.Lock()\n    defer sm.mu.Unlock()\n    sm.m[key] = value\n}\n\nfunc (sm *SafeMap) Get(key string) (int, bool) {\n    sm.mu.RLock()\n    defer sm.mu.RUnlock()\n    value, exists := sm.m[key]\n    return value, exists\n}\n\n// Using sync.Map (for specific use cases)\nvar m sync.Map\n\n// Store\nm.Store(\"key\", \"value\")\n\n// Load\nvalue, ok := m.Load(\"key\")\n\n// LoadOrStore\nactual, loaded := m.LoadOrStore(\"key\", \"new-value\")\n\n// Delete\nm.Delete(\"key\")\n\n// Range\nm.Range(func(key, value interface{}) bool {\n    fmt.Printf(\"%v: %v\\n\", key, value)\n    return true  // Continue iteration\n})\n```\n\n## Error Handling\n\n### Error Interface\n\n```go\n// Error interface\ntype error interface {\n    Error() string\n}\n\n// Creating errors\nimport \"errors\"\n\nerr := errors.New(\"something went wrong\")\nerr := fmt.Errorf(\"failed to process %s: %v\", filename, originalErr)\n\n// Custom error types\ntype ValidationError struct {\n    Field string\n    Value interface{}\n    Msg   string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"validation error: field=%s value=%v msg=%s\", \n        e.Field, e.Value, e.Msg)\n}\n\n// Sentinel errors\nvar (\n    ErrNotFound   = errors.New(\"not found\")\n    ErrPermission = errors.New(\"permission denied\")\n    ErrTimeout    = errors.New(\"operation timed out\")\n)\n\n// Error wrapping (Go 1.13+)\noriginalErr := errors.New(\"original error\")\nwrappedErr := fmt.Errorf(\"wrapped: %w\", originalErr)\n\n// Unwrap errors\nif errors.Is(wrappedErr, originalErr) {\n    fmt.Println(\"Error is originalErr\")\n}\n\nvar validationErr ValidationError\nif errors.As(wrappedErr, &validationErr) {\n    fmt.Printf(\"Validation error: %s\\n\", validationErr.Field)\n}\n```\n\n### Error Handling Patterns\n\n```go\n// Immediate error checking\nresult, err := doSomething()\nif err != nil {\n    return fmt.Errorf(\"doSomething failed: %w\", err)\n}\n\n// Multiple error sources\nfunc processFile(filename string) error {\n    file, err := os.Open(filename)\n    if err != nil {\n        return fmt.Errorf(\"open file: %w\", err)\n    }\n    defer file.Close()\n    \n    data, err := io.ReadAll(file)\n    if err != nil {\n        return fmt.Errorf(\"read file: %w\", err)\n    }\n    \n    if err := processData(data); err != nil {\n        return fmt.Errorf(\"process data: %w\", err)\n    }\n    \n    return nil\n}\n\n// Error accumulation\nvar errs []error\n\nfor _, item := range items {\n    if err := process(item); err != nil {\n        errs = append(errs, err)\n    }\n}\n\nif len(errs) > 0 {\n    return fmt.Errorf(\"processing failed with %d errors\", len(errs))\n}\n\n// Retry pattern\nfunc retryOperation(maxAttempts int) error {\n    var lastErr error\n    \n    for i := 0; i < maxAttempts; i++ {\n        if err := attemptOperation(); err != nil {\n            lastErr = err\n            time.Sleep(time.Second * time.Duration(i+1))\n            continue\n        }\n        return nil  // Success\n    }\n    \n    return fmt.Errorf(\"failed after %d attempts: %w\", maxAttempts, lastErr)\n}\n\n// Cleanup on error\nfunc createResources() (err error) {\n    resource1, err := createResource1()\n    if err != nil {\n        return err\n    }\n    defer func() {\n        if err != nil {\n            resource1.Cleanup()\n        }\n    }()\n    \n    resource2, err := createResource2()\n    if err != nil {\n        return err  // resource1 cleaned up by defer\n    }\n    \n    return nil\n}\n```\n\n## Packages and Modules\n\n### Package Organization\n\n```go\n// Package declaration (first non-comment line)\npackage mypackage\n\n// Package documentation\n// Package mypackage provides utilities for data processing.\n// It includes functions for parsing, validation, and transformation.\npackage mypackage\n\n// Import statements\nimport (\n    \"fmt\"           // Standard library\n    \"time\"\n    \n    \"github.com/pkg/errors\"  // External packages\n    \n    \"myproject/internal/utils\"  // Internal packages\n)\n\n// Import aliasing\nimport (\n    \"context\"\n    stdlog \"log\"  // Alias to avoid conflicts\n    . \"math\"      // Dot import (use sparingly)\n    _ \"image/png\" // Import for side effects only\n)\n\n// Package initialization\nfunc init() {\n    // Runs when package is imported\n    // Can have multiple init functions\n    fmt.Println(\"Package initialized\")\n}\n\n// Exported (public) - uppercase\nfunc PublicFunction() {}\ntype PublicType struct{}\nconst PublicConst = 42\nvar PublicVar = \"hello\"\n\n// Unexported (private) - lowercase\nfunc privateFunction() {}\ntype privateType struct{}\nconst privateConst = 42\nvar privateVar = \"hello\"\n```\n\n### Module Management\n\n```bash\n# Initialize module\ngo mod init github.com/username/projectname\n\n# Add dependencies\ngo get github.com/pkg/errors\ngo get github.com/stretchr/testify@v1.8.0\n\n# Update dependencies\ngo get -u ./...              # Update all\ngo get -u github.com/pkg/errors  # Update specific\n\n# Clean up\ngo mod tidy  # Remove unused dependencies\n\n# Vendor dependencies\ngo mod vendor  # Copy dependencies to vendor/\n\n# Module directives in go.mod\nmodule github.com/username/project\n\ngo 1.21\n\nrequire (\n    github.com/pkg/errors v0.9.1\n    github.com/stretchr/testify v1.8.0\n)\n\nreplace github.com/old/package => github.com/new/package v1.0.0\n\nexclude github.com/bad/package v1.0.0\n```\n\n### Internal Packages\n\n```go\n// Internal packages can only be imported by nearby code\nmyproject/\n├── cmd/\n│   └── app/\n│       └── main.go  // Can import internal/\n├── internal/\n│   ├── database/    // Only accessible within myproject\n│   └── utils/\n├── pkg/             // Public packages\n│   └── api/\n└── go.mod\n\n// This import works in myproject\nimport \"myproject/internal/database\"\n\n// This import fails outside myproject\nimport \"github.com/other/project/internal/database\"  // Error\n```\n\n## Type Assertions and Type Switches\n\n### Type Assertions\n\n```go\n// Basic type assertion\nvar i interface{} = \"hello\"\ns := i.(string)  // Panics if not string\nfmt.Println(s)\n\n// Safe type assertion\ns, ok := i.(string)\nif !ok {\n    fmt.Println(\"Not a string\")\n}\n\n// Common patterns\nfunc processValue(v interface{}) {\n    // Try multiple types\n    switch value := v.(type) {\n    case string:\n        fmt.Printf(\"String: %s\\n\", value)\n    case int:\n        fmt.Printf(\"Integer: %d\\n\", value)\n    case []byte:\n        fmt.Printf(\"Bytes: %s\\n\", string(value))\n    default:\n        fmt.Printf(\"Unknown: %T\\n\", value)\n    }\n}\n\n// Check for interface implementation\ntype Stringer interface {\n    String() string\n}\n\nfunc toString(v interface{}) string {\n    if s, ok := v.(Stringer); ok {\n        return s.String()\n    }\n    return fmt.Sprintf(\"%v\", v)\n}\n\n// Nil interface gotcha\nvar p *Person  // nil pointer\nvar i interface{} = p\n\nif i == nil {\n    fmt.Println(\"i is nil\")  // Won't print!\n}\n\nif p == nil {\n    fmt.Println(\"p is nil\")  // Will print\n}\n```\n\n## Embedding and Composition\n\n### Struct Embedding\n\n```go\n// Base types\ntype Person struct {\n    Name string\n    Age  int\n}\n\ntype Address struct {\n    Street string\n    City   string\n}\n\n// Embedding\ntype Employee struct {\n    Person      // Anonymous field\n    Address     // Another anonymous field\n    Department string\n    Salary     float64\n}\n\nemp := Employee{\n    Person:     Person{Name: \"Alice\", Age: 30},\n    Address:    Address{City: \"New York\"},\n    Department: \"Engineering\",\n}\n\n// Field promotion\nfmt.Println(emp.Name)  // Accessed directly\nfmt.Println(emp.City)\n\n// Method promotion\nfunc (p Person) Introduce() {\n    fmt.Printf(\"Hi, I'm %s\\n\", p.Name)\n}\n\nemp.Introduce()  // Method promoted from Person\n\n// Shadowing\ntype Manager struct {\n    Employee\n    Name string  // Shadows Person.Name\n}\n\nmgr := Manager{\n    Employee: emp,\n    Name:     \"Manager Name\",  // This shadows Employee.Person.Name\n}\n\nfmt.Println(mgr.Name)              // \"Manager Name\"\nfmt.Println(mgr.Employee.Name)     // \"Alice\"\nfmt.Println(mgr.Employee.Person.Name)  // \"Alice\"\n```\n\n### Interface Embedding\n\n```go\n// Base interfaces\ntype Reader interface {\n    Read([]byte) (int, error)\n}\n\ntype Writer interface {\n    Write([]byte) (int, error)\n}\n\ntype Closer interface {\n    Close() error\n}\n\n// Embedded interfaces\ntype ReadWriter interface {\n    Reader\n    Writer\n}\n\ntype ReadWriteCloser interface {\n    Reader\n    Writer\n    Closer\n}\n\n// Alternative syntax\ntype ReadWriteCloser interface {\n    Read([]byte) (int, error)\n    Write([]byte) (int, error)\n    Close() error\n}\n\n// Implementation\ntype File struct {\n    // fields\n}\n\nfunc (f *File) Read(p []byte) (int, error) {\n    // implementation\n}\n\nfunc (f *File) Write(p []byte) (int, error) {\n    // implementation\n}\n\nfunc (f *File) Close() error {\n    // implementation\n}\n\n// File now implements ReadWriteCloser\nvar rwc ReadWriteCloser = &File{}\n```\n\n## Generics\n\n### Generic Functions\n\n```go\n// Generic function with type parameter\nfunc Max[T comparable](a, b T) T {\n    if a > b {\n        return a\n    }\n    return b\n}\n\n// Usage\nmaxInt := Max(10, 20)           // Type inferred\nmaxFloat := Max[float64](3.14, 2.71)  // Explicit type\n\n// Multiple type parameters\nfunc Swap[T, U any](a T, b U) (U, T) {\n    return b, a\n}\n\n// Type constraints\ntype Number interface {\n    int | int32 | int64 | float32 | float64\n}\n\nfunc Sum[T Number](numbers []T) T {\n    var sum T\n    for _, n := range numbers {\n        sum += n\n    }\n    return sum\n}\n\n// Using standard constraints\nimport \"golang.org/x/exp/constraints\"\n\nfunc Min[T constraints.Ordered](a, b T) T {\n    if a < b {\n        return a\n    }\n    return b\n}\n```\n\n### Generic Types\n\n```go\n// Generic struct\ntype Stack[T any] struct {\n    items []T\n}\n\nfunc (s *Stack[T]) Push(item T) {\n    s.items = append(s.items, item)\n}\n\nfunc (s *Stack[T]) Pop() (T, bool) {\n    var zero T\n    if len(s.items) == 0 {\n        return zero, false\n    }\n    item := s.items[len(s.items)-1]\n    s.items = s.items[:len(s.items)-1]\n    return item, true\n}\n\n// Usage\nintStack := Stack[int]{}\nintStack.Push(42)\nvalue, ok := intStack.Pop()\n\n// Generic interface\ntype Container[T any] interface {\n    Add(T)\n    Get(int) T\n    Size() int\n}\n\n// Type inference with generics\ntype Pair[T, U any] struct {\n    First  T\n    Second U\n}\n\n// Constructor function\nfunc NewPair[T, U any](first T, second U) Pair[T, U] {\n    return Pair[T, U]{First: first, Second: second}\n}\n\n// Type inference in use\np := NewPair(1, \"hello\")  // Pair[int, string] inferred\n```\n\n### Type Constraints\n\n```go\n// Custom constraints\ntype Signed interface {\n    ~int | ~int8 | ~int16 | ~int32 | ~int64\n}\n\ntype Unsigned interface {\n    ~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64\n}\n\ntype Integer interface {\n    Signed | Unsigned\n}\n\n// Tilde (~) allows underlying types\ntype MyInt int\n\nfunc Double[T ~int](x T) T {\n    return x * 2\n}\n\nvar mi MyInt = 5\nresult := Double(mi)  // Works because MyInt's underlying type is int\n\n// Constraint with methods\ntype Stringer interface {\n    String() string\n}\n\nfunc PrintAll[T Stringer](items []T) {\n    for _, item := range items {\n        fmt.Println(item.String())\n    }\n}\n\n// Complex constraints\ntype Number interface {\n    ~int | ~int8 | ~int16 | ~int32 | ~int64 |\n    ~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64 |\n    ~float32 | ~float64\n}\n\ntype Addable[T any] interface {\n    Add(T) T\n}\n\ntype AddableNumber[T Number] interface {\n    Number\n    Addable[T]\n}\n```\n\n## Best Practices Summary\n\n### Code Organization\n- Keep packages small and focused\n- Use clear, descriptive names\n- Group related functionality\n- Minimize package dependencies\n- Use internal packages for private code\n\n### Error Handling\n- Always check errors\n- Wrap errors with context\n- Use sentinel errors for known conditions\n- Create custom error types when needed\n- Handle errors at the appropriate level\n\n### Concurrency\n- Don't communicate by sharing memory; share memory by communicating\n- Use channels for coordination\n- Keep goroutines simple\n- Always handle goroutine cleanup\n- Use context for cancellation\n\n### Performance\n- Measure before optimizing\n- Preallocate slices when size is known\n- Use string.Builder for string concatenation\n- Be aware of memory allocations\n- Profile your code\n\n### Testing\n- Write table-driven tests\n- Test edge cases\n- Use subtests for better organization\n- Mock external dependencies\n- Aim for high test coverage\n\n### Documentation\n- Document all exported items\n- Write clear package documentation\n- Include examples in documentation\n- Keep comments up to date\n- Use godoc format\n\nThis comprehensive guide covers the fundamental aspects of Go programming. Each topic includes practical examples and best practices to help write idiomatic, efficient Go code.","numLines":2063,"startLine":1,"totalLines":2063}}}
{"parentUuid":"ec955ed0-c137-4fb1-b409-b9a3eb89e0a8","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01JsHb9NUYGVPbcSwaJAQnKQ","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01GZTMop5XDXj5mzgrAmLjjG","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/design-patterns.md"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":21056,"cache_read_input_tokens":47739,"output_tokens":75,"service_tier":"standard"}},"requestId":"req_011CS5WgQZ5aqkqvZCV9wpBT","type":"assistant","uuid":"8f805a03-b772-4c14-8466-b7e1017b63f9","timestamp":"2025-08-13T09:59:07.182Z"}
{"parentUuid":"8f805a03-b772-4c14-8466-b7e1017b63f9","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GZTMop5XDXj5mzgrAmLjjG","type":"tool_result","content":"     1→# Design Patterns in Go\n     2→\n     3→## Overview\n     4→This document covers classic design patterns (Gang of Four) and architectural patterns as they apply to Go. For Go-specific idioms and conventions, see `practices-patterns.md`.\n     5→\n     6→## Table of Contents\n     7→1. [Creational Patterns](#creational-patterns)\n     8→2. [Structural Patterns](#structural-patterns)\n     9→3. [Behavioral Patterns](#behavioral-patterns)\n    10→4. [Architectural Patterns](#architectural-patterns)\n    11→5. [Domain-Driven Design Patterns](#domain-driven-design-patterns)\n    12→\n    13→## Creational Patterns\n    14→\n    15→### Singleton\n    16→The singleton pattern ensures only one instance of a type exists. In Go, use `sync.Once` for thread-safe initialization.\n    17→\n    18→```go\n    19→package database\n    20→\n    21→import (\n    22→    \"database/sql\"\n    23→    \"sync\"\n    24→)\n    25→\n    26→type DB struct {\n    27→    conn *sql.DB\n    28→}\n    29→\n    30→var (\n    31→    instance *DB\n    32→    once     sync.Once\n    33→)\n    34→\n    35→// GetInstance returns the singleton database instance\n    36→func GetInstance() *DB {\n    37→    once.Do(func() {\n    38→        conn, _ := sql.Open(\"postgres\", \"connection-string\")\n    39→        instance = &DB{conn: conn}\n    40→    })\n    41→    return instance\n    42→}\n    43→\n    44→// Alternative: Package-level initialization (simpler for most cases)\n    45→var defaultDB = initDB()\n    46→\n    47→func initDB() *DB {\n    48→    conn, _ := sql.Open(\"postgres\", \"connection-string\")\n    49→    return &DB{conn: conn}\n    50→}\n    51→```\n    52→\n    53→### Factory Method\n    54→Factory method defines an interface for creating objects but lets subclasses decide which class to instantiate.\n    55→\n    56→```go\n    57→// Product interface\n    58→type Transport interface {\n    59→    Deliver() string\n    60→    Cost() float64\n    61→}\n    62→\n    63→// Concrete products\n    64→type Truck struct {\n    65→    capacity int\n    66→}\n    67→\n    68→func (t *Truck) Deliver() string {\n    69→    return \"Delivering by land\"\n    70→}\n    71→\n    72→func (t *Truck) Cost() float64 {\n    73→    return 100.0\n    74→}\n    75→\n    76→type Ship struct {\n    77→    tonnage int\n    78→}\n    79→\n    80→func (s *Ship) Deliver() string {\n    81→    return \"Delivering by sea\"\n    82→}\n    83→\n    84→func (s *Ship) Cost() float64 {\n    85→    return 500.0\n    86→}\n    87→\n    88→// Factory\n    89→type LogisticsFactory interface {\n    90→    CreateTransport() Transport\n    91→}\n    92→\n    93→type RoadLogistics struct{}\n    94→\n    95→func (r *RoadLogistics) CreateTransport() Transport {\n    96→    return &Truck{capacity: 1000}\n    97→}\n    98→\n    99→type SeaLogistics struct{}\n   100→\n   101→func (s *SeaLogistics) CreateTransport() Transport {\n   102→    return &Ship{tonnage: 10000}\n   103→}\n   104→\n   105→// Usage\n   106→func planDelivery(factory LogisticsFactory) {\n   107→    transport := factory.CreateTransport()\n   108→    fmt.Println(transport.Deliver())\n   109→    fmt.Printf(\"Cost: $%.2f\\n\", transport.Cost())\n   110→}\n   111→```\n   112→\n   113→### Abstract Factory\n   114→Abstract factory provides an interface for creating families of related objects.\n   115→\n   116→```go\n   117→// Abstract products\n   118→type Button interface {\n   119→    Paint()\n   120→}\n   121→\n   122→type Checkbox interface {\n   123→    Check()\n   124→}\n   125→\n   126→// Concrete products - Windows family\n   127→type WindowsButton struct{}\n   128→\n   129→func (w *WindowsButton) Paint() {\n   130→    fmt.Println(\"Rendering Windows button\")\n   131→}\n   132→\n   133→type WindowsCheckbox struct{}\n   134→\n   135→func (w *WindowsCheckbox) Check() {\n   136→    fmt.Println(\"Checking Windows checkbox\")\n   137→}\n   138→\n   139→// Concrete products - Mac family\n   140→type MacButton struct{}\n   141→\n   142→func (m *MacButton) Paint() {\n   143→    fmt.Println(\"Rendering Mac button\")\n   144→}\n   145→\n   146→type MacCheckbox struct{}\n   147→\n   148→func (m *MacCheckbox) Check() {\n   149→    fmt.Println(\"Checking Mac checkbox\")\n   150→}\n   151→\n   152→// Abstract factory\n   153→type GUIFactory interface {\n   154→    CreateButton() Button\n   155→    CreateCheckbox() Checkbox\n   156→}\n   157→\n   158→// Concrete factories\n   159→type WindowsFactory struct{}\n   160→\n   161→func (w *WindowsFactory) CreateButton() Button {\n   162→    return &WindowsButton{}\n   163→}\n   164→\n   165→func (w *WindowsFactory) CreateCheckbox() Checkbox {\n   166→    return &WindowsCheckbox{}\n   167→}\n   168→\n   169→type MacFactory struct{}\n   170→\n   171→func (m *MacFactory) CreateButton() Button {\n   172→    return &MacButton{}\n   173→}\n   174→\n   175→func (m *MacFactory) CreateCheckbox() Checkbox {\n   176→    return &MacCheckbox{}\n   177→}\n   178→\n   179→// Application\n   180→type Application struct {\n   181→    factory GUIFactory\n   182→    button  Button\n   183→    checkbox Checkbox\n   184→}\n   185→\n   186→func NewApplication(factory GUIFactory) *Application {\n   187→    return &Application{\n   188→        factory:  factory,\n   189→        button:   factory.CreateButton(),\n   190→        checkbox: factory.CreateCheckbox(),\n   191→    }\n   192→}\n   193→\n   194→func (a *Application) Paint() {\n   195→    a.button.Paint()\n   196→    a.checkbox.Check()\n   197→}\n   198→```\n   199→\n   200→### Builder\n   201→Builder pattern separates the construction of complex objects from their representation.\n   202→\n   203→```go\n   204→// Product\n   205→type House struct {\n   206→    Foundation string\n   207→    Structure  string\n   208→    Roof       string\n   209→    Interior   string\n   210→    Garden     bool\n   211→    Pool       bool\n   212→}\n   213→\n   214→// Builder interface\n   215→type HouseBuilder interface {\n   216→    SetFoundation() HouseBuilder\n   217→    SetStructure() HouseBuilder\n   218→    SetRoof() HouseBuilder\n   219→    SetInterior() HouseBuilder\n   220→    SetGarden() HouseBuilder\n   221→    SetPool() HouseBuilder\n   222→    Build() *House\n   223→}\n   224→\n   225→// Concrete builder\n   226→type ModernHouseBuilder struct {\n   227→    house *House\n   228→}\n   229→\n   230→func NewModernHouseBuilder() *ModernHouseBuilder {\n   231→    return &ModernHouseBuilder{\n   232→        house: &House{},\n   233→    }\n   234→}\n   235→\n   236→func (b *ModernHouseBuilder) SetFoundation() HouseBuilder {\n   237→    b.house.Foundation = \"Concrete, brick, and stone\"\n   238→    return b\n   239→}\n   240→\n   241→func (b *ModernHouseBuilder) SetStructure() HouseBuilder {\n   242→    b.house.Structure = \"Steel and glass\"\n   243→    return b\n   244→}\n   245→\n   246→func (b *ModernHouseBuilder) SetRoof() HouseBuilder {\n   247→    b.house.Roof = \"Flat concrete\"\n   248→    return b\n   249→}\n   250→\n   251→func (b *ModernHouseBuilder) SetInterior() HouseBuilder {\n   252→    b.house.Interior = \"Modern minimalist\"\n   253→    return b\n   254→}\n   255→\n   256→func (b *ModernHouseBuilder) SetGarden() HouseBuilder {\n   257→    b.house.Garden = true\n   258→    return b\n   259→}\n   260→\n   261→func (b *ModernHouseBuilder) SetPool() HouseBuilder {\n   262→    b.house.Pool = true\n   263→    return b\n   264→}\n   265→\n   266→func (b *ModernHouseBuilder) Build() *House {\n   267→    return b.house\n   268→}\n   269→\n   270→// Director (optional)\n   271→type ConstructionDirector struct {\n   272→    builder HouseBuilder\n   273→}\n   274→\n   275→func (d *ConstructionDirector) ConstructLuxuryHouse() *House {\n   276→    return d.builder.\n   277→        SetFoundation().\n   278→        SetStructure().\n   279→        SetRoof().\n   280→        SetInterior().\n   281→        SetGarden().\n   282→        SetPool().\n   283→        Build()\n   284→}\n   285→\n   286→// Usage\n   287→func main() {\n   288→    builder := NewModernHouseBuilder()\n   289→    \n   290→    // Direct use\n   291→    house := builder.\n   292→        SetFoundation().\n   293→        SetStructure().\n   294→        SetRoof().\n   295→        Build()\n   296→    \n   297→    // Using director\n   298→    director := &ConstructionDirector{builder: builder}\n   299→    luxuryHouse := director.ConstructLuxuryHouse()\n   300→}\n   301→```\n   302→\n   303→### Prototype\n   304→Prototype pattern creates objects by cloning existing instances.\n   305→\n   306→```go\n   307→// Prototype interface\n   308→type Prototype interface {\n   309→    Clone() Prototype\n   310→}\n   311→\n   312→// Concrete prototype\n   313→type Document struct {\n   314→    Title    string\n   315→    Content  string\n   316→    Images   []string\n   317→    Metadata map[string]string\n   318→}\n   319→\n   320→func (d *Document) Clone() Prototype {\n   321→    // Deep copy\n   322→    newDoc := &Document{\n   323→        Title:   d.Title,\n   324→        Content: d.Content,\n   325→        Images:  make([]string, len(d.Images)),\n   326→        Metadata: make(map[string]string),\n   327→    }\n   328→    \n   329→    copy(newDoc.Images, d.Images)\n   330→    \n   331→    for k, v := range d.Metadata {\n   332→        newDoc.Metadata[k] = v\n   333→    }\n   334→    \n   335→    return newDoc\n   336→}\n   337→\n   338→// Prototype registry\n   339→type DocumentRegistry struct {\n   340→    prototypes map[string]Prototype\n   341→}\n   342→\n   343→func NewDocumentRegistry() *DocumentRegistry {\n   344→    return &DocumentRegistry{\n   345→        prototypes: make(map[string]Prototype),\n   346→    }\n   347→}\n   348→\n   349→func (r *DocumentRegistry) Register(name string, prototype Prototype) {\n   350→    r.prototypes[name] = prototype\n   351→}\n   352→\n   353→func (r *DocumentRegistry) Create(name string) Prototype {\n   354→    if prototype, exists := r.prototypes[name]; exists {\n   355→        return prototype.Clone()\n   356→    }\n   357→    return nil\n   358→}\n   359→\n   360→// Usage\n   361→func main() {\n   362→    registry := NewDocumentRegistry()\n   363→    \n   364→    // Register prototypes\n   365→    registry.Register(\"report\", &Document{\n   366→        Title:    \"Monthly Report Template\",\n   367→        Content:  \"...\",\n   368→        Metadata: map[string]string{\"type\": \"report\"},\n   369→    })\n   370→    \n   371→    registry.Register(\"letter\", &Document{\n   372→        Title:    \"Business Letter Template\",\n   373→        Content:  \"...\",\n   374→        Metadata: map[string]string{\"type\": \"letter\"},\n   375→    })\n   376→    \n   377→    // Create new documents from prototypes\n   378→    report := registry.Create(\"report\").(*Document)\n   379→    report.Title = \"January Report\"\n   380→}\n   381→```\n   382→\n   383→## Structural Patterns\n   384→\n   385→### Adapter\n   386→Adapter allows incompatible interfaces to work together.\n   387→\n   388→```go\n   389→// Target interface (what client expects)\n   390→type PaymentProcessor interface {\n   391→    ProcessPayment(amount float64) error\n   392→}\n   393→\n   394→// Adaptee (incompatible interface)\n   395→type LegacyPaymentSystem struct{}\n   396→\n   397→func (l *LegacyPaymentSystem) MakePayment(sum float64, currency string) string {\n   398→    return fmt.Sprintf(\"Payment of %.2f %s processed\", sum, currency)\n   399→}\n   400→\n   401→// Adapter\n   402→type PaymentAdapter struct {\n   403→    legacy   *LegacyPaymentSystem\n   404→    currency string\n   405→}\n   406→\n   407→func NewPaymentAdapter(legacy *LegacyPaymentSystem, currency string) *PaymentAdapter {\n   408→    return &PaymentAdapter{\n   409→        legacy:   legacy,\n   410→        currency: currency,\n   411→    }\n   412→}\n   413→\n   414→func (a *PaymentAdapter) ProcessPayment(amount float64) error {\n   415→    result := a.legacy.MakePayment(amount, a.currency)\n   416→    if result != \"\" {\n   417→        return nil\n   418→    }\n   419→    return fmt.Errorf(\"payment failed\")\n   420→}\n   421→\n   422→// Client code\n   423→func processOrder(processor PaymentProcessor, amount float64) {\n   424→    if err := processor.ProcessPayment(amount); err != nil {\n   425→        fmt.Printf(\"Payment failed: %v\\n\", err)\n   426→    } else {\n   427→        fmt.Println(\"Payment successful\")\n   428→    }\n   429→}\n   430→\n   431→// Usage\n   432→func main() {\n   433→    legacy := &LegacyPaymentSystem{}\n   434→    adapter := NewPaymentAdapter(legacy, \"USD\")\n   435→    processOrder(adapter, 100.00)\n   436→}\n   437→```\n   438→\n   439→### Bridge\n   440→Bridge decouples abstraction from implementation so both can vary independently.\n   441→\n   442→```go\n   443→// Implementation interface\n   444→type MessageSender interface {\n   445→    Send(title, body string) error\n   446→}\n   447→\n   448→// Concrete implementations\n   449→type EmailSender struct {\n   450→    emailAddress string\n   451→}\n   452→\n   453→func (e *EmailSender) Send(title, body string) error {\n   454→    fmt.Printf(\"Email to %s: %s - %s\\n\", e.emailAddress, title, body)\n   455→    return nil\n   456→}\n   457→\n   458→type SMSSender struct {\n   459→    phoneNumber string\n   460→}\n   461→\n   462→func (s *SMSSender) Send(title, body string) error {\n   463→    fmt.Printf(\"SMS to %s: %s\\n\", s.phoneNumber, body)\n   464→    return nil\n   465→}\n   466→\n   467→// Abstraction\n   468→type Message struct {\n   469→    sender MessageSender\n   470→}\n   471→\n   472→func NewMessage(sender MessageSender) *Message {\n   473→    return &Message{sender: sender}\n   474→}\n   475→\n   476→func (m *Message) Send(title, body string) error {\n   477→    return m.sender.Send(title, body)\n   478→}\n   479→\n   480→// Refined abstraction\n   481→type UrgentMessage struct {\n   482→    Message\n   483→}\n   484→\n   485→func NewUrgentMessage(sender MessageSender) *UrgentMessage {\n   486→    return &UrgentMessage{\n   487→        Message: Message{sender: sender},\n   488→    }\n   489→}\n   490→\n   491→func (u *UrgentMessage) Send(title, body string) error {\n   492→    title = \"URGENT: \" + title\n   493→    return u.sender.Send(title, body)\n   494→}\n   495→\n   496→// Usage\n   497→func main() {\n   498→    // Regular email\n   499→    email := NewMessage(&EmailSender{emailAddress: \"user@example.com\"})\n   500→    email.Send(\"Hello\", \"This is a test message\")\n   501→    \n   502→    // Urgent SMS\n   503→    sms := NewUrgentMessage(&SMSSender{phoneNumber: \"+1234567890\"})\n   504→    sms.Send(\"Alert\", \"Server is down\")\n   505→}\n   506→```\n   507→\n   508→### Composite\n   509→Composite lets you compose objects into tree structures to represent part-whole hierarchies.\n   510→\n   511→```go\n   512→// Component interface\n   513→type FileSystemNode interface {\n   514→    GetName() string\n   515→    GetSize() int64\n   516→    Print(indent string)\n   517→}\n   518→\n   519→// Leaf\n   520→type File struct {\n   521→    name string\n   522→    size int64\n   523→}\n   524→\n   525→func (f *File) GetName() string {\n   526→    return f.name\n   527→}\n   528→\n   529→func (f *File) GetSize() int64 {\n   530→    return f.size\n   531→}\n   532→\n   533→func (f *File) Print(indent string) {\n   534→    fmt.Printf(\"%sFile: %s (%d bytes)\\n\", indent, f.name, f.size)\n   535→}\n   536→\n   537→// Composite\n   538→type Directory struct {\n   539→    name     string\n   540→    children []FileSystemNode\n   541→}\n   542→\n   543→func (d *Directory) GetName() string {\n   544→    return d.name\n   545→}\n   546→\n   547→func (d *Directory) GetSize() int64 {\n   548→    var total int64\n   549→    for _, child := range d.children {\n   550→        total += child.GetSize()\n   551→    }\n   552→    return total\n   553→}\n   554→\n   555→func (d *Directory) Add(node FileSystemNode) {\n   556→    d.children = append(d.children, node)\n   557→}\n   558→\n   559→func (d *Directory) Remove(node FileSystemNode) {\n   560→    for i, child := range d.children {\n   561→        if child == node {\n   562→            d.children = append(d.children[:i], d.children[i+1:]...)\n   563→            break\n   564→        }\n   565→    }\n   566→}\n   567→\n   568→func (d *Directory) Print(indent string) {\n   569→    fmt.Printf(\"%sDirectory: %s (%d bytes)\\n\", indent, d.name, d.GetSize())\n   570→    for _, child := range d.children {\n   571→        child.Print(indent + \"  \")\n   572→    }\n   573→}\n   574→\n   575→// Usage\n   576→func main() {\n   577→    root := &Directory{name: \"root\"}\n   578→    \n   579→    home := &Directory{name: \"home\"}\n   580→    root.Add(home)\n   581→    \n   582→    documents := &Directory{name: \"documents\"}\n   583→    home.Add(documents)\n   584→    \n   585→    documents.Add(&File{name: \"report.pdf\", size: 1024000})\n   586→    documents.Add(&File{name: \"presentation.pptx\", size: 2048000})\n   587→    \n   588→    home.Add(&File{name: \"notes.txt\", size: 1024})\n   589→    \n   590→    root.Print(\"\")\n   591→}\n   592→```\n   593→\n   594→### Decorator\n   595→Decorator adds new functionality to objects without altering their structure.\n   596→\n   597→```go\n   598→// Component interface\n   599→type Coffee interface {\n   600→    GetCost() float64\n   601→    GetDescription() string\n   602→}\n   603→\n   604→// Concrete component\n   605→type SimpleCoffee struct{}\n   606→\n   607→func (c *SimpleCoffee) GetCost() float64 {\n   608→    return 2.0\n   609→}\n   610→\n   611→func (c *SimpleCoffee) GetDescription() string {\n   612→    return \"Simple coffee\"\n   613→}\n   614→\n   615→// Base decorator\n   616→type CoffeeDecorator struct {\n   617→    coffee Coffee\n   618→}\n   619→\n   620→func (d *CoffeeDecorator) GetCost() float64 {\n   621→    return d.coffee.GetCost()\n   622→}\n   623→\n   624→func (d *CoffeeDecorator) GetDescription() string {\n   625→    return d.coffee.GetDescription()\n   626→}\n   627→\n   628→// Concrete decorators\n   629→type MilkDecorator struct {\n   630→    CoffeeDecorator\n   631→}\n   632→\n   633→func NewMilkDecorator(coffee Coffee) *MilkDecorator {\n   634→    return &MilkDecorator{\n   635→        CoffeeDecorator: CoffeeDecorator{coffee: coffee},\n   636→    }\n   637→}\n   638→\n   639→func (m *MilkDecorator) GetCost() float64 {\n   640→    return m.coffee.GetCost() + 0.5\n   641→}\n   642→\n   643→func (m *MilkDecorator) GetDescription() string {\n   644→    return m.coffee.GetDescription() + \", milk\"\n   645→}\n   646→\n   647→type SugarDecorator struct {\n   648→    CoffeeDecorator\n   649→}\n   650→\n   651→func NewSugarDecorator(coffee Coffee) *SugarDecorator {\n   652→    return &SugarDecorator{\n   653→        CoffeeDecorator: CoffeeDecorator{coffee: coffee},\n   654→    }\n   655→}\n   656→\n   657→func (s *SugarDecorator) GetCost() float64 {\n   658→    return s.coffee.GetCost() + 0.2\n   659→}\n   660→\n   661→func (s *SugarDecorator) GetDescription() string {\n   662→    return s.coffee.GetDescription() + \", sugar\"\n   663→}\n   664→\n   665→// Usage\n   666→func main() {\n   667→    coffee := &SimpleCoffee{}\n   668→    fmt.Printf(\"%s: $%.2f\\n\", coffee.GetDescription(), coffee.GetCost())\n   669→    \n   670→    coffeeWithMilk := NewMilkDecorator(coffee)\n   671→    fmt.Printf(\"%s: $%.2f\\n\", coffeeWithMilk.GetDescription(), coffeeWithMilk.GetCost())\n   672→    \n   673→    coffeeWithMilkAndSugar := NewSugarDecorator(coffeeWithMilk)\n   674→    fmt.Printf(\"%s: $%.2f\\n\", coffeeWithMilkAndSugar.GetDescription(), coffeeWithMilkAndSugar.GetCost())\n   675→}\n   676→```\n   677→\n   678→### Facade\n   679→Facade provides a simplified interface to a complex subsystem.\n   680→\n   681→```go\n   682→// Complex subsystem components\n   683→type AccountService struct{}\n   684→\n   685→func (a *AccountService) GetAccount(id string) string {\n   686→    return fmt.Sprintf(\"Account %s\", id)\n   687→}\n   688→\n   689→func (a *AccountService) CheckBalance(id string) float64 {\n   690→    return 1000.00\n   691→}\n   692→\n   693→type SecurityService struct{}\n   694→\n   695→func (s *SecurityService) Authenticate(token string) bool {\n   696→    return token == \"valid-token\"\n   697→}\n   698→\n   699→func (s *SecurityService) Authorize(user, action string) bool {\n   700→    return true\n   701→}\n   702→\n   703→type TransactionService struct{}\n   704→\n   705→func (t *TransactionService) CreateTransaction(from, to string, amount float64) string {\n   706→    return fmt.Sprintf(\"Transaction: %s -> %s: %.2f\", from, to, amount)\n   707→}\n   708→\n   709→func (t *TransactionService) ValidateTransaction(id string) bool {\n   710→    return true\n   711→}\n   712→\n   713→type NotificationService struct{}\n   714→\n   715→func (n *NotificationService) SendEmail(to, message string) {\n   716→    fmt.Printf(\"Email to %s: %s\\n\", to, message)\n   717→}\n   718→\n   719→func (n *NotificationService) SendSMS(to, message string) {\n   720→    fmt.Printf(\"SMS to %s: %s\\n\", to, message)\n   721→}\n   722→\n   723→// Facade\n   724→type BankingFacade struct {\n   725→    account      *AccountService\n   726→    security     *SecurityService\n   727→    transaction  *TransactionService\n   728→    notification *NotificationService\n   729→}\n   730→\n   731→func NewBankingFacade() *BankingFacade {\n   732→    return &BankingFacade{\n   733→        account:      &AccountService{},\n   734→        security:     &SecurityService{},\n   735→        transaction:  &TransactionService{},\n   736→        notification: &NotificationService{},\n   737→    }\n   738→}\n   739→\n   740→func (b *BankingFacade) Transfer(token, from, to string, amount float64) error {\n   741→    // Authenticate\n   742→    if !b.security.Authenticate(token) {\n   743→        return fmt.Errorf(\"authentication failed\")\n   744→    }\n   745→    \n   746→    // Check authorization\n   747→    if !b.security.Authorize(from, \"transfer\") {\n   748→        return fmt.Errorf(\"not authorized\")\n   749→    }\n   750→    \n   751→    // Check balance\n   752→    if b.account.CheckBalance(from) < amount {\n   753→        return fmt.Errorf(\"insufficient funds\")\n   754→    }\n   755→    \n   756→    // Create transaction\n   757→    txID := b.transaction.CreateTransaction(from, to, amount)\n   758→    \n   759→    // Validate\n   760→    if !b.transaction.ValidateTransaction(txID) {\n   761→        return fmt.Errorf(\"transaction validation failed\")\n   762→    }\n   763→    \n   764→    // Notify\n   765→    b.notification.SendEmail(from, fmt.Sprintf(\"Transfer of %.2f completed\", amount))\n   766→    b.notification.SendSMS(to, fmt.Sprintf(\"Received %.2f\", amount))\n   767→    \n   768→    return nil\n   769→}\n   770→\n   771→// Usage\n   772→func main() {\n   773→    banking := NewBankingFacade()\n   774→    \n   775→    err := banking.Transfer(\"valid-token\", \"account1\", \"account2\", 100.00)\n   776→    if err != nil {\n   777→        fmt.Printf(\"Transfer failed: %v\\n\", err)\n   778→    } else {\n   779→        fmt.Println(\"Transfer successful\")\n   780→    }\n   781→}\n   782→```\n   783→\n   784→### Flyweight\n   785→Flyweight minimizes memory usage by sharing efficiently large numbers of fine-grained objects.\n   786→\n   787→```go\n   788→// Flyweight interface\n   789→type Character interface {\n   790→    Display(font string, size int, color string)\n   791→}\n   792→\n   793→// Concrete flyweight\n   794→type ConcreteCharacter struct {\n   795→    symbol rune // Intrinsic state (shared)\n   796→}\n   797→\n   798→func (c *ConcreteCharacter) Display(font string, size int, color string) {\n   799→    // Extrinsic state (passed in)\n   800→    fmt.Printf(\"Character: %c, Font: %s, Size: %d, Color: %s\\n\", \n   801→        c.symbol, font, size, color)\n   802→}\n   803→\n   804→// Flyweight factory\n   805→type CharacterFactory struct {\n   806→    characters map[rune]*ConcreteCharacter\n   807→}\n   808→\n   809→func NewCharacterFactory() *CharacterFactory {\n   810→    return &CharacterFactory{\n   811→        characters: make(map[rune]*ConcreteCharacter),\n   812→    }\n   813→}\n   814→\n   815→func (f *CharacterFactory) GetCharacter(symbol rune) Character {\n   816→    if char, exists := f.characters[symbol]; exists {\n   817→        return char\n   818→    }\n   819→    \n   820→    char := &ConcreteCharacter{symbol: symbol}\n   821→    f.characters[symbol] = char\n   822→    return char\n   823→}\n   824→\n   825→// Context that uses flyweights\n   826→type TextDocument struct {\n   827→    characters []Character\n   828→    fonts      []string\n   829→    sizes      []int\n   830→    colors     []string\n   831→}\n   832→\n   833→func (d *TextDocument) AddCharacter(char Character, font string, size int, color string) {\n   834→    d.characters = append(d.characters, char)\n   835→    d.fonts = append(d.fonts, font)\n   836→    d.sizes = append(d.sizes, size)\n   837→    d.colors = append(d.colors, color)\n   838→}\n   839→\n   840→func (d *TextDocument) Display() {\n   841→    for i, char := range d.characters {\n   842→        char.Display(d.fonts[i], d.sizes[i], d.colors[i])\n   843→    }\n   844→}\n   845→\n   846→// Usage\n   847→func main() {\n   848→    factory := NewCharacterFactory()\n   849→    doc := &TextDocument{}\n   850→    \n   851→    text := \"Hello World\"\n   852→    for _, r := range text {\n   853→        char := factory.GetCharacter(r)\n   854→        doc.AddCharacter(char, \"Arial\", 12, \"black\")\n   855→    }\n   856→    \n   857→    doc.Display()\n   858→    \n   859→    // Characters 'l' and 'o' are reused (shared instances)\n   860→    fmt.Printf(\"Total unique characters created: %d\\n\", len(factory.characters))\n   861→}\n   862→```\n   863→\n   864→### Proxy\n   865→Proxy provides a placeholder or surrogate for another object to control access to it.\n   866→\n   867→```go\n   868→// Subject interface\n   869→type Database interface {\n   870→    Query(sql string) ([]string, error)\n   871→}\n   872→\n   873→// Real subject\n   874→type RealDatabase struct {\n   875→    connectionString string\n   876→}\n   877→\n   878→func (d *RealDatabase) Query(sql string) ([]string, error) {\n   879→    fmt.Printf(\"Executing query: %s\\n\", sql)\n   880→    // Simulate database query\n   881→    return []string{\"result1\", \"result2\"}, nil\n   882→}\n   883→\n   884→// Proxy with caching\n   885→type CachingDatabaseProxy struct {\n   886→    database *RealDatabase\n   887→    cache    map[string][]string\n   888→}\n   889→\n   890→func NewCachingDatabaseProxy(connString string) *CachingDatabaseProxy {\n   891→    return &CachingDatabaseProxy{\n   892→        database: &RealDatabase{connectionString: connString},\n   893→        cache:    make(map[string][]string),\n   894→    }\n   895→}\n   896→\n   897→func (p *CachingDatabaseProxy) Query(sql string) ([]string, error) {\n   898→    // Check cache\n   899→    if results, exists := p.cache[sql]; exists {\n   900→        fmt.Printf(\"Returning cached results for: %s\\n\", sql)\n   901→        return results, nil\n   902→    }\n   903→    \n   904→    // Query real database\n   905→    results, err := p.database.Query(sql)\n   906→    if err != nil {\n   907→        return nil, err\n   908→    }\n   909→    \n   910→    // Cache results\n   911→    p.cache[sql] = results\n   912→    return results, nil\n   913→}\n   914→\n   915→// Security proxy\n   916→type SecureDatabaseProxy struct {\n   917→    database Database\n   918→    userRole string\n   919→}\n   920→\n   921→func NewSecureDatabaseProxy(db Database, role string) *SecureDatabaseProxy {\n   922→    return &SecureDatabaseProxy{\n   923→        database: db,\n   924→        userRole: role,\n   925→    }\n   926→}\n   927→\n   928→func (p *SecureDatabaseProxy) Query(sql string) ([]string, error) {\n   929→    // Check permissions\n   930→    if strings.Contains(strings.ToLower(sql), \"delete\") && p.userRole != \"admin\" {\n   931→        return nil, fmt.Errorf(\"permission denied: only admin can delete\")\n   932→    }\n   933→    \n   934→    return p.database.Query(sql)\n   935→}\n   936→\n   937→// Usage\n   938→func main() {\n   939→    // Caching proxy\n   940→    db := NewCachingDatabaseProxy(\"connection-string\")\n   941→    \n   942→    // First query hits the database\n   943→    results, _ := db.Query(\"SELECT * FROM users\")\n   944→    fmt.Println(\"Results:\", results)\n   945→    \n   946→    // Second identical query uses cache\n   947→    results, _ = db.Query(\"SELECT * FROM users\")\n   948→    fmt.Println(\"Results:\", results)\n   949→    \n   950→    // Security proxy\n   951→    secureDB := NewSecureDatabaseProxy(db, \"user\")\n   952→    _, err := secureDB.Query(\"DELETE FROM users\")\n   953→    if err != nil {\n   954→        fmt.Println(\"Error:\", err)\n   955→    }\n   956→}\n   957→```\n   958→\n   959→## Behavioral Patterns\n   960→\n   961→### Chain of Responsibility\n   962→Chain of Responsibility passes requests along a chain of handlers until one handles it.\n   963→\n   964→```go\n   965→// Handler interface\n   966→type Handler interface {\n   967→    SetNext(Handler) Handler\n   968→    Handle(request string) string\n   969→}\n   970→\n   971→// Base handler\n   972→type BaseHandler struct {\n   973→    next Handler\n   974→}\n   975→\n   976→func (h *BaseHandler) SetNext(next Handler) Handler {\n   977→    h.next = next\n   978→    return next\n   979→}\n   980→\n   981→func (h *BaseHandler) Handle(request string) string {\n   982→    if h.next != nil {\n   983→        return h.next.Handle(request)\n   984→    }\n   985→    return \"\"\n   986→}\n   987→\n   988→// Concrete handlers\n   989→type AuthenticationHandler struct {\n   990→    BaseHandler\n   991→}\n   992→\n   993→func (h *AuthenticationHandler) Handle(request string) string {\n   994→    if request == \"auth\" {\n   995→        return \"Authentication successful\"\n   996→    }\n   997→    return h.BaseHandler.Handle(request)\n   998→}\n   999→\n  1000→type AuthorizationHandler struct {\n  1001→    BaseHandler\n  1002→}\n  1003→\n  1004→func (h *AuthorizationHandler) Handle(request string) string {\n  1005→    if request == \"authz\" {\n  1006→        return \"Authorization granted\"\n  1007→    }\n  1008→    return h.BaseHandler.Handle(request)\n  1009→}\n  1010→\n  1011→type ValidationHandler struct {\n  1012→    BaseHandler\n  1013→}\n  1014→\n  1015→func (h *ValidationHandler) Handle(request string) string {\n  1016→    if request == \"validate\" {\n  1017→        return \"Validation passed\"\n  1018→    }\n  1019→    return h.BaseHandler.Handle(request)\n  1020→}\n  1021→\n  1022→// Usage\n  1023→func main() {\n  1024→    auth := &AuthenticationHandler{}\n  1025→    authz := &AuthorizationHandler{}\n  1026→    valid := &ValidationHandler{}\n  1027→    \n  1028→    // Build chain\n  1029→    auth.SetNext(authz).SetNext(valid)\n  1030→    \n  1031→    // Process requests\n  1032→    fmt.Println(auth.Handle(\"auth\"))     // Handled by auth\n  1033→    fmt.Println(auth.Handle(\"authz\"))    // Handled by authz\n  1034→    fmt.Println(auth.Handle(\"validate\")) // Handled by valid\n  1035→    fmt.Println(auth.Handle(\"unknown\"))  // Not handled\n  1036→}\n  1037→```\n  1038→\n  1039→### Command\n  1040→Command encapsulates a request as an object, letting you parameterize clients with different requests.\n  1041→\n  1042→```go\n  1043→// Command interface\n  1044→type Command interface {\n  1045→    Execute() error\n  1046→    Undo() error\n  1047→}\n  1048→\n  1049→// Receiver\n  1050→type Light struct {\n  1051→    isOn bool\n  1052→}\n  1053→\n  1054→func (l *Light) TurnOn() {\n  1055→    l.isOn = true\n  1056→    fmt.Println(\"Light is on\")\n  1057→}\n  1058→\n  1059→func (l *Light) TurnOff() {\n  1060→    l.isOn = false\n  1061→    fmt.Println(\"Light is off\")\n  1062→}\n  1063→\n  1064→// Concrete commands\n  1065→type TurnOnCommand struct {\n  1066→    light *Light\n  1067→}\n  1068→\n  1069→func (c *TurnOnCommand) Execute() error {\n  1070→    c.light.TurnOn()\n  1071→    return nil\n  1072→}\n  1073→\n  1074→func (c *TurnOnCommand) Undo() error {\n  1075→    c.light.TurnOff()\n  1076→    return nil\n  1077→}\n  1078→\n  1079→type TurnOffCommand struct {\n  1080→    light *Light\n  1081→}\n  1082→\n  1083→func (c *TurnOffCommand) Execute() error {\n  1084→    c.light.TurnOff()\n  1085→    return nil\n  1086→}\n  1087→\n  1088→func (c *TurnOffCommand) Undo() error {\n  1089→    c.light.TurnOn()\n  1090→    return nil\n  1091→}\n  1092→\n  1093→// Invoker\n  1094→type RemoteControl struct {\n  1095→    commands []Command\n  1096→    history  []Command\n  1097→}\n  1098→\n  1099→func (r *RemoteControl) SetCommand(slot int, cmd Command) {\n  1100→    if slot >= len(r.commands) {\n  1101→        r.commands = append(r.commands, make([]Command, slot-len(r.commands)+1)...)\n  1102→    }\n  1103→    r.commands[slot] = cmd\n  1104→}\n  1105→\n  1106→func (r *RemoteControl) PressButton(slot int) {\n  1107→    if slot < len(r.commands) && r.commands[slot] != nil {\n  1108→        r.commands[slot].Execute()\n  1109→        r.history = append(r.history, r.commands[slot])\n  1110→    }\n  1111→}\n  1112→\n  1113→func (r *RemoteControl) PressUndo() {\n  1114→    if len(r.history) > 0 {\n  1115→        lastCommand := r.history[len(r.history)-1]\n  1116→        lastCommand.Undo()\n  1117→        r.history = r.history[:len(r.history)-1]\n  1118→    }\n  1119→}\n  1120→\n  1121→// Macro command\n  1122→type MacroCommand struct {\n  1123→    commands []Command\n  1124→}\n  1125→\n  1126→func (m *MacroCommand) Execute() error {\n  1127→    for _, cmd := range m.commands {\n  1128→        if err := cmd.Execute(); err != nil {\n  1129→            return err\n  1130→        }\n  1131→    }\n  1132→    return nil\n  1133→}\n  1134→\n  1135→func (m *MacroCommand) Undo() error {\n  1136→    // Undo in reverse order\n  1137→    for i := len(m.commands) - 1; i >= 0; i-- {\n  1138→        if err := m.commands[i].Undo(); err != nil {\n  1139→            return err\n  1140→        }\n  1141→    }\n  1142→    return nil\n  1143→}\n  1144→\n  1145→// Usage\n  1146→func main() {\n  1147→    light := &Light{}\n  1148→    remote := &RemoteControl{}\n  1149→    \n  1150→    turnOn := &TurnOnCommand{light: light}\n  1151→    turnOff := &TurnOffCommand{light: light}\n  1152→    \n  1153→    remote.SetCommand(0, turnOn)\n  1154→    remote.SetCommand(1, turnOff)\n  1155→    \n  1156→    remote.PressButton(0) // Turn on\n  1157→    remote.PressButton(1) // Turn off\n  1158→    remote.PressUndo()    // Turn on again\n  1159→}\n  1160→```\n  1161→\n  1162→### Iterator\n  1163→Iterator provides a way to access elements of a collection sequentially without exposing its underlying representation.\n  1164→\n  1165→```go\n  1166→// Iterator interface\n  1167→type Iterator[T any] interface {\n  1168→    HasNext() bool\n  1169→    Next() T\n  1170→}\n  1171→\n  1172→// Collection interface\n  1173→type Collection[T any] interface {\n  1174→    CreateIterator() Iterator[T]\n  1175→}\n  1176→\n  1177→// Concrete collection\n  1178→type BookCollection struct {\n  1179→    books []string\n  1180→}\n  1181→\n  1182→func (c *BookCollection) Add(book string) {\n  1183→    c.books = append(c.books, book)\n  1184→}\n  1185→\n  1186→func (c *BookCollection) CreateIterator() Iterator[string] {\n  1187→    return &BookIterator{\n  1188→        collection: c,\n  1189→        index:      0,\n  1190→    }\n  1191→}\n  1192→\n  1193→// Concrete iterator\n  1194→type BookIterator struct {\n  1195→    collection *BookCollection\n  1196→    index      int\n  1197→}\n  1198→\n  1199→func (i *BookIterator) HasNext() bool {\n  1200→    return i.index < len(i.collection.books)\n  1201→}\n  1202→\n  1203→func (i *BookIterator) Next() string {\n  1204→    if i.HasNext() {\n  1205→        book := i.collection.books[i.index]\n  1206→        i.index++\n  1207→        return book\n  1208→    }\n  1209→    return \"\"\n  1210→}\n  1211→\n  1212→// Usage with channels (Go idiomatic)\n  1213→type ChannelIterator[T any] struct {\n  1214→    ch <-chan T\n  1215→    current T\n  1216→    hasNext bool\n  1217→}\n  1218→\n  1219→func NewChannelIterator[T any](items []T) *ChannelIterator[T] {\n  1220→    ch := make(chan T)\n  1221→    go func() {\n  1222→        for _, item := range items {\n  1223→            ch <- item\n  1224→        }\n  1225→        close(ch)\n  1226→    }()\n  1227→    \n  1228→    iter := &ChannelIterator[T]{ch: ch}\n  1229→    iter.advance()\n  1230→    return iter\n  1231→}\n  1232→\n  1233→func (i *ChannelIterator[T]) advance() {\n  1234→    i.current, i.hasNext = <-i.ch\n  1235→}\n  1236→\n  1237→func (i *ChannelIterator[T]) HasNext() bool {\n  1238→    return i.hasNext\n  1239→}\n  1240→\n  1241→func (i *ChannelIterator[T]) Next() T {\n  1242→    current := i.current\n  1243→    i.advance()\n  1244→    return current\n  1245→}\n  1246→\n  1247→// Usage\n  1248→func main() {\n  1249→    // Traditional iterator\n  1250→    collection := &BookCollection{}\n  1251→    collection.Add(\"Design Patterns\")\n  1252→    collection.Add(\"Clean Code\")\n  1253→    collection.Add(\"The Pragmatic Programmer\")\n  1254→    \n  1255→    iterator := collection.CreateIterator()\n  1256→    for iterator.HasNext() {\n  1257→        fmt.Println(iterator.Next())\n  1258→    }\n  1259→    \n  1260→    // Channel-based iterator\n  1261→    numbers := []int{1, 2, 3, 4, 5}\n  1262→    numIter := NewChannelIterator(numbers)\n  1263→    for numIter.HasNext() {\n  1264→        fmt.Println(numIter.Next())\n  1265→    }\n  1266→}\n  1267→```\n  1268→\n  1269→### Mediator\n  1270→Mediator defines how a set of objects interact, promoting loose coupling.\n  1271→\n  1272→```go\n  1273→// Mediator interface\n  1274→type ChatRoomMediator interface {\n  1275→    SendMessage(msg string, user User)\n  1276→    AddUser(user User)\n  1277→}\n  1278→\n  1279→// Colleague interface\n  1280→type User interface {\n  1281→    Send(msg string)\n  1282→    Receive(msg string)\n  1283→    SetMediator(mediator ChatRoomMediator)\n  1284→}\n  1285→\n  1286→// Concrete mediator\n  1287→type ChatRoom struct {\n  1288→    users []User\n  1289→}\n  1290→\n  1291→func (c *ChatRoom) SendMessage(msg string, sender User) {\n  1292→    for _, user := range c.users {\n  1293→        // Don't send message back to sender\n  1294→        if user != sender {\n  1295→            user.Receive(msg)\n  1296→        }\n  1297→    }\n  1298→}\n  1299→\n  1300→func (c *ChatRoom) AddUser(user User) {\n  1301→    c.users = append(c.users, user)\n  1302→    user.SetMediator(c)\n  1303→}\n  1304→\n  1305→// Concrete colleague\n  1306→type ChatUser struct {\n  1307→    name     string\n  1308→    mediator ChatRoomMediator\n  1309→}\n  1310→\n  1311→func NewChatUser(name string) *ChatUser {\n  1312→    return &ChatUser{name: name}\n  1313→}\n  1314→\n  1315→func (u *ChatUser) Send(msg string) {\n  1316→    fmt.Printf(\"%s sends: %s\\n\", u.name, msg)\n  1317→    if u.mediator != nil {\n  1318→        u.mediator.SendMessage(msg, u)\n  1319→    }\n  1320→}\n  1321→\n  1322→func (u *ChatUser) Receive(msg string) {\n  1323→    fmt.Printf(\"%s receives: %s\\n\", u.name, msg)\n  1324→}\n  1325→\n  1326→func (u *ChatUser) SetMediator(mediator ChatRoomMediator) {\n  1327→    u.mediator = mediator\n  1328→}\n  1329→\n  1330→// Usage\n  1331→func main() {\n  1332→    chatRoom := &ChatRoom{}\n  1333→    \n  1334→    alice := NewChatUser(\"Alice\")\n  1335→    bob := NewChatUser(\"Bob\")\n  1336→    charlie := NewChatUser(\"Charlie\")\n  1337→    \n  1338→    chatRoom.AddUser(alice)\n  1339→    chatRoom.AddUser(bob)\n  1340→    chatRoom.AddUser(charlie)\n  1341→    \n  1342→    alice.Send(\"Hello everyone!\")\n  1343→    bob.Send(\"Hey Alice!\")\n  1344→}\n  1345→```\n  1346→\n  1347→### Memento\n  1348→Memento captures and externalizes an object's internal state for later restoration.\n  1349→\n  1350→```go\n  1351→// Memento\n  1352→type EditorMemento struct {\n  1353→    content string\n  1354→    cursor  int\n  1355→}\n  1356→\n  1357→// Originator\n  1358→type TextEditor struct {\n  1359→    content string\n  1360→    cursor  int\n  1361→}\n  1362→\n  1363→func (e *TextEditor) Type(text string) {\n  1364→    e.content = e.content[:e.cursor] + text + e.content[e.cursor:]\n  1365→    e.cursor += len(text)\n  1366→}\n  1367→\n  1368→func (e *TextEditor) Delete(length int) {\n  1369→    if e.cursor >= length {\n  1370→        e.content = e.content[:e.cursor-length] + e.content[e.cursor:]\n  1371→        e.cursor -= length\n  1372→    }\n  1373→}\n  1374→\n  1375→func (e *TextEditor) Save() *EditorMemento {\n  1376→    return &EditorMemento{\n  1377→        content: e.content,\n  1378→        cursor:  e.cursor,\n  1379→    }\n  1380→}\n  1381→\n  1382→func (e *TextEditor) Restore(memento *EditorMemento) {\n  1383→    e.content = memento.content\n  1384→    e.cursor = memento.cursor\n  1385→}\n  1386→\n  1387→func (e *TextEditor) String() string {\n  1388→    return fmt.Sprintf(\"Content: %s (cursor at %d)\", e.content, e.cursor)\n  1389→}\n  1390→\n  1391→// Caretaker\n  1392→type History struct {\n  1393→    mementos []*EditorMemento\n  1394→    current  int\n  1395→}\n  1396→\n  1397→func (h *History) Push(memento *EditorMemento) {\n  1398→    // Remove any states after current position\n  1399→    h.mementos = h.mementos[:h.current+1]\n  1400→    h.mementos = append(h.mementos, memento)\n  1401→    h.current++\n  1402→}\n  1403→\n  1404→func (h *History) Undo() *EditorMemento {\n  1405→    if h.current > 0 {\n  1406→        h.current--\n  1407→        return h.mementos[h.current]\n  1408→    }\n  1409→    return nil\n  1410→}\n  1411→\n  1412→func (h *History) Redo() *EditorMemento {\n  1413→    if h.current < len(h.mementos)-1 {\n  1414→        h.current++\n  1415→        return h.mementos[h.current]\n  1416→    }\n  1417→    return nil\n  1418→}\n  1419→\n  1420→// Usage\n  1421→func main() {\n  1422→    editor := &TextEditor{}\n  1423→    history := &History{}\n  1424→    \n  1425→    // Initial state\n  1426→    history.Push(editor.Save())\n  1427→    \n  1428→    editor.Type(\"Hello \")\n  1429→    history.Push(editor.Save())\n  1430→    \n  1431→    editor.Type(\"World\")\n  1432→    history.Push(editor.Save())\n  1433→    \n  1434→    editor.Type(\"!\")\n  1435→    history.Push(editor.Save())\n  1436→    \n  1437→    fmt.Println(editor)\n  1438→    \n  1439→    // Undo\n  1440→    if memento := history.Undo(); memento != nil {\n  1441→        editor.Restore(memento)\n  1442→        fmt.Println(\"After undo:\", editor)\n  1443→    }\n  1444→    \n  1445→    // Undo again\n  1446→    if memento := history.Undo(); memento != nil {\n  1447→        editor.Restore(memento)\n  1448→        fmt.Println(\"After undo:\", editor)\n  1449→    }\n  1450→    \n  1451→    // Redo\n  1452→    if memento := history.Redo(); memento != nil {\n  1453→        editor.Restore(memento)\n  1454→        fmt.Println(\"After redo:\", editor)\n  1455→    }\n  1456→}\n  1457→```\n  1458→\n  1459→### Observer\n  1460→Observer defines a one-to-many dependency between objects where state changes are automatically notified.\n  1461→\n  1462→```go\n  1463→// Observer interface\n  1464→type Observer interface {\n  1465→    Update(event string, data interface{})\n  1466→}\n  1467→\n  1468→// Subject interface\n  1469→type Subject interface {\n  1470→    Attach(observer Observer)\n  1471→    Detach(observer Observer)\n  1472→    Notify(event string, data interface{})\n  1473→}\n  1474→\n  1475→// Concrete subject\n  1476→type StockPrice struct {\n  1477→    observers map[Observer]bool\n  1478→    symbol    string\n  1479→    price     float64\n  1480→}\n  1481→\n  1482→func NewStockPrice(symbol string) *StockPrice {\n  1483→    return &StockPrice{\n  1484→        observers: make(map[Observer]bool),\n  1485→        symbol:    symbol,\n  1486→    }\n  1487→}\n  1488→\n  1489→func (s *StockPrice) Attach(observer Observer) {\n  1490→    s.observers[observer] = true\n  1491→}\n  1492→\n  1493→func (s *StockPrice) Detach(observer Observer) {\n  1494→    delete(s.observers, observer)\n  1495→}\n  1496→\n  1497→func (s *StockPrice) Notify(event string, data interface{}) {\n  1498→    for observer := range s.observers {\n  1499→        observer.Update(event, data)\n  1500→    }\n  1501→}\n  1502→\n  1503→func (s *StockPrice) SetPrice(price float64) {\n  1504→    oldPrice := s.price\n  1505→    s.price = price\n  1506→    \n  1507→    change := ((price - oldPrice) / oldPrice) * 100\n  1508→    s.Notify(\"price_changed\", map[string]interface{}{\n  1509→        \"symbol\":    s.symbol,\n  1510→        \"old_price\": oldPrice,\n  1511→        \"new_price\": price,\n  1512→        \"change\":    change,\n  1513→    })\n  1514→}\n  1515→\n  1516→// Concrete observers\n  1517→type InvestorAlert struct {\n  1518→    name string\n  1519→}\n  1520→\n  1521→func (i *InvestorAlert) Update(event string, data interface{}) {\n  1522→    if event == \"price_changed\" {\n  1523→        priceData := data.(map[string]interface{})\n  1524→        fmt.Printf(\"[%s] Price alert: %s changed from %.2f to %.2f (%.2f%%)\\n\",\n  1525→            i.name,\n  1526→            priceData[\"symbol\"],\n  1527→            priceData[\"old_price\"],\n  1528→            priceData[\"new_price\"],\n  1529→            priceData[\"change\"])\n  1530→    }\n  1531→}\n  1532→\n  1533→type TradingBot struct {\n  1534→    threshold float64\n  1535→}\n  1536→\n  1537→func (t *TradingBot) Update(event string, data interface{}) {\n  1538→    if event == \"price_changed\" {\n  1539→        priceData := data.(map[string]interface{})\n  1540→        change := priceData[\"change\"].(float64)\n  1541→        \n  1542→        if change > t.threshold {\n  1543→            fmt.Printf(\"[Bot] BUY signal: price increased by %.2f%%\\n\", change)\n  1544→        } else if change < -t.threshold {\n  1545→            fmt.Printf(\"[Bot] SELL signal: price decreased by %.2f%%\\n\", change)\n  1546→        }\n  1547→    }\n  1548→}\n  1549→\n  1550→// Usage\n  1551→func main() {\n  1552→    stock := NewStockPrice(\"AAPL\")\n  1553→    \n  1554→    investor := &InvestorAlert{name: \"John\"}\n  1555→    bot := &TradingBot{threshold: 5.0}\n  1556→    \n  1557→    stock.Attach(investor)\n  1558→    stock.Attach(bot)\n  1559→    \n  1560→    stock.SetPrice(100.00)\n  1561→    stock.SetPrice(105.50)\n  1562→    stock.SetPrice(98.00)\n  1563→}\n  1564→```\n  1565→\n  1566→### State\n  1567→State allows an object to alter its behavior when its internal state changes.\n  1568→\n  1569→```go\n  1570→// State interface\n  1571→type State interface {\n  1572→    InsertCoin(m *VendingMachine)\n  1573→    SelectProduct(m *VendingMachine)\n  1574→    Dispense(m *VendingMachine)\n  1575→    Cancel(m *VendingMachine)\n  1576→}\n  1577→\n  1578→// Context\n  1579→type VendingMachine struct {\n  1580→    state    State\n  1581→    coins    int\n  1582→    products int\n  1583→}\n  1584→\n  1585→func NewVendingMachine(products int) *VendingMachine {\n  1586→    vm := &VendingMachine{\n  1587→        products: products,\n  1588→    }\n  1589→    vm.state = &IdleState{}\n  1590→    return vm\n  1591→}\n  1592→\n  1593→func (m *VendingMachine) SetState(state State) {\n  1594→    m.state = state\n  1595→    fmt.Printf(\"State changed to: %T\\n\", state)\n  1596→}\n  1597→\n  1598→func (m *VendingMachine) InsertCoin() {\n  1599→    m.state.InsertCoin(m)\n  1600→}\n  1601→\n  1602→func (m *VendingMachine) SelectProduct() {\n  1603→    m.state.SelectProduct(m)\n  1604→}\n  1605→\n  1606→func (m *VendingMachine) Dispense() {\n  1607→    m.state.Dispense(m)\n  1608→}\n  1609→\n  1610→func (m *VendingMachine) Cancel() {\n  1611→    m.state.Cancel(m)\n  1612→}\n  1613→\n  1614→// Concrete states\n  1615→type IdleState struct{}\n  1616→\n  1617→func (s *IdleState) InsertCoin(m *VendingMachine) {\n  1618→    fmt.Println(\"Coin inserted\")\n  1619→    m.coins++\n  1620→    m.SetState(&HasCoinState{})\n  1621→}\n  1622→\n  1623→func (s *IdleState) SelectProduct(m *VendingMachine) {\n  1624→    fmt.Println(\"Please insert coin first\")\n  1625→}\n  1626→\n  1627→func (s *IdleState) Dispense(m *VendingMachine) {\n  1628→    fmt.Println(\"Please insert coin and select product\")\n  1629→}\n  1630→\n  1631→func (s *IdleState) Cancel(m *VendingMachine) {\n  1632→    fmt.Println(\"Nothing to cancel\")\n  1633→}\n  1634→\n  1635→type HasCoinState struct{}\n  1636→\n  1637→func (s *HasCoinState) InsertCoin(m *VendingMachine) {\n  1638→    fmt.Println(\"Coin already inserted\")\n  1639→}\n  1640→\n  1641→func (s *HasCoinState) SelectProduct(m *VendingMachine) {\n  1642→    if m.products > 0 {\n  1643→        fmt.Println(\"Product selected\")\n  1644→        m.SetState(&DispensingState{})\n  1645→        m.Dispense()\n  1646→    } else {\n  1647→        fmt.Println(\"Out of products\")\n  1648→        m.Cancel()\n  1649→    }\n  1650→}\n  1651→\n  1652→func (s *HasCoinState) Dispense(m *VendingMachine) {\n  1653→    fmt.Println(\"Please select product first\")\n  1654→}\n  1655→\n  1656→func (s *HasCoinState) Cancel(m *VendingMachine) {\n  1657→    fmt.Println(\"Returning coin\")\n  1658→    m.coins--\n  1659→    m.SetState(&IdleState{})\n  1660→}\n  1661→\n  1662→type DispensingState struct{}\n  1663→\n  1664→func (s *DispensingState) InsertCoin(m *VendingMachine) {\n  1665→    fmt.Println(\"Please wait, dispensing product\")\n  1666→}\n  1667→\n  1668→func (s *DispensingState) SelectProduct(m *VendingMachine) {\n  1669→    fmt.Println(\"Please wait, dispensing product\")\n  1670→}\n  1671→\n  1672→func (s *DispensingState) Dispense(m *VendingMachine) {\n  1673→    fmt.Println(\"Dispensing product\")\n  1674→    m.products--\n  1675→    m.coins--\n  1676→    m.SetState(&IdleState{})\n  1677→}\n  1678→\n  1679→func (s *DispensingState) Cancel(m *VendingMachine) {\n  1680→    fmt.Println(\"Cannot cancel, already dispensing\")\n  1681→}\n  1682→\n  1683→// Usage\n  1684→func main() {\n  1685→    machine := NewVendingMachine(2)\n  1686→    \n  1687→    machine.SelectProduct() // Error: need coin\n  1688→    machine.InsertCoin()\n  1689→    machine.SelectProduct() // OK, dispenses\n  1690→    \n  1691→    machine.InsertCoin()\n  1692→    machine.Cancel() // Returns coin\n  1693→}\n  1694→```\n  1695→\n  1696→### Strategy\n  1697→Strategy defines a family of algorithms and makes them interchangeable.\n  1698→\n  1699→```go\n  1700→// Strategy interface\n  1701→type PaymentStrategy interface {\n  1702→    Pay(amount float64) error\n  1703→    GetName() string\n  1704→}\n  1705→\n  1706→// Concrete strategies\n  1707→type CreditCardStrategy struct {\n  1708→    number string\n  1709→    cvv    string\n  1710→}\n  1711→\n  1712→func (c *CreditCardStrategy) Pay(amount float64) error {\n  1713→    fmt.Printf(\"Paying $%.2f with credit card %s\\n\", amount, c.number)\n  1714→    // Payment logic\n  1715→    return nil\n  1716→}\n  1717→\n  1718→func (c *CreditCardStrategy) GetName() string {\n  1719→    return \"Credit Card\"\n  1720→}\n  1721→\n  1722→type PayPalStrategy struct {\n  1723→    email string\n  1724→}\n  1725→\n  1726→func (p *PayPalStrategy) Pay(amount float64) error {\n  1727→    fmt.Printf(\"Paying $%.2f with PayPal account %s\\n\", amount, p.email)\n  1728→    // Payment logic\n  1729→    return nil\n  1730→}\n  1731→\n  1732→func (p *PayPalStrategy) GetName() string {\n  1733→    return \"PayPal\"\n  1734→}\n  1735→\n  1736→type CryptoStrategy struct {\n  1737→    walletAddress string\n  1738→}\n  1739→\n  1740→func (c *CryptoStrategy) Pay(amount float64) error {\n  1741→    fmt.Printf(\"Paying $%.2f with crypto wallet %s\\n\", amount, c.walletAddress)\n  1742→    // Payment logic\n  1743→    return nil\n  1744→}\n  1745→\n  1746→func (c *CryptoStrategy) GetName() string {\n  1747→    return \"Cryptocurrency\"\n  1748→}\n  1749→\n  1750→// Context\n  1751→type ShoppingCart struct {\n  1752→    items    []string\n  1753→    total    float64\n  1754→    strategy PaymentStrategy\n  1755→}\n  1756→\n  1757→func (s *ShoppingCart) AddItem(item string, price float64) {\n  1758→    s.items = append(s.items, item)\n  1759→    s.total += price\n  1760→}\n  1761→\n  1762→func (s *ShoppingCart) SetPaymentStrategy(strategy PaymentStrategy) {\n  1763→    s.strategy = strategy\n  1764→    fmt.Printf(\"Payment method set to: %s\\n\", strategy.GetName())\n  1765→}\n  1766→\n  1767→func (s *ShoppingCart) Checkout() error {\n  1768→    if s.strategy == nil {\n  1769→        return fmt.Errorf(\"no payment method selected\")\n  1770→    }\n  1771→    \n  1772→    fmt.Printf(\"Total: $%.2f\\n\", s.total)\n  1773→    return s.strategy.Pay(s.total)\n  1774→}\n  1775→\n  1776→// Usage\n  1777→func main() {\n  1778→    cart := &ShoppingCart{}\n  1779→    cart.AddItem(\"Laptop\", 999.99)\n  1780→    cart.AddItem(\"Mouse\", 29.99)\n  1781→    \n  1782→    // Pay with credit card\n  1783→    cart.SetPaymentStrategy(&CreditCardStrategy{\n  1784→        number: \"1234-5678-9012-3456\",\n  1785→        cvv:    \"123\",\n  1786→    })\n  1787→    cart.Checkout()\n  1788→    \n  1789→    // Change to PayPal\n  1790→    cart.SetPaymentStrategy(&PayPalStrategy{\n  1791→        email: \"user@example.com\",\n  1792→    })\n  1793→    cart.Checkout()\n  1794→}\n  1795→```\n  1796→\n  1797→### Template Method\n  1798→Template Method defines the skeleton of an algorithm in a base class, letting subclasses override specific steps.\n  1799→\n  1800→```go\n  1801→// Abstract class (using struct embedding in Go)\n  1802→type DataProcessor struct {\n  1803→    // Define the interface that subclasses must implement\n  1804→    processor DataProcessorInterface\n  1805→}\n  1806→\n  1807→type DataProcessorInterface interface {\n  1808→    Extract() ([]byte, error)\n  1809→    Transform(data []byte) ([]byte, error)\n  1810→    Load(data []byte) error\n  1811→}\n  1812→\n  1813→// Template method\n  1814→func (d *DataProcessor) Process() error {\n  1815→    // Extract\n  1816→    data, err := d.processor.Extract()\n  1817→    if err != nil {\n  1818→        return fmt.Errorf(\"extraction failed: %w\", err)\n  1819→    }\n  1820→    \n  1821→    // Transform\n  1822→    transformed, err := d.processor.Transform(data)\n  1823→    if err != nil {\n  1824→        return fmt.Errorf(\"transformation failed: %w\", err)\n  1825→    }\n  1826→    \n  1827→    // Load\n  1828→    if err := d.processor.Load(transformed); err != nil {\n  1829→        return fmt.Errorf(\"loading failed: %w\", err)\n  1830→    }\n  1831→    \n  1832→    return nil\n  1833→}\n  1834→\n  1835→// Concrete implementation - CSV Processor\n  1836→type CSVProcessor struct {\n  1837→    DataProcessor\n  1838→    filename string\n  1839→}\n  1840→\n  1841→func NewCSVProcessor(filename string) *CSVProcessor {\n  1842→    p := &CSVProcessor{filename: filename}\n  1843→    p.DataProcessor.processor = p\n  1844→    return p\n  1845→}\n  1846→\n  1847→func (c *CSVProcessor) Extract() ([]byte, error) {\n  1848→    fmt.Printf(\"Extracting data from CSV file: %s\\n\", c.filename)\n  1849→    // Read CSV file\n  1850→    return []byte(\"csv,data,here\"), nil\n  1851→}\n  1852→\n  1853→func (c *CSVProcessor) Transform(data []byte) ([]byte, error) {\n  1854→    fmt.Println(\"Transforming CSV data\")\n  1855→    // Transform CSV data\n  1856→    return []byte(\"transformed csv data\"), nil\n  1857→}\n  1858→\n  1859→func (c *CSVProcessor) Load(data []byte) error {\n  1860→    fmt.Println(\"Loading CSV data to database\")\n  1861→    // Load to database\n  1862→    return nil\n  1863→}\n  1864→\n  1865→// Concrete implementation - JSON Processor\n  1866→type JSONProcessor struct {\n  1867→    DataProcessor\n  1868→    url string\n  1869→}\n  1870→\n  1871→func NewJSONProcessor(url string) *JSONProcessor {\n  1872→    p := &JSONProcessor{url: url}\n  1873→    p.DataProcessor.processor = p\n  1874→    return p\n  1875→}\n  1876→\n  1877→func (j *JSONProcessor) Extract() ([]byte, error) {\n  1878→    fmt.Printf(\"Fetching JSON from API: %s\\n\", j.url)\n  1879→    // Fetch from API\n  1880→    return []byte(`{\"data\": \"value\"}`), nil\n  1881→}\n  1882→\n  1883→func (j *JSONProcessor) Transform(data []byte) ([]byte, error) {\n  1884→    fmt.Println(\"Transforming JSON data\")\n  1885→    // Transform JSON\n  1886→    return []byte(\"transformed json\"), nil\n  1887→}\n  1888→\n  1889→func (j *JSONProcessor) Load(data []byte) error {\n  1890→    fmt.Println(\"Loading JSON data to cache\")\n  1891→    // Load to cache\n  1892→    return nil\n  1893→}\n  1894→\n  1895→// Usage\n  1896→func main() {\n  1897→    csvProcessor := NewCSVProcessor(\"data.csv\")\n  1898→    if err := csvProcessor.Process(); err != nil {\n  1899→        fmt.Printf(\"CSV processing failed: %v\\n\", err)\n  1900→    }\n  1901→    \n  1902→    fmt.Println()\n  1903→    \n  1904→    jsonProcessor := NewJSONProcessor(\"https://api.example.com/data\")\n  1905→    if err := jsonProcessor.Process(); err != nil {\n  1906→        fmt.Printf(\"JSON processing failed: %v\\n\", err)\n  1907→    }\n  1908→}\n  1909→```\n  1910→\n  1911→### Visitor\n  1912→Visitor lets you define new operations without changing the classes of elements on which it operates.\n  1913→\n  1914→```go\n  1915→// Element interface\n  1916→type Shape interface {\n  1917→    Accept(visitor Visitor)\n  1918→}\n  1919→\n  1920→// Visitor interface\n  1921→type Visitor interface {\n  1922→    VisitCircle(c *Circle)\n  1923→    VisitRectangle(r *Rectangle)\n  1924→    VisitTriangle(t *Triangle)\n  1925→}\n  1926→\n  1927→// Concrete elements\n  1928→type Circle struct {\n  1929→    Radius float64\n  1930→}\n  1931→\n  1932→func (c *Circle) Accept(visitor Visitor) {\n  1933→    visitor.VisitCircle(c)\n  1934→}\n  1935→\n  1936→type Rectangle struct {\n  1937→    Width, Height float64\n  1938→}\n  1939→\n  1940→func (r *Rectangle) Accept(visitor Visitor) {\n  1941→    visitor.VisitRectangle(r)\n  1942→}\n  1943→\n  1944→type Triangle struct {\n  1945→    Base, Height float64\n  1946→}\n  1947→\n  1948→func (t *Triangle) Accept(visitor Visitor) {\n  1949→    visitor.VisitTriangle(t)\n  1950→}\n  1951→\n  1952→// Concrete visitors\n  1953→type AreaCalculator struct {\n  1954→    totalArea float64\n  1955→}\n  1956→\n  1957→func (a *AreaCalculator) VisitCircle(c *Circle) {\n  1958→    area := 3.14159 * c.Radius * c.Radius\n  1959→    fmt.Printf(\"Circle area: %.2f\\n\", area)\n  1960→    a.totalArea += area\n  1961→}\n  1962→\n  1963→func (a *AreaCalculator) VisitRectangle(r *Rectangle) {\n  1964→    area := r.Width * r.Height\n  1965→    fmt.Printf(\"Rectangle area: %.2f\\n\", area)\n  1966→    a.totalArea += area\n  1967→}\n  1968→\n  1969→func (a *AreaCalculator) VisitTriangle(t *Triangle) {\n  1970→    area := 0.5 * t.Base * t.Height\n  1971→    fmt.Printf(\"Triangle area: %.2f\\n\", area)\n  1972→    a.totalArea += area\n  1973→}\n  1974→\n  1975→type PerimeterCalculator struct {\n  1976→    totalPerimeter float64\n  1977→}\n  1978→\n  1979→func (p *PerimeterCalculator) VisitCircle(c *Circle) {\n  1980→    perimeter := 2 * 3.14159 * c.Radius\n  1981→    fmt.Printf(\"Circle perimeter: %.2f\\n\", perimeter)\n  1982→    p.totalPerimeter += perimeter\n  1983→}\n  1984→\n  1985→func (p *PerimeterCalculator) VisitRectangle(r *Rectangle) {\n  1986→    perimeter := 2 * (r.Width + r.Height)\n  1987→    fmt.Printf(\"Rectangle perimeter: %.2f\\n\", perimeter)\n  1988→    p.totalPerimeter += perimeter\n  1989→}\n  1990→\n  1991→func (p *PerimeterCalculator) VisitTriangle(t *Triangle) {\n  1992→    // Simplified: assuming equilateral triangle\n  1993→    perimeter := 3 * t.Base\n  1994→    fmt.Printf(\"Triangle perimeter: %.2f\\n\", perimeter)\n  1995→    p.totalPerimeter += perimeter\n  1996→}\n  1997→\n  1998→// Usage\n  1999→func main() {\n  2000→    shapes := []Shape{\n  2001→        &Circle{Radius: 5},\n  2002→        &Rectangle{Width: 10, Height: 5},\n  2003→        &Triangle{Base: 6, Height: 4},\n  2004→    }\n  2005→    \n  2006→    areaCalc := &AreaCalculator{}\n  2007→    for _, shape := range shapes {\n  2008→        shape.Accept(areaCalc)\n  2009→    }\n  2010→    fmt.Printf(\"Total area: %.2f\\n\\n\", areaCalc.totalArea)\n  2011→    \n  2012→    perimCalc := &PerimeterCalculator{}\n  2013→    for _, shape := range shapes {\n  2014→        shape.Accept(perimCalc)\n  2015→    }\n  2016→    fmt.Printf(\"Total perimeter: %.2f\\n\", perimCalc.totalPerimeter)\n  2017→}\n  2018→```\n  2019→\n  2020→## Architectural Patterns\n  2021→\n  2022→### Repository Pattern\n  2023→Repository encapsulates data access logic and provides a more object-oriented view of the persistence layer.\n  2024→\n  2025→```go\n  2026→// Domain model\n  2027→type User struct {\n  2028→    ID        string\n  2029→    Email     string\n  2030→    FirstName string\n  2031→    LastName  string\n  2032→    CreatedAt time.Time\n  2033→}\n  2034→\n  2035→// Repository interface\n  2036→type UserRepository interface {\n  2037→    Create(ctx context.Context, user *User) error\n  2038→    GetByID(ctx context.Context, id string) (*User, error)\n  2039→    GetByEmail(ctx context.Context, email string) (*User, error)\n  2040→    Update(ctx context.Context, user *User) error\n  2041→    Delete(ctx context.Context, id string) error\n  2042→    List(ctx context.Context, offset, limit int) ([]*User, error)\n  2043→}\n  2044→\n  2045→// PostgreSQL implementation\n  2046→type PostgresUserRepository struct {\n  2047→    db *sql.DB\n  2048→}\n  2049→\n  2050→func NewPostgresUserRepository(db *sql.DB) *PostgresUserRepository {\n  2051→    return &PostgresUserRepository{db: db}\n  2052→}\n  2053→\n  2054→func (r *PostgresUserRepository) Create(ctx context.Context, user *User) error {\n  2055→    query := `\n  2056→        INSERT INTO users (id, email, first_name, last_name, created_at)\n  2057→        VALUES ($1, $2, $3, $4, $5)\n  2058→    `\n  2059→    _, err := r.db.ExecContext(ctx, query,\n  2060→        user.ID, user.Email, user.FirstName, user.LastName, user.CreatedAt)\n  2061→    return err\n  2062→}\n  2063→\n  2064→func (r *PostgresUserRepository) GetByID(ctx context.Context, id string) (*User, error) {\n  2065→    query := `\n  2066→        SELECT id, email, first_name, last_name, created_at\n  2067→        FROM users WHERE id = $1\n  2068→    `\n  2069→    user := &User{}\n  2070→    err := r.db.QueryRowContext(ctx, query, id).Scan(\n  2071→        &user.ID, &user.Email, &user.FirstName, &user.LastName, &user.CreatedAt)\n  2072→    if err == sql.ErrNoRows {\n  2073→        return nil, fmt.Errorf(\"user not found\")\n  2074→    }\n  2075→    return user, err\n  2076→}\n  2077→\n  2078→// In-memory implementation for testing\n  2079→type InMemoryUserRepository struct {\n  2080→    mu    sync.RWMutex\n  2081→    users map[string]*User\n  2082→}\n  2083→\n  2084→func NewInMemoryUserRepository() *InMemoryUserRepository {\n  2085→    return &InMemoryUserRepository{\n  2086→        users: make(map[string]*User),\n  2087→    }\n  2088→}\n  2089→\n  2090→func (r *InMemoryUserRepository) Create(ctx context.Context, user *User) error {\n  2091→    r.mu.Lock()\n  2092→    defer r.mu.Unlock()\n  2093→    \n  2094→    if _, exists := r.users[user.ID]; exists {\n  2095→        return fmt.Errorf(\"user already exists\")\n  2096→    }\n  2097→    r.users[user.ID] = user\n  2098→    return nil\n  2099→}\n  2100→\n  2101→func (r *InMemoryUserRepository) GetByID(ctx context.Context, id string) (*User, error) {\n  2102→    r.mu.RLock()\n  2103→    defer r.mu.RUnlock()\n  2104→    \n  2105→    if user, exists := r.users[id]; exists {\n  2106→        return user, nil\n  2107→    }\n  2108→    return nil, fmt.Errorf(\"user not found\")\n  2109→}\n  2110→```\n  2111→\n  2112→### Unit of Work Pattern\n  2113→Unit of Work maintains a list of objects affected by a business transaction and coordinates writing out changes.\n  2114→\n  2115→```go\n  2116→// Unit of Work interface\n  2117→type UnitOfWork interface {\n  2118→    UserRepository() UserRepository\n  2119→    OrderRepository() OrderRepository\n  2120→    Commit() error\n  2121→    Rollback() error\n  2122→}\n  2123→\n  2124→// PostgreSQL Unit of Work\n  2125→type PostgresUnitOfWork struct {\n  2126→    tx    *sql.Tx\n  2127→    users *PostgresUserRepository\n  2128→    orders *PostgresOrderRepository\n  2129→}\n  2130→\n  2131→func NewPostgresUnitOfWork(db *sql.DB) (*PostgresUnitOfWork, error) {\n  2132→    tx, err := db.Begin()\n  2133→    if err != nil {\n  2134→        return nil, err\n  2135→    }\n  2136→    \n  2137→    return &PostgresUnitOfWork{\n  2138→        tx:     tx,\n  2139→        users:  &PostgresUserRepository{db: db},\n  2140→        orders: &PostgresOrderRepository{db: db},\n  2141→    }, nil\n  2142→}\n  2143→\n  2144→func (u *PostgresUnitOfWork) UserRepository() UserRepository {\n  2145→    return u.users\n  2146→}\n  2147→\n  2148→func (u *PostgresUnitOfWork) OrderRepository() OrderRepository {\n  2149→    return u.orders\n  2150→}\n  2151→\n  2152→func (u *PostgresUnitOfWork) Commit() error {\n  2153→    return u.tx.Commit()\n  2154→}\n  2155→\n  2156→func (u *PostgresUnitOfWork) Rollback() error {\n  2157→    return u.tx.Rollback()\n  2158→}\n  2159→\n  2160→// Service using Unit of Work\n  2161→type OrderService struct {\n  2162→    uowFactory func() (UnitOfWork, error)\n  2163→}\n  2164→\n  2165→func (s *OrderService) CreateOrder(userID string, items []OrderItem) error {\n  2166→    uow, err := s.uowFactory()\n  2167→    if err != nil {\n  2168→        return err\n  2169→    }\n  2170→    defer uow.Rollback()\n  2171→    \n  2172→    // Check user exists\n  2173→    user, err := uow.UserRepository().GetByID(context.Background(), userID)\n  2174→    if err != nil {\n  2175→        return err\n  2176→    }\n  2177→    \n  2178→    // Create order\n  2179→    order := &Order{\n  2180→        UserID: user.ID,\n  2181→        Items:  items,\n  2182→        Total:  calculateTotal(items),\n  2183→    }\n  2184→    \n  2185→    if err := uow.OrderRepository().Create(context.Background(), order); err != nil {\n  2186→        return err\n  2187→    }\n  2188→    \n  2189→    // Update user stats\n  2190→    user.TotalOrders++\n  2191→    if err := uow.UserRepository().Update(context.Background(), user); err != nil {\n  2192→        return err\n  2193→    }\n  2194→    \n  2195→    // Commit transaction\n  2196→    return uow.Commit()\n  2197→}\n  2198→```\n  2199→\n  2200→## Domain-Driven Design Patterns\n  2201→\n  2202→### Value Object\n  2203→Value Objects are immutable objects that represent a descriptive aspect of the domain.\n  2204→\n  2205→```go\n  2206→// Value Object - immutable\n  2207→type Money struct {\n  2208→    amount   decimal.Decimal\n  2209→    currency string\n  2210→}\n  2211→\n  2212→func NewMoney(amount decimal.Decimal, currency string) (Money, error) {\n  2213→    if currency == \"\" {\n  2214→        return Money{}, fmt.Errorf(\"currency is required\")\n  2215→    }\n  2216→    if amount.IsNegative() {\n  2217→        return Money{}, fmt.Errorf(\"amount cannot be negative\")\n  2218→    }\n  2219→    return Money{amount: amount, currency: currency}, nil\n  2220→}\n  2221→\n  2222→func (m Money) Amount() decimal.Decimal {\n  2223→    return m.amount\n  2224→}\n  2225→\n  2226→func (m Money) Currency() string {\n  2227→    return m.currency\n  2228→}\n  2229→\n  2230→func (m Money) Add(other Money) (Money, error) {\n  2231→    if m.currency != other.currency {\n  2232→        return Money{}, fmt.Errorf(\"cannot add different currencies\")\n  2233→    }\n  2234→    return Money{\n  2235→        amount:   m.amount.Add(other.amount),\n  2236→        currency: m.currency,\n  2237→    }, nil\n  2238→}\n  2239→\n  2240→func (m Money) Equals(other Money) bool {\n  2241→    return m.amount.Equal(other.amount) && m.currency == other.currency\n  2242→}\n  2243→\n  2244→// Another Value Object example\n  2245→type Email struct {\n  2246→    value string\n  2247→}\n  2248→\n  2249→func NewEmail(value string) (Email, error) {\n  2250→    if !isValidEmail(value) {\n  2251→        return Email{}, fmt.Errorf(\"invalid email format\")\n  2252→    }\n  2253→    return Email{value: strings.ToLower(value)}, nil\n  2254→}\n  2255→\n  2256→func (e Email) String() string {\n  2257→    return e.value\n  2258→}\n  2259→\n  2260→func (e Email) Domain() string {\n  2261→    parts := strings.Split(e.value, \"@\")\n  2262→    if len(parts) == 2 {\n  2263→        return parts[1]\n  2264→    }\n  2265→    return \"\"\n  2266→}\n  2267→```\n  2268→\n  2269→### Entity\n  2270→Entities have identity and lifecycle.\n  2271→\n  2272→```go\n  2273→// Entity with identity\n  2274→type Product struct {\n  2275→    id          ProductID // Value object as ID\n  2276→    name        string\n  2277→    description string\n  2278→    price       Money\n  2279→    stock       int\n  2280→    version     int // For optimistic locking\n  2281→}\n  2282→\n  2283→type ProductID struct {\n  2284→    value string\n  2285→}\n  2286→\n  2287→func NewProductID(value string) (ProductID, error) {\n  2288→    if value == \"\" {\n  2289→        return ProductID{}, fmt.Errorf(\"product ID cannot be empty\")\n  2290→    }\n  2291→    return ProductID{value: value}, nil\n  2292→}\n  2293→\n  2294→func (p ProductID) String() string {\n  2295→    return p.value\n  2296→}\n  2297→\n  2298→func NewProduct(id ProductID, name string, price Money) (*Product, error) {\n  2299→    if name == \"\" {\n  2300→        return nil, fmt.Errorf(\"product name is required\")\n  2301→    }\n  2302→    \n  2303→    return &Product{\n  2304→        id:    id,\n  2305→        name:  name,\n  2306→        price: price,\n  2307→        stock: 0,\n  2308→    }, nil\n  2309→}\n  2310→\n  2311→func (p *Product) ID() ProductID {\n  2312→    return p.id\n  2313→}\n  2314→\n  2315→func (p *Product) UpdatePrice(newPrice Money) error {\n  2316→    if newPrice.Amount().IsZero() {\n  2317→        return fmt.Errorf(\"price cannot be zero\")\n  2318→    }\n  2319→    p.price = newPrice\n  2320→    p.version++\n  2321→    return nil\n  2322→}\n  2323→\n  2324→func (p *Product) AddStock(quantity int) error {\n  2325→    if quantity <= 0 {\n  2326→        return fmt.Errorf(\"quantity must be positive\")\n  2327→    }\n  2328→    p.stock += quantity\n  2329→    p.version++\n  2330→    return nil\n  2331→}\n  2332→\n  2333→func (p *Product) CanFulfillOrder(quantity int) bool {\n  2334→    return p.stock >= quantity\n  2335→}\n  2336→```\n  2337→\n  2338→### Aggregate\n  2339→Aggregates are clusters of domain objects that are treated as a single unit.\n  2340→\n  2341→```go\n  2342→// Aggregate root\n  2343→type Order struct {\n  2344→    id         OrderID\n  2345→    customerID CustomerID\n  2346→    items      []OrderItem\n  2347→    status     OrderStatus\n  2348→    totalAmount Money\n  2349→    placedAt   time.Time\n  2350→    version    int\n  2351→}\n  2352→\n  2353→// Part of the aggregate\n  2354→type OrderItem struct {\n  2355→    productID ProductID\n  2356→    quantity  int\n  2357→    unitPrice Money\n  2358→}\n  2359→\n  2360→type OrderStatus string\n  2361→\n  2362→const (\n  2363→    OrderStatusPending   OrderStatus = \"PENDING\"\n  2364→    OrderStatusConfirmed OrderStatus = \"CONFIRMED\"\n  2365→    OrderStatusShipped   OrderStatus = \"SHIPPED\"\n  2366→    OrderStatusDelivered OrderStatus = \"DELIVERED\"\n  2367→    OrderStatusCancelled OrderStatus = \"CANCELLED\"\n  2368→)\n  2369→\n  2370→func NewOrder(customerID CustomerID) *Order {\n  2371→    return &Order{\n  2372→        id:         NewOrderID(),\n  2373→        customerID: customerID,\n  2374→        items:      []OrderItem{},\n  2375→        status:     OrderStatusPending,\n  2376→        placedAt:   time.Now(),\n  2377→    }\n  2378→}\n  2379→\n  2380→func (o *Order) AddItem(productID ProductID, quantity int, unitPrice Money) error {\n  2381→    if o.status != OrderStatusPending {\n  2382→        return fmt.Errorf(\"cannot modify confirmed order\")\n  2383→    }\n  2384→    \n  2385→    if quantity <= 0 {\n  2386→        return fmt.Errorf(\"quantity must be positive\")\n  2387→    }\n  2388→    \n  2389→    // Check if item already exists\n  2390→    for i, item := range o.items {\n  2391→        if item.productID == productID {\n  2392→            o.items[i].quantity += quantity\n  2393→            o.recalculateTotal()\n  2394→            return nil\n  2395→        }\n  2396→    }\n  2397→    \n  2398→    // Add new item\n  2399→    o.items = append(o.items, OrderItem{\n  2400→        productID: productID,\n  2401→        quantity:  quantity,\n  2402→        unitPrice: unitPrice,\n  2403→    })\n  2404→    \n  2405→    o.recalculateTotal()\n  2406→    return nil\n  2407→}\n  2408→\n  2409→func (o *Order) RemoveItem(productID ProductID) error {\n  2410→    if o.status != OrderStatusPending {\n  2411→        return fmt.Errorf(\"cannot modify confirmed order\")\n  2412→    }\n  2413→    \n  2414→    for i, item := range o.items {\n  2415→        if item.productID == productID {\n  2416→            o.items = append(o.items[:i], o.items[i+1:]...)\n  2417→            o.recalculateTotal()\n  2418→            return nil\n  2419→        }\n  2420→    }\n  2421→    \n  2422→    return fmt.Errorf(\"item not found\")\n  2423→}\n  2424→\n  2425→func (o *Order) Confirm() error {\n  2426→    if o.status != OrderStatusPending {\n  2427→        return fmt.Errorf(\"order is not pending\")\n  2428→    }\n  2429→    \n  2430→    if len(o.items) == 0 {\n  2431→        return fmt.Errorf(\"order has no items\")\n  2432→    }\n  2433→    \n  2434→    o.status = OrderStatusConfirmed\n  2435→    o.version++\n  2436→    return nil\n  2437→}\n  2438→\n  2439→func (o *Order) recalculateTotal() {\n  2440→    total := decimal.Zero\n  2441→    currency := \"\"\n  2442→    \n  2443→    for _, item := range o.items {\n  2444→        itemTotal := item.unitPrice.Amount().Mul(decimal.NewFromInt(int64(item.quantity)))\n  2445→        total = total.Add(itemTotal)\n  2446→        if currency == \"\" {\n  2447→            currency = item.unitPrice.Currency()\n  2448→        }\n  2449→    }\n  2450→    \n  2451→    o.totalAmount, _ = NewMoney(total, currency)\n  2452→}\n  2453→\n  2454→// Aggregate repository\n  2455→type OrderRepository interface {\n  2456→    Save(ctx context.Context, order *Order) error\n  2457→    GetByID(ctx context.Context, id OrderID) (*Order, error)\n  2458→    // Never expose internal parts of aggregate\n  2459→    // Bad: GetOrderItems(orderID) []OrderItem\n  2460→}\n  2461→```\n  2462→\n  2463→### Domain Service\n  2464→Domain Services encapsulate domain logic that doesn't naturally fit within an entity or value object.\n  2465→\n  2466→```go\n  2467→// Domain service for complex business logic\n  2468→type PricingService struct {\n  2469→    taxCalculator TaxCalculator\n  2470→    discountRepo  DiscountRepository\n  2471→}\n  2472→\n  2473→func NewPricingService(tax TaxCalculator, discounts DiscountRepository) *PricingService {\n  2474→    return &PricingService{\n  2475→        taxCalculator: tax,\n  2476→        discountRepo:  discounts,\n  2477→    }\n  2478→}\n  2479→\n  2480→func (s *PricingService) CalculateOrderTotal(order *Order, customerType CustomerType) (Money, error) {\n  2481→    subtotal := order.totalAmount\n  2482→    \n  2483→    // Apply customer discount\n  2484→    discount := s.getCustomerDiscount(customerType)\n  2485→    discountAmount := subtotal.Amount().Mul(discount)\n  2486→    afterDiscount := subtotal.Amount().Sub(discountAmount)\n  2487→    \n  2488→    // Calculate tax\n  2489→    tax := s.taxCalculator.CalculateTax(afterDiscount, order.ShippingAddress())\n  2490→    \n  2491→    // Final total\n  2492→    total := afterDiscount.Add(tax)\n  2493→    \n  2494→    return NewMoney(total, subtotal.Currency())\n  2495→}\n  2496→\n  2497→func (s *PricingService) getCustomerDiscount(customerType CustomerType) decimal.Decimal {\n  2498→    switch customerType {\n  2499→    case CustomerTypePremium:\n  2500→        return decimal.NewFromFloat(0.15) // 15% discount\n  2501→    case CustomerTypeRegular:\n  2502→        return decimal.NewFromFloat(0.05) // 5% discount\n  2503→    default:\n  2504→        return decimal.Zero\n  2505→    }\n  2506→}\n  2507→\n  2508→// Another domain service example\n  2509→type TransferService struct {\n  2510→    accountRepo AccountRepository\n  2511→}\n  2512→\n  2513→func (s *TransferService) Transfer(ctx context.Context, fromID, toID AccountID, amount Money) error {\n  2514→    // This logic doesn't belong to either account\n  2515→    // It's a domain service coordinating between aggregates\n  2516→    \n  2517→    from, err := s.accountRepo.GetByID(ctx, fromID)\n  2518→    if err != nil {\n  2519→        return err\n  2520→    }\n  2521→    \n  2522→    to, err := s.accountRepo.GetByID(ctx, toID)\n  2523→    if err != nil {\n  2524→        return err\n  2525→    }\n  2526→    \n  2527→    if err := from.Withdraw(amount); err != nil {\n  2528→        return err\n  2529→    }\n  2530→    \n  2531→    if err := to.Deposit(amount); err != nil {\n  2532→        // Compensate\n  2533→        from.Deposit(amount)\n  2534→        return err\n  2535→    }\n  2536→    \n  2537→    // Save both accounts\n  2538→    if err := s.accountRepo.Save(ctx, from); err != nil {\n  2539→        return err\n  2540→    }\n  2541→    \n  2542→    return s.accountRepo.Save(ctx, to)\n  2543→}\n  2544→```\n  2545→\n  2546→### Specification Pattern\n  2547→Specification pattern encapsulates business rules in a reusable way.\n  2548→\n  2549→```go\n  2550→// Specification interface\n  2551→type Specification[T any] interface {\n  2552→    IsSatisfiedBy(T) bool\n  2553→    And(Specification[T]) Specification[T]\n  2554→    Or(Specification[T]) Specification[T]\n  2555→    Not() Specification[T]\n  2556→}\n  2557→\n  2558→// Base specification\n  2559→type BaseSpecification[T any] struct {\n  2560→    predicate func(T) bool\n  2561→}\n  2562→\n  2563→func NewSpecification[T any](predicate func(T) bool) Specification[T] {\n  2564→    return &BaseSpecification[T]{predicate: predicate}\n  2565→}\n  2566→\n  2567→func (s *BaseSpecification[T]) IsSatisfiedBy(item T) bool {\n  2568→    return s.predicate(item)\n  2569→}\n  2570→\n  2571→func (s *BaseSpecification[T]) And(other Specification[T]) Specification[T] {\n  2572→    return &BaseSpecification[T]{\n  2573→        predicate: func(item T) bool {\n  2574→            return s.IsSatisfiedBy(item) && other.IsSatisfiedBy(item)\n  2575→        },\n  2576→    }\n  2577→}\n  2578→\n  2579→func (s *BaseSpecification[T]) Or(other Specification[T]) Specification[T] {\n  2580→    return &BaseSpecification[T]{\n  2581→        predicate: func(item T) bool {\n  2582→            return s.IsSatisfiedBy(item) || other.IsSatisfiedBy(item)\n  2583→        },\n  2584→    }\n  2585→}\n  2586→\n  2587→func (s *BaseSpecification[T]) Not() Specification[T] {\n  2588→    return &BaseSpecification[T]{\n  2589→        predicate: func(item T) bool {\n  2590→            return !s.IsSatisfiedBy(item)\n  2591→        },\n  2592→    }\n  2593→}\n  2594→\n  2595→// Concrete specifications\n  2596→type Product struct {\n  2597→    Name     string\n  2598→    Price    decimal.Decimal\n  2599→    Category string\n  2600→    InStock  bool\n  2601→}\n  2602→\n  2603→var PremiumProductSpec = NewSpecification(func(p Product) bool {\n  2604→    return p.Price.GreaterThan(decimal.NewFromInt(100))\n  2605→})\n  2606→\n  2607→var InStockSpec = NewSpecification(func(p Product) bool {\n  2608→    return p.InStock\n  2609→})\n  2610→\n  2611→var ElectronicsSpec = NewSpecification(func(p Product) bool {\n  2612→    return p.Category == \"Electronics\"\n  2613→})\n  2614→\n  2615→// Usage\n  2616→func FilterProducts(products []Product, spec Specification[Product]) []Product {\n  2617→    var result []Product\n  2618→    for _, p := range products {\n  2619→        if spec.IsSatisfiedBy(p) {\n  2620→            result = append(result, p)\n  2621→        }\n  2622→    }\n  2623→    return result\n  2624→}\n  2625→\n  2626→func main() {\n  2627→    products := []Product{\n  2628→        {Name: \"Laptop\", Price: decimal.NewFromInt(1200), Category: \"Electronics\", InStock: true},\n  2629→        {Name: \"Mouse\", Price: decimal.NewFromInt(25), Category: \"Electronics\", InStock: true},\n  2630→        {Name: \"Book\", Price: decimal.NewFromInt(15), Category: \"Books\", InStock: false},\n  2631→    }\n  2632→    \n  2633→    // Premium electronics in stock\n  2634→    spec := PremiumProductSpec.And(ElectronicsSpec).And(InStockSpec)\n  2635→    \n  2636→    filtered := FilterProducts(products, spec)\n  2637→    fmt.Printf(\"Found %d products\\n\", len(filtered))\n  2638→}\n  2639→```\n  2640→\n  2641→## Summary\n  2642→\n  2643→This comprehensive guide covers the major design patterns adapted for Go:\n  2644→\n  2645→1. **Creational Patterns**: Control object creation mechanisms\n  2646→2. **Structural Patterns**: Compose objects to form larger structures\n  2647→3. **Behavioral Patterns**: Define communication between objects\n  2648→4. **Architectural Patterns**: Organize high-level application structure\n  2649→5. **Domain-Driven Design Patterns**: Model complex business domains\n  2650→\n  2651→Each pattern includes practical Go implementations with proper error handling, concurrency considerations, and idiomatic Go practices. Choose patterns based on your specific needs, keeping in mind Go's philosophy of simplicity and clarity.\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"55ad924a-6a0c-4feb-a6e5-1514ac1e12e2","timestamp":"2025-08-13T09:59:07.399Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/design-patterns.md","content":"# Design Patterns in Go\n\n## Overview\nThis document covers classic design patterns (Gang of Four) and architectural patterns as they apply to Go. For Go-specific idioms and conventions, see `practices-patterns.md`.\n\n## Table of Contents\n1. [Creational Patterns](#creational-patterns)\n2. [Structural Patterns](#structural-patterns)\n3. [Behavioral Patterns](#behavioral-patterns)\n4. [Architectural Patterns](#architectural-patterns)\n5. [Domain-Driven Design Patterns](#domain-driven-design-patterns)\n\n## Creational Patterns\n\n### Singleton\nThe singleton pattern ensures only one instance of a type exists. In Go, use `sync.Once` for thread-safe initialization.\n\n```go\npackage database\n\nimport (\n    \"database/sql\"\n    \"sync\"\n)\n\ntype DB struct {\n    conn *sql.DB\n}\n\nvar (\n    instance *DB\n    once     sync.Once\n)\n\n// GetInstance returns the singleton database instance\nfunc GetInstance() *DB {\n    once.Do(func() {\n        conn, _ := sql.Open(\"postgres\", \"connection-string\")\n        instance = &DB{conn: conn}\n    })\n    return instance\n}\n\n// Alternative: Package-level initialization (simpler for most cases)\nvar defaultDB = initDB()\n\nfunc initDB() *DB {\n    conn, _ := sql.Open(\"postgres\", \"connection-string\")\n    return &DB{conn: conn}\n}\n```\n\n### Factory Method\nFactory method defines an interface for creating objects but lets subclasses decide which class to instantiate.\n\n```go\n// Product interface\ntype Transport interface {\n    Deliver() string\n    Cost() float64\n}\n\n// Concrete products\ntype Truck struct {\n    capacity int\n}\n\nfunc (t *Truck) Deliver() string {\n    return \"Delivering by land\"\n}\n\nfunc (t *Truck) Cost() float64 {\n    return 100.0\n}\n\ntype Ship struct {\n    tonnage int\n}\n\nfunc (s *Ship) Deliver() string {\n    return \"Delivering by sea\"\n}\n\nfunc (s *Ship) Cost() float64 {\n    return 500.0\n}\n\n// Factory\ntype LogisticsFactory interface {\n    CreateTransport() Transport\n}\n\ntype RoadLogistics struct{}\n\nfunc (r *RoadLogistics) CreateTransport() Transport {\n    return &Truck{capacity: 1000}\n}\n\ntype SeaLogistics struct{}\n\nfunc (s *SeaLogistics) CreateTransport() Transport {\n    return &Ship{tonnage: 10000}\n}\n\n// Usage\nfunc planDelivery(factory LogisticsFactory) {\n    transport := factory.CreateTransport()\n    fmt.Println(transport.Deliver())\n    fmt.Printf(\"Cost: $%.2f\\n\", transport.Cost())\n}\n```\n\n### Abstract Factory\nAbstract factory provides an interface for creating families of related objects.\n\n```go\n// Abstract products\ntype Button interface {\n    Paint()\n}\n\ntype Checkbox interface {\n    Check()\n}\n\n// Concrete products - Windows family\ntype WindowsButton struct{}\n\nfunc (w *WindowsButton) Paint() {\n    fmt.Println(\"Rendering Windows button\")\n}\n\ntype WindowsCheckbox struct{}\n\nfunc (w *WindowsCheckbox) Check() {\n    fmt.Println(\"Checking Windows checkbox\")\n}\n\n// Concrete products - Mac family\ntype MacButton struct{}\n\nfunc (m *MacButton) Paint() {\n    fmt.Println(\"Rendering Mac button\")\n}\n\ntype MacCheckbox struct{}\n\nfunc (m *MacCheckbox) Check() {\n    fmt.Println(\"Checking Mac checkbox\")\n}\n\n// Abstract factory\ntype GUIFactory interface {\n    CreateButton() Button\n    CreateCheckbox() Checkbox\n}\n\n// Concrete factories\ntype WindowsFactory struct{}\n\nfunc (w *WindowsFactory) CreateButton() Button {\n    return &WindowsButton{}\n}\n\nfunc (w *WindowsFactory) CreateCheckbox() Checkbox {\n    return &WindowsCheckbox{}\n}\n\ntype MacFactory struct{}\n\nfunc (m *MacFactory) CreateButton() Button {\n    return &MacButton{}\n}\n\nfunc (m *MacFactory) CreateCheckbox() Checkbox {\n    return &MacCheckbox{}\n}\n\n// Application\ntype Application struct {\n    factory GUIFactory\n    button  Button\n    checkbox Checkbox\n}\n\nfunc NewApplication(factory GUIFactory) *Application {\n    return &Application{\n        factory:  factory,\n        button:   factory.CreateButton(),\n        checkbox: factory.CreateCheckbox(),\n    }\n}\n\nfunc (a *Application) Paint() {\n    a.button.Paint()\n    a.checkbox.Check()\n}\n```\n\n### Builder\nBuilder pattern separates the construction of complex objects from their representation.\n\n```go\n// Product\ntype House struct {\n    Foundation string\n    Structure  string\n    Roof       string\n    Interior   string\n    Garden     bool\n    Pool       bool\n}\n\n// Builder interface\ntype HouseBuilder interface {\n    SetFoundation() HouseBuilder\n    SetStructure() HouseBuilder\n    SetRoof() HouseBuilder\n    SetInterior() HouseBuilder\n    SetGarden() HouseBuilder\n    SetPool() HouseBuilder\n    Build() *House\n}\n\n// Concrete builder\ntype ModernHouseBuilder struct {\n    house *House\n}\n\nfunc NewModernHouseBuilder() *ModernHouseBuilder {\n    return &ModernHouseBuilder{\n        house: &House{},\n    }\n}\n\nfunc (b *ModernHouseBuilder) SetFoundation() HouseBuilder {\n    b.house.Foundation = \"Concrete, brick, and stone\"\n    return b\n}\n\nfunc (b *ModernHouseBuilder) SetStructure() HouseBuilder {\n    b.house.Structure = \"Steel and glass\"\n    return b\n}\n\nfunc (b *ModernHouseBuilder) SetRoof() HouseBuilder {\n    b.house.Roof = \"Flat concrete\"\n    return b\n}\n\nfunc (b *ModernHouseBuilder) SetInterior() HouseBuilder {\n    b.house.Interior = \"Modern minimalist\"\n    return b\n}\n\nfunc (b *ModernHouseBuilder) SetGarden() HouseBuilder {\n    b.house.Garden = true\n    return b\n}\n\nfunc (b *ModernHouseBuilder) SetPool() HouseBuilder {\n    b.house.Pool = true\n    return b\n}\n\nfunc (b *ModernHouseBuilder) Build() *House {\n    return b.house\n}\n\n// Director (optional)\ntype ConstructionDirector struct {\n    builder HouseBuilder\n}\n\nfunc (d *ConstructionDirector) ConstructLuxuryHouse() *House {\n    return d.builder.\n        SetFoundation().\n        SetStructure().\n        SetRoof().\n        SetInterior().\n        SetGarden().\n        SetPool().\n        Build()\n}\n\n// Usage\nfunc main() {\n    builder := NewModernHouseBuilder()\n    \n    // Direct use\n    house := builder.\n        SetFoundation().\n        SetStructure().\n        SetRoof().\n        Build()\n    \n    // Using director\n    director := &ConstructionDirector{builder: builder}\n    luxuryHouse := director.ConstructLuxuryHouse()\n}\n```\n\n### Prototype\nPrototype pattern creates objects by cloning existing instances.\n\n```go\n// Prototype interface\ntype Prototype interface {\n    Clone() Prototype\n}\n\n// Concrete prototype\ntype Document struct {\n    Title    string\n    Content  string\n    Images   []string\n    Metadata map[string]string\n}\n\nfunc (d *Document) Clone() Prototype {\n    // Deep copy\n    newDoc := &Document{\n        Title:   d.Title,\n        Content: d.Content,\n        Images:  make([]string, len(d.Images)),\n        Metadata: make(map[string]string),\n    }\n    \n    copy(newDoc.Images, d.Images)\n    \n    for k, v := range d.Metadata {\n        newDoc.Metadata[k] = v\n    }\n    \n    return newDoc\n}\n\n// Prototype registry\ntype DocumentRegistry struct {\n    prototypes map[string]Prototype\n}\n\nfunc NewDocumentRegistry() *DocumentRegistry {\n    return &DocumentRegistry{\n        prototypes: make(map[string]Prototype),\n    }\n}\n\nfunc (r *DocumentRegistry) Register(name string, prototype Prototype) {\n    r.prototypes[name] = prototype\n}\n\nfunc (r *DocumentRegistry) Create(name string) Prototype {\n    if prototype, exists := r.prototypes[name]; exists {\n        return prototype.Clone()\n    }\n    return nil\n}\n\n// Usage\nfunc main() {\n    registry := NewDocumentRegistry()\n    \n    // Register prototypes\n    registry.Register(\"report\", &Document{\n        Title:    \"Monthly Report Template\",\n        Content:  \"...\",\n        Metadata: map[string]string{\"type\": \"report\"},\n    })\n    \n    registry.Register(\"letter\", &Document{\n        Title:    \"Business Letter Template\",\n        Content:  \"...\",\n        Metadata: map[string]string{\"type\": \"letter\"},\n    })\n    \n    // Create new documents from prototypes\n    report := registry.Create(\"report\").(*Document)\n    report.Title = \"January Report\"\n}\n```\n\n## Structural Patterns\n\n### Adapter\nAdapter allows incompatible interfaces to work together.\n\n```go\n// Target interface (what client expects)\ntype PaymentProcessor interface {\n    ProcessPayment(amount float64) error\n}\n\n// Adaptee (incompatible interface)\ntype LegacyPaymentSystem struct{}\n\nfunc (l *LegacyPaymentSystem) MakePayment(sum float64, currency string) string {\n    return fmt.Sprintf(\"Payment of %.2f %s processed\", sum, currency)\n}\n\n// Adapter\ntype PaymentAdapter struct {\n    legacy   *LegacyPaymentSystem\n    currency string\n}\n\nfunc NewPaymentAdapter(legacy *LegacyPaymentSystem, currency string) *PaymentAdapter {\n    return &PaymentAdapter{\n        legacy:   legacy,\n        currency: currency,\n    }\n}\n\nfunc (a *PaymentAdapter) ProcessPayment(amount float64) error {\n    result := a.legacy.MakePayment(amount, a.currency)\n    if result != \"\" {\n        return nil\n    }\n    return fmt.Errorf(\"payment failed\")\n}\n\n// Client code\nfunc processOrder(processor PaymentProcessor, amount float64) {\n    if err := processor.ProcessPayment(amount); err != nil {\n        fmt.Printf(\"Payment failed: %v\\n\", err)\n    } else {\n        fmt.Println(\"Payment successful\")\n    }\n}\n\n// Usage\nfunc main() {\n    legacy := &LegacyPaymentSystem{}\n    adapter := NewPaymentAdapter(legacy, \"USD\")\n    processOrder(adapter, 100.00)\n}\n```\n\n### Bridge\nBridge decouples abstraction from implementation so both can vary independently.\n\n```go\n// Implementation interface\ntype MessageSender interface {\n    Send(title, body string) error\n}\n\n// Concrete implementations\ntype EmailSender struct {\n    emailAddress string\n}\n\nfunc (e *EmailSender) Send(title, body string) error {\n    fmt.Printf(\"Email to %s: %s - %s\\n\", e.emailAddress, title, body)\n    return nil\n}\n\ntype SMSSender struct {\n    phoneNumber string\n}\n\nfunc (s *SMSSender) Send(title, body string) error {\n    fmt.Printf(\"SMS to %s: %s\\n\", s.phoneNumber, body)\n    return nil\n}\n\n// Abstraction\ntype Message struct {\n    sender MessageSender\n}\n\nfunc NewMessage(sender MessageSender) *Message {\n    return &Message{sender: sender}\n}\n\nfunc (m *Message) Send(title, body string) error {\n    return m.sender.Send(title, body)\n}\n\n// Refined abstraction\ntype UrgentMessage struct {\n    Message\n}\n\nfunc NewUrgentMessage(sender MessageSender) *UrgentMessage {\n    return &UrgentMessage{\n        Message: Message{sender: sender},\n    }\n}\n\nfunc (u *UrgentMessage) Send(title, body string) error {\n    title = \"URGENT: \" + title\n    return u.sender.Send(title, body)\n}\n\n// Usage\nfunc main() {\n    // Regular email\n    email := NewMessage(&EmailSender{emailAddress: \"user@example.com\"})\n    email.Send(\"Hello\", \"This is a test message\")\n    \n    // Urgent SMS\n    sms := NewUrgentMessage(&SMSSender{phoneNumber: \"+1234567890\"})\n    sms.Send(\"Alert\", \"Server is down\")\n}\n```\n\n### Composite\nComposite lets you compose objects into tree structures to represent part-whole hierarchies.\n\n```go\n// Component interface\ntype FileSystemNode interface {\n    GetName() string\n    GetSize() int64\n    Print(indent string)\n}\n\n// Leaf\ntype File struct {\n    name string\n    size int64\n}\n\nfunc (f *File) GetName() string {\n    return f.name\n}\n\nfunc (f *File) GetSize() int64 {\n    return f.size\n}\n\nfunc (f *File) Print(indent string) {\n    fmt.Printf(\"%sFile: %s (%d bytes)\\n\", indent, f.name, f.size)\n}\n\n// Composite\ntype Directory struct {\n    name     string\n    children []FileSystemNode\n}\n\nfunc (d *Directory) GetName() string {\n    return d.name\n}\n\nfunc (d *Directory) GetSize() int64 {\n    var total int64\n    for _, child := range d.children {\n        total += child.GetSize()\n    }\n    return total\n}\n\nfunc (d *Directory) Add(node FileSystemNode) {\n    d.children = append(d.children, node)\n}\n\nfunc (d *Directory) Remove(node FileSystemNode) {\n    for i, child := range d.children {\n        if child == node {\n            d.children = append(d.children[:i], d.children[i+1:]...)\n            break\n        }\n    }\n}\n\nfunc (d *Directory) Print(indent string) {\n    fmt.Printf(\"%sDirectory: %s (%d bytes)\\n\", indent, d.name, d.GetSize())\n    for _, child := range d.children {\n        child.Print(indent + \"  \")\n    }\n}\n\n// Usage\nfunc main() {\n    root := &Directory{name: \"root\"}\n    \n    home := &Directory{name: \"home\"}\n    root.Add(home)\n    \n    documents := &Directory{name: \"documents\"}\n    home.Add(documents)\n    \n    documents.Add(&File{name: \"report.pdf\", size: 1024000})\n    documents.Add(&File{name: \"presentation.pptx\", size: 2048000})\n    \n    home.Add(&File{name: \"notes.txt\", size: 1024})\n    \n    root.Print(\"\")\n}\n```\n\n### Decorator\nDecorator adds new functionality to objects without altering their structure.\n\n```go\n// Component interface\ntype Coffee interface {\n    GetCost() float64\n    GetDescription() string\n}\n\n// Concrete component\ntype SimpleCoffee struct{}\n\nfunc (c *SimpleCoffee) GetCost() float64 {\n    return 2.0\n}\n\nfunc (c *SimpleCoffee) GetDescription() string {\n    return \"Simple coffee\"\n}\n\n// Base decorator\ntype CoffeeDecorator struct {\n    coffee Coffee\n}\n\nfunc (d *CoffeeDecorator) GetCost() float64 {\n    return d.coffee.GetCost()\n}\n\nfunc (d *CoffeeDecorator) GetDescription() string {\n    return d.coffee.GetDescription()\n}\n\n// Concrete decorators\ntype MilkDecorator struct {\n    CoffeeDecorator\n}\n\nfunc NewMilkDecorator(coffee Coffee) *MilkDecorator {\n    return &MilkDecorator{\n        CoffeeDecorator: CoffeeDecorator{coffee: coffee},\n    }\n}\n\nfunc (m *MilkDecorator) GetCost() float64 {\n    return m.coffee.GetCost() + 0.5\n}\n\nfunc (m *MilkDecorator) GetDescription() string {\n    return m.coffee.GetDescription() + \", milk\"\n}\n\ntype SugarDecorator struct {\n    CoffeeDecorator\n}\n\nfunc NewSugarDecorator(coffee Coffee) *SugarDecorator {\n    return &SugarDecorator{\n        CoffeeDecorator: CoffeeDecorator{coffee: coffee},\n    }\n}\n\nfunc (s *SugarDecorator) GetCost() float64 {\n    return s.coffee.GetCost() + 0.2\n}\n\nfunc (s *SugarDecorator) GetDescription() string {\n    return s.coffee.GetDescription() + \", sugar\"\n}\n\n// Usage\nfunc main() {\n    coffee := &SimpleCoffee{}\n    fmt.Printf(\"%s: $%.2f\\n\", coffee.GetDescription(), coffee.GetCost())\n    \n    coffeeWithMilk := NewMilkDecorator(coffee)\n    fmt.Printf(\"%s: $%.2f\\n\", coffeeWithMilk.GetDescription(), coffeeWithMilk.GetCost())\n    \n    coffeeWithMilkAndSugar := NewSugarDecorator(coffeeWithMilk)\n    fmt.Printf(\"%s: $%.2f\\n\", coffeeWithMilkAndSugar.GetDescription(), coffeeWithMilkAndSugar.GetCost())\n}\n```\n\n### Facade\nFacade provides a simplified interface to a complex subsystem.\n\n```go\n// Complex subsystem components\ntype AccountService struct{}\n\nfunc (a *AccountService) GetAccount(id string) string {\n    return fmt.Sprintf(\"Account %s\", id)\n}\n\nfunc (a *AccountService) CheckBalance(id string) float64 {\n    return 1000.00\n}\n\ntype SecurityService struct{}\n\nfunc (s *SecurityService) Authenticate(token string) bool {\n    return token == \"valid-token\"\n}\n\nfunc (s *SecurityService) Authorize(user, action string) bool {\n    return true\n}\n\ntype TransactionService struct{}\n\nfunc (t *TransactionService) CreateTransaction(from, to string, amount float64) string {\n    return fmt.Sprintf(\"Transaction: %s -> %s: %.2f\", from, to, amount)\n}\n\nfunc (t *TransactionService) ValidateTransaction(id string) bool {\n    return true\n}\n\ntype NotificationService struct{}\n\nfunc (n *NotificationService) SendEmail(to, message string) {\n    fmt.Printf(\"Email to %s: %s\\n\", to, message)\n}\n\nfunc (n *NotificationService) SendSMS(to, message string) {\n    fmt.Printf(\"SMS to %s: %s\\n\", to, message)\n}\n\n// Facade\ntype BankingFacade struct {\n    account      *AccountService\n    security     *SecurityService\n    transaction  *TransactionService\n    notification *NotificationService\n}\n\nfunc NewBankingFacade() *BankingFacade {\n    return &BankingFacade{\n        account:      &AccountService{},\n        security:     &SecurityService{},\n        transaction:  &TransactionService{},\n        notification: &NotificationService{},\n    }\n}\n\nfunc (b *BankingFacade) Transfer(token, from, to string, amount float64) error {\n    // Authenticate\n    if !b.security.Authenticate(token) {\n        return fmt.Errorf(\"authentication failed\")\n    }\n    \n    // Check authorization\n    if !b.security.Authorize(from, \"transfer\") {\n        return fmt.Errorf(\"not authorized\")\n    }\n    \n    // Check balance\n    if b.account.CheckBalance(from) < amount {\n        return fmt.Errorf(\"insufficient funds\")\n    }\n    \n    // Create transaction\n    txID := b.transaction.CreateTransaction(from, to, amount)\n    \n    // Validate\n    if !b.transaction.ValidateTransaction(txID) {\n        return fmt.Errorf(\"transaction validation failed\")\n    }\n    \n    // Notify\n    b.notification.SendEmail(from, fmt.Sprintf(\"Transfer of %.2f completed\", amount))\n    b.notification.SendSMS(to, fmt.Sprintf(\"Received %.2f\", amount))\n    \n    return nil\n}\n\n// Usage\nfunc main() {\n    banking := NewBankingFacade()\n    \n    err := banking.Transfer(\"valid-token\", \"account1\", \"account2\", 100.00)\n    if err != nil {\n        fmt.Printf(\"Transfer failed: %v\\n\", err)\n    } else {\n        fmt.Println(\"Transfer successful\")\n    }\n}\n```\n\n### Flyweight\nFlyweight minimizes memory usage by sharing efficiently large numbers of fine-grained objects.\n\n```go\n// Flyweight interface\ntype Character interface {\n    Display(font string, size int, color string)\n}\n\n// Concrete flyweight\ntype ConcreteCharacter struct {\n    symbol rune // Intrinsic state (shared)\n}\n\nfunc (c *ConcreteCharacter) Display(font string, size int, color string) {\n    // Extrinsic state (passed in)\n    fmt.Printf(\"Character: %c, Font: %s, Size: %d, Color: %s\\n\", \n        c.symbol, font, size, color)\n}\n\n// Flyweight factory\ntype CharacterFactory struct {\n    characters map[rune]*ConcreteCharacter\n}\n\nfunc NewCharacterFactory() *CharacterFactory {\n    return &CharacterFactory{\n        characters: make(map[rune]*ConcreteCharacter),\n    }\n}\n\nfunc (f *CharacterFactory) GetCharacter(symbol rune) Character {\n    if char, exists := f.characters[symbol]; exists {\n        return char\n    }\n    \n    char := &ConcreteCharacter{symbol: symbol}\n    f.characters[symbol] = char\n    return char\n}\n\n// Context that uses flyweights\ntype TextDocument struct {\n    characters []Character\n    fonts      []string\n    sizes      []int\n    colors     []string\n}\n\nfunc (d *TextDocument) AddCharacter(char Character, font string, size int, color string) {\n    d.characters = append(d.characters, char)\n    d.fonts = append(d.fonts, font)\n    d.sizes = append(d.sizes, size)\n    d.colors = append(d.colors, color)\n}\n\nfunc (d *TextDocument) Display() {\n    for i, char := range d.characters {\n        char.Display(d.fonts[i], d.sizes[i], d.colors[i])\n    }\n}\n\n// Usage\nfunc main() {\n    factory := NewCharacterFactory()\n    doc := &TextDocument{}\n    \n    text := \"Hello World\"\n    for _, r := range text {\n        char := factory.GetCharacter(r)\n        doc.AddCharacter(char, \"Arial\", 12, \"black\")\n    }\n    \n    doc.Display()\n    \n    // Characters 'l' and 'o' are reused (shared instances)\n    fmt.Printf(\"Total unique characters created: %d\\n\", len(factory.characters))\n}\n```\n\n### Proxy\nProxy provides a placeholder or surrogate for another object to control access to it.\n\n```go\n// Subject interface\ntype Database interface {\n    Query(sql string) ([]string, error)\n}\n\n// Real subject\ntype RealDatabase struct {\n    connectionString string\n}\n\nfunc (d *RealDatabase) Query(sql string) ([]string, error) {\n    fmt.Printf(\"Executing query: %s\\n\", sql)\n    // Simulate database query\n    return []string{\"result1\", \"result2\"}, nil\n}\n\n// Proxy with caching\ntype CachingDatabaseProxy struct {\n    database *RealDatabase\n    cache    map[string][]string\n}\n\nfunc NewCachingDatabaseProxy(connString string) *CachingDatabaseProxy {\n    return &CachingDatabaseProxy{\n        database: &RealDatabase{connectionString: connString},\n        cache:    make(map[string][]string),\n    }\n}\n\nfunc (p *CachingDatabaseProxy) Query(sql string) ([]string, error) {\n    // Check cache\n    if results, exists := p.cache[sql]; exists {\n        fmt.Printf(\"Returning cached results for: %s\\n\", sql)\n        return results, nil\n    }\n    \n    // Query real database\n    results, err := p.database.Query(sql)\n    if err != nil {\n        return nil, err\n    }\n    \n    // Cache results\n    p.cache[sql] = results\n    return results, nil\n}\n\n// Security proxy\ntype SecureDatabaseProxy struct {\n    database Database\n    userRole string\n}\n\nfunc NewSecureDatabaseProxy(db Database, role string) *SecureDatabaseProxy {\n    return &SecureDatabaseProxy{\n        database: db,\n        userRole: role,\n    }\n}\n\nfunc (p *SecureDatabaseProxy) Query(sql string) ([]string, error) {\n    // Check permissions\n    if strings.Contains(strings.ToLower(sql), \"delete\") && p.userRole != \"admin\" {\n        return nil, fmt.Errorf(\"permission denied: only admin can delete\")\n    }\n    \n    return p.database.Query(sql)\n}\n\n// Usage\nfunc main() {\n    // Caching proxy\n    db := NewCachingDatabaseProxy(\"connection-string\")\n    \n    // First query hits the database\n    results, _ := db.Query(\"SELECT * FROM users\")\n    fmt.Println(\"Results:\", results)\n    \n    // Second identical query uses cache\n    results, _ = db.Query(\"SELECT * FROM users\")\n    fmt.Println(\"Results:\", results)\n    \n    // Security proxy\n    secureDB := NewSecureDatabaseProxy(db, \"user\")\n    _, err := secureDB.Query(\"DELETE FROM users\")\n    if err != nil {\n        fmt.Println(\"Error:\", err)\n    }\n}\n```\n\n## Behavioral Patterns\n\n### Chain of Responsibility\nChain of Responsibility passes requests along a chain of handlers until one handles it.\n\n```go\n// Handler interface\ntype Handler interface {\n    SetNext(Handler) Handler\n    Handle(request string) string\n}\n\n// Base handler\ntype BaseHandler struct {\n    next Handler\n}\n\nfunc (h *BaseHandler) SetNext(next Handler) Handler {\n    h.next = next\n    return next\n}\n\nfunc (h *BaseHandler) Handle(request string) string {\n    if h.next != nil {\n        return h.next.Handle(request)\n    }\n    return \"\"\n}\n\n// Concrete handlers\ntype AuthenticationHandler struct {\n    BaseHandler\n}\n\nfunc (h *AuthenticationHandler) Handle(request string) string {\n    if request == \"auth\" {\n        return \"Authentication successful\"\n    }\n    return h.BaseHandler.Handle(request)\n}\n\ntype AuthorizationHandler struct {\n    BaseHandler\n}\n\nfunc (h *AuthorizationHandler) Handle(request string) string {\n    if request == \"authz\" {\n        return \"Authorization granted\"\n    }\n    return h.BaseHandler.Handle(request)\n}\n\ntype ValidationHandler struct {\n    BaseHandler\n}\n\nfunc (h *ValidationHandler) Handle(request string) string {\n    if request == \"validate\" {\n        return \"Validation passed\"\n    }\n    return h.BaseHandler.Handle(request)\n}\n\n// Usage\nfunc main() {\n    auth := &AuthenticationHandler{}\n    authz := &AuthorizationHandler{}\n    valid := &ValidationHandler{}\n    \n    // Build chain\n    auth.SetNext(authz).SetNext(valid)\n    \n    // Process requests\n    fmt.Println(auth.Handle(\"auth\"))     // Handled by auth\n    fmt.Println(auth.Handle(\"authz\"))    // Handled by authz\n    fmt.Println(auth.Handle(\"validate\")) // Handled by valid\n    fmt.Println(auth.Handle(\"unknown\"))  // Not handled\n}\n```\n\n### Command\nCommand encapsulates a request as an object, letting you parameterize clients with different requests.\n\n```go\n// Command interface\ntype Command interface {\n    Execute() error\n    Undo() error\n}\n\n// Receiver\ntype Light struct {\n    isOn bool\n}\n\nfunc (l *Light) TurnOn() {\n    l.isOn = true\n    fmt.Println(\"Light is on\")\n}\n\nfunc (l *Light) TurnOff() {\n    l.isOn = false\n    fmt.Println(\"Light is off\")\n}\n\n// Concrete commands\ntype TurnOnCommand struct {\n    light *Light\n}\n\nfunc (c *TurnOnCommand) Execute() error {\n    c.light.TurnOn()\n    return nil\n}\n\nfunc (c *TurnOnCommand) Undo() error {\n    c.light.TurnOff()\n    return nil\n}\n\ntype TurnOffCommand struct {\n    light *Light\n}\n\nfunc (c *TurnOffCommand) Execute() error {\n    c.light.TurnOff()\n    return nil\n}\n\nfunc (c *TurnOffCommand) Undo() error {\n    c.light.TurnOn()\n    return nil\n}\n\n// Invoker\ntype RemoteControl struct {\n    commands []Command\n    history  []Command\n}\n\nfunc (r *RemoteControl) SetCommand(slot int, cmd Command) {\n    if slot >= len(r.commands) {\n        r.commands = append(r.commands, make([]Command, slot-len(r.commands)+1)...)\n    }\n    r.commands[slot] = cmd\n}\n\nfunc (r *RemoteControl) PressButton(slot int) {\n    if slot < len(r.commands) && r.commands[slot] != nil {\n        r.commands[slot].Execute()\n        r.history = append(r.history, r.commands[slot])\n    }\n}\n\nfunc (r *RemoteControl) PressUndo() {\n    if len(r.history) > 0 {\n        lastCommand := r.history[len(r.history)-1]\n        lastCommand.Undo()\n        r.history = r.history[:len(r.history)-1]\n    }\n}\n\n// Macro command\ntype MacroCommand struct {\n    commands []Command\n}\n\nfunc (m *MacroCommand) Execute() error {\n    for _, cmd := range m.commands {\n        if err := cmd.Execute(); err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\nfunc (m *MacroCommand) Undo() error {\n    // Undo in reverse order\n    for i := len(m.commands) - 1; i >= 0; i-- {\n        if err := m.commands[i].Undo(); err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\n// Usage\nfunc main() {\n    light := &Light{}\n    remote := &RemoteControl{}\n    \n    turnOn := &TurnOnCommand{light: light}\n    turnOff := &TurnOffCommand{light: light}\n    \n    remote.SetCommand(0, turnOn)\n    remote.SetCommand(1, turnOff)\n    \n    remote.PressButton(0) // Turn on\n    remote.PressButton(1) // Turn off\n    remote.PressUndo()    // Turn on again\n}\n```\n\n### Iterator\nIterator provides a way to access elements of a collection sequentially without exposing its underlying representation.\n\n```go\n// Iterator interface\ntype Iterator[T any] interface {\n    HasNext() bool\n    Next() T\n}\n\n// Collection interface\ntype Collection[T any] interface {\n    CreateIterator() Iterator[T]\n}\n\n// Concrete collection\ntype BookCollection struct {\n    books []string\n}\n\nfunc (c *BookCollection) Add(book string) {\n    c.books = append(c.books, book)\n}\n\nfunc (c *BookCollection) CreateIterator() Iterator[string] {\n    return &BookIterator{\n        collection: c,\n        index:      0,\n    }\n}\n\n// Concrete iterator\ntype BookIterator struct {\n    collection *BookCollection\n    index      int\n}\n\nfunc (i *BookIterator) HasNext() bool {\n    return i.index < len(i.collection.books)\n}\n\nfunc (i *BookIterator) Next() string {\n    if i.HasNext() {\n        book := i.collection.books[i.index]\n        i.index++\n        return book\n    }\n    return \"\"\n}\n\n// Usage with channels (Go idiomatic)\ntype ChannelIterator[T any] struct {\n    ch <-chan T\n    current T\n    hasNext bool\n}\n\nfunc NewChannelIterator[T any](items []T) *ChannelIterator[T] {\n    ch := make(chan T)\n    go func() {\n        for _, item := range items {\n            ch <- item\n        }\n        close(ch)\n    }()\n    \n    iter := &ChannelIterator[T]{ch: ch}\n    iter.advance()\n    return iter\n}\n\nfunc (i *ChannelIterator[T]) advance() {\n    i.current, i.hasNext = <-i.ch\n}\n\nfunc (i *ChannelIterator[T]) HasNext() bool {\n    return i.hasNext\n}\n\nfunc (i *ChannelIterator[T]) Next() T {\n    current := i.current\n    i.advance()\n    return current\n}\n\n// Usage\nfunc main() {\n    // Traditional iterator\n    collection := &BookCollection{}\n    collection.Add(\"Design Patterns\")\n    collection.Add(\"Clean Code\")\n    collection.Add(\"The Pragmatic Programmer\")\n    \n    iterator := collection.CreateIterator()\n    for iterator.HasNext() {\n        fmt.Println(iterator.Next())\n    }\n    \n    // Channel-based iterator\n    numbers := []int{1, 2, 3, 4, 5}\n    numIter := NewChannelIterator(numbers)\n    for numIter.HasNext() {\n        fmt.Println(numIter.Next())\n    }\n}\n```\n\n### Mediator\nMediator defines how a set of objects interact, promoting loose coupling.\n\n```go\n// Mediator interface\ntype ChatRoomMediator interface {\n    SendMessage(msg string, user User)\n    AddUser(user User)\n}\n\n// Colleague interface\ntype User interface {\n    Send(msg string)\n    Receive(msg string)\n    SetMediator(mediator ChatRoomMediator)\n}\n\n// Concrete mediator\ntype ChatRoom struct {\n    users []User\n}\n\nfunc (c *ChatRoom) SendMessage(msg string, sender User) {\n    for _, user := range c.users {\n        // Don't send message back to sender\n        if user != sender {\n            user.Receive(msg)\n        }\n    }\n}\n\nfunc (c *ChatRoom) AddUser(user User) {\n    c.users = append(c.users, user)\n    user.SetMediator(c)\n}\n\n// Concrete colleague\ntype ChatUser struct {\n    name     string\n    mediator ChatRoomMediator\n}\n\nfunc NewChatUser(name string) *ChatUser {\n    return &ChatUser{name: name}\n}\n\nfunc (u *ChatUser) Send(msg string) {\n    fmt.Printf(\"%s sends: %s\\n\", u.name, msg)\n    if u.mediator != nil {\n        u.mediator.SendMessage(msg, u)\n    }\n}\n\nfunc (u *ChatUser) Receive(msg string) {\n    fmt.Printf(\"%s receives: %s\\n\", u.name, msg)\n}\n\nfunc (u *ChatUser) SetMediator(mediator ChatRoomMediator) {\n    u.mediator = mediator\n}\n\n// Usage\nfunc main() {\n    chatRoom := &ChatRoom{}\n    \n    alice := NewChatUser(\"Alice\")\n    bob := NewChatUser(\"Bob\")\n    charlie := NewChatUser(\"Charlie\")\n    \n    chatRoom.AddUser(alice)\n    chatRoom.AddUser(bob)\n    chatRoom.AddUser(charlie)\n    \n    alice.Send(\"Hello everyone!\")\n    bob.Send(\"Hey Alice!\")\n}\n```\n\n### Memento\nMemento captures and externalizes an object's internal state for later restoration.\n\n```go\n// Memento\ntype EditorMemento struct {\n    content string\n    cursor  int\n}\n\n// Originator\ntype TextEditor struct {\n    content string\n    cursor  int\n}\n\nfunc (e *TextEditor) Type(text string) {\n    e.content = e.content[:e.cursor] + text + e.content[e.cursor:]\n    e.cursor += len(text)\n}\n\nfunc (e *TextEditor) Delete(length int) {\n    if e.cursor >= length {\n        e.content = e.content[:e.cursor-length] + e.content[e.cursor:]\n        e.cursor -= length\n    }\n}\n\nfunc (e *TextEditor) Save() *EditorMemento {\n    return &EditorMemento{\n        content: e.content,\n        cursor:  e.cursor,\n    }\n}\n\nfunc (e *TextEditor) Restore(memento *EditorMemento) {\n    e.content = memento.content\n    e.cursor = memento.cursor\n}\n\nfunc (e *TextEditor) String() string {\n    return fmt.Sprintf(\"Content: %s (cursor at %d)\", e.content, e.cursor)\n}\n\n// Caretaker\ntype History struct {\n    mementos []*EditorMemento\n    current  int\n}\n\nfunc (h *History) Push(memento *EditorMemento) {\n    // Remove any states after current position\n    h.mementos = h.mementos[:h.current+1]\n    h.mementos = append(h.mementos, memento)\n    h.current++\n}\n\nfunc (h *History) Undo() *EditorMemento {\n    if h.current > 0 {\n        h.current--\n        return h.mementos[h.current]\n    }\n    return nil\n}\n\nfunc (h *History) Redo() *EditorMemento {\n    if h.current < len(h.mementos)-1 {\n        h.current++\n        return h.mementos[h.current]\n    }\n    return nil\n}\n\n// Usage\nfunc main() {\n    editor := &TextEditor{}\n    history := &History{}\n    \n    // Initial state\n    history.Push(editor.Save())\n    \n    editor.Type(\"Hello \")\n    history.Push(editor.Save())\n    \n    editor.Type(\"World\")\n    history.Push(editor.Save())\n    \n    editor.Type(\"!\")\n    history.Push(editor.Save())\n    \n    fmt.Println(editor)\n    \n    // Undo\n    if memento := history.Undo(); memento != nil {\n        editor.Restore(memento)\n        fmt.Println(\"After undo:\", editor)\n    }\n    \n    // Undo again\n    if memento := history.Undo(); memento != nil {\n        editor.Restore(memento)\n        fmt.Println(\"After undo:\", editor)\n    }\n    \n    // Redo\n    if memento := history.Redo(); memento != nil {\n        editor.Restore(memento)\n        fmt.Println(\"After redo:\", editor)\n    }\n}\n```\n\n### Observer\nObserver defines a one-to-many dependency between objects where state changes are automatically notified.\n\n```go\n// Observer interface\ntype Observer interface {\n    Update(event string, data interface{})\n}\n\n// Subject interface\ntype Subject interface {\n    Attach(observer Observer)\n    Detach(observer Observer)\n    Notify(event string, data interface{})\n}\n\n// Concrete subject\ntype StockPrice struct {\n    observers map[Observer]bool\n    symbol    string\n    price     float64\n}\n\nfunc NewStockPrice(symbol string) *StockPrice {\n    return &StockPrice{\n        observers: make(map[Observer]bool),\n        symbol:    symbol,\n    }\n}\n\nfunc (s *StockPrice) Attach(observer Observer) {\n    s.observers[observer] = true\n}\n\nfunc (s *StockPrice) Detach(observer Observer) {\n    delete(s.observers, observer)\n}\n\nfunc (s *StockPrice) Notify(event string, data interface{}) {\n    for observer := range s.observers {\n        observer.Update(event, data)\n    }\n}\n\nfunc (s *StockPrice) SetPrice(price float64) {\n    oldPrice := s.price\n    s.price = price\n    \n    change := ((price - oldPrice) / oldPrice) * 100\n    s.Notify(\"price_changed\", map[string]interface{}{\n        \"symbol\":    s.symbol,\n        \"old_price\": oldPrice,\n        \"new_price\": price,\n        \"change\":    change,\n    })\n}\n\n// Concrete observers\ntype InvestorAlert struct {\n    name string\n}\n\nfunc (i *InvestorAlert) Update(event string, data interface{}) {\n    if event == \"price_changed\" {\n        priceData := data.(map[string]interface{})\n        fmt.Printf(\"[%s] Price alert: %s changed from %.2f to %.2f (%.2f%%)\\n\",\n            i.name,\n            priceData[\"symbol\"],\n            priceData[\"old_price\"],\n            priceData[\"new_price\"],\n            priceData[\"change\"])\n    }\n}\n\ntype TradingBot struct {\n    threshold float64\n}\n\nfunc (t *TradingBot) Update(event string, data interface{}) {\n    if event == \"price_changed\" {\n        priceData := data.(map[string]interface{})\n        change := priceData[\"change\"].(float64)\n        \n        if change > t.threshold {\n            fmt.Printf(\"[Bot] BUY signal: price increased by %.2f%%\\n\", change)\n        } else if change < -t.threshold {\n            fmt.Printf(\"[Bot] SELL signal: price decreased by %.2f%%\\n\", change)\n        }\n    }\n}\n\n// Usage\nfunc main() {\n    stock := NewStockPrice(\"AAPL\")\n    \n    investor := &InvestorAlert{name: \"John\"}\n    bot := &TradingBot{threshold: 5.0}\n    \n    stock.Attach(investor)\n    stock.Attach(bot)\n    \n    stock.SetPrice(100.00)\n    stock.SetPrice(105.50)\n    stock.SetPrice(98.00)\n}\n```\n\n### State\nState allows an object to alter its behavior when its internal state changes.\n\n```go\n// State interface\ntype State interface {\n    InsertCoin(m *VendingMachine)\n    SelectProduct(m *VendingMachine)\n    Dispense(m *VendingMachine)\n    Cancel(m *VendingMachine)\n}\n\n// Context\ntype VendingMachine struct {\n    state    State\n    coins    int\n    products int\n}\n\nfunc NewVendingMachine(products int) *VendingMachine {\n    vm := &VendingMachine{\n        products: products,\n    }\n    vm.state = &IdleState{}\n    return vm\n}\n\nfunc (m *VendingMachine) SetState(state State) {\n    m.state = state\n    fmt.Printf(\"State changed to: %T\\n\", state)\n}\n\nfunc (m *VendingMachine) InsertCoin() {\n    m.state.InsertCoin(m)\n}\n\nfunc (m *VendingMachine) SelectProduct() {\n    m.state.SelectProduct(m)\n}\n\nfunc (m *VendingMachine) Dispense() {\n    m.state.Dispense(m)\n}\n\nfunc (m *VendingMachine) Cancel() {\n    m.state.Cancel(m)\n}\n\n// Concrete states\ntype IdleState struct{}\n\nfunc (s *IdleState) InsertCoin(m *VendingMachine) {\n    fmt.Println(\"Coin inserted\")\n    m.coins++\n    m.SetState(&HasCoinState{})\n}\n\nfunc (s *IdleState) SelectProduct(m *VendingMachine) {\n    fmt.Println(\"Please insert coin first\")\n}\n\nfunc (s *IdleState) Dispense(m *VendingMachine) {\n    fmt.Println(\"Please insert coin and select product\")\n}\n\nfunc (s *IdleState) Cancel(m *VendingMachine) {\n    fmt.Println(\"Nothing to cancel\")\n}\n\ntype HasCoinState struct{}\n\nfunc (s *HasCoinState) InsertCoin(m *VendingMachine) {\n    fmt.Println(\"Coin already inserted\")\n}\n\nfunc (s *HasCoinState) SelectProduct(m *VendingMachine) {\n    if m.products > 0 {\n        fmt.Println(\"Product selected\")\n        m.SetState(&DispensingState{})\n        m.Dispense()\n    } else {\n        fmt.Println(\"Out of products\")\n        m.Cancel()\n    }\n}\n\nfunc (s *HasCoinState) Dispense(m *VendingMachine) {\n    fmt.Println(\"Please select product first\")\n}\n\nfunc (s *HasCoinState) Cancel(m *VendingMachine) {\n    fmt.Println(\"Returning coin\")\n    m.coins--\n    m.SetState(&IdleState{})\n}\n\ntype DispensingState struct{}\n\nfunc (s *DispensingState) InsertCoin(m *VendingMachine) {\n    fmt.Println(\"Please wait, dispensing product\")\n}\n\nfunc (s *DispensingState) SelectProduct(m *VendingMachine) {\n    fmt.Println(\"Please wait, dispensing product\")\n}\n\nfunc (s *DispensingState) Dispense(m *VendingMachine) {\n    fmt.Println(\"Dispensing product\")\n    m.products--\n    m.coins--\n    m.SetState(&IdleState{})\n}\n\nfunc (s *DispensingState) Cancel(m *VendingMachine) {\n    fmt.Println(\"Cannot cancel, already dispensing\")\n}\n\n// Usage\nfunc main() {\n    machine := NewVendingMachine(2)\n    \n    machine.SelectProduct() // Error: need coin\n    machine.InsertCoin()\n    machine.SelectProduct() // OK, dispenses\n    \n    machine.InsertCoin()\n    machine.Cancel() // Returns coin\n}\n```\n\n### Strategy\nStrategy defines a family of algorithms and makes them interchangeable.\n\n```go\n// Strategy interface\ntype PaymentStrategy interface {\n    Pay(amount float64) error\n    GetName() string\n}\n\n// Concrete strategies\ntype CreditCardStrategy struct {\n    number string\n    cvv    string\n}\n\nfunc (c *CreditCardStrategy) Pay(amount float64) error {\n    fmt.Printf(\"Paying $%.2f with credit card %s\\n\", amount, c.number)\n    // Payment logic\n    return nil\n}\n\nfunc (c *CreditCardStrategy) GetName() string {\n    return \"Credit Card\"\n}\n\ntype PayPalStrategy struct {\n    email string\n}\n\nfunc (p *PayPalStrategy) Pay(amount float64) error {\n    fmt.Printf(\"Paying $%.2f with PayPal account %s\\n\", amount, p.email)\n    // Payment logic\n    return nil\n}\n\nfunc (p *PayPalStrategy) GetName() string {\n    return \"PayPal\"\n}\n\ntype CryptoStrategy struct {\n    walletAddress string\n}\n\nfunc (c *CryptoStrategy) Pay(amount float64) error {\n    fmt.Printf(\"Paying $%.2f with crypto wallet %s\\n\", amount, c.walletAddress)\n    // Payment logic\n    return nil\n}\n\nfunc (c *CryptoStrategy) GetName() string {\n    return \"Cryptocurrency\"\n}\n\n// Context\ntype ShoppingCart struct {\n    items    []string\n    total    float64\n    strategy PaymentStrategy\n}\n\nfunc (s *ShoppingCart) AddItem(item string, price float64) {\n    s.items = append(s.items, item)\n    s.total += price\n}\n\nfunc (s *ShoppingCart) SetPaymentStrategy(strategy PaymentStrategy) {\n    s.strategy = strategy\n    fmt.Printf(\"Payment method set to: %s\\n\", strategy.GetName())\n}\n\nfunc (s *ShoppingCart) Checkout() error {\n    if s.strategy == nil {\n        return fmt.Errorf(\"no payment method selected\")\n    }\n    \n    fmt.Printf(\"Total: $%.2f\\n\", s.total)\n    return s.strategy.Pay(s.total)\n}\n\n// Usage\nfunc main() {\n    cart := &ShoppingCart{}\n    cart.AddItem(\"Laptop\", 999.99)\n    cart.AddItem(\"Mouse\", 29.99)\n    \n    // Pay with credit card\n    cart.SetPaymentStrategy(&CreditCardStrategy{\n        number: \"1234-5678-9012-3456\",\n        cvv:    \"123\",\n    })\n    cart.Checkout()\n    \n    // Change to PayPal\n    cart.SetPaymentStrategy(&PayPalStrategy{\n        email: \"user@example.com\",\n    })\n    cart.Checkout()\n}\n```\n\n### Template Method\nTemplate Method defines the skeleton of an algorithm in a base class, letting subclasses override specific steps.\n\n```go\n// Abstract class (using struct embedding in Go)\ntype DataProcessor struct {\n    // Define the interface that subclasses must implement\n    processor DataProcessorInterface\n}\n\ntype DataProcessorInterface interface {\n    Extract() ([]byte, error)\n    Transform(data []byte) ([]byte, error)\n    Load(data []byte) error\n}\n\n// Template method\nfunc (d *DataProcessor) Process() error {\n    // Extract\n    data, err := d.processor.Extract()\n    if err != nil {\n        return fmt.Errorf(\"extraction failed: %w\", err)\n    }\n    \n    // Transform\n    transformed, err := d.processor.Transform(data)\n    if err != nil {\n        return fmt.Errorf(\"transformation failed: %w\", err)\n    }\n    \n    // Load\n    if err := d.processor.Load(transformed); err != nil {\n        return fmt.Errorf(\"loading failed: %w\", err)\n    }\n    \n    return nil\n}\n\n// Concrete implementation - CSV Processor\ntype CSVProcessor struct {\n    DataProcessor\n    filename string\n}\n\nfunc NewCSVProcessor(filename string) *CSVProcessor {\n    p := &CSVProcessor{filename: filename}\n    p.DataProcessor.processor = p\n    return p\n}\n\nfunc (c *CSVProcessor) Extract() ([]byte, error) {\n    fmt.Printf(\"Extracting data from CSV file: %s\\n\", c.filename)\n    // Read CSV file\n    return []byte(\"csv,data,here\"), nil\n}\n\nfunc (c *CSVProcessor) Transform(data []byte) ([]byte, error) {\n    fmt.Println(\"Transforming CSV data\")\n    // Transform CSV data\n    return []byte(\"transformed csv data\"), nil\n}\n\nfunc (c *CSVProcessor) Load(data []byte) error {\n    fmt.Println(\"Loading CSV data to database\")\n    // Load to database\n    return nil\n}\n\n// Concrete implementation - JSON Processor\ntype JSONProcessor struct {\n    DataProcessor\n    url string\n}\n\nfunc NewJSONProcessor(url string) *JSONProcessor {\n    p := &JSONProcessor{url: url}\n    p.DataProcessor.processor = p\n    return p\n}\n\nfunc (j *JSONProcessor) Extract() ([]byte, error) {\n    fmt.Printf(\"Fetching JSON from API: %s\\n\", j.url)\n    // Fetch from API\n    return []byte(`{\"data\": \"value\"}`), nil\n}\n\nfunc (j *JSONProcessor) Transform(data []byte) ([]byte, error) {\n    fmt.Println(\"Transforming JSON data\")\n    // Transform JSON\n    return []byte(\"transformed json\"), nil\n}\n\nfunc (j *JSONProcessor) Load(data []byte) error {\n    fmt.Println(\"Loading JSON data to cache\")\n    // Load to cache\n    return nil\n}\n\n// Usage\nfunc main() {\n    csvProcessor := NewCSVProcessor(\"data.csv\")\n    if err := csvProcessor.Process(); err != nil {\n        fmt.Printf(\"CSV processing failed: %v\\n\", err)\n    }\n    \n    fmt.Println()\n    \n    jsonProcessor := NewJSONProcessor(\"https://api.example.com/data\")\n    if err := jsonProcessor.Process(); err != nil {\n        fmt.Printf(\"JSON processing failed: %v\\n\", err)\n    }\n}\n```\n\n### Visitor\nVisitor lets you define new operations without changing the classes of elements on which it operates.\n\n```go\n// Element interface\ntype Shape interface {\n    Accept(visitor Visitor)\n}\n\n// Visitor interface\ntype Visitor interface {\n    VisitCircle(c *Circle)\n    VisitRectangle(r *Rectangle)\n    VisitTriangle(t *Triangle)\n}\n\n// Concrete elements\ntype Circle struct {\n    Radius float64\n}\n\nfunc (c *Circle) Accept(visitor Visitor) {\n    visitor.VisitCircle(c)\n}\n\ntype Rectangle struct {\n    Width, Height float64\n}\n\nfunc (r *Rectangle) Accept(visitor Visitor) {\n    visitor.VisitRectangle(r)\n}\n\ntype Triangle struct {\n    Base, Height float64\n}\n\nfunc (t *Triangle) Accept(visitor Visitor) {\n    visitor.VisitTriangle(t)\n}\n\n// Concrete visitors\ntype AreaCalculator struct {\n    totalArea float64\n}\n\nfunc (a *AreaCalculator) VisitCircle(c *Circle) {\n    area := 3.14159 * c.Radius * c.Radius\n    fmt.Printf(\"Circle area: %.2f\\n\", area)\n    a.totalArea += area\n}\n\nfunc (a *AreaCalculator) VisitRectangle(r *Rectangle) {\n    area := r.Width * r.Height\n    fmt.Printf(\"Rectangle area: %.2f\\n\", area)\n    a.totalArea += area\n}\n\nfunc (a *AreaCalculator) VisitTriangle(t *Triangle) {\n    area := 0.5 * t.Base * t.Height\n    fmt.Printf(\"Triangle area: %.2f\\n\", area)\n    a.totalArea += area\n}\n\ntype PerimeterCalculator struct {\n    totalPerimeter float64\n}\n\nfunc (p *PerimeterCalculator) VisitCircle(c *Circle) {\n    perimeter := 2 * 3.14159 * c.Radius\n    fmt.Printf(\"Circle perimeter: %.2f\\n\", perimeter)\n    p.totalPerimeter += perimeter\n}\n\nfunc (p *PerimeterCalculator) VisitRectangle(r *Rectangle) {\n    perimeter := 2 * (r.Width + r.Height)\n    fmt.Printf(\"Rectangle perimeter: %.2f\\n\", perimeter)\n    p.totalPerimeter += perimeter\n}\n\nfunc (p *PerimeterCalculator) VisitTriangle(t *Triangle) {\n    // Simplified: assuming equilateral triangle\n    perimeter := 3 * t.Base\n    fmt.Printf(\"Triangle perimeter: %.2f\\n\", perimeter)\n    p.totalPerimeter += perimeter\n}\n\n// Usage\nfunc main() {\n    shapes := []Shape{\n        &Circle{Radius: 5},\n        &Rectangle{Width: 10, Height: 5},\n        &Triangle{Base: 6, Height: 4},\n    }\n    \n    areaCalc := &AreaCalculator{}\n    for _, shape := range shapes {\n        shape.Accept(areaCalc)\n    }\n    fmt.Printf(\"Total area: %.2f\\n\\n\", areaCalc.totalArea)\n    \n    perimCalc := &PerimeterCalculator{}\n    for _, shape := range shapes {\n        shape.Accept(perimCalc)\n    }\n    fmt.Printf(\"Total perimeter: %.2f\\n\", perimCalc.totalPerimeter)\n}\n```\n\n## Architectural Patterns\n\n### Repository Pattern\nRepository encapsulates data access logic and provides a more object-oriented view of the persistence layer.\n\n```go\n// Domain model\ntype User struct {\n    ID        string\n    Email     string\n    FirstName string\n    LastName  string\n    CreatedAt time.Time\n}\n\n// Repository interface\ntype UserRepository interface {\n    Create(ctx context.Context, user *User) error\n    GetByID(ctx context.Context, id string) (*User, error)\n    GetByEmail(ctx context.Context, email string) (*User, error)\n    Update(ctx context.Context, user *User) error\n    Delete(ctx context.Context, id string) error\n    List(ctx context.Context, offset, limit int) ([]*User, error)\n}\n\n// PostgreSQL implementation\ntype PostgresUserRepository struct {\n    db *sql.DB\n}\n\nfunc NewPostgresUserRepository(db *sql.DB) *PostgresUserRepository {\n    return &PostgresUserRepository{db: db}\n}\n\nfunc (r *PostgresUserRepository) Create(ctx context.Context, user *User) error {\n    query := `\n        INSERT INTO users (id, email, first_name, last_name, created_at)\n        VALUES ($1, $2, $3, $4, $5)\n    `\n    _, err := r.db.ExecContext(ctx, query,\n        user.ID, user.Email, user.FirstName, user.LastName, user.CreatedAt)\n    return err\n}\n\nfunc (r *PostgresUserRepository) GetByID(ctx context.Context, id string) (*User, error) {\n    query := `\n        SELECT id, email, first_name, last_name, created_at\n        FROM users WHERE id = $1\n    `\n    user := &User{}\n    err := r.db.QueryRowContext(ctx, query, id).Scan(\n        &user.ID, &user.Email, &user.FirstName, &user.LastName, &user.CreatedAt)\n    if err == sql.ErrNoRows {\n        return nil, fmt.Errorf(\"user not found\")\n    }\n    return user, err\n}\n\n// In-memory implementation for testing\ntype InMemoryUserRepository struct {\n    mu    sync.RWMutex\n    users map[string]*User\n}\n\nfunc NewInMemoryUserRepository() *InMemoryUserRepository {\n    return &InMemoryUserRepository{\n        users: make(map[string]*User),\n    }\n}\n\nfunc (r *InMemoryUserRepository) Create(ctx context.Context, user *User) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    \n    if _, exists := r.users[user.ID]; exists {\n        return fmt.Errorf(\"user already exists\")\n    }\n    r.users[user.ID] = user\n    return nil\n}\n\nfunc (r *InMemoryUserRepository) GetByID(ctx context.Context, id string) (*User, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    \n    if user, exists := r.users[id]; exists {\n        return user, nil\n    }\n    return nil, fmt.Errorf(\"user not found\")\n}\n```\n\n### Unit of Work Pattern\nUnit of Work maintains a list of objects affected by a business transaction and coordinates writing out changes.\n\n```go\n// Unit of Work interface\ntype UnitOfWork interface {\n    UserRepository() UserRepository\n    OrderRepository() OrderRepository\n    Commit() error\n    Rollback() error\n}\n\n// PostgreSQL Unit of Work\ntype PostgresUnitOfWork struct {\n    tx    *sql.Tx\n    users *PostgresUserRepository\n    orders *PostgresOrderRepository\n}\n\nfunc NewPostgresUnitOfWork(db *sql.DB) (*PostgresUnitOfWork, error) {\n    tx, err := db.Begin()\n    if err != nil {\n        return nil, err\n    }\n    \n    return &PostgresUnitOfWork{\n        tx:     tx,\n        users:  &PostgresUserRepository{db: db},\n        orders: &PostgresOrderRepository{db: db},\n    }, nil\n}\n\nfunc (u *PostgresUnitOfWork) UserRepository() UserRepository {\n    return u.users\n}\n\nfunc (u *PostgresUnitOfWork) OrderRepository() OrderRepository {\n    return u.orders\n}\n\nfunc (u *PostgresUnitOfWork) Commit() error {\n    return u.tx.Commit()\n}\n\nfunc (u *PostgresUnitOfWork) Rollback() error {\n    return u.tx.Rollback()\n}\n\n// Service using Unit of Work\ntype OrderService struct {\n    uowFactory func() (UnitOfWork, error)\n}\n\nfunc (s *OrderService) CreateOrder(userID string, items []OrderItem) error {\n    uow, err := s.uowFactory()\n    if err != nil {\n        return err\n    }\n    defer uow.Rollback()\n    \n    // Check user exists\n    user, err := uow.UserRepository().GetByID(context.Background(), userID)\n    if err != nil {\n        return err\n    }\n    \n    // Create order\n    order := &Order{\n        UserID: user.ID,\n        Items:  items,\n        Total:  calculateTotal(items),\n    }\n    \n    if err := uow.OrderRepository().Create(context.Background(), order); err != nil {\n        return err\n    }\n    \n    // Update user stats\n    user.TotalOrders++\n    if err := uow.UserRepository().Update(context.Background(), user); err != nil {\n        return err\n    }\n    \n    // Commit transaction\n    return uow.Commit()\n}\n```\n\n## Domain-Driven Design Patterns\n\n### Value Object\nValue Objects are immutable objects that represent a descriptive aspect of the domain.\n\n```go\n// Value Object - immutable\ntype Money struct {\n    amount   decimal.Decimal\n    currency string\n}\n\nfunc NewMoney(amount decimal.Decimal, currency string) (Money, error) {\n    if currency == \"\" {\n        return Money{}, fmt.Errorf(\"currency is required\")\n    }\n    if amount.IsNegative() {\n        return Money{}, fmt.Errorf(\"amount cannot be negative\")\n    }\n    return Money{amount: amount, currency: currency}, nil\n}\n\nfunc (m Money) Amount() decimal.Decimal {\n    return m.amount\n}\n\nfunc (m Money) Currency() string {\n    return m.currency\n}\n\nfunc (m Money) Add(other Money) (Money, error) {\n    if m.currency != other.currency {\n        return Money{}, fmt.Errorf(\"cannot add different currencies\")\n    }\n    return Money{\n        amount:   m.amount.Add(other.amount),\n        currency: m.currency,\n    }, nil\n}\n\nfunc (m Money) Equals(other Money) bool {\n    return m.amount.Equal(other.amount) && m.currency == other.currency\n}\n\n// Another Value Object example\ntype Email struct {\n    value string\n}\n\nfunc NewEmail(value string) (Email, error) {\n    if !isValidEmail(value) {\n        return Email{}, fmt.Errorf(\"invalid email format\")\n    }\n    return Email{value: strings.ToLower(value)}, nil\n}\n\nfunc (e Email) String() string {\n    return e.value\n}\n\nfunc (e Email) Domain() string {\n    parts := strings.Split(e.value, \"@\")\n    if len(parts) == 2 {\n        return parts[1]\n    }\n    return \"\"\n}\n```\n\n### Entity\nEntities have identity and lifecycle.\n\n```go\n// Entity with identity\ntype Product struct {\n    id          ProductID // Value object as ID\n    name        string\n    description string\n    price       Money\n    stock       int\n    version     int // For optimistic locking\n}\n\ntype ProductID struct {\n    value string\n}\n\nfunc NewProductID(value string) (ProductID, error) {\n    if value == \"\" {\n        return ProductID{}, fmt.Errorf(\"product ID cannot be empty\")\n    }\n    return ProductID{value: value}, nil\n}\n\nfunc (p ProductID) String() string {\n    return p.value\n}\n\nfunc NewProduct(id ProductID, name string, price Money) (*Product, error) {\n    if name == \"\" {\n        return nil, fmt.Errorf(\"product name is required\")\n    }\n    \n    return &Product{\n        id:    id,\n        name:  name,\n        price: price,\n        stock: 0,\n    }, nil\n}\n\nfunc (p *Product) ID() ProductID {\n    return p.id\n}\n\nfunc (p *Product) UpdatePrice(newPrice Money) error {\n    if newPrice.Amount().IsZero() {\n        return fmt.Errorf(\"price cannot be zero\")\n    }\n    p.price = newPrice\n    p.version++\n    return nil\n}\n\nfunc (p *Product) AddStock(quantity int) error {\n    if quantity <= 0 {\n        return fmt.Errorf(\"quantity must be positive\")\n    }\n    p.stock += quantity\n    p.version++\n    return nil\n}\n\nfunc (p *Product) CanFulfillOrder(quantity int) bool {\n    return p.stock >= quantity\n}\n```\n\n### Aggregate\nAggregates are clusters of domain objects that are treated as a single unit.\n\n```go\n// Aggregate root\ntype Order struct {\n    id         OrderID\n    customerID CustomerID\n    items      []OrderItem\n    status     OrderStatus\n    totalAmount Money\n    placedAt   time.Time\n    version    int\n}\n\n// Part of the aggregate\ntype OrderItem struct {\n    productID ProductID\n    quantity  int\n    unitPrice Money\n}\n\ntype OrderStatus string\n\nconst (\n    OrderStatusPending   OrderStatus = \"PENDING\"\n    OrderStatusConfirmed OrderStatus = \"CONFIRMED\"\n    OrderStatusShipped   OrderStatus = \"SHIPPED\"\n    OrderStatusDelivered OrderStatus = \"DELIVERED\"\n    OrderStatusCancelled OrderStatus = \"CANCELLED\"\n)\n\nfunc NewOrder(customerID CustomerID) *Order {\n    return &Order{\n        id:         NewOrderID(),\n        customerID: customerID,\n        items:      []OrderItem{},\n        status:     OrderStatusPending,\n        placedAt:   time.Now(),\n    }\n}\n\nfunc (o *Order) AddItem(productID ProductID, quantity int, unitPrice Money) error {\n    if o.status != OrderStatusPending {\n        return fmt.Errorf(\"cannot modify confirmed order\")\n    }\n    \n    if quantity <= 0 {\n        return fmt.Errorf(\"quantity must be positive\")\n    }\n    \n    // Check if item already exists\n    for i, item := range o.items {\n        if item.productID == productID {\n            o.items[i].quantity += quantity\n            o.recalculateTotal()\n            return nil\n        }\n    }\n    \n    // Add new item\n    o.items = append(o.items, OrderItem{\n        productID: productID,\n        quantity:  quantity,\n        unitPrice: unitPrice,\n    })\n    \n    o.recalculateTotal()\n    return nil\n}\n\nfunc (o *Order) RemoveItem(productID ProductID) error {\n    if o.status != OrderStatusPending {\n        return fmt.Errorf(\"cannot modify confirmed order\")\n    }\n    \n    for i, item := range o.items {\n        if item.productID == productID {\n            o.items = append(o.items[:i], o.items[i+1:]...)\n            o.recalculateTotal()\n            return nil\n        }\n    }\n    \n    return fmt.Errorf(\"item not found\")\n}\n\nfunc (o *Order) Confirm() error {\n    if o.status != OrderStatusPending {\n        return fmt.Errorf(\"order is not pending\")\n    }\n    \n    if len(o.items) == 0 {\n        return fmt.Errorf(\"order has no items\")\n    }\n    \n    o.status = OrderStatusConfirmed\n    o.version++\n    return nil\n}\n\nfunc (o *Order) recalculateTotal() {\n    total := decimal.Zero\n    currency := \"\"\n    \n    for _, item := range o.items {\n        itemTotal := item.unitPrice.Amount().Mul(decimal.NewFromInt(int64(item.quantity)))\n        total = total.Add(itemTotal)\n        if currency == \"\" {\n            currency = item.unitPrice.Currency()\n        }\n    }\n    \n    o.totalAmount, _ = NewMoney(total, currency)\n}\n\n// Aggregate repository\ntype OrderRepository interface {\n    Save(ctx context.Context, order *Order) error\n    GetByID(ctx context.Context, id OrderID) (*Order, error)\n    // Never expose internal parts of aggregate\n    // Bad: GetOrderItems(orderID) []OrderItem\n}\n```\n\n### Domain Service\nDomain Services encapsulate domain logic that doesn't naturally fit within an entity or value object.\n\n```go\n// Domain service for complex business logic\ntype PricingService struct {\n    taxCalculator TaxCalculator\n    discountRepo  DiscountRepository\n}\n\nfunc NewPricingService(tax TaxCalculator, discounts DiscountRepository) *PricingService {\n    return &PricingService{\n        taxCalculator: tax,\n        discountRepo:  discounts,\n    }\n}\n\nfunc (s *PricingService) CalculateOrderTotal(order *Order, customerType CustomerType) (Money, error) {\n    subtotal := order.totalAmount\n    \n    // Apply customer discount\n    discount := s.getCustomerDiscount(customerType)\n    discountAmount := subtotal.Amount().Mul(discount)\n    afterDiscount := subtotal.Amount().Sub(discountAmount)\n    \n    // Calculate tax\n    tax := s.taxCalculator.CalculateTax(afterDiscount, order.ShippingAddress())\n    \n    // Final total\n    total := afterDiscount.Add(tax)\n    \n    return NewMoney(total, subtotal.Currency())\n}\n\nfunc (s *PricingService) getCustomerDiscount(customerType CustomerType) decimal.Decimal {\n    switch customerType {\n    case CustomerTypePremium:\n        return decimal.NewFromFloat(0.15) // 15% discount\n    case CustomerTypeRegular:\n        return decimal.NewFromFloat(0.05) // 5% discount\n    default:\n        return decimal.Zero\n    }\n}\n\n// Another domain service example\ntype TransferService struct {\n    accountRepo AccountRepository\n}\n\nfunc (s *TransferService) Transfer(ctx context.Context, fromID, toID AccountID, amount Money) error {\n    // This logic doesn't belong to either account\n    // It's a domain service coordinating between aggregates\n    \n    from, err := s.accountRepo.GetByID(ctx, fromID)\n    if err != nil {\n        return err\n    }\n    \n    to, err := s.accountRepo.GetByID(ctx, toID)\n    if err != nil {\n        return err\n    }\n    \n    if err := from.Withdraw(amount); err != nil {\n        return err\n    }\n    \n    if err := to.Deposit(amount); err != nil {\n        // Compensate\n        from.Deposit(amount)\n        return err\n    }\n    \n    // Save both accounts\n    if err := s.accountRepo.Save(ctx, from); err != nil {\n        return err\n    }\n    \n    return s.accountRepo.Save(ctx, to)\n}\n```\n\n### Specification Pattern\nSpecification pattern encapsulates business rules in a reusable way.\n\n```go\n// Specification interface\ntype Specification[T any] interface {\n    IsSatisfiedBy(T) bool\n    And(Specification[T]) Specification[T]\n    Or(Specification[T]) Specification[T]\n    Not() Specification[T]\n}\n\n// Base specification\ntype BaseSpecification[T any] struct {\n    predicate func(T) bool\n}\n\nfunc NewSpecification[T any](predicate func(T) bool) Specification[T] {\n    return &BaseSpecification[T]{predicate: predicate}\n}\n\nfunc (s *BaseSpecification[T]) IsSatisfiedBy(item T) bool {\n    return s.predicate(item)\n}\n\nfunc (s *BaseSpecification[T]) And(other Specification[T]) Specification[T] {\n    return &BaseSpecification[T]{\n        predicate: func(item T) bool {\n            return s.IsSatisfiedBy(item) && other.IsSatisfiedBy(item)\n        },\n    }\n}\n\nfunc (s *BaseSpecification[T]) Or(other Specification[T]) Specification[T] {\n    return &BaseSpecification[T]{\n        predicate: func(item T) bool {\n            return s.IsSatisfiedBy(item) || other.IsSatisfiedBy(item)\n        },\n    }\n}\n\nfunc (s *BaseSpecification[T]) Not() Specification[T] {\n    return &BaseSpecification[T]{\n        predicate: func(item T) bool {\n            return !s.IsSatisfiedBy(item)\n        },\n    }\n}\n\n// Concrete specifications\ntype Product struct {\n    Name     string\n    Price    decimal.Decimal\n    Category string\n    InStock  bool\n}\n\nvar PremiumProductSpec = NewSpecification(func(p Product) bool {\n    return p.Price.GreaterThan(decimal.NewFromInt(100))\n})\n\nvar InStockSpec = NewSpecification(func(p Product) bool {\n    return p.InStock\n})\n\nvar ElectronicsSpec = NewSpecification(func(p Product) bool {\n    return p.Category == \"Electronics\"\n})\n\n// Usage\nfunc FilterProducts(products []Product, spec Specification[Product]) []Product {\n    var result []Product\n    for _, p := range products {\n        if spec.IsSatisfiedBy(p) {\n            result = append(result, p)\n        }\n    }\n    return result\n}\n\nfunc main() {\n    products := []Product{\n        {Name: \"Laptop\", Price: decimal.NewFromInt(1200), Category: \"Electronics\", InStock: true},\n        {Name: \"Mouse\", Price: decimal.NewFromInt(25), Category: \"Electronics\", InStock: true},\n        {Name: \"Book\", Price: decimal.NewFromInt(15), Category: \"Books\", InStock: false},\n    }\n    \n    // Premium electronics in stock\n    spec := PremiumProductSpec.And(ElectronicsSpec).And(InStockSpec)\n    \n    filtered := FilterProducts(products, spec)\n    fmt.Printf(\"Found %d products\\n\", len(filtered))\n}\n```\n\n## Summary\n\nThis comprehensive guide covers the major design patterns adapted for Go:\n\n1. **Creational Patterns**: Control object creation mechanisms\n2. **Structural Patterns**: Compose objects to form larger structures\n3. **Behavioral Patterns**: Define communication between objects\n4. **Architectural Patterns**: Organize high-level application structure\n5. **Domain-Driven Design Patterns**: Model complex business domains\n\nEach pattern includes practical Go implementations with proper error handling, concurrency considerations, and idiomatic Go practices. Choose patterns based on your specific needs, keeping in mind Go's philosophy of simplicity and clarity.","numLines":2651,"startLine":1,"totalLines":2651}}}
{"parentUuid":"55ad924a-6a0c-4feb-a6e5-1514ac1e12e2","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_019miyL8qAcznYBxC7xzFCnP","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01HV8htpJRgRBw6qcnkzq8K2","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/packages.md"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":28910,"cache_read_input_tokens":68795,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5Wgt9Wkzn4R1vhYtkjw","type":"assistant","uuid":"7b603f72-7b53-457a-8ec1-56a1a9d30bd7","timestamp":"2025-08-13T09:59:11.953Z"}
{"parentUuid":"7b603f72-7b53-457a-8ec1-56a1a9d30bd7","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HV8htpJRgRBw6qcnkzq8K2","type":"tool_result","content":"     1→# Go Packages - Package Design and Management\n     2→\n     3→## Table of Contents\n     4→1. [Package Design](#package-design)\n     5→2. [API Design](#api-design)\n     6→3. [Internal Packages](#internal-packages)\n     7→4. [Versioning](#versioning)\n     8→5. [Documentation](#documentation)\n     9→6. [Module Management](#module-management)\n    10→7. [Dependencies](#dependencies)\n    11→8. [Package Patterns](#package-patterns)\n    12→9. [Publishing Packages](#publishing-packages)\n    13→10. [Best Practices](#best-practices)\n    14→\n    15→## Package Design\n    16→\n    17→### Package Structure\n    18→```go\n    19→// Package naming conventions\n    20→package user        // Good: singular, lowercase\n    21→package users       // Bad: plural\n    22→package userMgmt    // Bad: camelCase\n    23→package user_mgmt   // Bad: underscore\n    24→\n    25→// Package organization\n    26→myproject/\n    27→├── cmd/\n    28→│   ├── api/\n    29→│   │   └── main.go\n    30→│   └── worker/\n    31→│       └── main.go\n    32→├── internal/\n    33→│   ├── auth/\n    34→│   ├── database/\n    35→│   └── models/\n    36→├── pkg/\n    37→│   ├── client/\n    38→│   └── utils/\n    39→├── api/\n    40→│   └── v1/\n    41→├── docs/\n    42→├── scripts/\n    43→├── go.mod\n    44→└── go.sum\n    45→\n    46→// Package declaration with documentation\n    47→// Package user provides user management functionality.\n    48→// It includes user creation, authentication, and profile management.\n    49→package user\n    50→\n    51→// Import grouping\n    52→import (\n    53→    // Standard library\n    54→    \"context\"\n    55→    \"fmt\"\n    56→    \"time\"\n    57→    \n    58→    // Third-party packages\n    59→    \"github.com/google/uuid\"\n    60→    \"golang.org/x/crypto/bcrypt\"\n    61→    \n    62→    // Internal packages\n    63→    \"myproject/internal/database\"\n    64→    \"myproject/pkg/errors\"\n    65→)\n    66→```\n    67→\n    68→### Package Cohesion\n    69→```go\n    70→// High cohesion - related functionality\n    71→package auth\n    72→\n    73→type Authenticator interface {\n    74→    Authenticate(credentials Credentials) (*User, error)\n    75→    Refresh(token string) (*Token, error)\n    76→    Revoke(token string) error\n    77→}\n    78→\n    79→type Credentials struct {\n    80→    Username string\n    81→    Password string\n    82→}\n    83→\n    84→type Token struct {\n    85→    AccessToken  string\n    86→    RefreshToken string\n    87→    ExpiresAt    time.Time\n    88→}\n    89→\n    90→type User struct {\n    91→    ID       string\n    92→    Username string\n    93→    Roles    []string\n    94→}\n    95→\n    96→// Low cohesion - avoid generic packages\n    97→package utils  // Bad: too generic\n    98→\n    99→func HashPassword(password string) string { }\n   100→func SendEmail(to, subject, body string) error { }\n   101→func ParseJSON(data []byte) (interface{}, error) { }\n   102→func GenerateID() string { }\n   103→\n   104→// Better: specific packages\n   105→package password\n   106→package email\n   107→package json\n   108→package id\n   109→```\n   110→\n   111→### Package Dependencies\n   112→```go\n   113→// Minimize dependencies\n   114→package user\n   115→\n   116→// Good: depends only on necessary packages\n   117→import (\n   118→    \"context\"\n   119→    \"myproject/internal/database\"\n   120→)\n   121→\n   122→// Bad: too many dependencies\n   123→import (\n   124→    \"myproject/internal/auth\"\n   125→    \"myproject/internal/email\"\n   126→    \"myproject/internal/sms\"\n   127→    \"myproject/internal/push\"\n   128→    \"myproject/internal/analytics\"\n   129→    // ... many more\n   130→)\n   131→\n   132→// Dependency inversion\n   133→package service\n   134→\n   135→// Define interface in the consumer package\n   136→type UserRepository interface {\n   137→    GetUser(ctx context.Context, id string) (*User, error)\n   138→    SaveUser(ctx context.Context, user *User) error\n   139→}\n   140→\n   141→type UserService struct {\n   142→    repo UserRepository  // Depend on interface\n   143→}\n   144→\n   145→// Implementation in another package\n   146→package database\n   147→\n   148→type PostgresUserRepository struct {\n   149→    db *sql.DB\n   150→}\n   151→\n   152→func (r *PostgresUserRepository) GetUser(ctx context.Context, id string) (*User, error) {\n   153→    // Implementation\n   154→}\n   155→\n   156→// Avoid circular dependencies\n   157→package a\n   158→import \"b\"  // a depends on b\n   159→\n   160→package b\n   161→import \"a\"  // b depends on a - CIRCULAR!\n   162→\n   163→// Solution: introduce interface or third package\n   164→package c\n   165→type SharedInterface interface { }\n   166→\n   167→package a\n   168→import \"c\"\n   169→\n   170→package b\n   171→import \"c\"\n   172→```\n   173→\n   174→## API Design\n   175→\n   176→### Exported vs Unexported\n   177→```go\n   178→package mypackage\n   179→\n   180→// Exported (public) - capitalized\n   181→type Client struct {\n   182→    Endpoint string\n   183→    Timeout  time.Duration\n   184→}\n   185→\n   186→func NewClient(endpoint string) *Client {\n   187→    return &Client{\n   188→        Endpoint: endpoint,\n   189→        Timeout:  30 * time.Second,\n   190→    }\n   191→}\n   192→\n   193→func (c *Client) Request(ctx context.Context, data []byte) (*Response, error) {\n   194→    return c.doRequest(ctx, data)\n   195→}\n   196→\n   197→// Unexported (private) - lowercase\n   198→type config struct {\n   199→    retryCount int\n   200→    backoff    time.Duration\n   201→}\n   202→\n   203→func (c *Client) doRequest(ctx context.Context, data []byte) (*Response, error) {\n   204→    // Internal implementation\n   205→}\n   206→\n   207→// Partially exported struct\n   208→type Response struct {\n   209→    Status  int         // Exported\n   210→    Data    []byte      // Exported\n   211→    headers http.Header // Unexported\n   212→}\n   213→```\n   214→\n   215→### API Stability\n   216→```go\n   217→// Stable API design\n   218→package stable\n   219→\n   220→// Use interfaces for flexibility\n   221→type Store interface {\n   222→    Get(key string) ([]byte, error)\n   223→    Set(key string, value []byte) error\n   224→    Delete(key string) error\n   225→}\n   226→\n   227→// Options pattern for extensibility\n   228→type ClientOptions struct {\n   229→    Timeout     time.Duration\n   230→    MaxRetries  int\n   231→    Headers     map[string]string\n   232→    // Can add new fields without breaking\n   233→}\n   234→\n   235→func NewClient(opts ClientOptions) *Client {\n   236→    // Set defaults for zero values\n   237→    if opts.Timeout == 0 {\n   238→        opts.Timeout = 30 * time.Second\n   239→    }\n   240→    if opts.MaxRetries == 0 {\n   241→        opts.MaxRetries = 3\n   242→    }\n   243→    \n   244→    return &Client{opts: opts}\n   245→}\n   246→\n   247→// Functional options for better API\n   248→type Option func(*Client)\n   249→\n   250→func WithTimeout(d time.Duration) Option {\n   251→    return func(c *Client) {\n   252→        c.timeout = d\n   253→    }\n   254→}\n   255→\n   256→func WithRetries(n int) Option {\n   257→    return func(c *Client) {\n   258→        c.maxRetries = n\n   259→    }\n   260→}\n   261→\n   262→func NewClientWithOptions(opts ...Option) *Client {\n   263→    c := &Client{\n   264→        timeout:    30 * time.Second,\n   265→        maxRetries: 3,\n   266→    }\n   267→    \n   268→    for _, opt := range opts {\n   269→        opt(c)\n   270→    }\n   271→    \n   272→    return c\n   273→}\n   274→\n   275→// Deprecation\n   276→// Deprecated: Use NewClientWithOptions instead.\n   277→func NewClientOld(endpoint string) *Client {\n   278→    return NewClientWithOptions(WithEndpoint(endpoint))\n   279→}\n   280→```\n   281→\n   282→### Error Design\n   283→```go\n   284→package mypackage\n   285→\n   286→// Sentinel errors\n   287→var (\n   288→    ErrNotFound      = errors.New(\"not found\")\n   289→    ErrUnauthorized  = errors.New(\"unauthorized\")\n   290→    ErrInvalidInput  = errors.New(\"invalid input\")\n   291→)\n   292→\n   293→// Error types\n   294→type ValidationError struct {\n   295→    Field   string\n   296→    Message string\n   297→}\n   298→\n   299→func (e ValidationError) Error() string {\n   300→    return fmt.Sprintf(\"validation error on field %s: %s\", e.Field, e.Message)\n   301→}\n   302→\n   303→// Error wrapping\n   304→func GetUser(id string) (*User, error) {\n   305→    user, err := db.Query(id)\n   306→    if err != nil {\n   307→        if errors.Is(err, sql.ErrNoRows) {\n   308→            return nil, ErrNotFound\n   309→        }\n   310→        return nil, fmt.Errorf(\"failed to get user %s: %w\", id, err)\n   311→    }\n   312→    return user, nil\n   313→}\n   314→\n   315→// Custom error checking\n   316→func IsNotFound(err error) bool {\n   317→    return errors.Is(err, ErrNotFound)\n   318→}\n   319→\n   320→func IsValidation(err error) bool {\n   321→    var validationErr ValidationError\n   322→    return errors.As(err, &validationErr)\n   323→}\n   324→```\n   325→\n   326→## Internal Packages\n   327→\n   328→### Using Internal\n   329→```go\n   330→// internal/ prevents external imports\n   331→myproject/\n   332→├── internal/\n   333→│   ├── auth/       // Only importable within myproject\n   334→│   ├── database/\n   335→│   └── config/\n   336→├── pkg/\n   337→│   └── public/     // Importable by anyone\n   338→└── cmd/\n   339→\n   340→// In myproject/internal/auth/auth.go\n   341→package auth\n   342→\n   343→type internalAuthenticator struct {\n   344→    // Cannot be imported outside myproject\n   345→}\n   346→\n   347→// In external project - FAILS\n   348→import \"github.com/user/myproject/internal/auth\" // Compile error!\n   349→\n   350→// Internal for sub-packages\n   351→myproject/\n   352→├── feature/\n   353→│   ├── internal/   // Only importable within feature/\n   354→│   ├── api/\n   355→│   └── service/\n   356→\n   357→// Organizing internal packages\n   358→internal/\n   359→├── platform/       // Platform-specific code\n   360→│   ├── database/\n   361→│   ├── cache/\n   362→│   └── queue/\n   363→├── domain/         // Business logic\n   364→│   ├── user/\n   365→│   ├── order/\n   366→│   └── payment/\n   367→└── adapter/        // External adapters\n   368→    ├── http/\n   369→    ├── grpc/\n   370→    └── cli/\n   371→```\n   372→\n   373→### Internal Best Practices\n   374→```go\n   375→// Hide implementation details\n   376→// Public package\n   377→package user\n   378→\n   379→type Service interface {\n   380→    GetUser(id string) (*User, error)\n   381→}\n   382→\n   383→func NewService(db Database) Service {\n   384→    return &service{\n   385→        db: db,\n   386→        validator: internal.NewValidator(),\n   387→    }\n   388→}\n   389→\n   390→// Internal package\n   391→package internal\n   392→\n   393→type Validator struct {\n   394→    rules []Rule\n   395→}\n   396→\n   397→func NewValidator() *Validator {\n   398→    // Hidden from external packages\n   399→}\n   400→\n   401→// Share code between packages\n   402→internal/\n   403→├── shared/\n   404→│   ├── logger/\n   405→│   ├── metrics/\n   406→│   └── errors/\n   407→\n   408→// Use in multiple packages\n   409→package service1\n   410→import \"myproject/internal/shared/logger\"\n   411→\n   412→package service2\n   413→import \"myproject/internal/shared/logger\"\n   414→```\n   415→\n   416→## Versioning\n   417→\n   418→### Semantic Versioning\n   419→```go\n   420→// go.mod versioning\n   421→module github.com/user/myproject\n   422→\n   423→go 1.21\n   424→\n   425→require (\n   426→    github.com/some/dep v1.2.3   // Exact version\n   427→    github.com/other/dep v2.0.0+incompatible\n   428→    github.com/new/dep/v2 v2.1.0 // Major version in path\n   429→)\n   430→\n   431→// Version tags\n   432→// git tag v1.0.0\n   433→// git tag v1.0.1\n   434→// git tag v1.1.0\n   435→// git tag v2.0.0\n   436→\n   437→// Major version changes (v2+)\n   438→// Update module path\n   439→module github.com/user/myproject/v2\n   440→\n   441→// Import with version\n   442→import \"github.com/user/myproject/v2/pkg/client\"\n   443→\n   444→// Maintaining multiple versions\n   445→myproject/\n   446→├── go.mod          // module github.com/user/myproject\n   447→└── v2/\n   448→    └── go.mod      // module github.com/user/myproject/v2\n   449→\n   450→// Version constraints\n   451→require (\n   452→    github.com/some/dep v1.2.3     // Exact\n   453→    github.com/some/dep v1.2.x     // Patch updates\n   454→    github.com/some/dep v1.x.x     // Minor updates\n   455→    github.com/some/dep latest     // Latest\n   456→    github.com/some/dep master     // Branch\n   457→)\n   458→```\n   459→\n   460→### API Versioning\n   461→```go\n   462→// Package versioning\n   463→api/\n   464→├── v1/\n   465→│   └── client.go\n   466→└── v2/\n   467→    └── client.go\n   468→\n   469→// v1/client.go\n   470→package v1\n   471→\n   472→type Client struct {\n   473→    Endpoint string\n   474→}\n   475→\n   476→func (c *Client) Request(data string) (string, error) {\n   477→    // v1 implementation\n   478→}\n   479→\n   480→// v2/client.go\n   481→package v2\n   482→\n   483→type Client struct {\n   484→    Endpoint string\n   485→    Timeout  time.Duration  // New field\n   486→}\n   487→\n   488→func (c *Client) Request(ctx context.Context, data []byte) ([]byte, error) {\n   489→    // v2 implementation with context\n   490→}\n   491→\n   492→// Supporting multiple versions\n   493→package api\n   494→\n   495→import (\n   496→    v1 \"myproject/api/v1\"\n   497→    v2 \"myproject/api/v2\"\n   498→)\n   499→\n   500→func NewClientV1() *v1.Client {\n   501→    return &v1.Client{}\n   502→}\n   503→\n   504→func NewClientV2() *v2.Client {\n   505→    return &v2.Client{}\n   506→}\n   507→```\n   508→\n   509→## Documentation\n   510→\n   511→### Package Documentation\n   512→```go\n   513→// Package documentation (doc.go)\n   514→/*\n   515→Package user provides user management functionality for the application.\n   516→\n   517→The package includes:\n   518→  - User CRUD operations\n   519→  - Authentication and authorization\n   520→  - Profile management\n   521→  - Password reset functionality\n   522→\n   523→Basic usage:\n   524→\n   525→\tservice := user.NewService(db)\n   526→\t\n   527→\t// Create user\n   528→\tu, err := service.Create(ctx, user.CreateRequest{\n   529→\t\tEmail:    \"user@example.com\",\n   530→\t\tPassword: \"secure123\",\n   531→\t})\n   532→\t\n   533→\t// Authenticate\n   534→\ttoken, err := service.Authenticate(ctx, email, password)\n   535→\n   536→For more examples, see the examples directory.\n   537→*/\n   538→package user\n   539→\n   540→// Type documentation\n   541→// User represents a system user.\n   542→// Users can have multiple roles and permissions.\n   543→type User struct {\n   544→    // ID is the unique identifier for the user.\n   545→    ID string\n   546→    \n   547→    // Email is the user's email address.\n   548→    // It must be unique across all users.\n   549→    Email string\n   550→    \n   551→    // CreatedAt is when the user was created.\n   552→    CreatedAt time.Time\n   553→    \n   554→    // Roles contains the user's assigned roles.\n   555→    Roles []Role\n   556→}\n   557→\n   558→// Method documentation\n   559→// Create creates a new user with the given request.\n   560→// It returns an error if the email already exists or validation fails.\n   561→//\n   562→// Example:\n   563→//\n   564→//\tuser, err := service.Create(ctx, CreateRequest{\n   565→//\t    Email:    \"user@example.com\",\n   566→//\t    Password: \"secure123\",\n   567→//\t})\n   568→//\tif err != nil {\n   569→//\t    log.Fatal(err)\n   570→//\t}\n   571→func (s *Service) Create(ctx context.Context, req CreateRequest) (*User, error) {\n   572→    // Implementation\n   573→}\n   574→\n   575→// Deprecated documentation\n   576→// Deprecated: Use CreateWithOptions instead.\n   577→// This function will be removed in v2.0.0.\n   578→func (s *Service) CreateOld(email, password string) (*User, error) {\n   579→    return s.CreateWithOptions(CreateOptions{\n   580→        Email:    email,\n   581→        Password: password,\n   582→    })\n   583→}\n   584→```\n   585→\n   586→### Examples\n   587→```go\n   588→// Example functions (show in documentation)\n   589→func ExampleService_Create() {\n   590→    service := NewService(mockDB)\n   591→    ctx := context.Background()\n   592→    \n   593→    user, err := service.Create(ctx, CreateRequest{\n   594→        Email:    \"user@example.com\",\n   595→        Password: \"secure123\",\n   596→    })\n   597→    if err != nil {\n   598→        log.Fatal(err)\n   599→    }\n   600→    \n   601→    fmt.Println(user.Email)\n   602→    // Output: user@example.com\n   603→}\n   604→\n   605→// Example with suffix\n   606→func ExampleService_Create_withRoles() {\n   607→    service := NewService(mockDB)\n   608→    ctx := context.Background()\n   609→    \n   610→    user, err := service.Create(ctx, CreateRequest{\n   611→        Email:    \"admin@example.com\",\n   612→        Password: \"secure123\",\n   613→        Roles:    []string{\"admin\", \"user\"},\n   614→    })\n   615→    if err != nil {\n   616→        log.Fatal(err)\n   617→    }\n   618→    \n   619→    fmt.Println(user.Roles)\n   620→    // Output: [admin user]\n   621→}\n   622→\n   623→// Package examples\n   624→func Example() {\n   625→    // Initialize service\n   626→    db := setupDatabase()\n   627→    service := NewService(db)\n   628→    \n   629→    // Create user\n   630→    user, _ := service.Create(context.Background(), CreateRequest{\n   631→        Email: \"user@example.com\",\n   632→    })\n   633→    \n   634→    // Authenticate\n   635→    token, _ := service.Authenticate(context.Background(), \n   636→        user.Email, \"password\")\n   637→    \n   638→    fmt.Println(token != \"\")\n   639→    // Output: true\n   640→}\n   641→\n   642→// Testable examples\n   643→func ExampleService_paginate() {\n   644→    users := []User{\n   645→        {Email: \"user1@example.com\"},\n   646→        {Email: \"user2@example.com\"},\n   647→        {Email: \"user3@example.com\"},\n   648→    }\n   649→    \n   650→    page := Paginate(users, 2, 1)\n   651→    for _, u := range page {\n   652→        fmt.Println(u.Email)\n   653→    }\n   654→    // Output:\n   655→    // user1@example.com\n   656→    // user2@example.com\n   657→}\n   658→```\n   659→\n   660→## Module Management\n   661→\n   662→### Go Modules\n   663→```go\n   664→// Initialize module\n   665→// go mod init github.com/user/project\n   666→\n   667→// go.mod structure\n   668→module github.com/user/project\n   669→\n   670→go 1.21\n   671→\n   672→require (\n   673→    github.com/gorilla/mux v1.8.0\n   674→    github.com/stretchr/testify v1.8.0\n   675→)\n   676→\n   677→require (\n   678→    // Indirect dependencies\n   679→    github.com/davecgh/go-spew v1.1.1 // indirect\n   680→    github.com/pmezard/go-difflib v1.0.0 // indirect\n   681→)\n   682→\n   683→// Replace directive\n   684→replace github.com/old/package => github.com/new/package v1.0.0\n   685→\n   686→// Local replace for development\n   687→replace github.com/user/dependency => ../dependency\n   688→\n   689→// Exclude versions\n   690→exclude github.com/bad/package v1.0.0\n   691→\n   692→// Retract versions (go 1.16+)\n   693→retract (\n   694→    v1.0.0 // Critical bug\n   695→    v1.0.1 // Security issue\n   696→)\n   697→\n   698→// Module commands\n   699→// go mod download    - Download dependencies\n   700→// go mod tidy       - Clean up dependencies\n   701→// go mod verify     - Verify dependencies\n   702→// go mod graph      - Show dependency graph\n   703→// go mod vendor     - Create vendor directory\n   704→// go mod why pkg    - Explain why package is needed\n   705→```\n   706→\n   707→### Workspace Mode\n   708→```go\n   709→// go.work (Go 1.18+)\n   710→go 1.21\n   711→\n   712→use (\n   713→    ./project1\n   714→    ./project2\n   715→    ../shared\n   716→)\n   717→\n   718→replace github.com/example/lib => ../lib\n   719→\n   720→// Commands\n   721→// go work init project1 project2\n   722→// go work use ../another-project\n   723→// go work sync\n   724→\n   725→// Development workflow\n   726→workspace/\n   727→├── go.work\n   728→├── project1/\n   729→│   └── go.mod\n   730→├── project2/\n   731→│   └── go.mod\n   732→└── shared/\n   733→    └── go.mod\n   734→\n   735→// Each project has its own module\n   736→// Work on multiple modules simultaneously\n   737→```\n   738→\n   739→## Dependencies\n   740→\n   741→### Managing Dependencies\n   742→```go\n   743→// Adding dependencies\n   744→// go get github.com/pkg/errors\n   745→// go get github.com/pkg/errors@v0.9.1\n   746→// go get github.com/pkg/errors@latest\n   747→// go get github.com/pkg/errors@master\n   748→\n   749→// Updating dependencies\n   750→// go get -u                    - Update all\n   751→// go get -u ./...             - Update all in module\n   752→// go get -u=patch ./...       - Update patch versions\n   753→// go get -u github.com/pkg/...  - Update specific package\n   754→\n   755→// Removing dependencies\n   756→// go mod tidy                  - Remove unused\n   757→\n   758→// Vendoring\n   759→// go mod vendor               - Create vendor/\n   760→// go build -mod=vendor        - Build with vendor/\n   761→\n   762→// Dependency analysis\n   763→import \"golang.org/x/mod/modfile\"\n   764→\n   765→func analyzeDependencies() {\n   766→    data, _ := os.ReadFile(\"go.mod\")\n   767→    file, _ := modfile.Parse(\"go.mod\", data, nil)\n   768→    \n   769→    for _, req := range file.Require {\n   770→        fmt.Printf(\"%s: %s\\n\", req.Mod.Path, req.Mod.Version)\n   771→    }\n   772→}\n   773→\n   774→// Private dependencies\n   775→// Set GOPRIVATE environment variable\n   776→// GOPRIVATE=github.com/company/*\n   777→\n   778→// Use .netrc for authentication\n   779→// machine github.com\n   780→// login username\n   781→// password token\n   782→\n   783→// Or use SSH\n   784→// git config --global url.\"git@github.com:\".insteadOf \"https://github.com/\"\n   785→```\n   786→\n   787→### Dependency Injection\n   788→```go\n   789→// Constructor injection\n   790→type Service struct {\n   791→    db     Database\n   792→    cache  Cache\n   793→    logger Logger\n   794→}\n   795→\n   796→func NewService(db Database, cache Cache, logger Logger) *Service {\n   797→    return &Service{\n   798→        db:     db,\n   799→        cache:  cache,\n   800→        logger: logger,\n   801→    }\n   802→}\n   803→\n   804→// Interface injection\n   805→type Database interface {\n   806→    Query(string) ([]Row, error)\n   807→}\n   808→\n   809→type Cache interface {\n   810→    Get(string) (interface{}, bool)\n   811→    Set(string, interface{})\n   812→}\n   813→\n   814→// Wire for dependency injection\n   815→//go:build wireinject\n   816→\n   817→import \"github.com/google/wire\"\n   818→\n   819→func InitializeService() (*Service, error) {\n   820→    wire.Build(\n   821→        NewDatabase,\n   822→        NewCache,\n   823→        NewLogger,\n   824→        NewService,\n   825→    )\n   826→    return nil, nil\n   827→}\n   828→\n   829→// Provider sets\n   830→var BasicSet = wire.NewSet(\n   831→    NewDatabase,\n   832→    NewCache,\n   833→    NewLogger,\n   834→)\n   835→\n   836→var ServiceSet = wire.NewSet(\n   837→    BasicSet,\n   838→    NewService,\n   839→    NewRepository,\n   840→)\n   841→```\n   842→\n   843→## Package Patterns\n   844→\n   845→### Plugin Pattern\n   846→```go\n   847→// Plugin interface\n   848→package plugin\n   849→\n   850→type Plugin interface {\n   851→    Name() string\n   852→    Initialize(config map[string]interface{}) error\n   853→    Execute(context.Context, interface{}) (interface{}, error)\n   854→    Shutdown() error\n   855→}\n   856→\n   857→// Registry\n   858→type Registry struct {\n   859→    mu      sync.RWMutex\n   860→    plugins map[string]Plugin\n   861→}\n   862→\n   863→func (r *Registry) Register(p Plugin) {\n   864→    r.mu.Lock()\n   865→    defer r.mu.Unlock()\n   866→    r.plugins[p.Name()] = p\n   867→}\n   868→\n   869→func (r *Registry) Get(name string) (Plugin, bool) {\n   870→    r.mu.RLock()\n   871→    defer r.mu.RUnlock()\n   872→    p, ok := r.plugins[name]\n   873→    return p, ok\n   874→}\n   875→\n   876→// Plugin implementation\n   877→package myplugin\n   878→\n   879→type MyPlugin struct {\n   880→    config map[string]interface{}\n   881→}\n   882→\n   883→func (p *MyPlugin) Name() string {\n   884→    return \"my-plugin\"\n   885→}\n   886→\n   887→func (p *MyPlugin) Initialize(config map[string]interface{}) error {\n   888→    p.config = config\n   889→    return nil\n   890→}\n   891→\n   892→// Auto-registration\n   893→func init() {\n   894→    plugin.DefaultRegistry.Register(&MyPlugin{})\n   895→}\n   896→```\n   897→\n   898→### Provider Pattern\n   899→```go\n   900→// Provider interface\n   901→package provider\n   902→\n   903→type StorageProvider interface {\n   904→    Read(key string) ([]byte, error)\n   905→    Write(key string, data []byte) error\n   906→    Delete(key string) error\n   907→}\n   908→\n   909→// Factory\n   910→type ProviderFactory func(config Config) (StorageProvider, error)\n   911→\n   912→var providers = make(map[string]ProviderFactory)\n   913→\n   914→func Register(name string, factory ProviderFactory) {\n   915→    providers[name] = factory\n   916→}\n   917→\n   918→func New(name string, config Config) (StorageProvider, error) {\n   919→    factory, ok := providers[name]\n   920→    if !ok {\n   921→        return nil, fmt.Errorf(\"unknown provider: %s\", name)\n   922→    }\n   923→    return factory(config)\n   924→}\n   925→\n   926→// S3 provider\n   927→package s3\n   928→\n   929→func init() {\n   930→    provider.Register(\"s3\", NewS3Provider)\n   931→}\n   932→\n   933→func NewS3Provider(config provider.Config) (provider.StorageProvider, error) {\n   934→    return &S3Provider{\n   935→        bucket: config.Get(\"bucket\"),\n   936→        region: config.Get(\"region\"),\n   937→    }, nil\n   938→}\n   939→```\n   940→\n   941→### Repository Pattern\n   942→```go\n   943→package repository\n   944→\n   945→// Generic repository interface\n   946→type Repository[T any] interface {\n   947→    Find(ctx context.Context, id string) (*T, error)\n   948→    FindAll(ctx context.Context) ([]*T, error)\n   949→    Create(ctx context.Context, entity *T) error\n   950→    Update(ctx context.Context, entity *T) error\n   951→    Delete(ctx context.Context, id string) error\n   952→}\n   953→\n   954→// Specific implementation\n   955→type UserRepository interface {\n   956→    Repository[User]\n   957→    FindByEmail(ctx context.Context, email string) (*User, error)\n   958→    FindByRole(ctx context.Context, role string) ([]*User, error)\n   959→}\n   960→\n   961→// SQL implementation\n   962→type sqlUserRepository struct {\n   963→    db *sql.DB\n   964→}\n   965→\n   966→func NewSQLUserRepository(db *sql.DB) UserRepository {\n   967→    return &sqlUserRepository{db: db}\n   968→}\n   969→\n   970→func (r *sqlUserRepository) Find(ctx context.Context, id string) (*User, error) {\n   971→    query := `SELECT id, email, created_at FROM users WHERE id = $1`\n   972→    // Implementation\n   973→}\n   974→\n   975→// MongoDB implementation\n   976→type mongoUserRepository struct {\n   977→    collection *mongo.Collection\n   978→}\n   979→\n   980→func NewMongoUserRepository(db *mongo.Database) UserRepository {\n   981→    return &mongoUserRepository{\n   982→        collection: db.Collection(\"users\"),\n   983→    }\n   984→}\n   985→```\n   986→\n   987→## Publishing Packages\n   988→\n   989→### Preparing for Publication\n   990→```go\n   991→// 1. Choose a good name\n   992→// - Descriptive and unique\n   993→// - Avoid generic names (utils, helpers, common)\n   994→// - Check if name is available\n   995→\n   996→// 2. Create comprehensive documentation\n   997→// - README.md with examples\n   998→// - Package documentation\n   999→// - API documentation\n  1000→// - CONTRIBUTING.md\n  1001→// - LICENSE file\n  1002→\n  1003→// 3. Add examples\n  1004→examples/\n  1005→├── basic/\n  1006→│   └── main.go\n  1007→├── advanced/\n  1008→│   └── main.go\n  1009→└── README.md\n  1010→\n  1011→// 4. Write comprehensive tests\n  1012→// - Unit tests\n  1013→// - Integration tests\n  1014→// - Benchmarks\n  1015→// - Examples\n  1016→\n  1017→// 5. Set up CI/CD\n  1018→// .github/workflows/test.yml\n  1019→name: Test\n  1020→on: [push, pull_request]\n  1021→jobs:\n  1022→  test:\n  1023→    runs-on: ubuntu-latest\n  1024→    steps:\n  1025→    - uses: actions/checkout@v2\n  1026→    - uses: actions/setup-go@v2\n  1027→      with:\n  1028→        go-version: 1.21\n  1029→    - run: go test -v ./...\n  1030→    - run: go test -race ./...\n  1031→    - run: go test -cover ./...\n  1032→```\n  1033→\n  1034→### Publishing Process\n  1035→```bash\n  1036→# 1. Tag version\n  1037→git tag v1.0.0\n  1038→git push origin v1.0.0\n  1039→\n  1040→# 2. The package is automatically available\n  1041→# go get github.com/username/package@v1.0.0\n  1042→\n  1043→# 3. Update pkg.go.dev\n  1044→# Visit https://pkg.go.dev/github.com/username/package\n  1045→# Click \"Request\" button\n  1046→\n  1047→# 4. Add badges to README\n  1048→[![Go Reference](https://pkg.go.dev/badge/github.com/username/package.svg)](https://pkg.go.dev/github.com/username/package)\n  1049→[![Go Report Card](https://goreportcard.com/badge/github.com/username/package)](https://goreportcard.com/report/github.com/username/package)\n  1050→[![Coverage Status](https://coveralls.io/repos/github/username/package/badge.svg)](https://coveralls.io/github/username/package)\n  1051→\n  1052→# 5. Create release on GitHub\n  1053→# - Add release notes\n  1054→# - Attach binaries if applicable\n  1055→```\n  1056→\n  1057→### Package Maintenance\n  1058→```go\n  1059→// Deprecation process\n  1060→// 1. Mark as deprecated in documentation\n  1061→// Deprecated: Use NewFunction instead.\n  1062→// This will be removed in v2.0.0.\n  1063→func OldFunction() {}\n  1064→\n  1065→// 2. Log deprecation warnings\n  1066→func OldFunction() {\n  1067→    log.Println(\"Warning: OldFunction is deprecated. Use NewFunction instead.\")\n  1068→    // Existing implementation\n  1069→}\n  1070→\n  1071→// 3. Provide migration guide\n  1072→/*\n  1073→Migration Guide from v1 to v2:\n  1074→\n  1075→1. Replace OldFunction() with NewFunction()\n  1076→2. Update Client struct initialization:\n  1077→   Old: client := &Client{Endpoint: \"url\"}\n  1078→   New: client := NewClient(WithEndpoint(\"url\"))\n  1079→3. Change import path:\n  1080→   Old: import \"github.com/user/package\"\n  1081→   New: import \"github.com/user/package/v2\"\n  1082→*/\n  1083→\n  1084→// Version compatibility\n  1085→// Support multiple versions\n  1086→package compat\n  1087→\n  1088→import (\n  1089→    v1 \"mypackage/v1\"\n  1090→    v2 \"mypackage/v2\"\n  1091→)\n  1092→\n  1093→func MigrateV1ToV2(old *v1.Config) *v2.Config {\n  1094→    return &v2.Config{\n  1095→        // Map old fields to new\n  1096→    }\n  1097→}\n  1098→```\n  1099→\n  1100→## Best Practices\n  1101→\n  1102→### Package Design Principles\n  1103→```go\n  1104→// 1. Single Responsibility\n  1105→// Each package should have one clear purpose\n  1106→\n  1107→// 2. Minimal Public API\n  1108→// Export only what's necessary\n  1109→package mypackage\n  1110→\n  1111→type Client struct{} // Exported\n  1112→\n  1113→type implementation struct{} // Unexported\n  1114→\n  1115→// 3. Accept Interfaces, Return Structs\n  1116→func Process(r io.Reader) *Result {\n  1117→    // Accept interface for flexibility\n  1118→    // Return concrete type for clarity\n  1119→}\n  1120→\n  1121→// 4. Avoid Init Functions\n  1122→// Bad: Side effects on import\n  1123→func init() {\n  1124→    database.Connect() // Side effect!\n  1125→}\n  1126→\n  1127→// Good: Explicit initialization\n  1128→func Initialize() error {\n  1129→    return database.Connect()\n  1130→}\n  1131→\n  1132→// 5. No Circular Dependencies\n  1133→// Use interfaces to break cycles\n  1134→\n  1135→// 6. Consistent Naming\n  1136→// Package name should match directory name\n  1137→// Avoid stuttering: user.User not user.UserUser\n  1138→\n  1139→// 7. Semantic Versioning\n  1140→// Follow semver strictly\n  1141→// Major.Minor.Patch\n  1142→\n  1143→// 8. Comprehensive Testing\n  1144→// Aim for >80% coverage\n  1145→// Include edge cases\n  1146→\n  1147→// 9. Clear Documentation\n  1148→// Document all exports\n  1149→// Provide examples\n  1150→\n  1151→// 10. Minimal Dependencies\n  1152→// Avoid unnecessary dependencies\n  1153→// Vendor or ensure stability\n  1154→```\n  1155→\n  1156→### Common Pitfalls\n  1157→```go\n  1158→// 1. Overusing init()\n  1159→// Avoid side effects on import\n  1160→\n  1161→// 2. God packages\n  1162→// Don't create packages that do everything\n  1163→\n  1164→// 3. Premature abstraction\n  1165→// Start simple, refactor when needed\n  1166→\n  1167→// 4. Ignoring internal/\n  1168→// Use internal/ for non-public code\n  1169→\n  1170→// 5. Poor error messages\n  1171→// Provide context in errors\n  1172→\n  1173→// 6. Breaking changes in minor versions\n  1174→// Use major version for breaking changes\n  1175→\n  1176→// 7. No examples\n  1177→// Always provide usage examples\n  1178→\n  1179→// 8. Inconsistent API\n  1180→// Maintain consistency across package\n  1181→\n  1182→// 9. Global state\n  1183→// Avoid package-level variables\n  1184→\n  1185→// 10. Missing context support\n  1186→// Accept context.Context in long operations\n  1187→```\n  1188→\n  1189→## Best Practices Summary\n  1190→\n  1191→1. **Design cohesive packages** - Single, clear purpose\n  1192→2. **Minimize public API** - Export only what's necessary  \n  1193→3. **Use internal packages** - Hide implementation details\n  1194→4. **Follow semantic versioning** - Major.Minor.Patch\n  1195→5. **Document thoroughly** - Package, types, functions\n  1196→6. **Provide examples** - Show common usage patterns\n  1197→7. **Accept interfaces** - Return concrete types\n  1198→8. **Avoid circular dependencies** - Use interfaces to break cycles\n  1199→9. **Test comprehensively** - Unit, integration, benchmarks\n  1200→10. **Maintain backwards compatibility** - Use versioning for breaking changes\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"f2ee137a-eba9-4a9f-9ae3-b5856c3bfd58","timestamp":"2025-08-13T09:59:12.149Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/packages.md","content":"# Go Packages - Package Design and Management\n\n## Table of Contents\n1. [Package Design](#package-design)\n2. [API Design](#api-design)\n3. [Internal Packages](#internal-packages)\n4. [Versioning](#versioning)\n5. [Documentation](#documentation)\n6. [Module Management](#module-management)\n7. [Dependencies](#dependencies)\n8. [Package Patterns](#package-patterns)\n9. [Publishing Packages](#publishing-packages)\n10. [Best Practices](#best-practices)\n\n## Package Design\n\n### Package Structure\n```go\n// Package naming conventions\npackage user        // Good: singular, lowercase\npackage users       // Bad: plural\npackage userMgmt    // Bad: camelCase\npackage user_mgmt   // Bad: underscore\n\n// Package organization\nmyproject/\n├── cmd/\n│   ├── api/\n│   │   └── main.go\n│   └── worker/\n│       └── main.go\n├── internal/\n│   ├── auth/\n│   ├── database/\n│   └── models/\n├── pkg/\n│   ├── client/\n│   └── utils/\n├── api/\n│   └── v1/\n├── docs/\n├── scripts/\n├── go.mod\n└── go.sum\n\n// Package declaration with documentation\n// Package user provides user management functionality.\n// It includes user creation, authentication, and profile management.\npackage user\n\n// Import grouping\nimport (\n    // Standard library\n    \"context\"\n    \"fmt\"\n    \"time\"\n    \n    // Third-party packages\n    \"github.com/google/uuid\"\n    \"golang.org/x/crypto/bcrypt\"\n    \n    // Internal packages\n    \"myproject/internal/database\"\n    \"myproject/pkg/errors\"\n)\n```\n\n### Package Cohesion\n```go\n// High cohesion - related functionality\npackage auth\n\ntype Authenticator interface {\n    Authenticate(credentials Credentials) (*User, error)\n    Refresh(token string) (*Token, error)\n    Revoke(token string) error\n}\n\ntype Credentials struct {\n    Username string\n    Password string\n}\n\ntype Token struct {\n    AccessToken  string\n    RefreshToken string\n    ExpiresAt    time.Time\n}\n\ntype User struct {\n    ID       string\n    Username string\n    Roles    []string\n}\n\n// Low cohesion - avoid generic packages\npackage utils  // Bad: too generic\n\nfunc HashPassword(password string) string { }\nfunc SendEmail(to, subject, body string) error { }\nfunc ParseJSON(data []byte) (interface{}, error) { }\nfunc GenerateID() string { }\n\n// Better: specific packages\npackage password\npackage email\npackage json\npackage id\n```\n\n### Package Dependencies\n```go\n// Minimize dependencies\npackage user\n\n// Good: depends only on necessary packages\nimport (\n    \"context\"\n    \"myproject/internal/database\"\n)\n\n// Bad: too many dependencies\nimport (\n    \"myproject/internal/auth\"\n    \"myproject/internal/email\"\n    \"myproject/internal/sms\"\n    \"myproject/internal/push\"\n    \"myproject/internal/analytics\"\n    // ... many more\n)\n\n// Dependency inversion\npackage service\n\n// Define interface in the consumer package\ntype UserRepository interface {\n    GetUser(ctx context.Context, id string) (*User, error)\n    SaveUser(ctx context.Context, user *User) error\n}\n\ntype UserService struct {\n    repo UserRepository  // Depend on interface\n}\n\n// Implementation in another package\npackage database\n\ntype PostgresUserRepository struct {\n    db *sql.DB\n}\n\nfunc (r *PostgresUserRepository) GetUser(ctx context.Context, id string) (*User, error) {\n    // Implementation\n}\n\n// Avoid circular dependencies\npackage a\nimport \"b\"  // a depends on b\n\npackage b\nimport \"a\"  // b depends on a - CIRCULAR!\n\n// Solution: introduce interface or third package\npackage c\ntype SharedInterface interface { }\n\npackage a\nimport \"c\"\n\npackage b\nimport \"c\"\n```\n\n## API Design\n\n### Exported vs Unexported\n```go\npackage mypackage\n\n// Exported (public) - capitalized\ntype Client struct {\n    Endpoint string\n    Timeout  time.Duration\n}\n\nfunc NewClient(endpoint string) *Client {\n    return &Client{\n        Endpoint: endpoint,\n        Timeout:  30 * time.Second,\n    }\n}\n\nfunc (c *Client) Request(ctx context.Context, data []byte) (*Response, error) {\n    return c.doRequest(ctx, data)\n}\n\n// Unexported (private) - lowercase\ntype config struct {\n    retryCount int\n    backoff    time.Duration\n}\n\nfunc (c *Client) doRequest(ctx context.Context, data []byte) (*Response, error) {\n    // Internal implementation\n}\n\n// Partially exported struct\ntype Response struct {\n    Status  int         // Exported\n    Data    []byte      // Exported\n    headers http.Header // Unexported\n}\n```\n\n### API Stability\n```go\n// Stable API design\npackage stable\n\n// Use interfaces for flexibility\ntype Store interface {\n    Get(key string) ([]byte, error)\n    Set(key string, value []byte) error\n    Delete(key string) error\n}\n\n// Options pattern for extensibility\ntype ClientOptions struct {\n    Timeout     time.Duration\n    MaxRetries  int\n    Headers     map[string]string\n    // Can add new fields without breaking\n}\n\nfunc NewClient(opts ClientOptions) *Client {\n    // Set defaults for zero values\n    if opts.Timeout == 0 {\n        opts.Timeout = 30 * time.Second\n    }\n    if opts.MaxRetries == 0 {\n        opts.MaxRetries = 3\n    }\n    \n    return &Client{opts: opts}\n}\n\n// Functional options for better API\ntype Option func(*Client)\n\nfunc WithTimeout(d time.Duration) Option {\n    return func(c *Client) {\n        c.timeout = d\n    }\n}\n\nfunc WithRetries(n int) Option {\n    return func(c *Client) {\n        c.maxRetries = n\n    }\n}\n\nfunc NewClientWithOptions(opts ...Option) *Client {\n    c := &Client{\n        timeout:    30 * time.Second,\n        maxRetries: 3,\n    }\n    \n    for _, opt := range opts {\n        opt(c)\n    }\n    \n    return c\n}\n\n// Deprecation\n// Deprecated: Use NewClientWithOptions instead.\nfunc NewClientOld(endpoint string) *Client {\n    return NewClientWithOptions(WithEndpoint(endpoint))\n}\n```\n\n### Error Design\n```go\npackage mypackage\n\n// Sentinel errors\nvar (\n    ErrNotFound      = errors.New(\"not found\")\n    ErrUnauthorized  = errors.New(\"unauthorized\")\n    ErrInvalidInput  = errors.New(\"invalid input\")\n)\n\n// Error types\ntype ValidationError struct {\n    Field   string\n    Message string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"validation error on field %s: %s\", e.Field, e.Message)\n}\n\n// Error wrapping\nfunc GetUser(id string) (*User, error) {\n    user, err := db.Query(id)\n    if err != nil {\n        if errors.Is(err, sql.ErrNoRows) {\n            return nil, ErrNotFound\n        }\n        return nil, fmt.Errorf(\"failed to get user %s: %w\", id, err)\n    }\n    return user, nil\n}\n\n// Custom error checking\nfunc IsNotFound(err error) bool {\n    return errors.Is(err, ErrNotFound)\n}\n\nfunc IsValidation(err error) bool {\n    var validationErr ValidationError\n    return errors.As(err, &validationErr)\n}\n```\n\n## Internal Packages\n\n### Using Internal\n```go\n// internal/ prevents external imports\nmyproject/\n├── internal/\n│   ├── auth/       // Only importable within myproject\n│   ├── database/\n│   └── config/\n├── pkg/\n│   └── public/     // Importable by anyone\n└── cmd/\n\n// In myproject/internal/auth/auth.go\npackage auth\n\ntype internalAuthenticator struct {\n    // Cannot be imported outside myproject\n}\n\n// In external project - FAILS\nimport \"github.com/user/myproject/internal/auth\" // Compile error!\n\n// Internal for sub-packages\nmyproject/\n├── feature/\n│   ├── internal/   // Only importable within feature/\n│   ├── api/\n│   └── service/\n\n// Organizing internal packages\ninternal/\n├── platform/       // Platform-specific code\n│   ├── database/\n│   ├── cache/\n│   └── queue/\n├── domain/         // Business logic\n│   ├── user/\n│   ├── order/\n│   └── payment/\n└── adapter/        // External adapters\n    ├── http/\n    ├── grpc/\n    └── cli/\n```\n\n### Internal Best Practices\n```go\n// Hide implementation details\n// Public package\npackage user\n\ntype Service interface {\n    GetUser(id string) (*User, error)\n}\n\nfunc NewService(db Database) Service {\n    return &service{\n        db: db,\n        validator: internal.NewValidator(),\n    }\n}\n\n// Internal package\npackage internal\n\ntype Validator struct {\n    rules []Rule\n}\n\nfunc NewValidator() *Validator {\n    // Hidden from external packages\n}\n\n// Share code between packages\ninternal/\n├── shared/\n│   ├── logger/\n│   ├── metrics/\n│   └── errors/\n\n// Use in multiple packages\npackage service1\nimport \"myproject/internal/shared/logger\"\n\npackage service2\nimport \"myproject/internal/shared/logger\"\n```\n\n## Versioning\n\n### Semantic Versioning\n```go\n// go.mod versioning\nmodule github.com/user/myproject\n\ngo 1.21\n\nrequire (\n    github.com/some/dep v1.2.3   // Exact version\n    github.com/other/dep v2.0.0+incompatible\n    github.com/new/dep/v2 v2.1.0 // Major version in path\n)\n\n// Version tags\n// git tag v1.0.0\n// git tag v1.0.1\n// git tag v1.1.0\n// git tag v2.0.0\n\n// Major version changes (v2+)\n// Update module path\nmodule github.com/user/myproject/v2\n\n// Import with version\nimport \"github.com/user/myproject/v2/pkg/client\"\n\n// Maintaining multiple versions\nmyproject/\n├── go.mod          // module github.com/user/myproject\n└── v2/\n    └── go.mod      // module github.com/user/myproject/v2\n\n// Version constraints\nrequire (\n    github.com/some/dep v1.2.3     // Exact\n    github.com/some/dep v1.2.x     // Patch updates\n    github.com/some/dep v1.x.x     // Minor updates\n    github.com/some/dep latest     // Latest\n    github.com/some/dep master     // Branch\n)\n```\n\n### API Versioning\n```go\n// Package versioning\napi/\n├── v1/\n│   └── client.go\n└── v2/\n    └── client.go\n\n// v1/client.go\npackage v1\n\ntype Client struct {\n    Endpoint string\n}\n\nfunc (c *Client) Request(data string) (string, error) {\n    // v1 implementation\n}\n\n// v2/client.go\npackage v2\n\ntype Client struct {\n    Endpoint string\n    Timeout  time.Duration  // New field\n}\n\nfunc (c *Client) Request(ctx context.Context, data []byte) ([]byte, error) {\n    // v2 implementation with context\n}\n\n// Supporting multiple versions\npackage api\n\nimport (\n    v1 \"myproject/api/v1\"\n    v2 \"myproject/api/v2\"\n)\n\nfunc NewClientV1() *v1.Client {\n    return &v1.Client{}\n}\n\nfunc NewClientV2() *v2.Client {\n    return &v2.Client{}\n}\n```\n\n## Documentation\n\n### Package Documentation\n```go\n// Package documentation (doc.go)\n/*\nPackage user provides user management functionality for the application.\n\nThe package includes:\n  - User CRUD operations\n  - Authentication and authorization\n  - Profile management\n  - Password reset functionality\n\nBasic usage:\n\n\tservice := user.NewService(db)\n\t\n\t// Create user\n\tu, err := service.Create(ctx, user.CreateRequest{\n\t\tEmail:    \"user@example.com\",\n\t\tPassword: \"secure123\",\n\t})\n\t\n\t// Authenticate\n\ttoken, err := service.Authenticate(ctx, email, password)\n\nFor more examples, see the examples directory.\n*/\npackage user\n\n// Type documentation\n// User represents a system user.\n// Users can have multiple roles and permissions.\ntype User struct {\n    // ID is the unique identifier for the user.\n    ID string\n    \n    // Email is the user's email address.\n    // It must be unique across all users.\n    Email string\n    \n    // CreatedAt is when the user was created.\n    CreatedAt time.Time\n    \n    // Roles contains the user's assigned roles.\n    Roles []Role\n}\n\n// Method documentation\n// Create creates a new user with the given request.\n// It returns an error if the email already exists or validation fails.\n//\n// Example:\n//\n//\tuser, err := service.Create(ctx, CreateRequest{\n//\t    Email:    \"user@example.com\",\n//\t    Password: \"secure123\",\n//\t})\n//\tif err != nil {\n//\t    log.Fatal(err)\n//\t}\nfunc (s *Service) Create(ctx context.Context, req CreateRequest) (*User, error) {\n    // Implementation\n}\n\n// Deprecated documentation\n// Deprecated: Use CreateWithOptions instead.\n// This function will be removed in v2.0.0.\nfunc (s *Service) CreateOld(email, password string) (*User, error) {\n    return s.CreateWithOptions(CreateOptions{\n        Email:    email,\n        Password: password,\n    })\n}\n```\n\n### Examples\n```go\n// Example functions (show in documentation)\nfunc ExampleService_Create() {\n    service := NewService(mockDB)\n    ctx := context.Background()\n    \n    user, err := service.Create(ctx, CreateRequest{\n        Email:    \"user@example.com\",\n        Password: \"secure123\",\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    \n    fmt.Println(user.Email)\n    // Output: user@example.com\n}\n\n// Example with suffix\nfunc ExampleService_Create_withRoles() {\n    service := NewService(mockDB)\n    ctx := context.Background()\n    \n    user, err := service.Create(ctx, CreateRequest{\n        Email:    \"admin@example.com\",\n        Password: \"secure123\",\n        Roles:    []string{\"admin\", \"user\"},\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    \n    fmt.Println(user.Roles)\n    // Output: [admin user]\n}\n\n// Package examples\nfunc Example() {\n    // Initialize service\n    db := setupDatabase()\n    service := NewService(db)\n    \n    // Create user\n    user, _ := service.Create(context.Background(), CreateRequest{\n        Email: \"user@example.com\",\n    })\n    \n    // Authenticate\n    token, _ := service.Authenticate(context.Background(), \n        user.Email, \"password\")\n    \n    fmt.Println(token != \"\")\n    // Output: true\n}\n\n// Testable examples\nfunc ExampleService_paginate() {\n    users := []User{\n        {Email: \"user1@example.com\"},\n        {Email: \"user2@example.com\"},\n        {Email: \"user3@example.com\"},\n    }\n    \n    page := Paginate(users, 2, 1)\n    for _, u := range page {\n        fmt.Println(u.Email)\n    }\n    // Output:\n    // user1@example.com\n    // user2@example.com\n}\n```\n\n## Module Management\n\n### Go Modules\n```go\n// Initialize module\n// go mod init github.com/user/project\n\n// go.mod structure\nmodule github.com/user/project\n\ngo 1.21\n\nrequire (\n    github.com/gorilla/mux v1.8.0\n    github.com/stretchr/testify v1.8.0\n)\n\nrequire (\n    // Indirect dependencies\n    github.com/davecgh/go-spew v1.1.1 // indirect\n    github.com/pmezard/go-difflib v1.0.0 // indirect\n)\n\n// Replace directive\nreplace github.com/old/package => github.com/new/package v1.0.0\n\n// Local replace for development\nreplace github.com/user/dependency => ../dependency\n\n// Exclude versions\nexclude github.com/bad/package v1.0.0\n\n// Retract versions (go 1.16+)\nretract (\n    v1.0.0 // Critical bug\n    v1.0.1 // Security issue\n)\n\n// Module commands\n// go mod download    - Download dependencies\n// go mod tidy       - Clean up dependencies\n// go mod verify     - Verify dependencies\n// go mod graph      - Show dependency graph\n// go mod vendor     - Create vendor directory\n// go mod why pkg    - Explain why package is needed\n```\n\n### Workspace Mode\n```go\n// go.work (Go 1.18+)\ngo 1.21\n\nuse (\n    ./project1\n    ./project2\n    ../shared\n)\n\nreplace github.com/example/lib => ../lib\n\n// Commands\n// go work init project1 project2\n// go work use ../another-project\n// go work sync\n\n// Development workflow\nworkspace/\n├── go.work\n├── project1/\n│   └── go.mod\n├── project2/\n│   └── go.mod\n└── shared/\n    └── go.mod\n\n// Each project has its own module\n// Work on multiple modules simultaneously\n```\n\n## Dependencies\n\n### Managing Dependencies\n```go\n// Adding dependencies\n// go get github.com/pkg/errors\n// go get github.com/pkg/errors@v0.9.1\n// go get github.com/pkg/errors@latest\n// go get github.com/pkg/errors@master\n\n// Updating dependencies\n// go get -u                    - Update all\n// go get -u ./...             - Update all in module\n// go get -u=patch ./...       - Update patch versions\n// go get -u github.com/pkg/...  - Update specific package\n\n// Removing dependencies\n// go mod tidy                  - Remove unused\n\n// Vendoring\n// go mod vendor               - Create vendor/\n// go build -mod=vendor        - Build with vendor/\n\n// Dependency analysis\nimport \"golang.org/x/mod/modfile\"\n\nfunc analyzeDependencies() {\n    data, _ := os.ReadFile(\"go.mod\")\n    file, _ := modfile.Parse(\"go.mod\", data, nil)\n    \n    for _, req := range file.Require {\n        fmt.Printf(\"%s: %s\\n\", req.Mod.Path, req.Mod.Version)\n    }\n}\n\n// Private dependencies\n// Set GOPRIVATE environment variable\n// GOPRIVATE=github.com/company/*\n\n// Use .netrc for authentication\n// machine github.com\n// login username\n// password token\n\n// Or use SSH\n// git config --global url.\"git@github.com:\".insteadOf \"https://github.com/\"\n```\n\n### Dependency Injection\n```go\n// Constructor injection\ntype Service struct {\n    db     Database\n    cache  Cache\n    logger Logger\n}\n\nfunc NewService(db Database, cache Cache, logger Logger) *Service {\n    return &Service{\n        db:     db,\n        cache:  cache,\n        logger: logger,\n    }\n}\n\n// Interface injection\ntype Database interface {\n    Query(string) ([]Row, error)\n}\n\ntype Cache interface {\n    Get(string) (interface{}, bool)\n    Set(string, interface{})\n}\n\n// Wire for dependency injection\n//go:build wireinject\n\nimport \"github.com/google/wire\"\n\nfunc InitializeService() (*Service, error) {\n    wire.Build(\n        NewDatabase,\n        NewCache,\n        NewLogger,\n        NewService,\n    )\n    return nil, nil\n}\n\n// Provider sets\nvar BasicSet = wire.NewSet(\n    NewDatabase,\n    NewCache,\n    NewLogger,\n)\n\nvar ServiceSet = wire.NewSet(\n    BasicSet,\n    NewService,\n    NewRepository,\n)\n```\n\n## Package Patterns\n\n### Plugin Pattern\n```go\n// Plugin interface\npackage plugin\n\ntype Plugin interface {\n    Name() string\n    Initialize(config map[string]interface{}) error\n    Execute(context.Context, interface{}) (interface{}, error)\n    Shutdown() error\n}\n\n// Registry\ntype Registry struct {\n    mu      sync.RWMutex\n    plugins map[string]Plugin\n}\n\nfunc (r *Registry) Register(p Plugin) {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    r.plugins[p.Name()] = p\n}\n\nfunc (r *Registry) Get(name string) (Plugin, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    p, ok := r.plugins[name]\n    return p, ok\n}\n\n// Plugin implementation\npackage myplugin\n\ntype MyPlugin struct {\n    config map[string]interface{}\n}\n\nfunc (p *MyPlugin) Name() string {\n    return \"my-plugin\"\n}\n\nfunc (p *MyPlugin) Initialize(config map[string]interface{}) error {\n    p.config = config\n    return nil\n}\n\n// Auto-registration\nfunc init() {\n    plugin.DefaultRegistry.Register(&MyPlugin{})\n}\n```\n\n### Provider Pattern\n```go\n// Provider interface\npackage provider\n\ntype StorageProvider interface {\n    Read(key string) ([]byte, error)\n    Write(key string, data []byte) error\n    Delete(key string) error\n}\n\n// Factory\ntype ProviderFactory func(config Config) (StorageProvider, error)\n\nvar providers = make(map[string]ProviderFactory)\n\nfunc Register(name string, factory ProviderFactory) {\n    providers[name] = factory\n}\n\nfunc New(name string, config Config) (StorageProvider, error) {\n    factory, ok := providers[name]\n    if !ok {\n        return nil, fmt.Errorf(\"unknown provider: %s\", name)\n    }\n    return factory(config)\n}\n\n// S3 provider\npackage s3\n\nfunc init() {\n    provider.Register(\"s3\", NewS3Provider)\n}\n\nfunc NewS3Provider(config provider.Config) (provider.StorageProvider, error) {\n    return &S3Provider{\n        bucket: config.Get(\"bucket\"),\n        region: config.Get(\"region\"),\n    }, nil\n}\n```\n\n### Repository Pattern\n```go\npackage repository\n\n// Generic repository interface\ntype Repository[T any] interface {\n    Find(ctx context.Context, id string) (*T, error)\n    FindAll(ctx context.Context) ([]*T, error)\n    Create(ctx context.Context, entity *T) error\n    Update(ctx context.Context, entity *T) error\n    Delete(ctx context.Context, id string) error\n}\n\n// Specific implementation\ntype UserRepository interface {\n    Repository[User]\n    FindByEmail(ctx context.Context, email string) (*User, error)\n    FindByRole(ctx context.Context, role string) ([]*User, error)\n}\n\n// SQL implementation\ntype sqlUserRepository struct {\n    db *sql.DB\n}\n\nfunc NewSQLUserRepository(db *sql.DB) UserRepository {\n    return &sqlUserRepository{db: db}\n}\n\nfunc (r *sqlUserRepository) Find(ctx context.Context, id string) (*User, error) {\n    query := `SELECT id, email, created_at FROM users WHERE id = $1`\n    // Implementation\n}\n\n// MongoDB implementation\ntype mongoUserRepository struct {\n    collection *mongo.Collection\n}\n\nfunc NewMongoUserRepository(db *mongo.Database) UserRepository {\n    return &mongoUserRepository{\n        collection: db.Collection(\"users\"),\n    }\n}\n```\n\n## Publishing Packages\n\n### Preparing for Publication\n```go\n// 1. Choose a good name\n// - Descriptive and unique\n// - Avoid generic names (utils, helpers, common)\n// - Check if name is available\n\n// 2. Create comprehensive documentation\n// - README.md with examples\n// - Package documentation\n// - API documentation\n// - CONTRIBUTING.md\n// - LICENSE file\n\n// 3. Add examples\nexamples/\n├── basic/\n│   └── main.go\n├── advanced/\n│   └── main.go\n└── README.md\n\n// 4. Write comprehensive tests\n// - Unit tests\n// - Integration tests\n// - Benchmarks\n// - Examples\n\n// 5. Set up CI/CD\n// .github/workflows/test.yml\nname: Test\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: 1.21\n    - run: go test -v ./...\n    - run: go test -race ./...\n    - run: go test -cover ./...\n```\n\n### Publishing Process\n```bash\n# 1. Tag version\ngit tag v1.0.0\ngit push origin v1.0.0\n\n# 2. The package is automatically available\n# go get github.com/username/package@v1.0.0\n\n# 3. Update pkg.go.dev\n# Visit https://pkg.go.dev/github.com/username/package\n# Click \"Request\" button\n\n# 4. Add badges to README\n[![Go Reference](https://pkg.go.dev/badge/github.com/username/package.svg)](https://pkg.go.dev/github.com/username/package)\n[![Go Report Card](https://goreportcard.com/badge/github.com/username/package)](https://goreportcard.com/report/github.com/username/package)\n[![Coverage Status](https://coveralls.io/repos/github/username/package/badge.svg)](https://coveralls.io/github/username/package)\n\n# 5. Create release on GitHub\n# - Add release notes\n# - Attach binaries if applicable\n```\n\n### Package Maintenance\n```go\n// Deprecation process\n// 1. Mark as deprecated in documentation\n// Deprecated: Use NewFunction instead.\n// This will be removed in v2.0.0.\nfunc OldFunction() {}\n\n// 2. Log deprecation warnings\nfunc OldFunction() {\n    log.Println(\"Warning: OldFunction is deprecated. Use NewFunction instead.\")\n    // Existing implementation\n}\n\n// 3. Provide migration guide\n/*\nMigration Guide from v1 to v2:\n\n1. Replace OldFunction() with NewFunction()\n2. Update Client struct initialization:\n   Old: client := &Client{Endpoint: \"url\"}\n   New: client := NewClient(WithEndpoint(\"url\"))\n3. Change import path:\n   Old: import \"github.com/user/package\"\n   New: import \"github.com/user/package/v2\"\n*/\n\n// Version compatibility\n// Support multiple versions\npackage compat\n\nimport (\n    v1 \"mypackage/v1\"\n    v2 \"mypackage/v2\"\n)\n\nfunc MigrateV1ToV2(old *v1.Config) *v2.Config {\n    return &v2.Config{\n        // Map old fields to new\n    }\n}\n```\n\n## Best Practices\n\n### Package Design Principles\n```go\n// 1. Single Responsibility\n// Each package should have one clear purpose\n\n// 2. Minimal Public API\n// Export only what's necessary\npackage mypackage\n\ntype Client struct{} // Exported\n\ntype implementation struct{} // Unexported\n\n// 3. Accept Interfaces, Return Structs\nfunc Process(r io.Reader) *Result {\n    // Accept interface for flexibility\n    // Return concrete type for clarity\n}\n\n// 4. Avoid Init Functions\n// Bad: Side effects on import\nfunc init() {\n    database.Connect() // Side effect!\n}\n\n// Good: Explicit initialization\nfunc Initialize() error {\n    return database.Connect()\n}\n\n// 5. No Circular Dependencies\n// Use interfaces to break cycles\n\n// 6. Consistent Naming\n// Package name should match directory name\n// Avoid stuttering: user.User not user.UserUser\n\n// 7. Semantic Versioning\n// Follow semver strictly\n// Major.Minor.Patch\n\n// 8. Comprehensive Testing\n// Aim for >80% coverage\n// Include edge cases\n\n// 9. Clear Documentation\n// Document all exports\n// Provide examples\n\n// 10. Minimal Dependencies\n// Avoid unnecessary dependencies\n// Vendor or ensure stability\n```\n\n### Common Pitfalls\n```go\n// 1. Overusing init()\n// Avoid side effects on import\n\n// 2. God packages\n// Don't create packages that do everything\n\n// 3. Premature abstraction\n// Start simple, refactor when needed\n\n// 4. Ignoring internal/\n// Use internal/ for non-public code\n\n// 5. Poor error messages\n// Provide context in errors\n\n// 6. Breaking changes in minor versions\n// Use major version for breaking changes\n\n// 7. No examples\n// Always provide usage examples\n\n// 8. Inconsistent API\n// Maintain consistency across package\n\n// 9. Global state\n// Avoid package-level variables\n\n// 10. Missing context support\n// Accept context.Context in long operations\n```\n\n## Best Practices Summary\n\n1. **Design cohesive packages** - Single, clear purpose\n2. **Minimize public API** - Export only what's necessary  \n3. **Use internal packages** - Hide implementation details\n4. **Follow semantic versioning** - Major.Minor.Patch\n5. **Document thoroughly** - Package, types, functions\n6. **Provide examples** - Show common usage patterns\n7. **Accept interfaces** - Return concrete types\n8. **Avoid circular dependencies** - Use interfaces to break cycles\n9. **Test comprehensively** - Unit, integration, benchmarks\n10. **Maintain backwards compatibility** - Use versioning for breaking changes","numLines":1200,"startLine":1,"totalLines":1200}}}
{"parentUuid":"f2ee137a-eba9-4a9f-9ae3-b5856c3bfd58","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_018zitv4XiG4JUJzMSsfy7X4","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01TL39VBMuC7tW2kQFByuYNw","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/concurrency.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":11696,"cache_read_input_tokens":97705,"output_tokens":74,"service_tier":"standard"}},"requestId":"req_011CS5WhEU8wLmKwmQwjH6kD","type":"assistant","uuid":"f9eb1616-4d0e-4350-9680-34c00e257181","timestamp":"2025-08-13T09:59:17.181Z"}
{"parentUuid":"f9eb1616-4d0e-4350-9680-34c00e257181","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TL39VBMuC7tW2kQFByuYNw","type":"tool_result","content":"     1→# Go Concurrency - Mastering Concurrent Programming\n     2→\n     3→## Table of Contents\n     4→1. [Goroutines](#goroutines)\n     5→2. [Channels](#channels)\n     6→3. [Select Statement](#select-statement)\n     7→4. [Sync Package](#sync-package)\n     8→5. [Atomic Operations](#atomic-operations)\n     9→6. [Concurrency Patterns](#concurrency-patterns)\n    10→7. [Context Package](#context-package)\n    11→8. [Race Conditions](#race-conditions)\n    12→9. [Deadlocks](#deadlocks)\n    13→10. [Performance and Optimization](#performance-and-optimization)\n    14→\n    15→## Goroutines\n    16→\n    17→### Goroutine Basics\n    18→```go\n    19→// Starting a goroutine\n    20→go functionName()\n    21→go func() {\n    22→    // Anonymous function as goroutine\n    23→}()\n    24→\n    25→// Goroutines with parameters\n    26→go processItem(item)\n    27→\n    28→// Common mistake: loop variable capture\n    29→// WRONG:\n    30→for _, item := range items {\n    31→    go func() {\n    32→        process(item)  // All goroutines get last item!\n    33→    }()\n    34→}\n    35→\n    36→// CORRECT:\n    37→for _, item := range items {\n    38→    item := item  // Create new variable\n    39→    go func() {\n    40→        process(item)\n    41→    }()\n    42→}\n    43→\n    44→// Alternative: pass as parameter\n    45→for _, item := range items {\n    46→    go func(i Item) {\n    47→        process(i)\n    48→    }(item)\n    49→}\n    50→\n    51→// Waiting for goroutines to complete\n    52→var wg sync.WaitGroup\n    53→\n    54→for i := 0; i < 10; i++ {\n    55→    wg.Add(1)\n    56→    go func(id int) {\n    57→        defer wg.Done()\n    58→        doWork(id)\n    59→    }(i)\n    60→}\n    61→\n    62→wg.Wait()  // Block until all complete\n    63→\n    64→// Goroutine lifecycle management\n    65→type Worker struct {\n    66→    done chan struct{}\n    67→}\n    68→\n    69→func (w *Worker) Start() {\n    70→    go w.run()\n    71→}\n    72→\n    73→func (w *Worker) run() {\n    74→    ticker := time.NewTicker(1 * time.Second)\n    75→    defer ticker.Stop()\n    76→    \n    77→    for {\n    78→        select {\n    79→        case <-ticker.C:\n    80→            w.doWork()\n    81→        case <-w.done:\n    82→            return\n    83→        }\n    84→    }\n    85→}\n    86→\n    87→func (w *Worker) Stop() {\n    88→    close(w.done)\n    89→}\n    90→```\n    91→\n    92→### Goroutine Patterns\n    93→```go\n    94→// Limiting concurrent goroutines\n    95→const maxWorkers = 10\n    96→sem := make(chan struct{}, maxWorkers)\n    97→\n    98→for _, item := range items {\n    99→    sem <- struct{}{}  // Acquire\n   100→    go func(i Item) {\n   101→        defer func() { <-sem }()  // Release\n   102→        process(i)\n   103→    }(item)\n   104→}\n   105→\n   106→// Wait for all to complete\n   107→for i := 0; i < maxWorkers; i++ {\n   108→    sem <- struct{}{}\n   109→}\n   110→\n   111→// Error handling in goroutines\n   112→type Result struct {\n   113→    Value interface{}\n   114→    Err   error\n   115→}\n   116→\n   117→results := make(chan Result, len(items))\n   118→\n   119→for _, item := range items {\n   120→    go func(i Item) {\n   121→        value, err := process(i)\n   122→        results <- Result{Value: value, Err: err}\n   123→    }(item)\n   124→}\n   125→\n   126→// Collect results\n   127→for i := 0; i < len(items); i++ {\n   128→    result := <-results\n   129→    if result.Err != nil {\n   130→        log.Printf(\"Error: %v\", result.Err)\n   131→    }\n   132→}\n   133→\n   134→// Goroutine pool pattern\n   135→type Pool struct {\n   136→    work chan func()\n   137→    wg   sync.WaitGroup\n   138→}\n   139→\n   140→func NewPool(workers int) *Pool {\n   141→    p := &Pool{\n   142→        work: make(chan func(), 100),\n   143→    }\n   144→    \n   145→    p.wg.Add(workers)\n   146→    for i := 0; i < workers; i++ {\n   147→        go p.worker()\n   148→    }\n   149→    \n   150→    return p\n   151→}\n   152→\n   153→func (p *Pool) worker() {\n   154→    defer p.wg.Done()\n   155→    for fn := range p.work {\n   156→        fn()\n   157→    }\n   158→}\n   159→\n   160→func (p *Pool) Submit(fn func()) {\n   161→    p.work <- fn\n   162→}\n   163→\n   164→func (p *Pool) Shutdown() {\n   165→    close(p.work)\n   166→    p.wg.Wait()\n   167→}\n   168→```\n   169→\n   170→## Channels\n   171→\n   172→### Channel Basics\n   173→```go\n   174→// Creating channels\n   175→ch := make(chan int)       // Unbuffered\n   176→ch := make(chan int, 10)   // Buffered with capacity 10\n   177→\n   178→// Channel operations\n   179→ch <- 42        // Send\n   180→value := <-ch   // Receive\n   181→value, ok := <-ch  // Receive with closed check\n   182→\n   183→// Closing channels\n   184→close(ch)\n   185→\n   186→// Check if channel is closed\n   187→if v, ok := <-ch; !ok {\n   188→    // Channel is closed\n   189→}\n   190→\n   191→// Directional channels\n   192→func send(ch chan<- int) {  // Send-only\n   193→    ch <- 42\n   194→}\n   195→\n   196→func receive(ch <-chan int) {  // Receive-only\n   197→    value := <-ch\n   198→}\n   199→\n   200→// Channel zero value is nil\n   201→var ch chan int\n   202→// ch <- 1  // Blocks forever!\n   203→// <-ch     // Blocks forever!\n   204→\n   205→// Range over channel\n   206→ch := make(chan int)\n   207→go func() {\n   208→    for i := 0; i < 5; i++ {\n   209→        ch <- i\n   210→    }\n   211→    close(ch)\n   212→}()\n   213→\n   214→for value := range ch {\n   215→    fmt.Println(value)\n   216→}\n   217→```\n   218→\n   219→### Buffered vs Unbuffered Channels\n   220→```go\n   221→// Unbuffered channels - synchronous\n   222→ch := make(chan int)\n   223→go func() {\n   224→    ch <- 42  // Blocks until someone receives\n   225→}()\n   226→value := <-ch  // Blocks until someone sends\n   227→\n   228→// Buffered channels - asynchronous up to capacity\n   229→ch := make(chan int, 3)\n   230→ch <- 1  // Doesn't block\n   231→ch <- 2  // Doesn't block\n   232→ch <- 3  // Doesn't block\n   233→// ch <- 4  // Would block!\n   234→\n   235→// Using buffered channels as semaphores\n   236→type Semaphore chan struct{}\n   237→\n   238→func NewSemaphore(n int) Semaphore {\n   239→    return make(Semaphore, n)\n   240→}\n   241→\n   242→func (s Semaphore) Acquire() {\n   243→    s <- struct{}{}\n   244→}\n   245→\n   246→func (s Semaphore) Release() {\n   247→    <-s\n   248→}\n   249→\n   250→// Channel of channels\n   251→type Request struct {\n   252→    data  string\n   253→    reply chan Response\n   254→}\n   255→\n   256→requests := make(chan Request)\n   257→\n   258→// Server\n   259→go func() {\n   260→    for req := range requests {\n   261→        response := processRequest(req.data)\n   262→        req.reply <- response\n   263→    }\n   264→}()\n   265→\n   266→// Client\n   267→reply := make(chan Response)\n   268→requests <- Request{data: \"hello\", reply: reply}\n   269→response := <-reply\n   270→```\n   271→\n   272→### Channel Patterns\n   273→```go\n   274→// Fan-in: Merge multiple channels\n   275→func fanIn(channels ...<-chan int) <-chan int {\n   276→    out := make(chan int)\n   277→    var wg sync.WaitGroup\n   278→    \n   279→    for _, ch := range channels {\n   280→        wg.Add(1)\n   281→        go func(c <-chan int) {\n   282→            defer wg.Done()\n   283→            for val := range c {\n   284→                out <- val\n   285→            }\n   286→        }(ch)\n   287→    }\n   288→    \n   289→    go func() {\n   290→        wg.Wait()\n   291→        close(out)\n   292→    }()\n   293→    \n   294→    return out\n   295→}\n   296→\n   297→// Fan-out: Distribute work\n   298→func fanOut(in <-chan int, workers int) []<-chan int {\n   299→    channels := make([]<-chan int, workers)\n   300→    \n   301→    for i := 0; i < workers; i++ {\n   302→        ch := make(chan int)\n   303→        channels[i] = ch\n   304→        \n   305→        go func(out chan int) {\n   306→            for val := range in {\n   307→                out <- process(val)\n   308→            }\n   309→            close(out)\n   310→        }(ch)\n   311→    }\n   312→    \n   313→    return channels\n   314→}\n   315→\n   316→// Pipeline pattern\n   317→func pipeline() {\n   318→    // Stage 1: Generate numbers\n   319→    numbers := make(chan int)\n   320→    go func() {\n   321→        for i := 1; i <= 100; i++ {\n   322→            numbers <- i\n   323→        }\n   324→        close(numbers)\n   325→    }()\n   326→    \n   327→    // Stage 2: Square numbers\n   328→    squares := make(chan int)\n   329→    go func() {\n   330→        for n := range numbers {\n   331→            squares <- n * n\n   332→        }\n   333→        close(squares)\n   334→    }()\n   335→    \n   336→    // Stage 3: Filter even\n   337→    evens := make(chan int)\n   338→    go func() {\n   339→        for sq := range squares {\n   340→            if sq%2 == 0 {\n   341→                evens <- sq\n   342→            }\n   343→        }\n   344→        close(evens)\n   345→    }()\n   346→    \n   347→    // Consume\n   348→    for even := range evens {\n   349→        fmt.Println(even)\n   350→    }\n   351→}\n   352→\n   353→// Timeout pattern\n   354→func timeoutExample() {\n   355→    ch := make(chan string)\n   356→    \n   357→    go func() {\n   358→        time.Sleep(2 * time.Second)\n   359→        ch <- \"result\"\n   360→    }()\n   361→    \n   362→    select {\n   363→    case result := <-ch:\n   364→        fmt.Println(\"Got:\", result)\n   365→    case <-time.After(1 * time.Second):\n   366→        fmt.Println(\"Timeout!\")\n   367→    }\n   368→}\n   369→```\n   370→\n   371→## Select Statement\n   372→\n   373→### Select Basics\n   374→```go\n   375→// Basic select\n   376→select {\n   377→case v1 := <-ch1:\n   378→    fmt.Println(\"Received from ch1:\", v1)\n   379→case v2 := <-ch2:\n   380→    fmt.Println(\"Received from ch2:\", v2)\n   381→case ch3 <- 42:\n   382→    fmt.Println(\"Sent to ch3\")\n   383→default:\n   384→    fmt.Println(\"No channels ready\")\n   385→}\n   386→\n   387→// Non-blocking receive\n   388→select {\n   389→case msg := <-ch:\n   390→    fmt.Println(\"Received:\", msg)\n   391→default:\n   392→    fmt.Println(\"No message available\")\n   393→}\n   394→\n   395→// Non-blocking send\n   396→select {\n   397→case ch <- msg:\n   398→    fmt.Println(\"Sent message\")\n   399→default:\n   400→    fmt.Println(\"Channel full or not ready\")\n   401→}\n   402→\n   403→// Timeout with select\n   404→select {\n   405→case result := <-ch:\n   406→    fmt.Println(\"Got result:\", result)\n   407→case <-time.After(5 * time.Second):\n   408→    fmt.Println(\"Timeout after 5 seconds\")\n   409→}\n   410→\n   411→// Ticker with select\n   412→ticker := time.NewTicker(1 * time.Second)\n   413→defer ticker.Stop()\n   414→\n   415→done := make(chan bool)\n   416→go func() {\n   417→    time.Sleep(5 * time.Second)\n   418→    done <- true\n   419→}()\n   420→\n   421→for {\n   422→    select {\n   423→    case <-ticker.C:\n   424→        fmt.Println(\"Tick\")\n   425→    case <-done:\n   426→        fmt.Println(\"Done!\")\n   427→        return\n   428→    }\n   429→}\n   430→```\n   431→\n   432→### Advanced Select Patterns\n   433→```go\n   434→// Priority select using default\n   435→func prioritySelect(high, low <-chan int) int {\n   436→    select {\n   437→    case val := <-high:\n   438→        return val\n   439→    default:\n   440→        select {\n   441→        case val := <-high:\n   442→            return val\n   443→        case val := <-low:\n   444→            return val\n   445→        }\n   446→    }\n   447→}\n   448→\n   449→// Quit channel pattern\n   450→func worker(work <-chan int, quit <-chan struct{}) {\n   451→    for {\n   452→        select {\n   453→        case w := <-work:\n   454→            process(w)\n   455→        case <-quit:\n   456→            cleanup()\n   457→            return\n   458→        }\n   459→    }\n   460→}\n   461→\n   462→// Multiple return channels\n   463→func multiReturn() (chan int, chan error) {\n   464→    results := make(chan int)\n   465→    errors := make(chan error)\n   466→    \n   467→    go func() {\n   468→        defer close(results)\n   469→        defer close(errors)\n   470→        \n   471→        for i := 0; i < 10; i++ {\n   472→            if i%3 == 0 {\n   473→                errors <- fmt.Errorf(\"error at %d\", i)\n   474→            } else {\n   475→                results <- i * i\n   476→            }\n   477→        }\n   478→    }()\n   479→    \n   480→    return results, errors\n   481→}\n   482→\n   483→// Using nil channels in select\n   484→func dynamicSelect() {\n   485→    ch1 := make(chan int)\n   486→    ch2 := make(chan int)\n   487→    \n   488→    go func() {\n   489→        for i := 0; i < 5; i++ {\n   490→            ch1 <- i\n   491→            time.Sleep(100 * time.Millisecond)\n   492→        }\n   493→        close(ch1)\n   494→    }()\n   495→    \n   496→    go func() {\n   497→        for i := 5; i < 10; i++ {\n   498→            ch2 <- i\n   499→            time.Sleep(150 * time.Millisecond)\n   500→        }\n   501→        close(ch2)\n   502→    }()\n   503→    \n   504→    for ch1 != nil || ch2 != nil {\n   505→        select {\n   506→        case v, ok := <-ch1:\n   507→            if !ok {\n   508→                ch1 = nil  // Disable this case\n   509→                continue\n   510→            }\n   511→            fmt.Println(\"ch1:\", v)\n   512→        case v, ok := <-ch2:\n   513→            if !ok {\n   514→                ch2 = nil  // Disable this case\n   515→                continue\n   516→            }\n   517→            fmt.Println(\"ch2:\", v)\n   518→        }\n   519→    }\n   520→}\n   521→```\n   522→\n   523→## Sync Package\n   524→\n   525→### WaitGroup\n   526→```go\n   527→var wg sync.WaitGroup\n   528→\n   529→// Basic usage\n   530→for i := 0; i < 5; i++ {\n   531→    wg.Add(1)\n   532→    go func(id int) {\n   533→        defer wg.Done()\n   534→        doWork(id)\n   535→    }(i)\n   536→}\n   537→wg.Wait()\n   538→\n   539→// Reusable WaitGroup\n   540→type Task struct {\n   541→    wg sync.WaitGroup\n   542→}\n   543→\n   544→func (t *Task) Run(workers int) {\n   545→    t.wg.Add(workers)\n   546→    for i := 0; i < workers; i++ {\n   547→        go t.worker(i)\n   548→    }\n   549→    t.wg.Wait()\n   550→}\n   551→\n   552→func (t *Task) worker(id int) {\n   553→    defer t.wg.Done()\n   554→    // Do work\n   555→}\n   556→```\n   557→\n   558→### Mutex\n   559→```go\n   560→// Basic mutex\n   561→type Counter struct {\n   562→    mu    sync.Mutex\n   563→    value int\n   564→}\n   565→\n   566→func (c *Counter) Inc() {\n   567→    c.mu.Lock()\n   568→    defer c.mu.Unlock()\n   569→    c.value++\n   570→}\n   571→\n   572→func (c *Counter) Value() int {\n   573→    c.mu.Lock()\n   574→    defer c.mu.Unlock()\n   575→    return c.value\n   576→}\n   577→\n   578→// RWMutex for read-heavy workloads\n   579→type Cache struct {\n   580→    mu    sync.RWMutex\n   581→    data  map[string]string\n   582→}\n   583→\n   584→func (c *Cache) Get(key string) (string, bool) {\n   585→    c.mu.RLock()\n   586→    defer c.mu.RUnlock()\n   587→    val, ok := c.data[key]\n   588→    return val, ok\n   589→}\n   590→\n   591→func (c *Cache) Set(key, value string) {\n   592→    c.mu.Lock()\n   593→    defer c.mu.Unlock()\n   594→    c.data[key] = value\n   595→}\n   596→\n   597→// Mutex embedding pattern\n   598→type SafeMap struct {\n   599→    sync.RWMutex\n   600→    m map[string]int\n   601→}\n   602→\n   603→func (sm *SafeMap) Load(key string) (int, bool) {\n   604→    sm.RLock()\n   605→    defer sm.RUnlock()\n   606→    val, ok := sm.m[key]\n   607→    return val, ok\n   608→}\n   609→```\n   610→\n   611→### Once\n   612→```go\n   613→var once sync.Once\n   614→var instance *Singleton\n   615→\n   616→type Singleton struct {\n   617→    // fields\n   618→}\n   619→\n   620→func GetInstance() *Singleton {\n   621→    once.Do(func() {\n   622→        instance = &Singleton{}\n   623→        // Initialize\n   624→    })\n   625→    return instance\n   626→}\n   627→\n   628→// Once for expensive initialization\n   629→type Service struct {\n   630→    once   sync.Once\n   631→    client *http.Client\n   632→}\n   633→\n   634→func (s *Service) getClient() *http.Client {\n   635→    s.once.Do(func() {\n   636→        s.client = &http.Client{\n   637→            Timeout: 30 * time.Second,\n   638→            Transport: &http.Transport{\n   639→                MaxIdleConns:    100,\n   640→                IdleConnTimeout: 90 * time.Second,\n   641→            },\n   642→        }\n   643→    })\n   644→    return s.client\n   645→}\n   646→```\n   647→\n   648→### Cond\n   649→```go\n   650→// Condition variable for signaling\n   651→type Queue struct {\n   652→    mu    sync.Mutex\n   653→    cond  *sync.Cond\n   654→    items []interface{}\n   655→}\n   656→\n   657→func NewQueue() *Queue {\n   658→    q := &Queue{}\n   659→    q.cond = sync.NewCond(&q.mu)\n   660→    return q\n   661→}\n   662→\n   663→func (q *Queue) Put(item interface{}) {\n   664→    q.mu.Lock()\n   665→    defer q.mu.Unlock()\n   666→    q.items = append(q.items, item)\n   667→    q.cond.Signal()  // Wake one waiter\n   668→}\n   669→\n   670→func (q *Queue) Get() interface{} {\n   671→    q.mu.Lock()\n   672→    defer q.mu.Unlock()\n   673→    \n   674→    for len(q.items) == 0 {\n   675→        q.cond.Wait()  // Releases lock while waiting\n   676→    }\n   677→    \n   678→    item := q.items[0]\n   679→    q.items = q.items[1:]\n   680→    return item\n   681→}\n   682→\n   683→// Broadcast to all waiters\n   684→func (q *Queue) Close() {\n   685→    q.mu.Lock()\n   686→    defer q.mu.Unlock()\n   687→    q.cond.Broadcast()  // Wake all waiters\n   688→}\n   689→```\n   690→\n   691→### Pool\n   692→```go\n   693→// Object pool for reuse\n   694→var bufferPool = sync.Pool{\n   695→    New: func() interface{} {\n   696→        return new(bytes.Buffer)\n   697→    },\n   698→}\n   699→\n   700→func processData(data []byte) {\n   701→    buf := bufferPool.Get().(*bytes.Buffer)\n   702→    defer func() {\n   703→        buf.Reset()\n   704→        bufferPool.Put(buf)\n   705→    }()\n   706→    \n   707→    buf.Write(data)\n   708→    // Process buffer\n   709→}\n   710→\n   711→// Connection pool pattern\n   712→type ConnPool struct {\n   713→    pool chan net.Conn\n   714→}\n   715→\n   716→func NewConnPool(size int, dial func() (net.Conn, error)) (*ConnPool, error) {\n   717→    pool := make(chan net.Conn, size)\n   718→    for i := 0; i < size; i++ {\n   719→        conn, err := dial()\n   720→        if err != nil {\n   721→            return nil, err\n   722→        }\n   723→        pool <- conn\n   724→    }\n   725→    return &ConnPool{pool: pool}, nil\n   726→}\n   727→\n   728→func (p *ConnPool) Get() net.Conn {\n   729→    return <-p.pool\n   730→}\n   731→\n   732→func (p *ConnPool) Put(conn net.Conn) {\n   733→    p.pool <- conn\n   734→}\n   735→```\n   736→\n   737→### Map (sync.Map)\n   738→```go\n   739→// Thread-safe map without explicit locking\n   740→var m sync.Map\n   741→\n   742→// Store\n   743→m.Store(\"key\", \"value\")\n   744→m.Store(123, \"numeric key\")\n   745→\n   746→// Load\n   747→if val, ok := m.Load(\"key\"); ok {\n   748→    fmt.Println(val.(string))\n   749→}\n   750→\n   751→// LoadOrStore\n   752→actual, loaded := m.LoadOrStore(\"key\", \"new value\")\n   753→if loaded {\n   754→    fmt.Println(\"Key existed:\", actual)\n   755→}\n   756→\n   757→// Delete\n   758→m.Delete(\"key\")\n   759→\n   760→// Range\n   761→m.Range(func(key, value interface{}) bool {\n   762→    fmt.Printf(\"%v: %v\\n\", key, value)\n   763→    return true  // Continue iteration\n   764→})\n   765→\n   766→// Use cases for sync.Map:\n   767→// 1. Keys are written once but read many times\n   768→// 2. Different goroutines read/write disjoint key sets\n   769→// 3. When lock contention would be a problem\n   770→```\n   771→\n   772→## Atomic Operations\n   773→\n   774→### Atomic Package\n   775→```go\n   776→import \"sync/atomic\"\n   777→\n   778→// Atomic integers\n   779→var counter int64\n   780→\n   781→atomic.AddInt64(&counter, 1)           // Increment\n   782→atomic.AddInt64(&counter, -1)          // Decrement\n   783→val := atomic.LoadInt64(&counter)      // Read\n   784→atomic.StoreInt64(&counter, 100)       // Write\n   785→old := atomic.SwapInt64(&counter, 200) // Swap\n   786→\n   787→// Compare and swap (CAS)\n   788→if atomic.CompareAndSwapInt64(&counter, 100, 200) {\n   789→    // Successfully changed from 100 to 200\n   790→}\n   791→\n   792→// Atomic boolean using int32\n   793→type AtomicBool struct {\n   794→    flag int32\n   795→}\n   796→\n   797→func (b *AtomicBool) Set(value bool) {\n   798→    var i int32\n   799→    if value {\n   800→        i = 1\n   801→    }\n   802→    atomic.StoreInt32(&b.flag, i)\n   803→}\n   804→\n   805→func (b *AtomicBool) Get() bool {\n   806→    return atomic.LoadInt32(&b.flag) != 0\n   807→}\n   808→\n   809→// Atomic pointer\n   810→type Config struct {\n   811→    // fields\n   812→}\n   813→\n   814→var config atomic.Value\n   815→\n   816→// Store new config\n   817→config.Store(&Config{})\n   818→\n   819→// Load config\n   820→cfg := config.Load().(*Config)\n   821→\n   822→// Atomic counter implementation\n   823→type Counter struct {\n   824→    value int64\n   825→}\n   826→\n   827→func (c *Counter) Inc() int64 {\n   828→    return atomic.AddInt64(&c.value, 1)\n   829→}\n   830→\n   831→func (c *Counter) Dec() int64 {\n   832→    return atomic.AddInt64(&c.value, -1)\n   833→}\n   834→\n   835→func (c *Counter) Value() int64 {\n   836→    return atomic.LoadInt64(&c.value)\n   837→}\n   838→\n   839→func (c *Counter) Reset() {\n   840→    atomic.StoreInt64(&c.value, 0)\n   841→}\n   842→```\n   843→\n   844→### Atomic Patterns\n   845→```go\n   846→// Lock-free stack\n   847→type Stack struct {\n   848→    head atomic.Value\n   849→}\n   850→\n   851→type node struct {\n   852→    value interface{}\n   853→    next  *node\n   854→}\n   855→\n   856→func (s *Stack) Push(v interface{}) {\n   857→    n := &node{value: v}\n   858→    for {\n   859→        head := s.head.Load()\n   860→        if head != nil {\n   861→            n.next = head.(*node)\n   862→        }\n   863→        if s.head.CompareAndSwap(head, n) {\n   864→            return\n   865→        }\n   866→    }\n   867→}\n   868→\n   869→func (s *Stack) Pop() interface{} {\n   870→    for {\n   871→        head := s.head.Load()\n   872→        if head == nil {\n   873→            return nil\n   874→        }\n   875→        n := head.(*node)\n   876→        if s.head.CompareAndSwap(head, n.next) {\n   877→            return n.value\n   878→        }\n   879→    }\n   880→}\n   881→\n   882→// Atomic statistics collector\n   883→type Stats struct {\n   884→    requests  int64\n   885→    errors    int64\n   886→    totalTime int64\n   887→}\n   888→\n   889→func (s *Stats) RecordRequest(duration time.Duration, err error) {\n   890→    atomic.AddInt64(&s.requests, 1)\n   891→    atomic.AddInt64(&s.totalTime, int64(duration))\n   892→    if err != nil {\n   893→        atomic.AddInt64(&s.errors, 1)\n   894→    }\n   895→}\n   896→\n   897→func (s *Stats) Snapshot() (requests, errors, avgTime int64) {\n   898→    requests = atomic.LoadInt64(&s.requests)\n   899→    errors = atomic.LoadInt64(&s.errors)\n   900→    totalTime := atomic.LoadInt64(&s.totalTime)\n   901→    if requests > 0 {\n   902→        avgTime = totalTime / requests\n   903→    }\n   904→    return\n   905→}\n   906→```\n   907→\n   908→## Concurrency Patterns\n   909→\n   910→### Worker Pool\n   911→```go\n   912→type Job struct {\n   913→    ID   int\n   914→    Data string\n   915→}\n   916→\n   917→type Result struct {\n   918→    JobID  int\n   919→    Output string\n   920→    Err    error\n   921→}\n   922→\n   923→func workerPool(jobs <-chan Job, results chan<- Result, workers int) {\n   924→    var wg sync.WaitGroup\n   925→    \n   926→    for i := 0; i < workers; i++ {\n   927→        wg.Add(1)\n   928→        go func(workerID int) {\n   929→            defer wg.Done()\n   930→            for job := range jobs {\n   931→                output, err := processJob(job)\n   932→                results <- Result{\n   933→                    JobID:  job.ID,\n   934→                    Output: output,\n   935→                    Err:    err,\n   936→                }\n   937→            }\n   938→        }(i)\n   939→    }\n   940→    \n   941→    wg.Wait()\n   942→    close(results)\n   943→}\n   944→\n   945→// Usage\n   946→jobs := make(chan Job, 100)\n   947→results := make(chan Result, 100)\n   948→\n   949→go workerPool(jobs, results, 10)\n   950→\n   951→// Send jobs\n   952→go func() {\n   953→    for i := 0; i < 1000; i++ {\n   954→        jobs <- Job{ID: i, Data: fmt.Sprintf(\"job-%d\", i)}\n   955→    }\n   956→    close(jobs)\n   957→}()\n   958→\n   959→// Collect results\n   960→for result := range results {\n   961→    if result.Err != nil {\n   962→        log.Printf(\"Job %d failed: %v\", result.JobID, result.Err)\n   963→    } else {\n   964→        fmt.Printf(\"Job %d completed: %s\\n\", result.JobID, result.Output)\n   965→    }\n   966→}\n   967→```\n   968→\n   969→### Rate Limiting\n   970→```go\n   971→// Simple rate limiter\n   972→func rateLimiter() {\n   973→    rate := time.Second / 10  // 10 requests per second\n   974→    ticker := time.NewTicker(rate)\n   975→    defer ticker.Stop()\n   976→    \n   977→    requests := make(chan int, 100)\n   978→    \n   979→    go func() {\n   980→        for i := 0; i < 100; i++ {\n   981→            requests <- i\n   982→        }\n   983→        close(requests)\n   984→    }()\n   985→    \n   986→    for req := range requests {\n   987→        <-ticker.C  // Wait for tick\n   988→        go process(req)\n   989→    }\n   990→}\n   991→\n   992→// Token bucket rate limiter\n   993→type RateLimiter struct {\n   994→    tokens chan struct{}\n   995→}\n   996→\n   997→func NewRateLimiter(rate int, burst int) *RateLimiter {\n   998→    rl := &RateLimiter{\n   999→        tokens: make(chan struct{}, burst),\n  1000→    }\n  1001→    \n  1002→    // Fill bucket\n  1003→    for i := 0; i < burst; i++ {\n  1004→        rl.tokens <- struct{}{}\n  1005→    }\n  1006→    \n  1007→    // Refill tokens\n  1008→    go func() {\n  1009→        ticker := time.NewTicker(time.Second / time.Duration(rate))\n  1010→        defer ticker.Stop()\n  1011→        \n  1012→        for range ticker.C {\n  1013→            select {\n  1014→            case rl.tokens <- struct{}{}:\n  1015→            default:\n  1016→                // Bucket full\n  1017→            }\n  1018→        }\n  1019→    }()\n  1020→    \n  1021→    return rl\n  1022→}\n  1023→\n  1024→func (rl *RateLimiter) Allow() bool {\n  1025→    select {\n  1026→    case <-rl.tokens:\n  1027→        return true\n  1028→    default:\n  1029→        return false\n  1030→    }\n  1031→}\n  1032→\n  1033→func (rl *RateLimiter) Wait() {\n  1034→    <-rl.tokens\n  1035→}\n  1036→```\n  1037→\n  1038→### Circuit Breaker\n  1039→```go\n  1040→type CircuitBreaker struct {\n  1041→    mu            sync.RWMutex\n  1042→    failures      int\n  1043→    lastFailTime  time.Time\n  1044→    state         string // \"closed\", \"open\", \"half-open\"\n  1045→    maxFailures   int\n  1046→    resetTimeout  time.Duration\n  1047→}\n  1048→\n  1049→func NewCircuitBreaker(maxFailures int, resetTimeout time.Duration) *CircuitBreaker {\n  1050→    return &CircuitBreaker{\n  1051→        maxFailures:  maxFailures,\n  1052→        resetTimeout: resetTimeout,\n  1053→        state:        \"closed\",\n  1054→    }\n  1055→}\n  1056→\n  1057→func (cb *CircuitBreaker) Call(fn func() error) error {\n  1058→    cb.mu.RLock()\n  1059→    state := cb.state\n  1060→    cb.mu.RUnlock()\n  1061→    \n  1062→    if state == \"open\" {\n  1063→        cb.mu.RLock()\n  1064→        if time.Since(cb.lastFailTime) > cb.resetTimeout {\n  1065→            cb.mu.RUnlock()\n  1066→            cb.mu.Lock()\n  1067→            cb.state = \"half-open\"\n  1068→            cb.failures = 0\n  1069→            cb.mu.Unlock()\n  1070→        } else {\n  1071→            cb.mu.RUnlock()\n  1072→            return errors.New(\"circuit breaker is open\")\n  1073→        }\n  1074→    }\n  1075→    \n  1076→    err := fn()\n  1077→    \n  1078→    cb.mu.Lock()\n  1079→    defer cb.mu.Unlock()\n  1080→    \n  1081→    if err != nil {\n  1082→        cb.failures++\n  1083→        cb.lastFailTime = time.Now()\n  1084→        \n  1085→        if cb.failures >= cb.maxFailures {\n  1086→            cb.state = \"open\"\n  1087→        }\n  1088→        return err\n  1089→    }\n  1090→    \n  1091→    if cb.state == \"half-open\" {\n  1092→        cb.state = \"closed\"\n  1093→    }\n  1094→    cb.failures = 0\n  1095→    return nil\n  1096→}\n  1097→```\n  1098→\n  1099→### Pub-Sub Pattern\n  1100→```go\n  1101→type PubSub struct {\n  1102→    mu   sync.RWMutex\n  1103→    subs map[string][]chan interface{}\n  1104→}\n  1105→\n  1106→func NewPubSub() *PubSub {\n  1107→    return &PubSub{\n  1108→        subs: make(map[string][]chan interface{}),\n  1109→    }\n  1110→}\n  1111→\n  1112→func (ps *PubSub) Subscribe(topic string) <-chan interface{} {\n  1113→    ps.mu.Lock()\n  1114→    defer ps.mu.Unlock()\n  1115→    \n  1116→    ch := make(chan interface{}, 10)\n  1117→    ps.subs[topic] = append(ps.subs[topic], ch)\n  1118→    return ch\n  1119→}\n  1120→\n  1121→func (ps *PubSub) Publish(topic string, msg interface{}) {\n  1122→    ps.mu.RLock()\n  1123→    defer ps.mu.RUnlock()\n  1124→    \n  1125→    for _, ch := range ps.subs[topic] {\n  1126→        select {\n  1127→        case ch <- msg:\n  1128→        default:\n  1129→            // Subscriber is slow, skip\n  1130→        }\n  1131→    }\n  1132→}\n  1133→\n  1134→func (ps *PubSub) Unsubscribe(topic string, sub <-chan interface{}) {\n  1135→    ps.mu.Lock()\n  1136→    defer ps.mu.Unlock()\n  1137→    \n  1138→    subscribers := ps.subs[topic]\n  1139→    for i, ch := range subscribers {\n  1140→        if ch == sub {\n  1141→            close(ch)\n  1142→            ps.subs[topic] = append(subscribers[:i], subscribers[i+1:]...)\n  1143→            break\n  1144→        }\n  1145→    }\n  1146→}\n  1147→```\n  1148→\n  1149→## Context Package\n  1150→\n  1151→### Context Basics\n  1152→```go\n  1153→// Creating contexts\n  1154→ctx := context.Background()  // Root context\n  1155→ctx := context.TODO()        // When unsure what to use\n  1156→\n  1157→// With cancel\n  1158→ctx, cancel := context.WithCancel(context.Background())\n  1159→defer cancel()  // Always call cancel\n  1160→\n  1161→// With timeout\n  1162→ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n  1163→defer cancel()\n  1164→\n  1165→// With deadline\n  1166→deadline := time.Now().Add(5 * time.Second)\n  1167→ctx, cancel := context.WithDeadline(context.Background(), deadline)\n  1168→defer cancel()\n  1169→\n  1170→// With value\n  1171→ctx := context.WithValue(context.Background(), \"userID\", 123)\n  1172→\n  1173→// Using context\n  1174→func doWork(ctx context.Context) error {\n  1175→    select {\n  1176→    case <-time.After(2 * time.Second):\n  1177→        return nil\n  1178→    case <-ctx.Done():\n  1179→        return ctx.Err()\n  1180→    }\n  1181→}\n  1182→\n  1183→// HTTP request with context\n  1184→func fetchData(ctx context.Context, url string) (*http.Response, error) {\n  1185→    req, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n  1186→    if err != nil {\n  1187→        return nil, err\n  1188→    }\n  1189→    \n  1190→    return http.DefaultClient.Do(req)\n  1191→}\n  1192→```\n  1193→\n  1194→### Context Patterns\n  1195→```go\n  1196→// Propagating cancellation\n  1197→func pipeline(ctx context.Context) error {\n  1198→    ctx, cancel := context.WithCancel(ctx)\n  1199→    defer cancel()\n  1200→    \n  1201→    errc := make(chan error, 3)\n  1202→    \n  1203→    go func() {\n  1204→        errc <- stage1(ctx)\n  1205→    }()\n  1206→    \n  1207→    go func() {\n  1208→        errc <- stage2(ctx)\n  1209→    }()\n  1210→    \n  1211→    go func() {\n  1212→        errc <- stage3(ctx)\n  1213→    }()\n  1214→    \n  1215→    // Wait for first error or all complete\n  1216→    for i := 0; i < 3; i++ {\n  1217→        if err := <-errc; err != nil {\n  1218→            return err  // Cancel will stop other stages\n  1219→        }\n  1220→    }\n  1221→    \n  1222→    return nil\n  1223→}\n  1224→\n  1225→// Request scoped values\n  1226→type contextKey string\n  1227→\n  1228→const (\n  1229→    userIDKey contextKey = \"userID\"\n  1230→    traceIDKey contextKey = \"traceID\"\n  1231→)\n  1232→\n  1233→func WithUserID(ctx context.Context, userID string) context.Context {\n  1234→    return context.WithValue(ctx, userIDKey, userID)\n  1235→}\n  1236→\n  1237→func GetUserID(ctx context.Context) (string, bool) {\n  1238→    userID, ok := ctx.Value(userIDKey).(string)\n  1239→    return userID, ok\n  1240→}\n  1241→\n  1242→// Graceful shutdown\n  1243→func server(ctx context.Context) error {\n  1244→    srv := &http.Server{Addr: \":8080\"}\n  1245→    \n  1246→    go func() {\n  1247→        <-ctx.Done()\n  1248→        shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n  1249→        defer cancel()\n  1250→        srv.Shutdown(shutdownCtx)\n  1251→    }()\n  1252→    \n  1253→    return srv.ListenAndServe()\n  1254→}\n  1255→```\n  1256→\n  1257→## Race Conditions\n  1258→\n  1259→### Detecting Race Conditions\n  1260→```go\n  1261→// Run with race detector: go run -race main.go\n  1262→// Test with race detector: go test -race ./...\n  1263→\n  1264→// Common race condition\n  1265→type Counter struct {\n  1266→    value int  // Not protected!\n  1267→}\n  1268→\n  1269→func (c *Counter) Inc() {\n  1270→    c.value++  // Race condition!\n  1271→}\n  1272→\n  1273→// Fixed version\n  1274→type SafeCounter struct {\n  1275→    mu    sync.Mutex\n  1276→    value int\n  1277→}\n  1278→\n  1279→func (c *SafeCounter) Inc() {\n  1280→    c.mu.Lock()\n  1281→    defer c.mu.Unlock()\n  1282→    c.value++\n  1283→}\n  1284→\n  1285→// Race on map\n  1286→m := make(map[string]int)\n  1287→\n  1288→go func() {\n  1289→    m[\"key\"] = 1  // Write\n  1290→}()\n  1291→\n  1292→go func() {\n  1293→    _ = m[\"key\"]  // Read - RACE!\n  1294→}()\n  1295→\n  1296→// Race on slice append\n  1297→var slice []int\n  1298→\n  1299→go func() {\n  1300→    slice = append(slice, 1)  // Race!\n  1301→}()\n  1302→\n  1303→go func() {\n  1304→    slice = append(slice, 2)  // Race!\n  1305→}()\n  1306→```\n  1307→\n  1308→### Preventing Race Conditions\n  1309→```go\n  1310→// Use channels instead of shared memory\n  1311→type SafeCounter struct {\n  1312→    ch chan int\n  1313→}\n  1314→\n  1315→func NewSafeCounter() *SafeCounter {\n  1316→    c := &SafeCounter{\n  1317→        ch: make(chan int),\n  1318→    }\n  1319→    go c.run()\n  1320→    return c\n  1321→}\n  1322→\n  1323→func (c *SafeCounter) run() {\n  1324→    var value int\n  1325→    for delta := range c.ch {\n  1326→        value += delta\n  1327→    }\n  1328→}\n  1329→\n  1330→func (c *SafeCounter) Inc() {\n  1331→    c.ch <- 1\n  1332→}\n  1333→\n  1334→// Immutability pattern\n  1335→type Config struct {\n  1336→    values map[string]string\n  1337→}\n  1338→\n  1339→func (c *Config) With(key, value string) *Config {\n  1340→    newValues := make(map[string]string)\n  1341→    for k, v := range c.values {\n  1342→        newValues[k] = v\n  1343→    }\n  1344→    newValues[key] = value\n  1345→    return &Config{values: newValues}\n  1346→}\n  1347→\n  1348→// Copy-on-write pattern\n  1349→type Data struct {\n  1350→    mu    sync.RWMutex\n  1351→    items []Item\n  1352→}\n  1353→\n  1354→func (d *Data) Append(item Item) {\n  1355→    d.mu.Lock()\n  1356→    defer d.mu.Unlock()\n  1357→    \n  1358→    // Create new slice\n  1359→    newItems := make([]Item, len(d.items)+1)\n  1360→    copy(newItems, d.items)\n  1361→    newItems[len(newItems)-1] = item\n  1362→    d.items = newItems\n  1363→}\n  1364→\n  1365→func (d *Data) Items() []Item {\n  1366→    d.mu.RLock()\n  1367→    defer d.mu.RUnlock()\n  1368→    return d.items  // Safe because we copy on write\n  1369→}\n  1370→```\n  1371→\n  1372→## Deadlocks\n  1373→\n  1374→### Common Deadlock Patterns\n  1375→```go\n  1376→// Deadlock: Circular wait\n  1377→var mu1, mu2 sync.Mutex\n  1378→\n  1379→// Goroutine 1\n  1380→go func() {\n  1381→    mu1.Lock()\n  1382→    time.Sleep(10 * time.Millisecond)\n  1383→    mu2.Lock()  // Waits for mu2\n  1384→    // ...\n  1385→    mu2.Unlock()\n  1386→    mu1.Unlock()\n  1387→}()\n  1388→\n  1389→// Goroutine 2\n  1390→go func() {\n  1391→    mu2.Lock()\n  1392→    time.Sleep(10 * time.Millisecond)\n  1393→    mu1.Lock()  // Waits for mu1 - DEADLOCK!\n  1394→    // ...\n  1395→    mu1.Unlock()\n  1396→    mu2.Unlock()\n  1397→}()\n  1398→\n  1399→// Fix: Always acquire locks in same order\n  1400→func transfer(from, to *Account, amount int) {\n  1401→    // Order accounts by ID to prevent deadlock\n  1402→    if from.ID < to.ID {\n  1403→        from.mu.Lock()\n  1404→        defer from.mu.Unlock()\n  1405→        to.mu.Lock()\n  1406→        defer to.mu.Unlock()\n  1407→    } else {\n  1408→        to.mu.Lock()\n  1409→        defer to.mu.Unlock()\n  1410→        from.mu.Lock()\n  1411→        defer from.mu.Unlock()\n  1412→    }\n  1413→    // Transfer logic\n  1414→}\n  1415→\n  1416→// Deadlock: Channel misuse\n  1417→ch := make(chan int)\n  1418→ch <- 42  // Blocks forever - no receiver!\n  1419→\n  1420→// Deadlock: Waiting for yourself\n  1421→ch := make(chan int)\n  1422→val := <-ch  // Blocks forever\n  1423→ch <- val    // Never reached\n  1424→\n  1425→// Deadlock: Select without default\n  1426→ch1 := make(chan int)\n  1427→ch2 := make(chan int)\n  1428→\n  1429→select {\n  1430→case <-ch1:\n  1431→case <-ch2:\n  1432→// No default case - blocks forever if neither ready\n  1433→}\n  1434→```\n  1435→\n  1436→### Preventing Deadlocks\n  1437→```go\n  1438→// Use timeouts\n  1439→func safeLock(mu *sync.Mutex, timeout time.Duration) bool {\n  1440→    done := make(chan struct{})\n  1441→    go func() {\n  1442→        mu.Lock()\n  1443→        close(done)\n  1444→    }()\n  1445→    \n  1446→    select {\n  1447→    case <-done:\n  1448→        return true\n  1449→    case <-time.After(timeout):\n  1450→        return false\n  1451→    }\n  1452→}\n  1453→\n  1454→// Try-lock pattern\n  1455→type TryMutex struct {\n  1456→    ch chan struct{}\n  1457→}\n  1458→\n  1459→func NewTryMutex() *TryMutex {\n  1460→    ch := make(chan struct{}, 1)\n  1461→    ch <- struct{}{}\n  1462→    return &TryMutex{ch: ch}\n  1463→}\n  1464→\n  1465→func (m *TryMutex) Lock() {\n  1466→    <-m.ch\n  1467→}\n  1468→\n  1469→func (m *TryMutex) Unlock() {\n  1470→    m.ch <- struct{}{}\n  1471→}\n  1472→\n  1473→func (m *TryMutex) TryLock() bool {\n  1474→    select {\n  1475→    case <-m.ch:\n  1476→        return true\n  1477→    default:\n  1478→        return false\n  1479→    }\n  1480→}\n  1481→\n  1482→// Deadlock detection\n  1483→type DeadlockDetector struct {\n  1484→    mu       sync.Mutex\n  1485→    holding  map[string]string  // goroutine -> resource\n  1486→    waiting  map[string]string  // goroutine -> resource\n  1487→}\n  1488→\n  1489→func (d *DeadlockDetector) BeforeLock(goroutine, resource string) {\n  1490→    d.mu.Lock()\n  1491→    defer d.mu.Unlock()\n  1492→    \n  1493→    d.waiting[goroutine] = resource\n  1494→    // Check for cycle in wait graph\n  1495→    if d.hasCycle() {\n  1496→        panic(\"Potential deadlock detected!\")\n  1497→    }\n  1498→}\n  1499→\n  1500→func (d *DeadlockDetector) AfterLock(goroutine, resource string) {\n  1501→    d.mu.Lock()\n  1502→    defer d.mu.Unlock()\n  1503→    \n  1504→    delete(d.waiting, goroutine)\n  1505→    d.holding[goroutine] = resource\n  1506→}\n  1507→```\n  1508→\n  1509→## Performance and Optimization\n  1510→\n  1511→### Goroutine Performance\n  1512→```go\n  1513→// Limiting goroutines\n  1514→const maxGoroutines = 100\n  1515→sem := make(chan struct{}, maxGoroutines)\n  1516→\n  1517→for i := 0; i < 10000; i++ {\n  1518→    sem <- struct{}{}\n  1519→    go func(id int) {\n  1520→        defer func() { <-sem }()\n  1521→        process(id)\n  1522→    }(i)\n  1523→}\n  1524→\n  1525→// Reusing goroutines (worker pool)\n  1526→type WorkerPool struct {\n  1527→    workers int\n  1528→    jobs    chan func()\n  1529→    wg      sync.WaitGroup\n  1530→}\n  1531→\n  1532→func NewWorkerPool(workers int) *WorkerPool {\n  1533→    pool := &WorkerPool{\n  1534→        workers: workers,\n  1535→        jobs:    make(chan func(), workers*2),\n  1536→    }\n  1537→    pool.start()\n  1538→    return pool\n  1539→}\n  1540→\n  1541→func (p *WorkerPool) start() {\n  1542→    for i := 0; i < p.workers; i++ {\n  1543→        p.wg.Add(1)\n  1544→        go func() {\n  1545→            defer p.wg.Done()\n  1546→            for job := range p.jobs {\n  1547→                job()\n  1548→            }\n  1549→        }()\n  1550→    }\n  1551→}\n  1552→\n  1553→func (p *WorkerPool) Submit(job func()) {\n  1554→    p.jobs <- job\n  1555→}\n  1556→\n  1557→func (p *WorkerPool) Stop() {\n  1558→    close(p.jobs)\n  1559→    p.wg.Wait()\n  1560→}\n  1561→\n  1562→// Batching for efficiency\n  1563→func batchProcessor(items <-chan Item) {\n  1564→    batch := make([]Item, 0, 100)\n  1565→    ticker := time.NewTicker(1 * time.Second)\n  1566→    defer ticker.Stop()\n  1567→    \n  1568→    for {\n  1569→        select {\n  1570→        case item, ok := <-items:\n  1571→            if !ok {\n  1572→                if len(batch) > 0 {\n  1573→                    processBatch(batch)\n  1574→                }\n  1575→                return\n  1576→            }\n  1577→            batch = append(batch, item)\n  1578→            if len(batch) >= 100 {\n  1579→                processBatch(batch)\n  1580→                batch = batch[:0]\n  1581→            }\n  1582→        case <-ticker.C:\n  1583→            if len(batch) > 0 {\n  1584→                processBatch(batch)\n  1585→                batch = batch[:0]\n  1586→            }\n  1587→        }\n  1588→    }\n  1589→}\n  1590→```\n  1591→\n  1592→### Channel Performance\n  1593→```go\n  1594→// Buffered channels for performance\n  1595→ch := make(chan int, 1000)  // Reduce blocking\n  1596→\n  1597→// Channel direction for optimization\n  1598→func producer() <-chan int {  // Read-only return\n  1599→    ch := make(chan int)\n  1600→    go func() {\n  1601→        defer close(ch)\n  1602→        for i := 0; i < 100; i++ {\n  1603→            ch <- i\n  1604→        }\n  1605→    }()\n  1606→    return ch\n  1607→}\n  1608→\n  1609→// Avoid channel operations in hot paths\n  1610→// Bad:\n  1611→for i := 0; i < 1000000; i++ {\n  1612→    ch <- i  // Channel operation in tight loop\n  1613→}\n  1614→\n  1615→// Good:\n  1616→batch := make([]int, 0, 1000)\n  1617→for i := 0; i < 1000000; i++ {\n  1618→    batch = append(batch, i)\n  1619→    if len(batch) >= 1000 {\n  1620→        ch <- batch\n  1621→        batch = make([]int, 0, 1000)\n  1622→    }\n  1623→}\n  1624→\n  1625→// Select with default for non-blocking\n  1626→select {\n  1627→case ch <- value:\n  1628→    // Sent\n  1629→default:\n  1630→    // Channel full, handle accordingly\n  1631→}\n  1632→```\n  1633→\n  1634→### Memory and Lock Optimization\n  1635→```go\n  1636→// Reduce lock contention with sharding\n  1637→type ShardedMap struct {\n  1638→    shards [16]struct {\n  1639→        sync.RWMutex\n  1640→        m map[string]interface{}\n  1641→    }\n  1642→}\n  1643→\n  1644→func (sm *ShardedMap) getShard(key string) *struct {\n  1645→    sync.RWMutex\n  1646→    m map[string]interface{}\n  1647→} {\n  1648→    hash := fnv32(key)\n  1649→    return &sm.shards[hash%16]\n  1650→}\n  1651→\n  1652→func (sm *ShardedMap) Get(key string) (interface{}, bool) {\n  1653→    shard := sm.getShard(key)\n  1654→    shard.RLock()\n  1655→    defer shard.RUnlock()\n  1656→    val, ok := shard.m[key]\n  1657→    return val, ok\n  1658→}\n  1659→\n  1660→// Lock-free with atomic\n  1661→type Config struct {\n  1662→    v atomic.Value\n  1663→}\n  1664→\n  1665→func (c *Config) Load() *ConfigData {\n  1666→    return c.v.Load().(*ConfigData)\n  1667→}\n  1668→\n  1669→func (c *Config) Store(cfg *ConfigData) {\n  1670→    c.v.Store(cfg)\n  1671→}\n  1672→\n  1673→// Reduce allocations\n  1674→var bufferPool = sync.Pool{\n  1675→    New: func() interface{} {\n  1676→        return make([]byte, 1024)\n  1677→    },\n  1678→}\n  1679→\n  1680→func process() {\n  1681→    buf := bufferPool.Get().([]byte)\n  1682→    defer bufferPool.Put(buf)\n  1683→    // Use buf\n  1684→}\n  1685→```\n  1686→\n  1687→## Best Practices Summary\n  1688→\n  1689→1. **Start goroutines responsibly** - Always know how they'll stop\n  1690→2. **Don't leak goroutines** - Ensure cleanup with context or channels\n  1691→3. **Prefer channels over shared memory** - But use sync primitives when appropriate\n  1692→4. **Always handle context cancellation** - Check ctx.Done() in loops\n  1693→5. **Close channels from sender side only** - Never close from receiver\n  1694→6. **Use buffered channels thoughtfully** - Not just to \"fix\" synchronization\n  1695→7. **Protect shared state** - Use mutex, channels, or atomic operations\n  1696→8. **Run with -race during development** - Catch races early\n  1697→9. **Design for graceful shutdown** - Handle signals and cleanup\n  1698→10. **Profile before optimizing** - Measure, don't guess performance issues\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"f390127d-f873-4e74-904e-735af7edd554","timestamp":"2025-08-13T09:59:17.504Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/concurrency.md","content":"# Go Concurrency - Mastering Concurrent Programming\n\n## Table of Contents\n1. [Goroutines](#goroutines)\n2. [Channels](#channels)\n3. [Select Statement](#select-statement)\n4. [Sync Package](#sync-package)\n5. [Atomic Operations](#atomic-operations)\n6. [Concurrency Patterns](#concurrency-patterns)\n7. [Context Package](#context-package)\n8. [Race Conditions](#race-conditions)\n9. [Deadlocks](#deadlocks)\n10. [Performance and Optimization](#performance-and-optimization)\n\n## Goroutines\n\n### Goroutine Basics\n```go\n// Starting a goroutine\ngo functionName()\ngo func() {\n    // Anonymous function as goroutine\n}()\n\n// Goroutines with parameters\ngo processItem(item)\n\n// Common mistake: loop variable capture\n// WRONG:\nfor _, item := range items {\n    go func() {\n        process(item)  // All goroutines get last item!\n    }()\n}\n\n// CORRECT:\nfor _, item := range items {\n    item := item  // Create new variable\n    go func() {\n        process(item)\n    }()\n}\n\n// Alternative: pass as parameter\nfor _, item := range items {\n    go func(i Item) {\n        process(i)\n    }(item)\n}\n\n// Waiting for goroutines to complete\nvar wg sync.WaitGroup\n\nfor i := 0; i < 10; i++ {\n    wg.Add(1)\n    go func(id int) {\n        defer wg.Done()\n        doWork(id)\n    }(i)\n}\n\nwg.Wait()  // Block until all complete\n\n// Goroutine lifecycle management\ntype Worker struct {\n    done chan struct{}\n}\n\nfunc (w *Worker) Start() {\n    go w.run()\n}\n\nfunc (w *Worker) run() {\n    ticker := time.NewTicker(1 * time.Second)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case <-ticker.C:\n            w.doWork()\n        case <-w.done:\n            return\n        }\n    }\n}\n\nfunc (w *Worker) Stop() {\n    close(w.done)\n}\n```\n\n### Goroutine Patterns\n```go\n// Limiting concurrent goroutines\nconst maxWorkers = 10\nsem := make(chan struct{}, maxWorkers)\n\nfor _, item := range items {\n    sem <- struct{}{}  // Acquire\n    go func(i Item) {\n        defer func() { <-sem }()  // Release\n        process(i)\n    }(item)\n}\n\n// Wait for all to complete\nfor i := 0; i < maxWorkers; i++ {\n    sem <- struct{}{}\n}\n\n// Error handling in goroutines\ntype Result struct {\n    Value interface{}\n    Err   error\n}\n\nresults := make(chan Result, len(items))\n\nfor _, item := range items {\n    go func(i Item) {\n        value, err := process(i)\n        results <- Result{Value: value, Err: err}\n    }(item)\n}\n\n// Collect results\nfor i := 0; i < len(items); i++ {\n    result := <-results\n    if result.Err != nil {\n        log.Printf(\"Error: %v\", result.Err)\n    }\n}\n\n// Goroutine pool pattern\ntype Pool struct {\n    work chan func()\n    wg   sync.WaitGroup\n}\n\nfunc NewPool(workers int) *Pool {\n    p := &Pool{\n        work: make(chan func(), 100),\n    }\n    \n    p.wg.Add(workers)\n    for i := 0; i < workers; i++ {\n        go p.worker()\n    }\n    \n    return p\n}\n\nfunc (p *Pool) worker() {\n    defer p.wg.Done()\n    for fn := range p.work {\n        fn()\n    }\n}\n\nfunc (p *Pool) Submit(fn func()) {\n    p.work <- fn\n}\n\nfunc (p *Pool) Shutdown() {\n    close(p.work)\n    p.wg.Wait()\n}\n```\n\n## Channels\n\n### Channel Basics\n```go\n// Creating channels\nch := make(chan int)       // Unbuffered\nch := make(chan int, 10)   // Buffered with capacity 10\n\n// Channel operations\nch <- 42        // Send\nvalue := <-ch   // Receive\nvalue, ok := <-ch  // Receive with closed check\n\n// Closing channels\nclose(ch)\n\n// Check if channel is closed\nif v, ok := <-ch; !ok {\n    // Channel is closed\n}\n\n// Directional channels\nfunc send(ch chan<- int) {  // Send-only\n    ch <- 42\n}\n\nfunc receive(ch <-chan int) {  // Receive-only\n    value := <-ch\n}\n\n// Channel zero value is nil\nvar ch chan int\n// ch <- 1  // Blocks forever!\n// <-ch     // Blocks forever!\n\n// Range over channel\nch := make(chan int)\ngo func() {\n    for i := 0; i < 5; i++ {\n        ch <- i\n    }\n    close(ch)\n}()\n\nfor value := range ch {\n    fmt.Println(value)\n}\n```\n\n### Buffered vs Unbuffered Channels\n```go\n// Unbuffered channels - synchronous\nch := make(chan int)\ngo func() {\n    ch <- 42  // Blocks until someone receives\n}()\nvalue := <-ch  // Blocks until someone sends\n\n// Buffered channels - asynchronous up to capacity\nch := make(chan int, 3)\nch <- 1  // Doesn't block\nch <- 2  // Doesn't block\nch <- 3  // Doesn't block\n// ch <- 4  // Would block!\n\n// Using buffered channels as semaphores\ntype Semaphore chan struct{}\n\nfunc NewSemaphore(n int) Semaphore {\n    return make(Semaphore, n)\n}\n\nfunc (s Semaphore) Acquire() {\n    s <- struct{}{}\n}\n\nfunc (s Semaphore) Release() {\n    <-s\n}\n\n// Channel of channels\ntype Request struct {\n    data  string\n    reply chan Response\n}\n\nrequests := make(chan Request)\n\n// Server\ngo func() {\n    for req := range requests {\n        response := processRequest(req.data)\n        req.reply <- response\n    }\n}()\n\n// Client\nreply := make(chan Response)\nrequests <- Request{data: \"hello\", reply: reply}\nresponse := <-reply\n```\n\n### Channel Patterns\n```go\n// Fan-in: Merge multiple channels\nfunc fanIn(channels ...<-chan int) <-chan int {\n    out := make(chan int)\n    var wg sync.WaitGroup\n    \n    for _, ch := range channels {\n        wg.Add(1)\n        go func(c <-chan int) {\n            defer wg.Done()\n            for val := range c {\n                out <- val\n            }\n        }(ch)\n    }\n    \n    go func() {\n        wg.Wait()\n        close(out)\n    }()\n    \n    return out\n}\n\n// Fan-out: Distribute work\nfunc fanOut(in <-chan int, workers int) []<-chan int {\n    channels := make([]<-chan int, workers)\n    \n    for i := 0; i < workers; i++ {\n        ch := make(chan int)\n        channels[i] = ch\n        \n        go func(out chan int) {\n            for val := range in {\n                out <- process(val)\n            }\n            close(out)\n        }(ch)\n    }\n    \n    return channels\n}\n\n// Pipeline pattern\nfunc pipeline() {\n    // Stage 1: Generate numbers\n    numbers := make(chan int)\n    go func() {\n        for i := 1; i <= 100; i++ {\n            numbers <- i\n        }\n        close(numbers)\n    }()\n    \n    // Stage 2: Square numbers\n    squares := make(chan int)\n    go func() {\n        for n := range numbers {\n            squares <- n * n\n        }\n        close(squares)\n    }()\n    \n    // Stage 3: Filter even\n    evens := make(chan int)\n    go func() {\n        for sq := range squares {\n            if sq%2 == 0 {\n                evens <- sq\n            }\n        }\n        close(evens)\n    }()\n    \n    // Consume\n    for even := range evens {\n        fmt.Println(even)\n    }\n}\n\n// Timeout pattern\nfunc timeoutExample() {\n    ch := make(chan string)\n    \n    go func() {\n        time.Sleep(2 * time.Second)\n        ch <- \"result\"\n    }()\n    \n    select {\n    case result := <-ch:\n        fmt.Println(\"Got:\", result)\n    case <-time.After(1 * time.Second):\n        fmt.Println(\"Timeout!\")\n    }\n}\n```\n\n## Select Statement\n\n### Select Basics\n```go\n// Basic select\nselect {\ncase v1 := <-ch1:\n    fmt.Println(\"Received from ch1:\", v1)\ncase v2 := <-ch2:\n    fmt.Println(\"Received from ch2:\", v2)\ncase ch3 <- 42:\n    fmt.Println(\"Sent to ch3\")\ndefault:\n    fmt.Println(\"No channels ready\")\n}\n\n// Non-blocking receive\nselect {\ncase msg := <-ch:\n    fmt.Println(\"Received:\", msg)\ndefault:\n    fmt.Println(\"No message available\")\n}\n\n// Non-blocking send\nselect {\ncase ch <- msg:\n    fmt.Println(\"Sent message\")\ndefault:\n    fmt.Println(\"Channel full or not ready\")\n}\n\n// Timeout with select\nselect {\ncase result := <-ch:\n    fmt.Println(\"Got result:\", result)\ncase <-time.After(5 * time.Second):\n    fmt.Println(\"Timeout after 5 seconds\")\n}\n\n// Ticker with select\nticker := time.NewTicker(1 * time.Second)\ndefer ticker.Stop()\n\ndone := make(chan bool)\ngo func() {\n    time.Sleep(5 * time.Second)\n    done <- true\n}()\n\nfor {\n    select {\n    case <-ticker.C:\n        fmt.Println(\"Tick\")\n    case <-done:\n        fmt.Println(\"Done!\")\n        return\n    }\n}\n```\n\n### Advanced Select Patterns\n```go\n// Priority select using default\nfunc prioritySelect(high, low <-chan int) int {\n    select {\n    case val := <-high:\n        return val\n    default:\n        select {\n        case val := <-high:\n            return val\n        case val := <-low:\n            return val\n        }\n    }\n}\n\n// Quit channel pattern\nfunc worker(work <-chan int, quit <-chan struct{}) {\n    for {\n        select {\n        case w := <-work:\n            process(w)\n        case <-quit:\n            cleanup()\n            return\n        }\n    }\n}\n\n// Multiple return channels\nfunc multiReturn() (chan int, chan error) {\n    results := make(chan int)\n    errors := make(chan error)\n    \n    go func() {\n        defer close(results)\n        defer close(errors)\n        \n        for i := 0; i < 10; i++ {\n            if i%3 == 0 {\n                errors <- fmt.Errorf(\"error at %d\", i)\n            } else {\n                results <- i * i\n            }\n        }\n    }()\n    \n    return results, errors\n}\n\n// Using nil channels in select\nfunc dynamicSelect() {\n    ch1 := make(chan int)\n    ch2 := make(chan int)\n    \n    go func() {\n        for i := 0; i < 5; i++ {\n            ch1 <- i\n            time.Sleep(100 * time.Millisecond)\n        }\n        close(ch1)\n    }()\n    \n    go func() {\n        for i := 5; i < 10; i++ {\n            ch2 <- i\n            time.Sleep(150 * time.Millisecond)\n        }\n        close(ch2)\n    }()\n    \n    for ch1 != nil || ch2 != nil {\n        select {\n        case v, ok := <-ch1:\n            if !ok {\n                ch1 = nil  // Disable this case\n                continue\n            }\n            fmt.Println(\"ch1:\", v)\n        case v, ok := <-ch2:\n            if !ok {\n                ch2 = nil  // Disable this case\n                continue\n            }\n            fmt.Println(\"ch2:\", v)\n        }\n    }\n}\n```\n\n## Sync Package\n\n### WaitGroup\n```go\nvar wg sync.WaitGroup\n\n// Basic usage\nfor i := 0; i < 5; i++ {\n    wg.Add(1)\n    go func(id int) {\n        defer wg.Done()\n        doWork(id)\n    }(i)\n}\nwg.Wait()\n\n// Reusable WaitGroup\ntype Task struct {\n    wg sync.WaitGroup\n}\n\nfunc (t *Task) Run(workers int) {\n    t.wg.Add(workers)\n    for i := 0; i < workers; i++ {\n        go t.worker(i)\n    }\n    t.wg.Wait()\n}\n\nfunc (t *Task) worker(id int) {\n    defer t.wg.Done()\n    // Do work\n}\n```\n\n### Mutex\n```go\n// Basic mutex\ntype Counter struct {\n    mu    sync.Mutex\n    value int\n}\n\nfunc (c *Counter) Inc() {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    c.value++\n}\n\nfunc (c *Counter) Value() int {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    return c.value\n}\n\n// RWMutex for read-heavy workloads\ntype Cache struct {\n    mu    sync.RWMutex\n    data  map[string]string\n}\n\nfunc (c *Cache) Get(key string) (string, bool) {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    val, ok := c.data[key]\n    return val, ok\n}\n\nfunc (c *Cache) Set(key, value string) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    c.data[key] = value\n}\n\n// Mutex embedding pattern\ntype SafeMap struct {\n    sync.RWMutex\n    m map[string]int\n}\n\nfunc (sm *SafeMap) Load(key string) (int, bool) {\n    sm.RLock()\n    defer sm.RUnlock()\n    val, ok := sm.m[key]\n    return val, ok\n}\n```\n\n### Once\n```go\nvar once sync.Once\nvar instance *Singleton\n\ntype Singleton struct {\n    // fields\n}\n\nfunc GetInstance() *Singleton {\n    once.Do(func() {\n        instance = &Singleton{}\n        // Initialize\n    })\n    return instance\n}\n\n// Once for expensive initialization\ntype Service struct {\n    once   sync.Once\n    client *http.Client\n}\n\nfunc (s *Service) getClient() *http.Client {\n    s.once.Do(func() {\n        s.client = &http.Client{\n            Timeout: 30 * time.Second,\n            Transport: &http.Transport{\n                MaxIdleConns:    100,\n                IdleConnTimeout: 90 * time.Second,\n            },\n        }\n    })\n    return s.client\n}\n```\n\n### Cond\n```go\n// Condition variable for signaling\ntype Queue struct {\n    mu    sync.Mutex\n    cond  *sync.Cond\n    items []interface{}\n}\n\nfunc NewQueue() *Queue {\n    q := &Queue{}\n    q.cond = sync.NewCond(&q.mu)\n    return q\n}\n\nfunc (q *Queue) Put(item interface{}) {\n    q.mu.Lock()\n    defer q.mu.Unlock()\n    q.items = append(q.items, item)\n    q.cond.Signal()  // Wake one waiter\n}\n\nfunc (q *Queue) Get() interface{} {\n    q.mu.Lock()\n    defer q.mu.Unlock()\n    \n    for len(q.items) == 0 {\n        q.cond.Wait()  // Releases lock while waiting\n    }\n    \n    item := q.items[0]\n    q.items = q.items[1:]\n    return item\n}\n\n// Broadcast to all waiters\nfunc (q *Queue) Close() {\n    q.mu.Lock()\n    defer q.mu.Unlock()\n    q.cond.Broadcast()  // Wake all waiters\n}\n```\n\n### Pool\n```go\n// Object pool for reuse\nvar bufferPool = sync.Pool{\n    New: func() interface{} {\n        return new(bytes.Buffer)\n    },\n}\n\nfunc processData(data []byte) {\n    buf := bufferPool.Get().(*bytes.Buffer)\n    defer func() {\n        buf.Reset()\n        bufferPool.Put(buf)\n    }()\n    \n    buf.Write(data)\n    // Process buffer\n}\n\n// Connection pool pattern\ntype ConnPool struct {\n    pool chan net.Conn\n}\n\nfunc NewConnPool(size int, dial func() (net.Conn, error)) (*ConnPool, error) {\n    pool := make(chan net.Conn, size)\n    for i := 0; i < size; i++ {\n        conn, err := dial()\n        if err != nil {\n            return nil, err\n        }\n        pool <- conn\n    }\n    return &ConnPool{pool: pool}, nil\n}\n\nfunc (p *ConnPool) Get() net.Conn {\n    return <-p.pool\n}\n\nfunc (p *ConnPool) Put(conn net.Conn) {\n    p.pool <- conn\n}\n```\n\n### Map (sync.Map)\n```go\n// Thread-safe map without explicit locking\nvar m sync.Map\n\n// Store\nm.Store(\"key\", \"value\")\nm.Store(123, \"numeric key\")\n\n// Load\nif val, ok := m.Load(\"key\"); ok {\n    fmt.Println(val.(string))\n}\n\n// LoadOrStore\nactual, loaded := m.LoadOrStore(\"key\", \"new value\")\nif loaded {\n    fmt.Println(\"Key existed:\", actual)\n}\n\n// Delete\nm.Delete(\"key\")\n\n// Range\nm.Range(func(key, value interface{}) bool {\n    fmt.Printf(\"%v: %v\\n\", key, value)\n    return true  // Continue iteration\n})\n\n// Use cases for sync.Map:\n// 1. Keys are written once but read many times\n// 2. Different goroutines read/write disjoint key sets\n// 3. When lock contention would be a problem\n```\n\n## Atomic Operations\n\n### Atomic Package\n```go\nimport \"sync/atomic\"\n\n// Atomic integers\nvar counter int64\n\natomic.AddInt64(&counter, 1)           // Increment\natomic.AddInt64(&counter, -1)          // Decrement\nval := atomic.LoadInt64(&counter)      // Read\natomic.StoreInt64(&counter, 100)       // Write\nold := atomic.SwapInt64(&counter, 200) // Swap\n\n// Compare and swap (CAS)\nif atomic.CompareAndSwapInt64(&counter, 100, 200) {\n    // Successfully changed from 100 to 200\n}\n\n// Atomic boolean using int32\ntype AtomicBool struct {\n    flag int32\n}\n\nfunc (b *AtomicBool) Set(value bool) {\n    var i int32\n    if value {\n        i = 1\n    }\n    atomic.StoreInt32(&b.flag, i)\n}\n\nfunc (b *AtomicBool) Get() bool {\n    return atomic.LoadInt32(&b.flag) != 0\n}\n\n// Atomic pointer\ntype Config struct {\n    // fields\n}\n\nvar config atomic.Value\n\n// Store new config\nconfig.Store(&Config{})\n\n// Load config\ncfg := config.Load().(*Config)\n\n// Atomic counter implementation\ntype Counter struct {\n    value int64\n}\n\nfunc (c *Counter) Inc() int64 {\n    return atomic.AddInt64(&c.value, 1)\n}\n\nfunc (c *Counter) Dec() int64 {\n    return atomic.AddInt64(&c.value, -1)\n}\n\nfunc (c *Counter) Value() int64 {\n    return atomic.LoadInt64(&c.value)\n}\n\nfunc (c *Counter) Reset() {\n    atomic.StoreInt64(&c.value, 0)\n}\n```\n\n### Atomic Patterns\n```go\n// Lock-free stack\ntype Stack struct {\n    head atomic.Value\n}\n\ntype node struct {\n    value interface{}\n    next  *node\n}\n\nfunc (s *Stack) Push(v interface{}) {\n    n := &node{value: v}\n    for {\n        head := s.head.Load()\n        if head != nil {\n            n.next = head.(*node)\n        }\n        if s.head.CompareAndSwap(head, n) {\n            return\n        }\n    }\n}\n\nfunc (s *Stack) Pop() interface{} {\n    for {\n        head := s.head.Load()\n        if head == nil {\n            return nil\n        }\n        n := head.(*node)\n        if s.head.CompareAndSwap(head, n.next) {\n            return n.value\n        }\n    }\n}\n\n// Atomic statistics collector\ntype Stats struct {\n    requests  int64\n    errors    int64\n    totalTime int64\n}\n\nfunc (s *Stats) RecordRequest(duration time.Duration, err error) {\n    atomic.AddInt64(&s.requests, 1)\n    atomic.AddInt64(&s.totalTime, int64(duration))\n    if err != nil {\n        atomic.AddInt64(&s.errors, 1)\n    }\n}\n\nfunc (s *Stats) Snapshot() (requests, errors, avgTime int64) {\n    requests = atomic.LoadInt64(&s.requests)\n    errors = atomic.LoadInt64(&s.errors)\n    totalTime := atomic.LoadInt64(&s.totalTime)\n    if requests > 0 {\n        avgTime = totalTime / requests\n    }\n    return\n}\n```\n\n## Concurrency Patterns\n\n### Worker Pool\n```go\ntype Job struct {\n    ID   int\n    Data string\n}\n\ntype Result struct {\n    JobID  int\n    Output string\n    Err    error\n}\n\nfunc workerPool(jobs <-chan Job, results chan<- Result, workers int) {\n    var wg sync.WaitGroup\n    \n    for i := 0; i < workers; i++ {\n        wg.Add(1)\n        go func(workerID int) {\n            defer wg.Done()\n            for job := range jobs {\n                output, err := processJob(job)\n                results <- Result{\n                    JobID:  job.ID,\n                    Output: output,\n                    Err:    err,\n                }\n            }\n        }(i)\n    }\n    \n    wg.Wait()\n    close(results)\n}\n\n// Usage\njobs := make(chan Job, 100)\nresults := make(chan Result, 100)\n\ngo workerPool(jobs, results, 10)\n\n// Send jobs\ngo func() {\n    for i := 0; i < 1000; i++ {\n        jobs <- Job{ID: i, Data: fmt.Sprintf(\"job-%d\", i)}\n    }\n    close(jobs)\n}()\n\n// Collect results\nfor result := range results {\n    if result.Err != nil {\n        log.Printf(\"Job %d failed: %v\", result.JobID, result.Err)\n    } else {\n        fmt.Printf(\"Job %d completed: %s\\n\", result.JobID, result.Output)\n    }\n}\n```\n\n### Rate Limiting\n```go\n// Simple rate limiter\nfunc rateLimiter() {\n    rate := time.Second / 10  // 10 requests per second\n    ticker := time.NewTicker(rate)\n    defer ticker.Stop()\n    \n    requests := make(chan int, 100)\n    \n    go func() {\n        for i := 0; i < 100; i++ {\n            requests <- i\n        }\n        close(requests)\n    }()\n    \n    for req := range requests {\n        <-ticker.C  // Wait for tick\n        go process(req)\n    }\n}\n\n// Token bucket rate limiter\ntype RateLimiter struct {\n    tokens chan struct{}\n}\n\nfunc NewRateLimiter(rate int, burst int) *RateLimiter {\n    rl := &RateLimiter{\n        tokens: make(chan struct{}, burst),\n    }\n    \n    // Fill bucket\n    for i := 0; i < burst; i++ {\n        rl.tokens <- struct{}{}\n    }\n    \n    // Refill tokens\n    go func() {\n        ticker := time.NewTicker(time.Second / time.Duration(rate))\n        defer ticker.Stop()\n        \n        for range ticker.C {\n            select {\n            case rl.tokens <- struct{}{}:\n            default:\n                // Bucket full\n            }\n        }\n    }()\n    \n    return rl\n}\n\nfunc (rl *RateLimiter) Allow() bool {\n    select {\n    case <-rl.tokens:\n        return true\n    default:\n        return false\n    }\n}\n\nfunc (rl *RateLimiter) Wait() {\n    <-rl.tokens\n}\n```\n\n### Circuit Breaker\n```go\ntype CircuitBreaker struct {\n    mu            sync.RWMutex\n    failures      int\n    lastFailTime  time.Time\n    state         string // \"closed\", \"open\", \"half-open\"\n    maxFailures   int\n    resetTimeout  time.Duration\n}\n\nfunc NewCircuitBreaker(maxFailures int, resetTimeout time.Duration) *CircuitBreaker {\n    return &CircuitBreaker{\n        maxFailures:  maxFailures,\n        resetTimeout: resetTimeout,\n        state:        \"closed\",\n    }\n}\n\nfunc (cb *CircuitBreaker) Call(fn func() error) error {\n    cb.mu.RLock()\n    state := cb.state\n    cb.mu.RUnlock()\n    \n    if state == \"open\" {\n        cb.mu.RLock()\n        if time.Since(cb.lastFailTime) > cb.resetTimeout {\n            cb.mu.RUnlock()\n            cb.mu.Lock()\n            cb.state = \"half-open\"\n            cb.failures = 0\n            cb.mu.Unlock()\n        } else {\n            cb.mu.RUnlock()\n            return errors.New(\"circuit breaker is open\")\n        }\n    }\n    \n    err := fn()\n    \n    cb.mu.Lock()\n    defer cb.mu.Unlock()\n    \n    if err != nil {\n        cb.failures++\n        cb.lastFailTime = time.Now()\n        \n        if cb.failures >= cb.maxFailures {\n            cb.state = \"open\"\n        }\n        return err\n    }\n    \n    if cb.state == \"half-open\" {\n        cb.state = \"closed\"\n    }\n    cb.failures = 0\n    return nil\n}\n```\n\n### Pub-Sub Pattern\n```go\ntype PubSub struct {\n    mu   sync.RWMutex\n    subs map[string][]chan interface{}\n}\n\nfunc NewPubSub() *PubSub {\n    return &PubSub{\n        subs: make(map[string][]chan interface{}),\n    }\n}\n\nfunc (ps *PubSub) Subscribe(topic string) <-chan interface{} {\n    ps.mu.Lock()\n    defer ps.mu.Unlock()\n    \n    ch := make(chan interface{}, 10)\n    ps.subs[topic] = append(ps.subs[topic], ch)\n    return ch\n}\n\nfunc (ps *PubSub) Publish(topic string, msg interface{}) {\n    ps.mu.RLock()\n    defer ps.mu.RUnlock()\n    \n    for _, ch := range ps.subs[topic] {\n        select {\n        case ch <- msg:\n        default:\n            // Subscriber is slow, skip\n        }\n    }\n}\n\nfunc (ps *PubSub) Unsubscribe(topic string, sub <-chan interface{}) {\n    ps.mu.Lock()\n    defer ps.mu.Unlock()\n    \n    subscribers := ps.subs[topic]\n    for i, ch := range subscribers {\n        if ch == sub {\n            close(ch)\n            ps.subs[topic] = append(subscribers[:i], subscribers[i+1:]...)\n            break\n        }\n    }\n}\n```\n\n## Context Package\n\n### Context Basics\n```go\n// Creating contexts\nctx := context.Background()  // Root context\nctx := context.TODO()        // When unsure what to use\n\n// With cancel\nctx, cancel := context.WithCancel(context.Background())\ndefer cancel()  // Always call cancel\n\n// With timeout\nctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\ndefer cancel()\n\n// With deadline\ndeadline := time.Now().Add(5 * time.Second)\nctx, cancel := context.WithDeadline(context.Background(), deadline)\ndefer cancel()\n\n// With value\nctx := context.WithValue(context.Background(), \"userID\", 123)\n\n// Using context\nfunc doWork(ctx context.Context) error {\n    select {\n    case <-time.After(2 * time.Second):\n        return nil\n    case <-ctx.Done():\n        return ctx.Err()\n    }\n}\n\n// HTTP request with context\nfunc fetchData(ctx context.Context, url string) (*http.Response, error) {\n    req, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n    if err != nil {\n        return nil, err\n    }\n    \n    return http.DefaultClient.Do(req)\n}\n```\n\n### Context Patterns\n```go\n// Propagating cancellation\nfunc pipeline(ctx context.Context) error {\n    ctx, cancel := context.WithCancel(ctx)\n    defer cancel()\n    \n    errc := make(chan error, 3)\n    \n    go func() {\n        errc <- stage1(ctx)\n    }()\n    \n    go func() {\n        errc <- stage2(ctx)\n    }()\n    \n    go func() {\n        errc <- stage3(ctx)\n    }()\n    \n    // Wait for first error or all complete\n    for i := 0; i < 3; i++ {\n        if err := <-errc; err != nil {\n            return err  // Cancel will stop other stages\n        }\n    }\n    \n    return nil\n}\n\n// Request scoped values\ntype contextKey string\n\nconst (\n    userIDKey contextKey = \"userID\"\n    traceIDKey contextKey = \"traceID\"\n)\n\nfunc WithUserID(ctx context.Context, userID string) context.Context {\n    return context.WithValue(ctx, userIDKey, userID)\n}\n\nfunc GetUserID(ctx context.Context) (string, bool) {\n    userID, ok := ctx.Value(userIDKey).(string)\n    return userID, ok\n}\n\n// Graceful shutdown\nfunc server(ctx context.Context) error {\n    srv := &http.Server{Addr: \":8080\"}\n    \n    go func() {\n        <-ctx.Done()\n        shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n        defer cancel()\n        srv.Shutdown(shutdownCtx)\n    }()\n    \n    return srv.ListenAndServe()\n}\n```\n\n## Race Conditions\n\n### Detecting Race Conditions\n```go\n// Run with race detector: go run -race main.go\n// Test with race detector: go test -race ./...\n\n// Common race condition\ntype Counter struct {\n    value int  // Not protected!\n}\n\nfunc (c *Counter) Inc() {\n    c.value++  // Race condition!\n}\n\n// Fixed version\ntype SafeCounter struct {\n    mu    sync.Mutex\n    value int\n}\n\nfunc (c *SafeCounter) Inc() {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    c.value++\n}\n\n// Race on map\nm := make(map[string]int)\n\ngo func() {\n    m[\"key\"] = 1  // Write\n}()\n\ngo func() {\n    _ = m[\"key\"]  // Read - RACE!\n}()\n\n// Race on slice append\nvar slice []int\n\ngo func() {\n    slice = append(slice, 1)  // Race!\n}()\n\ngo func() {\n    slice = append(slice, 2)  // Race!\n}()\n```\n\n### Preventing Race Conditions\n```go\n// Use channels instead of shared memory\ntype SafeCounter struct {\n    ch chan int\n}\n\nfunc NewSafeCounter() *SafeCounter {\n    c := &SafeCounter{\n        ch: make(chan int),\n    }\n    go c.run()\n    return c\n}\n\nfunc (c *SafeCounter) run() {\n    var value int\n    for delta := range c.ch {\n        value += delta\n    }\n}\n\nfunc (c *SafeCounter) Inc() {\n    c.ch <- 1\n}\n\n// Immutability pattern\ntype Config struct {\n    values map[string]string\n}\n\nfunc (c *Config) With(key, value string) *Config {\n    newValues := make(map[string]string)\n    for k, v := range c.values {\n        newValues[k] = v\n    }\n    newValues[key] = value\n    return &Config{values: newValues}\n}\n\n// Copy-on-write pattern\ntype Data struct {\n    mu    sync.RWMutex\n    items []Item\n}\n\nfunc (d *Data) Append(item Item) {\n    d.mu.Lock()\n    defer d.mu.Unlock()\n    \n    // Create new slice\n    newItems := make([]Item, len(d.items)+1)\n    copy(newItems, d.items)\n    newItems[len(newItems)-1] = item\n    d.items = newItems\n}\n\nfunc (d *Data) Items() []Item {\n    d.mu.RLock()\n    defer d.mu.RUnlock()\n    return d.items  // Safe because we copy on write\n}\n```\n\n## Deadlocks\n\n### Common Deadlock Patterns\n```go\n// Deadlock: Circular wait\nvar mu1, mu2 sync.Mutex\n\n// Goroutine 1\ngo func() {\n    mu1.Lock()\n    time.Sleep(10 * time.Millisecond)\n    mu2.Lock()  // Waits for mu2\n    // ...\n    mu2.Unlock()\n    mu1.Unlock()\n}()\n\n// Goroutine 2\ngo func() {\n    mu2.Lock()\n    time.Sleep(10 * time.Millisecond)\n    mu1.Lock()  // Waits for mu1 - DEADLOCK!\n    // ...\n    mu1.Unlock()\n    mu2.Unlock()\n}()\n\n// Fix: Always acquire locks in same order\nfunc transfer(from, to *Account, amount int) {\n    // Order accounts by ID to prevent deadlock\n    if from.ID < to.ID {\n        from.mu.Lock()\n        defer from.mu.Unlock()\n        to.mu.Lock()\n        defer to.mu.Unlock()\n    } else {\n        to.mu.Lock()\n        defer to.mu.Unlock()\n        from.mu.Lock()\n        defer from.mu.Unlock()\n    }\n    // Transfer logic\n}\n\n// Deadlock: Channel misuse\nch := make(chan int)\nch <- 42  // Blocks forever - no receiver!\n\n// Deadlock: Waiting for yourself\nch := make(chan int)\nval := <-ch  // Blocks forever\nch <- val    // Never reached\n\n// Deadlock: Select without default\nch1 := make(chan int)\nch2 := make(chan int)\n\nselect {\ncase <-ch1:\ncase <-ch2:\n// No default case - blocks forever if neither ready\n}\n```\n\n### Preventing Deadlocks\n```go\n// Use timeouts\nfunc safeLock(mu *sync.Mutex, timeout time.Duration) bool {\n    done := make(chan struct{})\n    go func() {\n        mu.Lock()\n        close(done)\n    }()\n    \n    select {\n    case <-done:\n        return true\n    case <-time.After(timeout):\n        return false\n    }\n}\n\n// Try-lock pattern\ntype TryMutex struct {\n    ch chan struct{}\n}\n\nfunc NewTryMutex() *TryMutex {\n    ch := make(chan struct{}, 1)\n    ch <- struct{}{}\n    return &TryMutex{ch: ch}\n}\n\nfunc (m *TryMutex) Lock() {\n    <-m.ch\n}\n\nfunc (m *TryMutex) Unlock() {\n    m.ch <- struct{}{}\n}\n\nfunc (m *TryMutex) TryLock() bool {\n    select {\n    case <-m.ch:\n        return true\n    default:\n        return false\n    }\n}\n\n// Deadlock detection\ntype DeadlockDetector struct {\n    mu       sync.Mutex\n    holding  map[string]string  // goroutine -> resource\n    waiting  map[string]string  // goroutine -> resource\n}\n\nfunc (d *DeadlockDetector) BeforeLock(goroutine, resource string) {\n    d.mu.Lock()\n    defer d.mu.Unlock()\n    \n    d.waiting[goroutine] = resource\n    // Check for cycle in wait graph\n    if d.hasCycle() {\n        panic(\"Potential deadlock detected!\")\n    }\n}\n\nfunc (d *DeadlockDetector) AfterLock(goroutine, resource string) {\n    d.mu.Lock()\n    defer d.mu.Unlock()\n    \n    delete(d.waiting, goroutine)\n    d.holding[goroutine] = resource\n}\n```\n\n## Performance and Optimization\n\n### Goroutine Performance\n```go\n// Limiting goroutines\nconst maxGoroutines = 100\nsem := make(chan struct{}, maxGoroutines)\n\nfor i := 0; i < 10000; i++ {\n    sem <- struct{}{}\n    go func(id int) {\n        defer func() { <-sem }()\n        process(id)\n    }(i)\n}\n\n// Reusing goroutines (worker pool)\ntype WorkerPool struct {\n    workers int\n    jobs    chan func()\n    wg      sync.WaitGroup\n}\n\nfunc NewWorkerPool(workers int) *WorkerPool {\n    pool := &WorkerPool{\n        workers: workers,\n        jobs:    make(chan func(), workers*2),\n    }\n    pool.start()\n    return pool\n}\n\nfunc (p *WorkerPool) start() {\n    for i := 0; i < p.workers; i++ {\n        p.wg.Add(1)\n        go func() {\n            defer p.wg.Done()\n            for job := range p.jobs {\n                job()\n            }\n        }()\n    }\n}\n\nfunc (p *WorkerPool) Submit(job func()) {\n    p.jobs <- job\n}\n\nfunc (p *WorkerPool) Stop() {\n    close(p.jobs)\n    p.wg.Wait()\n}\n\n// Batching for efficiency\nfunc batchProcessor(items <-chan Item) {\n    batch := make([]Item, 0, 100)\n    ticker := time.NewTicker(1 * time.Second)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case item, ok := <-items:\n            if !ok {\n                if len(batch) > 0 {\n                    processBatch(batch)\n                }\n                return\n            }\n            batch = append(batch, item)\n            if len(batch) >= 100 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n        case <-ticker.C:\n            if len(batch) > 0 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n        }\n    }\n}\n```\n\n### Channel Performance\n```go\n// Buffered channels for performance\nch := make(chan int, 1000)  // Reduce blocking\n\n// Channel direction for optimization\nfunc producer() <-chan int {  // Read-only return\n    ch := make(chan int)\n    go func() {\n        defer close(ch)\n        for i := 0; i < 100; i++ {\n            ch <- i\n        }\n    }()\n    return ch\n}\n\n// Avoid channel operations in hot paths\n// Bad:\nfor i := 0; i < 1000000; i++ {\n    ch <- i  // Channel operation in tight loop\n}\n\n// Good:\nbatch := make([]int, 0, 1000)\nfor i := 0; i < 1000000; i++ {\n    batch = append(batch, i)\n    if len(batch) >= 1000 {\n        ch <- batch\n        batch = make([]int, 0, 1000)\n    }\n}\n\n// Select with default for non-blocking\nselect {\ncase ch <- value:\n    // Sent\ndefault:\n    // Channel full, handle accordingly\n}\n```\n\n### Memory and Lock Optimization\n```go\n// Reduce lock contention with sharding\ntype ShardedMap struct {\n    shards [16]struct {\n        sync.RWMutex\n        m map[string]interface{}\n    }\n}\n\nfunc (sm *ShardedMap) getShard(key string) *struct {\n    sync.RWMutex\n    m map[string]interface{}\n} {\n    hash := fnv32(key)\n    return &sm.shards[hash%16]\n}\n\nfunc (sm *ShardedMap) Get(key string) (interface{}, bool) {\n    shard := sm.getShard(key)\n    shard.RLock()\n    defer shard.RUnlock()\n    val, ok := shard.m[key]\n    return val, ok\n}\n\n// Lock-free with atomic\ntype Config struct {\n    v atomic.Value\n}\n\nfunc (c *Config) Load() *ConfigData {\n    return c.v.Load().(*ConfigData)\n}\n\nfunc (c *Config) Store(cfg *ConfigData) {\n    c.v.Store(cfg)\n}\n\n// Reduce allocations\nvar bufferPool = sync.Pool{\n    New: func() interface{} {\n        return make([]byte, 1024)\n    },\n}\n\nfunc process() {\n    buf := bufferPool.Get().([]byte)\n    defer bufferPool.Put(buf)\n    // Use buf\n}\n```\n\n## Best Practices Summary\n\n1. **Start goroutines responsibly** - Always know how they'll stop\n2. **Don't leak goroutines** - Ensure cleanup with context or channels\n3. **Prefer channels over shared memory** - But use sync primitives when appropriate\n4. **Always handle context cancellation** - Check ctx.Done() in loops\n5. **Close channels from sender side only** - Never close from receiver\n6. **Use buffered channels thoughtfully** - Not just to \"fix\" synchronization\n7. **Protect shared state** - Use mutex, channels, or atomic operations\n8. **Run with -race during development** - Catch races early\n9. **Design for graceful shutdown** - Handle signals and cleanup\n10. **Profile before optimizing** - Measure, don't guess performance issues","numLines":1698,"startLine":1,"totalLines":1698}}}
{"parentUuid":"f390127d-f873-4e74-904e-735af7edd554","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01P8ERwRpXN5fKtbpnuo3TCR","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_0181pb9wLsG3ZE8vFo9KTm3z","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/testing.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":17212,"cache_read_input_tokens":109401,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5WhdQmmLiQWHSfJcqVx","type":"assistant","uuid":"244e2eb5-e942-4971-bb7a-c7383b079f9c","timestamp":"2025-08-13T09:59:22.578Z"}
{"parentUuid":"244e2eb5-e942-4971-bb7a-c7383b079f9c","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0181pb9wLsG3ZE8vFo9KTm3z","type":"tool_result","content":"     1→# Go Testing - Complete Testing Guide\n     2→\n     3→## Table of Contents\n     4→1. [Unit Tests](#unit-tests)\n     5→2. [Table-Driven Tests](#table-driven-tests)\n     6→3. [Subtests](#subtests)\n     7→4. [Mocks and Stubs](#mocks-and-stubs)\n     8→5. [Fuzz Testing](#fuzz-testing)\n     9→6. [Benchmarks](#benchmarks)\n    10→7. [Coverage](#coverage)\n    11→8. [Integration Tests](#integration-tests)\n    12→9. [Test Fixtures and Helpers](#test-fixtures-and-helpers)\n    13→10. [Advanced Testing Techniques](#advanced-testing-techniques)\n    14→\n    15→## Unit Tests\n    16→\n    17→### Basic Test Structure\n    18→```go\n    19→// File: math.go\n    20→package math\n    21→\n    22→func Add(a, b int) int {\n    23→    return a + b\n    24→}\n    25→\n    26→// File: math_test.go\n    27→package math\n    28→\n    29→import \"testing\"\n    30→\n    31→func TestAdd(t *testing.T) {\n    32→    result := Add(2, 3)\n    33→    expected := 5\n    34→    \n    35→    if result != expected {\n    36→        t.Errorf(\"Add(2, 3) = %d; want %d\", result, expected)\n    37→    }\n    38→}\n    39→\n    40→// Test with multiple assertions\n    41→func TestMultipleAssertions(t *testing.T) {\n    42→    // Arrange\n    43→    input := \"test\"\n    44→    \n    45→    // Act\n    46→    result := Process(input)\n    47→    \n    48→    // Assert\n    49→    if result.Status != \"success\" {\n    50→        t.Errorf(\"expected status 'success', got %q\", result.Status)\n    51→    }\n    52→    \n    53→    if len(result.Data) == 0 {\n    54→        t.Error(\"expected non-empty data\")\n    55→    }\n    56→    \n    57→    if result.Timestamp.IsZero() {\n    58→        t.Error(\"expected non-zero timestamp\")\n    59→    }\n    60→}\n    61→\n    62→// Using t.Fatal for critical failures\n    63→func TestCriticalFailure(t *testing.T) {\n    64→    db, err := connectDB()\n    65→    if err != nil {\n    66→        t.Fatalf(\"failed to connect to database: %v\", err)\n    67→    }\n    68→    defer db.Close()\n    69→    \n    70→    // Continue with test...\n    71→}\n    72→\n    73→// Using t.Skip for conditional tests\n    74→func TestRequiresDocker(t *testing.T) {\n    75→    if !dockerAvailable() {\n    76→        t.Skip(\"skipping test; Docker not available\")\n    77→    }\n    78→    \n    79→    // Docker-dependent test...\n    80→}\n    81→\n    82→// Parallel tests\n    83→func TestParallel1(t *testing.T) {\n    84→    t.Parallel() // Run in parallel with other parallel tests\n    85→    // Test implementation...\n    86→}\n    87→\n    88→func TestParallel2(t *testing.T) {\n    89→    t.Parallel()\n    90→    // Test implementation...\n    91→}\n    92→```\n    93→\n    94→### Test Organization\n    95→```go\n    96→// Testing exported functions\n    97→func TestPublicFunction(t *testing.T) {\n    98→    result := PublicFunction(\"input\")\n    99→    if result != \"expected\" {\n   100→        t.Errorf(\"got %q, want %q\", result, \"expected\")\n   101→    }\n   102→}\n   103→\n   104→// Testing unexported functions (same package)\n   105→func TestPrivateFunction(t *testing.T) {\n   106→    result := privateFunction(\"input\")\n   107→    if result != \"expected\" {\n   108→        t.Errorf(\"got %q, want %q\", result, \"expected\")\n   109→    }\n   110→}\n   111→\n   112→// Testing with external package (black-box testing)\n   113→package math_test\n   114→\n   115→import (\n   116→    \"testing\"\n   117→    \"myproject/math\"\n   118→)\n   119→\n   120→func TestAddExternal(t *testing.T) {\n   121→    result := math.Add(2, 3)\n   122→    if result != 5 {\n   123→        t.Errorf(\"math.Add(2, 3) = %d; want 5\", result)\n   124→    }\n   125→}\n   126→\n   127→// Example tests (show up in documentation)\n   128→func ExampleAdd() {\n   129→    result := Add(2, 3)\n   130→    fmt.Println(result)\n   131→    // Output: 5\n   132→}\n   133→\n   134→func ExampleAdd_negative() {\n   135→    result := Add(-2, -3)\n   136→    fmt.Println(result)\n   137→    // Output: -5\n   138→}\n   139→\n   140→// Testing main function\n   141→func TestMain(m *testing.M) {\n   142→    // Setup before tests\n   143→    setup()\n   144→    \n   145→    // Run tests\n   146→    code := m.Run()\n   147→    \n   148→    // Cleanup after tests\n   149→    teardown()\n   150→    \n   151→    os.Exit(code)\n   152→}\n   153→```\n   154→\n   155→## Table-Driven Tests\n   156→\n   157→### Basic Table-Driven Tests\n   158→```go\n   159→func TestAdd(t *testing.T) {\n   160→    tests := []struct {\n   161→        name     string\n   162→        a, b     int\n   163→        expected int\n   164→    }{\n   165→        {\"positive numbers\", 2, 3, 5},\n   166→        {\"negative numbers\", -2, -3, -5},\n   167→        {\"mixed\", -5, 10, 5},\n   168→        {\"with zero\", 0, 5, 5},\n   169→        {\"both zero\", 0, 0, 0},\n   170→    }\n   171→    \n   172→    for _, tt := range tests {\n   173→        t.Run(tt.name, func(t *testing.T) {\n   174→            result := Add(tt.a, tt.b)\n   175→            if result != tt.expected {\n   176→                t.Errorf(\"Add(%d, %d) = %d; want %d\", \n   177→                    tt.a, tt.b, result, tt.expected)\n   178→            }\n   179→        })\n   180→    }\n   181→}\n   182→\n   183→// Table-driven tests with errors\n   184→func TestDivide(t *testing.T) {\n   185→    tests := []struct {\n   186→        name      string\n   187→        dividend  float64\n   188→        divisor   float64\n   189→        want      float64\n   190→        wantErr   bool\n   191→        errString string\n   192→    }{\n   193→        {\n   194→            name:     \"normal division\",\n   195→            dividend: 10,\n   196→            divisor:  2,\n   197→            want:     5,\n   198→            wantErr:  false,\n   199→        },\n   200→        {\n   201→            name:      \"divide by zero\",\n   202→            dividend:  10,\n   203→            divisor:   0,\n   204→            want:      0,\n   205→            wantErr:   true,\n   206→            errString: \"division by zero\",\n   207→        },\n   208→        {\n   209→            name:     \"negative division\",\n   210→            dividend: -10,\n   211→            divisor:  2,\n   212→            want:     -5,\n   213→            wantErr:  false,\n   214→        },\n   215→    }\n   216→    \n   217→    for _, tt := range tests {\n   218→        t.Run(tt.name, func(t *testing.T) {\n   219→            got, err := Divide(tt.dividend, tt.divisor)\n   220→            \n   221→            if (err != nil) != tt.wantErr {\n   222→                t.Errorf(\"Divide() error = %v, wantErr %v\", err, tt.wantErr)\n   223→                return\n   224→            }\n   225→            \n   226→            if tt.wantErr && err.Error() != tt.errString {\n   227→                t.Errorf(\"Divide() error = %q, want %q\", err.Error(), tt.errString)\n   228→                return\n   229→            }\n   230→            \n   231→            if got != tt.want {\n   232→                t.Errorf(\"Divide() = %v, want %v\", got, tt.want)\n   233→            }\n   234→        })\n   235→    }\n   236→}\n   237→\n   238→// Complex table-driven tests\n   239→func TestParser(t *testing.T) {\n   240→    tests := []struct {\n   241→        name    string\n   242→        input   string\n   243→        setup   func()\n   244→        cleanup func()\n   245→        want    *Result\n   246→        wantErr bool\n   247→        check   func(t *testing.T, got *Result)\n   248→    }{\n   249→        {\n   250→            name:  \"valid JSON\",\n   251→            input: `{\"key\": \"value\"}`,\n   252→            want: &Result{\n   253→                Type: \"object\",\n   254→                Data: map[string]interface{}{\"key\": \"value\"},\n   255→            },\n   256→        },\n   257→        {\n   258→            name:  \"complex validation\",\n   259→            input: `{\"items\": [1, 2, 3]}`,\n   260→            check: func(t *testing.T, got *Result) {\n   261→                if got.Type != \"object\" {\n   262→                    t.Errorf(\"wrong type: %s\", got.Type)\n   263→                }\n   264→                items, ok := got.Data.(map[string]interface{})[\"items\"].([]interface{})\n   265→                if !ok || len(items) != 3 {\n   266→                    t.Error(\"expected 3 items\")\n   267→                }\n   268→            },\n   269→        },\n   270→        {\n   271→            name: \"with setup\",\n   272→            input: \"special\",\n   273→            setup: func() {\n   274→                // Prepare test environment\n   275→                os.Setenv(\"TEST_MODE\", \"special\")\n   276→            },\n   277→            cleanup: func() {\n   278→                os.Unsetenv(\"TEST_MODE\")\n   279→            },\n   280→            want: &Result{Type: \"special\"},\n   281→        },\n   282→    }\n   283→    \n   284→    for _, tt := range tests {\n   285→        t.Run(tt.name, func(t *testing.T) {\n   286→            if tt.setup != nil {\n   287→                tt.setup()\n   288→            }\n   289→            if tt.cleanup != nil {\n   290→                defer tt.cleanup()\n   291→            }\n   292→            \n   293→            got, err := Parse(tt.input)\n   294→            \n   295→            if (err != nil) != tt.wantErr {\n   296→                t.Errorf(\"Parse() error = %v, wantErr %v\", err, tt.wantErr)\n   297→                return\n   298→            }\n   299→            \n   300→            if tt.check != nil {\n   301→                tt.check(t, got)\n   302→            } else if !reflect.DeepEqual(got, tt.want) {\n   303→                t.Errorf(\"Parse() = %v, want %v\", got, tt.want)\n   304→            }\n   305→        })\n   306→    }\n   307→}\n   308→```\n   309→\n   310→## Subtests\n   311→\n   312→### Using Subtests\n   313→```go\n   314→func TestFeature(t *testing.T) {\n   315→    // Setup shared by all subtests\n   316→    db := setupTestDB(t)\n   317→    defer db.Close()\n   318→    \n   319→    t.Run(\"Create\", func(t *testing.T) {\n   320→        // Can run in parallel with other subtests\n   321→        t.Parallel()\n   322→        \n   323→        err := db.Create(&User{Name: \"Alice\"})\n   324→        if err != nil {\n   325→            t.Errorf(\"failed to create user: %v\", err)\n   326→        }\n   327→    })\n   328→    \n   329→    t.Run(\"Read\", func(t *testing.T) {\n   330→        t.Parallel()\n   331→        \n   332→        user, err := db.Read(1)\n   333→        if err != nil {\n   334→            t.Errorf(\"failed to read user: %v\", err)\n   335→        }\n   336→        if user.Name != \"Alice\" {\n   337→            t.Errorf(\"wrong name: got %q, want %q\", user.Name, \"Alice\")\n   338→        }\n   339→    })\n   340→    \n   341→    t.Run(\"Update\", func(t *testing.T) {\n   342→        t.Parallel()\n   343→        \n   344→        err := db.Update(1, &User{Name: \"Bob\"})\n   345→        if err != nil {\n   346→            t.Errorf(\"failed to update user: %v\", err)\n   347→        }\n   348→    })\n   349→    \n   350→    t.Run(\"Delete\", func(t *testing.T) {\n   351→        t.Parallel()\n   352→        \n   353→        err := db.Delete(1)\n   354→        if err != nil {\n   355→            t.Errorf(\"failed to delete user: %v\", err)\n   356→        }\n   357→    })\n   358→}\n   359→\n   360→// Nested subtests\n   361→func TestComplexFeature(t *testing.T) {\n   362→    t.Run(\"Component1\", func(t *testing.T) {\n   363→        t.Run(\"Subcomponent1\", func(t *testing.T) {\n   364→            // Test specific functionality\n   365→        })\n   366→        \n   367→        t.Run(\"Subcomponent2\", func(t *testing.T) {\n   368→            // Test specific functionality\n   369→        })\n   370→    })\n   371→    \n   372→    t.Run(\"Component2\", func(t *testing.T) {\n   373→        t.Run(\"Subcomponent1\", func(t *testing.T) {\n   374→            // Test specific functionality\n   375→        })\n   376→    })\n   377→}\n   378→\n   379→// Dynamic subtests\n   380→func TestDynamicSubtests(t *testing.T) {\n   381→    scenarios := loadTestScenarios()\n   382→    \n   383→    for _, scenario := range scenarios {\n   384→        scenario := scenario // Capture range variable\n   385→        t.Run(scenario.Name, func(t *testing.T) {\n   386→            t.Parallel()\n   387→            \n   388→            result := ProcessScenario(scenario)\n   389→            if !result.Success {\n   390→                t.Errorf(\"scenario %q failed: %v\", scenario.Name, result.Error)\n   391→            }\n   392→        })\n   393→    }\n   394→}\n   395→```\n   396→\n   397→## Mocks and Stubs\n   398→\n   399→### Manual Mocks\n   400→```go\n   401→// Interface to mock\n   402→type DataStore interface {\n   403→    Get(key string) (string, error)\n   404→    Set(key, value string) error\n   405→}\n   406→\n   407→// Mock implementation\n   408→type MockDataStore struct {\n   409→    data      map[string]string\n   410→    getCalls  []string\n   411→    setCalls  []struct{ key, value string }\n   412→    getError  error\n   413→    setError  error\n   414→}\n   415→\n   416→func NewMockDataStore() *MockDataStore {\n   417→    return &MockDataStore{\n   418→        data: make(map[string]string),\n   419→    }\n   420→}\n   421→\n   422→func (m *MockDataStore) Get(key string) (string, error) {\n   423→    m.getCalls = append(m.getCalls, key)\n   424→    if m.getError != nil {\n   425→        return \"\", m.getError\n   426→    }\n   427→    return m.data[key], nil\n   428→}\n   429→\n   430→func (m *MockDataStore) Set(key, value string) error {\n   431→    m.setCalls = append(m.setCalls, struct{ key, value string }{key, value})\n   432→    if m.setError != nil {\n   433→        return m.setError\n   434→    }\n   435→    m.data[key] = value\n   436→    return nil\n   437→}\n   438→\n   439→// Using the mock in tests\n   440→func TestService(t *testing.T) {\n   441→    mock := NewMockDataStore()\n   442→    mock.data[\"key1\"] = \"value1\"\n   443→    \n   444→    service := NewService(mock)\n   445→    \n   446→    result, err := service.Process(\"key1\")\n   447→    if err != nil {\n   448→        t.Fatalf(\"unexpected error: %v\", err)\n   449→    }\n   450→    \n   451→    if result != \"processed: value1\" {\n   452→        t.Errorf(\"got %q, want %q\", result, \"processed: value1\")\n   453→    }\n   454→    \n   455→    // Verify mock was called correctly\n   456→    if len(mock.getCalls) != 1 || mock.getCalls[0] != \"key1\" {\n   457→        t.Errorf(\"unexpected Get calls: %v\", mock.getCalls)\n   458→    }\n   459→}\n   460→\n   461→// Stub with configurable behavior\n   462→type StubHTTPClient struct {\n   463→    responses map[string]*http.Response\n   464→    errors    map[string]error\n   465→}\n   466→\n   467→func (s *StubHTTPClient) Do(req *http.Request) (*http.Response, error) {\n   468→    key := req.Method + \" \" + req.URL.String()\n   469→    \n   470→    if err, ok := s.errors[key]; ok {\n   471→        return nil, err\n   472→    }\n   473→    \n   474→    if resp, ok := s.responses[key]; ok {\n   475→        return resp, nil\n   476→    }\n   477→    \n   478→    return &http.Response{\n   479→        StatusCode: 404,\n   480→        Body:       io.NopCloser(strings.NewReader(\"Not Found\")),\n   481→    }, nil\n   482→}\n   483→```\n   484→\n   485→### Using testify/mock\n   486→```go\n   487→import (\n   488→    \"github.com/stretchr/testify/mock\"\n   489→    \"github.com/stretchr/testify/assert\"\n   490→)\n   491→\n   492→// Mock using testify\n   493→type MockRepository struct {\n   494→    mock.Mock\n   495→}\n   496→\n   497→func (m *MockRepository) GetUser(id int) (*User, error) {\n   498→    args := m.Called(id)\n   499→    if args.Get(0) == nil {\n   500→        return nil, args.Error(1)\n   501→    }\n   502→    return args.Get(0).(*User), args.Error(1)\n   503→}\n   504→\n   505→func (m *MockRepository) SaveUser(user *User) error {\n   506→    args := m.Called(user)\n   507→    return args.Error(0)\n   508→}\n   509→\n   510→func TestUserService(t *testing.T) {\n   511→    // Create mock\n   512→    mockRepo := new(MockRepository)\n   513→    \n   514→    // Set expectations\n   515→    mockRepo.On(\"GetUser\", 1).Return(&User{ID: 1, Name: \"Alice\"}, nil)\n   516→    mockRepo.On(\"SaveUser\", mock.Anything).Return(nil)\n   517→    \n   518→    // Create service with mock\n   519→    service := NewUserService(mockRepo)\n   520→    \n   521→    // Test\n   522→    user, err := service.GetUser(1)\n   523→    assert.NoError(t, err)\n   524→    assert.Equal(t, \"Alice\", user.Name)\n   525→    \n   526→    // Verify expectations were met\n   527→    mockRepo.AssertExpectations(t)\n   528→}\n   529→\n   530→// Advanced mocking\n   531→func TestComplexInteraction(t *testing.T) {\n   532→    mockRepo := new(MockRepository)\n   533→    \n   534→    // Match specific arguments\n   535→    mockRepo.On(\"GetUser\", mock.MatchedBy(func(id int) bool {\n   536→        return id > 0\n   537→    })).Return(&User{}, nil)\n   538→    \n   539→    // Return different values on successive calls\n   540→    mockRepo.On(\"SaveUser\", mock.Anything).\n   541→        Return(errors.New(\"first error\")).Once()\n   542→    mockRepo.On(\"SaveUser\", mock.Anything).\n   543→        Return(nil).Once()\n   544→    \n   545→    // Run function when called\n   546→    mockRepo.On(\"GetUser\", 2).\n   547→        Run(func(args mock.Arguments) {\n   548→            id := args.Get(0).(int)\n   549→            t.Logf(\"GetUser called with id: %d\", id)\n   550→        }).\n   551→        Return(&User{ID: 2}, nil)\n   552→}\n   553→```\n   554→\n   555→### Using gomock\n   556→```go\n   557→//go:generate mockgen -source=interface.go -destination=mocks/mock_interface.go\n   558→\n   559→import (\n   560→    \"github.com/golang/mock/gomock\"\n   561→    \"myproject/mocks\"\n   562→)\n   563→\n   564→func TestWithGoMock(t *testing.T) {\n   565→    ctrl := gomock.NewController(t)\n   566→    defer ctrl.Finish()\n   567→    \n   568→    mockStore := mocks.NewMockDataStore(ctrl)\n   569→    \n   570→    // Set expectations\n   571→    mockStore.EXPECT().\n   572→        Get(\"key1\").\n   573→        Return(\"value1\", nil).\n   574→        Times(1)\n   575→    \n   576→    mockStore.EXPECT().\n   577→        Set(\"key2\", \"value2\").\n   578→        Return(nil).\n   579→        AnyTimes()\n   580→    \n   581→    // Ordered expectations\n   582→    gomock.InOrder(\n   583→        mockStore.EXPECT().Get(\"first\"),\n   584→        mockStore.EXPECT().Get(\"second\"),\n   585→        mockStore.EXPECT().Get(\"third\"),\n   586→    )\n   587→    \n   588→    // Use mock in test\n   589→    service := NewService(mockStore)\n   590→    result := service.Process()\n   591→    \n   592→    assert.Equal(t, \"expected\", result)\n   593→}\n   594→```\n   595→\n   596→## Fuzz Testing\n   597→\n   598→### Basic Fuzzing\n   599→```go\n   600→// Fuzz test (Go 1.18+)\n   601→func FuzzReverse(f *testing.F) {\n   602→    // Add seed corpus\n   603→    f.Add(\"hello\")\n   604→    f.Add(\"world\")\n   605→    f.Add(\"12345\")\n   606→    f.Add(\"\")\n   607→    f.Add(\"a\")\n   608→    \n   609→    // Fuzz target\n   610→    f.Fuzz(func(t *testing.T, input string) {\n   611→        reversed := Reverse(input)\n   612→        doubleReversed := Reverse(reversed)\n   613→        \n   614→        // Property: reversing twice should give original\n   615→        if input != doubleReversed {\n   616→            t.Errorf(\"double reverse failed: input=%q, got=%q\", \n   617→                input, doubleReversed)\n   618→        }\n   619→        \n   620→        // Property: length should be same\n   621→        if len(input) != len(reversed) {\n   622→            t.Errorf(\"length mismatch: input=%d, reversed=%d\", \n   623→                len(input), len(reversed))\n   624→        }\n   625→    })\n   626→}\n   627→\n   628→// Fuzz with multiple inputs\n   629→func FuzzAdd(f *testing.F) {\n   630→    // Seed corpus\n   631→    f.Add(int8(1), int8(2))\n   632→    f.Add(int8(127), int8(1))\n   633→    f.Add(int8(-128), int8(-1))\n   634→    \n   635→    f.Fuzz(func(t *testing.T, a, b int8) {\n   636→        result := Add(a, b)\n   637→        \n   638→        // Check for overflow\n   639→        if a > 0 && b > 0 && result < 0 {\n   640→            t.Skip(\"overflow detected\")\n   641→        }\n   642→        if a < 0 && b < 0 && result > 0 {\n   643→            t.Skip(\"underflow detected\")\n   644→        }\n   645→        \n   646→        // Property: addition is commutative\n   647→        if Add(a, b) != Add(b, a) {\n   648→            t.Errorf(\"not commutative: Add(%d,%d) != Add(%d,%d)\", \n   649→                a, b, b, a)\n   650→        }\n   651→    })\n   652→}\n   653→\n   654→// Complex fuzzing\n   655→func FuzzJSONParser(f *testing.F) {\n   656→    // Add valid JSON seeds\n   657→    f.Add(`{\"key\": \"value\"}`)\n   658→    f.Add(`[1, 2, 3]`)\n   659→    f.Add(`null`)\n   660→    f.Add(`true`)\n   661→    f.Add(`123.45`)\n   662→    f.Add(`\"string\"`)\n   663→    \n   664→    f.Fuzz(func(t *testing.T, input string) {\n   665→        parsed, err := ParseJSON(input)\n   666→        if err != nil {\n   667→            // Invalid JSON is expected sometimes\n   668→            return\n   669→        }\n   670→        \n   671→        // If parsing succeeded, marshaling should work\n   672→        marshaled, err := json.Marshal(parsed)\n   673→        if err != nil {\n   674→            t.Fatalf(\"failed to marshal parsed JSON: %v\", err)\n   675→        }\n   676→        \n   677→        // Parse again and compare\n   678→        var reparsed interface{}\n   679→        if err := json.Unmarshal(marshaled, &reparsed); err != nil {\n   680→            t.Fatalf(\"failed to unmarshal: %v\", err)\n   681→        }\n   682→        \n   683→        if !reflect.DeepEqual(parsed, reparsed) {\n   684→            t.Errorf(\"roundtrip failed: %v != %v\", parsed, reparsed)\n   685→        }\n   686→    })\n   687→}\n   688→```\n   689→\n   690→## Benchmarks\n   691→\n   692→### Basic Benchmarks\n   693→```go\n   694→func BenchmarkAdd(b *testing.B) {\n   695→    for i := 0; i < b.N; i++ {\n   696→        Add(2, 3)\n   697→    }\n   698→}\n   699→\n   700→// Benchmark with setup\n   701→func BenchmarkComplexOperation(b *testing.B) {\n   702→    // Setup is not counted in benchmark time\n   703→    data := generateTestData()\n   704→    \n   705→    b.ResetTimer() // Reset timer after setup\n   706→    \n   707→    for i := 0; i < b.N; i++ {\n   708→        ProcessData(data)\n   709→    }\n   710→}\n   711→\n   712→// Benchmark with cleanup\n   713→func BenchmarkWithCleanup(b *testing.B) {\n   714→    for i := 0; i < b.N; i++ {\n   715→        b.StopTimer() // Pause timer for cleanup\n   716→        cleanup()\n   717→        b.StartTimer() // Resume timer\n   718→        \n   719→        ExpensiveOperation()\n   720→    }\n   721→}\n   722→\n   723→// Parallel benchmarks\n   724→func BenchmarkParallel(b *testing.B) {\n   725→    b.RunParallel(func(pb *testing.PB) {\n   726→        for pb.Next() {\n   727→            ConcurrentOperation()\n   728→        }\n   729→    })\n   730→}\n   731→\n   732→// Sub-benchmarks\n   733→func BenchmarkSort(b *testing.B) {\n   734→    sizes := []int{10, 100, 1000, 10000}\n   735→    \n   736→    for _, size := range sizes {\n   737→        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n   738→            data := generateData(size)\n   739→            b.ResetTimer()\n   740→            \n   741→            for i := 0; i < b.N; i++ {\n   742→                b.StopTimer()\n   743→                unsorted := make([]int, len(data))\n   744→                copy(unsorted, data)\n   745→                b.StartTimer()\n   746→                \n   747→                Sort(unsorted)\n   748→            }\n   749→        })\n   750→    }\n   751→}\n   752→\n   753→// Memory allocation benchmarks\n   754→func BenchmarkMemory(b *testing.B) {\n   755→    b.ReportAllocs() // Report memory allocations\n   756→    \n   757→    for i := 0; i < b.N; i++ {\n   758→        result := AllocatingFunction()\n   759→        _ = result\n   760→    }\n   761→}\n   762→\n   763→// Custom metrics\n   764→func BenchmarkCustomMetric(b *testing.B) {\n   765→    var totalBytes int64\n   766→    \n   767→    for i := 0; i < b.N; i++ {\n   768→        bytes := ProcessFile(\"test.txt\")\n   769→        totalBytes += bytes\n   770→    }\n   771→    \n   772→    b.SetBytes(totalBytes / int64(b.N)) // Bytes processed per operation\n   773→    b.ReportMetric(float64(totalBytes)/float64(b.N), \"bytes/op\")\n   774→}\n   775→\n   776→// Comparative benchmarks\n   777→func BenchmarkImplementations(b *testing.B) {\n   778→    b.Run(\"Implementation1\", func(b *testing.B) {\n   779→        for i := 0; i < b.N; i++ {\n   780→            Implementation1()\n   781→        }\n   782→    })\n   783→    \n   784→    b.Run(\"Implementation2\", func(b *testing.B) {\n   785→        for i := 0; i < b.N; i++ {\n   786→            Implementation2()\n   787→        }\n   788→    })\n   789→    \n   790→    b.Run(\"Implementation3\", func(b *testing.B) {\n   791→        for i := 0; i < b.N; i++ {\n   792→            Implementation3()\n   793→        }\n   794→    })\n   795→}\n   796→```\n   797→\n   798→## Coverage\n   799→\n   800→### Running Coverage\n   801→```bash\n   802→# Run tests with coverage\n   803→go test -cover\n   804→\n   805→# Generate coverage profile\n   806→go test -coverprofile=coverage.out\n   807→\n   808→# View coverage in browser\n   809→go tool cover -html=coverage.out\n   810→\n   811→# Coverage for specific functions\n   812→go tool cover -func=coverage.out\n   813→\n   814→# Coverage with multiple packages\n   815→go test -coverprofile=coverage.out ./...\n   816→\n   817→# Coverage mode\n   818→go test -covermode=count -coverprofile=coverage.out\n   819→# Modes: set (default), count, atomic\n   820→\n   821→# Exclude files from coverage\n   822→# Use build tags\n   823→//go:build !test\n   824→```\n   825→\n   826→### Coverage in Code\n   827→```go\n   828→// Ensuring coverage\n   829→func TestFullCoverage(t *testing.T) {\n   830→    tests := []struct {\n   831→        name  string\n   832→        input int\n   833→        want  string\n   834→    }{\n   835→        {\"positive\", 1, \"positive\"},\n   836→        {\"negative\", -1, \"negative\"},\n   837→        {\"zero\", 0, \"zero\"}, // Cover all branches\n   838→    }\n   839→    \n   840→    for _, tt := range tests {\n   841→        t.Run(tt.name, func(t *testing.T) {\n   842→            got := Classify(tt.input)\n   843→            if got != tt.want {\n   844→                t.Errorf(\"Classify(%d) = %q, want %q\", \n   845→                    tt.input, got, tt.want)\n   846→            }\n   847→        })\n   848→    }\n   849→}\n   850→\n   851→// Testing error paths for coverage\n   852→func TestErrorPaths(t *testing.T) {\n   853→    // Test success path\n   854→    result, err := RiskyOperation(validInput)\n   855→    if err != nil {\n   856→        t.Fatalf(\"unexpected error: %v\", err)\n   857→    }\n   858→    \n   859→    // Test error path 1\n   860→    _, err = RiskyOperation(invalidInput1)\n   861→    if err == nil {\n   862→        t.Error(\"expected error for invalid input 1\")\n   863→    }\n   864→    \n   865→    // Test error path 2\n   866→    _, err = RiskyOperation(invalidInput2)\n   867→    if err == nil {\n   868→        t.Error(\"expected error for invalid input 2\")\n   869→    }\n   870→}\n   871→```\n   872→\n   873→## Integration Tests\n   874→\n   875→### Database Integration Tests\n   876→```go\n   877→//go:build integration\n   878→\n   879→package db_test\n   880→\n   881→import (\n   882→    \"database/sql\"\n   883→    \"testing\"\n   884→    _ \"github.com/lib/pq\"\n   885→)\n   886→\n   887→func TestDatabaseIntegration(t *testing.T) {\n   888→    if testing.Short() {\n   889→        t.Skip(\"skipping integration test in short mode\")\n   890→    }\n   891→    \n   892→    // Connect to test database\n   893→    db, err := sql.Open(\"postgres\", getTestDatabaseURL())\n   894→    if err != nil {\n   895→        t.Fatalf(\"failed to connect: %v\", err)\n   896→    }\n   897→    defer db.Close()\n   898→    \n   899→    // Run migrations\n   900→    if err := runMigrations(db); err != nil {\n   901→        t.Fatalf(\"failed to run migrations: %v\", err)\n   902→    }\n   903→    \n   904→    // Test repository\n   905→    repo := NewUserRepository(db)\n   906→    \n   907→    t.Run(\"Create\", func(t *testing.T) {\n   908→        user := &User{Name: \"Alice\", Email: \"alice@example.com\"}\n   909→        err := repo.Create(user)\n   910→        if err != nil {\n   911→            t.Fatalf(\"failed to create user: %v\", err)\n   912→        }\n   913→        if user.ID == 0 {\n   914→            t.Error(\"expected user ID to be set\")\n   915→        }\n   916→    })\n   917→    \n   918→    t.Run(\"Transaction\", func(t *testing.T) {\n   919→        tx, err := db.Begin()\n   920→        if err != nil {\n   921→            t.Fatal(err)\n   922→        }\n   923→        defer tx.Rollback()\n   924→        \n   925→        // Operations in transaction\n   926→        repoTx := NewUserRepositoryTx(tx)\n   927→        // ... test operations\n   928→        \n   929→        if err := tx.Commit(); err != nil {\n   930→            t.Fatal(err)\n   931→        }\n   932→    })\n   933→}\n   934→\n   935→// HTTP Integration Tests\n   936→func TestHTTPIntegration(t *testing.T) {\n   937→    // Start test server\n   938→    server := httptest.NewServer(NewRouter())\n   939→    defer server.Close()\n   940→    \n   941→    client := server.Client()\n   942→    \n   943→    t.Run(\"GET /users\", func(t *testing.T) {\n   944→        resp, err := client.Get(server.URL + \"/users\")\n   945→        if err != nil {\n   946→            t.Fatal(err)\n   947→        }\n   948→        defer resp.Body.Close()\n   949→        \n   950→        if resp.StatusCode != http.StatusOK {\n   951→            t.Errorf(\"expected status 200, got %d\", resp.StatusCode)\n   952→        }\n   953→        \n   954→        var users []User\n   955→        if err := json.NewDecoder(resp.Body).Decode(&users); err != nil {\n   956→            t.Fatal(err)\n   957→        }\n   958→    })\n   959→    \n   960→    t.Run(\"POST /users\", func(t *testing.T) {\n   961→        user := User{Name: \"Bob\", Email: \"bob@example.com\"}\n   962→        body, _ := json.Marshal(user)\n   963→        \n   964→        resp, err := client.Post(\n   965→            server.URL+\"/users\",\n   966→            \"application/json\",\n   967→            bytes.NewReader(body),\n   968→        )\n   969→        if err != nil {\n   970→            t.Fatal(err)\n   971→        }\n   972→        defer resp.Body.Close()\n   973→        \n   974→        if resp.StatusCode != http.StatusCreated {\n   975→            t.Errorf(\"expected status 201, got %d\", resp.StatusCode)\n   976→        }\n   977→    })\n   978→}\n   979→```\n   980→\n   981→### Container Integration Tests\n   982→```go\n   983→import (\n   984→    \"github.com/testcontainers/testcontainers-go\"\n   985→    \"github.com/testcontainers/testcontainers-go/wait\"\n   986→)\n   987→\n   988→func TestWithRedis(t *testing.T) {\n   989→    ctx := context.Background()\n   990→    \n   991→    // Start Redis container\n   992→    req := testcontainers.ContainerRequest{\n   993→        Image:        \"redis:latest\",\n   994→        ExposedPorts: []string{\"6379/tcp\"},\n   995→        WaitingFor:   wait.ForLog(\"Ready to accept connections\"),\n   996→    }\n   997→    \n   998→    redis, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n   999→        ContainerRequest: req,\n  1000→        Started:          true,\n  1001→    })\n  1002→    if err != nil {\n  1003→        t.Fatal(err)\n  1004→    }\n  1005→    defer redis.Terminate(ctx)\n  1006→    \n  1007→    // Get connection details\n  1008→    host, err := redis.Host(ctx)\n  1009→    if err != nil {\n  1010→        t.Fatal(err)\n  1011→    }\n  1012→    \n  1013→    port, err := redis.MappedPort(ctx, \"6379\")\n  1014→    if err != nil {\n  1015→        t.Fatal(err)\n  1016→    }\n  1017→    \n  1018→    // Connect to Redis\n  1019→    client := NewRedisClient(host, port.Port())\n  1020→    \n  1021→    // Run tests\n  1022→    t.Run(\"Set and Get\", func(t *testing.T) {\n  1023→        err := client.Set(\"key\", \"value\")\n  1024→        if err != nil {\n  1025→            t.Fatal(err)\n  1026→        }\n  1027→        \n  1028→        val, err := client.Get(\"key\")\n  1029→        if err != nil {\n  1030→            t.Fatal(err)\n  1031→        }\n  1032→        \n  1033→        if val != \"value\" {\n  1034→            t.Errorf(\"got %q, want %q\", val, \"value\")\n  1035→        }\n  1036→    })\n  1037→}\n  1038→```\n  1039→\n  1040→## Test Fixtures and Helpers\n  1041→\n  1042→### Test Fixtures\n  1043→```go\n  1044→// fixtures.go\n  1045→package testutil\n  1046→\n  1047→type Fixtures struct {\n  1048→    Users    []*User\n  1049→    Products []*Product\n  1050→    Orders   []*Order\n  1051→}\n  1052→\n  1053→func LoadFixtures() *Fixtures {\n  1054→    return &Fixtures{\n  1055→        Users: []*User{\n  1056→            {ID: 1, Name: \"Alice\", Email: \"alice@example.com\"},\n  1057→            {ID: 2, Name: \"Bob\", Email: \"bob@example.com\"},\n  1058→        },\n  1059→        Products: []*Product{\n  1060→            {ID: 1, Name: \"Widget\", Price: 9.99},\n  1061→            {ID: 2, Name: \"Gadget\", Price: 19.99},\n  1062→        },\n  1063→        Orders: []*Order{\n  1064→            {ID: 1, UserID: 1, Total: 29.98},\n  1065→        },\n  1066→    }\n  1067→}\n  1068→\n  1069→// Test data builders\n  1070→type UserBuilder struct {\n  1071→    user User\n  1072→}\n  1073→\n  1074→func NewUserBuilder() *UserBuilder {\n  1075→    return &UserBuilder{\n  1076→        user: User{\n  1077→            ID:    1,\n  1078→            Name:  \"Test User\",\n  1079→            Email: \"test@example.com\",\n  1080→        },\n  1081→    }\n  1082→}\n  1083→\n  1084→func (b *UserBuilder) WithName(name string) *UserBuilder {\n  1085→    b.user.Name = name\n  1086→    return b\n  1087→}\n  1088→\n  1089→func (b *UserBuilder) WithEmail(email string) *UserBuilder {\n  1090→    b.user.Email = email\n  1091→    return b\n  1092→}\n  1093→\n  1094→func (b *UserBuilder) Build() *User {\n  1095→    return &b.user\n  1096→}\n  1097→\n  1098→// Usage\n  1099→func TestWithBuilder(t *testing.T) {\n  1100→    user := NewUserBuilder().\n  1101→        WithName(\"Alice\").\n  1102→        WithEmail(\"alice@test.com\").\n  1103→        Build()\n  1104→    \n  1105→    // Test with user...\n  1106→}\n  1107→```\n  1108→\n  1109→### Test Helpers\n  1110→```go\n  1111→// helpers.go\n  1112→package testutil\n  1113→\n  1114→// Test database helper\n  1115→func SetupTestDB(t testing.TB) *sql.DB {\n  1116→    t.Helper()\n  1117→    \n  1118→    db, err := sql.Open(\"sqlite3\", \":memory:\")\n  1119→    if err != nil {\n  1120→        t.Fatal(err)\n  1121→    }\n  1122→    \n  1123→    if err := runMigrations(db); err != nil {\n  1124→        t.Fatal(err)\n  1125→    }\n  1126→    \n  1127→    t.Cleanup(func() {\n  1128→        db.Close()\n  1129→    })\n  1130→    \n  1131→    return db\n  1132→}\n  1133→\n  1134→// Temporary directory helper\n  1135→func TempDir(t testing.TB) string {\n  1136→    t.Helper()\n  1137→    \n  1138→    dir, err := os.MkdirTemp(\"\", \"test\")\n  1139→    if err != nil {\n  1140→        t.Fatal(err)\n  1141→    }\n  1142→    \n  1143→    t.Cleanup(func() {\n  1144→        os.RemoveAll(dir)\n  1145→    })\n  1146→    \n  1147→    return dir\n  1148→}\n  1149→\n  1150→// Assert helpers\n  1151→func AssertEqual(t testing.TB, got, want interface{}) {\n  1152→    t.Helper()\n  1153→    \n  1154→    if !reflect.DeepEqual(got, want) {\n  1155→        t.Errorf(\"got %v, want %v\", got, want)\n  1156→    }\n  1157→}\n  1158→\n  1159→func AssertNoError(t testing.TB, err error) {\n  1160→    t.Helper()\n  1161→    \n  1162→    if err != nil {\n  1163→        t.Fatalf(\"unexpected error: %v\", err)\n  1164→    }\n  1165→}\n  1166→\n  1167→func AssertError(t testing.TB, err error) {\n  1168→    t.Helper()\n  1169→    \n  1170→    if err == nil {\n  1171→        t.Fatal(\"expected error, got nil\")\n  1172→    }\n  1173→}\n  1174→\n  1175→// Golden file helper\n  1176→func GoldenFile(t testing.TB, name string, got []byte) {\n  1177→    t.Helper()\n  1178→    \n  1179→    golden := filepath.Join(\"testdata\", name+\".golden\")\n  1180→    \n  1181→    if *update {\n  1182→        os.WriteFile(golden, got, 0644)\n  1183→        return\n  1184→    }\n  1185→    \n  1186→    want, err := os.ReadFile(golden)\n  1187→    if err != nil {\n  1188→        t.Fatal(err)\n  1189→    }\n  1190→    \n  1191→    if !bytes.Equal(got, want) {\n  1192→        t.Errorf(\"output mismatch for %s\", name)\n  1193→    }\n  1194→}\n  1195→```\n  1196→\n  1197→## Advanced Testing Techniques\n  1198→\n  1199→### Property-Based Testing\n  1200→```go\n  1201→import \"github.com/leanovate/gopter\"\n  1202→\n  1203→func TestPropertyBased(t *testing.T) {\n  1204→    properties := gopter.NewProperties(nil)\n  1205→    \n  1206→    properties.Property(\"reverse twice is identity\", prop.ForAll(\n  1207→        func(s string) bool {\n  1208→            return s == Reverse(Reverse(s))\n  1209→        },\n  1210→        gopter.Gen.String(),\n  1211→    ))\n  1212→    \n  1213→    properties.Property(\"list append preserves length\", prop.ForAll(\n  1214→        func(list []int, item int) bool {\n  1215→            original := len(list)\n  1216→            result := append(list, item)\n  1217→            return len(result) == original+1\n  1218→        },\n  1219→        gopter.Gen.SliceOf(gopter.Gen.Int()),\n  1220→        gopter.Gen.Int(),\n  1221→    ))\n  1222→    \n  1223→    properties.TestingRun(t)\n  1224→}\n  1225→```\n  1226→\n  1227→### Snapshot Testing\n  1228→```go\n  1229→func TestSnapshot(t *testing.T) {\n  1230→    data := generateComplexData()\n  1231→    output := RenderHTML(data)\n  1232→    \n  1233→    snapshot := filepath.Join(\"testdata\", t.Name()+\".snapshot\")\n  1234→    \n  1235→    if *updateSnapshots {\n  1236→        if err := os.WriteFile(snapshot, []byte(output), 0644); err != nil {\n  1237→            t.Fatal(err)\n  1238→        }\n  1239→        return\n  1240→    }\n  1241→    \n  1242→    expected, err := os.ReadFile(snapshot)\n  1243→    if err != nil {\n  1244→        t.Fatal(err)\n  1245→    }\n  1246→    \n  1247→    if output != string(expected) {\n  1248→        t.Error(\"snapshot mismatch\")\n  1249→        // Could use diff library to show differences\n  1250→    }\n  1251→}\n  1252→```\n  1253→\n  1254→### Contract Testing\n  1255→```go\n  1256→// Define contract that implementations must satisfy\n  1257→type StorageContract struct {\n  1258→    t       testing.TB\n  1259→    storage Storage\n  1260→}\n  1261→\n  1262→func (c *StorageContract) TestStore() {\n  1263→    c.t.Helper()\n  1264→    \n  1265→    err := c.storage.Store(\"key\", \"value\")\n  1266→    if err != nil {\n  1267→        c.t.Errorf(\"Store failed: %v\", err)\n  1268→    }\n  1269→    \n  1270→    val, err := c.storage.Retrieve(\"key\")\n  1271→    if err != nil {\n  1272→        c.t.Errorf(\"Retrieve failed: %v\", err)\n  1273→    }\n  1274→    \n  1275→    if val != \"value\" {\n  1276→        c.t.Errorf(\"got %q, want %q\", val, \"value\")\n  1277→    }\n  1278→}\n  1279→\n  1280→func (c *StorageContract) TestDelete() {\n  1281→    c.t.Helper()\n  1282→    \n  1283→    c.storage.Store(\"key\", \"value\")\n  1284→    err := c.storage.Delete(\"key\")\n  1285→    if err != nil {\n  1286→        c.t.Errorf(\"Delete failed: %v\", err)\n  1287→    }\n  1288→    \n  1289→    _, err = c.storage.Retrieve(\"key\")\n  1290→    if err == nil {\n  1291→        c.t.Error(\"expected error after delete\")\n  1292→    }\n  1293→}\n  1294→\n  1295→// Test different implementations\n  1296→func TestMemoryStorage(t *testing.T) {\n  1297→    storage := NewMemoryStorage()\n  1298→    contract := &StorageContract{t: t, storage: storage}\n  1299→    contract.TestStore()\n  1300→    contract.TestDelete()\n  1301→}\n  1302→\n  1303→func TestDiskStorage(t *testing.T) {\n  1304→    storage := NewDiskStorage(t.TempDir())\n  1305→    contract := &StorageContract{t: t, storage: storage}\n  1306→    contract.TestStore()\n  1307→    contract.TestDelete()\n  1308→}\n  1309→```\n  1310→\n  1311→## Best Practices Summary\n  1312→\n  1313→1. **Write table-driven tests** - Comprehensive and maintainable\n  1314→2. **Use subtests** - Better organization and parallel execution\n  1315→3. **Mock external dependencies** - Fast and reliable tests\n  1316→4. **Test edge cases** - Empty inputs, nil values, errors\n  1317→5. **Benchmark critical paths** - Measure performance\n  1318→6. **Aim for high coverage** - But focus on meaningful tests\n  1319→7. **Use t.Helper()** - Better error reporting in test helpers\n  1320→8. **Cleanup with t.Cleanup()** - Guaranteed cleanup\n  1321→9. **Use build tags for integration tests** - Separate slow tests\n  1322→10. **Keep tests deterministic** - No random failures\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"71cab5ef-679e-4a7c-9616-758ed72f9c54","timestamp":"2025-08-13T09:59:22.772Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/testing.md","content":"# Go Testing - Complete Testing Guide\n\n## Table of Contents\n1. [Unit Tests](#unit-tests)\n2. [Table-Driven Tests](#table-driven-tests)\n3. [Subtests](#subtests)\n4. [Mocks and Stubs](#mocks-and-stubs)\n5. [Fuzz Testing](#fuzz-testing)\n6. [Benchmarks](#benchmarks)\n7. [Coverage](#coverage)\n8. [Integration Tests](#integration-tests)\n9. [Test Fixtures and Helpers](#test-fixtures-and-helpers)\n10. [Advanced Testing Techniques](#advanced-testing-techniques)\n\n## Unit Tests\n\n### Basic Test Structure\n```go\n// File: math.go\npackage math\n\nfunc Add(a, b int) int {\n    return a + b\n}\n\n// File: math_test.go\npackage math\n\nimport \"testing\"\n\nfunc TestAdd(t *testing.T) {\n    result := Add(2, 3)\n    expected := 5\n    \n    if result != expected {\n        t.Errorf(\"Add(2, 3) = %d; want %d\", result, expected)\n    }\n}\n\n// Test with multiple assertions\nfunc TestMultipleAssertions(t *testing.T) {\n    // Arrange\n    input := \"test\"\n    \n    // Act\n    result := Process(input)\n    \n    // Assert\n    if result.Status != \"success\" {\n        t.Errorf(\"expected status 'success', got %q\", result.Status)\n    }\n    \n    if len(result.Data) == 0 {\n        t.Error(\"expected non-empty data\")\n    }\n    \n    if result.Timestamp.IsZero() {\n        t.Error(\"expected non-zero timestamp\")\n    }\n}\n\n// Using t.Fatal for critical failures\nfunc TestCriticalFailure(t *testing.T) {\n    db, err := connectDB()\n    if err != nil {\n        t.Fatalf(\"failed to connect to database: %v\", err)\n    }\n    defer db.Close()\n    \n    // Continue with test...\n}\n\n// Using t.Skip for conditional tests\nfunc TestRequiresDocker(t *testing.T) {\n    if !dockerAvailable() {\n        t.Skip(\"skipping test; Docker not available\")\n    }\n    \n    // Docker-dependent test...\n}\n\n// Parallel tests\nfunc TestParallel1(t *testing.T) {\n    t.Parallel() // Run in parallel with other parallel tests\n    // Test implementation...\n}\n\nfunc TestParallel2(t *testing.T) {\n    t.Parallel()\n    // Test implementation...\n}\n```\n\n### Test Organization\n```go\n// Testing exported functions\nfunc TestPublicFunction(t *testing.T) {\n    result := PublicFunction(\"input\")\n    if result != \"expected\" {\n        t.Errorf(\"got %q, want %q\", result, \"expected\")\n    }\n}\n\n// Testing unexported functions (same package)\nfunc TestPrivateFunction(t *testing.T) {\n    result := privateFunction(\"input\")\n    if result != \"expected\" {\n        t.Errorf(\"got %q, want %q\", result, \"expected\")\n    }\n}\n\n// Testing with external package (black-box testing)\npackage math_test\n\nimport (\n    \"testing\"\n    \"myproject/math\"\n)\n\nfunc TestAddExternal(t *testing.T) {\n    result := math.Add(2, 3)\n    if result != 5 {\n        t.Errorf(\"math.Add(2, 3) = %d; want 5\", result)\n    }\n}\n\n// Example tests (show up in documentation)\nfunc ExampleAdd() {\n    result := Add(2, 3)\n    fmt.Println(result)\n    // Output: 5\n}\n\nfunc ExampleAdd_negative() {\n    result := Add(-2, -3)\n    fmt.Println(result)\n    // Output: -5\n}\n\n// Testing main function\nfunc TestMain(m *testing.M) {\n    // Setup before tests\n    setup()\n    \n    // Run tests\n    code := m.Run()\n    \n    // Cleanup after tests\n    teardown()\n    \n    os.Exit(code)\n}\n```\n\n## Table-Driven Tests\n\n### Basic Table-Driven Tests\n```go\nfunc TestAdd(t *testing.T) {\n    tests := []struct {\n        name     string\n        a, b     int\n        expected int\n    }{\n        {\"positive numbers\", 2, 3, 5},\n        {\"negative numbers\", -2, -3, -5},\n        {\"mixed\", -5, 10, 5},\n        {\"with zero\", 0, 5, 5},\n        {\"both zero\", 0, 0, 0},\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            result := Add(tt.a, tt.b)\n            if result != tt.expected {\n                t.Errorf(\"Add(%d, %d) = %d; want %d\", \n                    tt.a, tt.b, result, tt.expected)\n            }\n        })\n    }\n}\n\n// Table-driven tests with errors\nfunc TestDivide(t *testing.T) {\n    tests := []struct {\n        name      string\n        dividend  float64\n        divisor   float64\n        want      float64\n        wantErr   bool\n        errString string\n    }{\n        {\n            name:     \"normal division\",\n            dividend: 10,\n            divisor:  2,\n            want:     5,\n            wantErr:  false,\n        },\n        {\n            name:      \"divide by zero\",\n            dividend:  10,\n            divisor:   0,\n            want:      0,\n            wantErr:   true,\n            errString: \"division by zero\",\n        },\n        {\n            name:     \"negative division\",\n            dividend: -10,\n            divisor:  2,\n            want:     -5,\n            wantErr:  false,\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got, err := Divide(tt.dividend, tt.divisor)\n            \n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Divide() error = %v, wantErr %v\", err, tt.wantErr)\n                return\n            }\n            \n            if tt.wantErr && err.Error() != tt.errString {\n                t.Errorf(\"Divide() error = %q, want %q\", err.Error(), tt.errString)\n                return\n            }\n            \n            if got != tt.want {\n                t.Errorf(\"Divide() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n\n// Complex table-driven tests\nfunc TestParser(t *testing.T) {\n    tests := []struct {\n        name    string\n        input   string\n        setup   func()\n        cleanup func()\n        want    *Result\n        wantErr bool\n        check   func(t *testing.T, got *Result)\n    }{\n        {\n            name:  \"valid JSON\",\n            input: `{\"key\": \"value\"}`,\n            want: &Result{\n                Type: \"object\",\n                Data: map[string]interface{}{\"key\": \"value\"},\n            },\n        },\n        {\n            name:  \"complex validation\",\n            input: `{\"items\": [1, 2, 3]}`,\n            check: func(t *testing.T, got *Result) {\n                if got.Type != \"object\" {\n                    t.Errorf(\"wrong type: %s\", got.Type)\n                }\n                items, ok := got.Data.(map[string]interface{})[\"items\"].([]interface{})\n                if !ok || len(items) != 3 {\n                    t.Error(\"expected 3 items\")\n                }\n            },\n        },\n        {\n            name: \"with setup\",\n            input: \"special\",\n            setup: func() {\n                // Prepare test environment\n                os.Setenv(\"TEST_MODE\", \"special\")\n            },\n            cleanup: func() {\n                os.Unsetenv(\"TEST_MODE\")\n            },\n            want: &Result{Type: \"special\"},\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            if tt.setup != nil {\n                tt.setup()\n            }\n            if tt.cleanup != nil {\n                defer tt.cleanup()\n            }\n            \n            got, err := Parse(tt.input)\n            \n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Parse() error = %v, wantErr %v\", err, tt.wantErr)\n                return\n            }\n            \n            if tt.check != nil {\n                tt.check(t, got)\n            } else if !reflect.DeepEqual(got, tt.want) {\n                t.Errorf(\"Parse() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n```\n\n## Subtests\n\n### Using Subtests\n```go\nfunc TestFeature(t *testing.T) {\n    // Setup shared by all subtests\n    db := setupTestDB(t)\n    defer db.Close()\n    \n    t.Run(\"Create\", func(t *testing.T) {\n        // Can run in parallel with other subtests\n        t.Parallel()\n        \n        err := db.Create(&User{Name: \"Alice\"})\n        if err != nil {\n            t.Errorf(\"failed to create user: %v\", err)\n        }\n    })\n    \n    t.Run(\"Read\", func(t *testing.T) {\n        t.Parallel()\n        \n        user, err := db.Read(1)\n        if err != nil {\n            t.Errorf(\"failed to read user: %v\", err)\n        }\n        if user.Name != \"Alice\" {\n            t.Errorf(\"wrong name: got %q, want %q\", user.Name, \"Alice\")\n        }\n    })\n    \n    t.Run(\"Update\", func(t *testing.T) {\n        t.Parallel()\n        \n        err := db.Update(1, &User{Name: \"Bob\"})\n        if err != nil {\n            t.Errorf(\"failed to update user: %v\", err)\n        }\n    })\n    \n    t.Run(\"Delete\", func(t *testing.T) {\n        t.Parallel()\n        \n        err := db.Delete(1)\n        if err != nil {\n            t.Errorf(\"failed to delete user: %v\", err)\n        }\n    })\n}\n\n// Nested subtests\nfunc TestComplexFeature(t *testing.T) {\n    t.Run(\"Component1\", func(t *testing.T) {\n        t.Run(\"Subcomponent1\", func(t *testing.T) {\n            // Test specific functionality\n        })\n        \n        t.Run(\"Subcomponent2\", func(t *testing.T) {\n            // Test specific functionality\n        })\n    })\n    \n    t.Run(\"Component2\", func(t *testing.T) {\n        t.Run(\"Subcomponent1\", func(t *testing.T) {\n            // Test specific functionality\n        })\n    })\n}\n\n// Dynamic subtests\nfunc TestDynamicSubtests(t *testing.T) {\n    scenarios := loadTestScenarios()\n    \n    for _, scenario := range scenarios {\n        scenario := scenario // Capture range variable\n        t.Run(scenario.Name, func(t *testing.T) {\n            t.Parallel()\n            \n            result := ProcessScenario(scenario)\n            if !result.Success {\n                t.Errorf(\"scenario %q failed: %v\", scenario.Name, result.Error)\n            }\n        })\n    }\n}\n```\n\n## Mocks and Stubs\n\n### Manual Mocks\n```go\n// Interface to mock\ntype DataStore interface {\n    Get(key string) (string, error)\n    Set(key, value string) error\n}\n\n// Mock implementation\ntype MockDataStore struct {\n    data      map[string]string\n    getCalls  []string\n    setCalls  []struct{ key, value string }\n    getError  error\n    setError  error\n}\n\nfunc NewMockDataStore() *MockDataStore {\n    return &MockDataStore{\n        data: make(map[string]string),\n    }\n}\n\nfunc (m *MockDataStore) Get(key string) (string, error) {\n    m.getCalls = append(m.getCalls, key)\n    if m.getError != nil {\n        return \"\", m.getError\n    }\n    return m.data[key], nil\n}\n\nfunc (m *MockDataStore) Set(key, value string) error {\n    m.setCalls = append(m.setCalls, struct{ key, value string }{key, value})\n    if m.setError != nil {\n        return m.setError\n    }\n    m.data[key] = value\n    return nil\n}\n\n// Using the mock in tests\nfunc TestService(t *testing.T) {\n    mock := NewMockDataStore()\n    mock.data[\"key1\"] = \"value1\"\n    \n    service := NewService(mock)\n    \n    result, err := service.Process(\"key1\")\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n    \n    if result != \"processed: value1\" {\n        t.Errorf(\"got %q, want %q\", result, \"processed: value1\")\n    }\n    \n    // Verify mock was called correctly\n    if len(mock.getCalls) != 1 || mock.getCalls[0] != \"key1\" {\n        t.Errorf(\"unexpected Get calls: %v\", mock.getCalls)\n    }\n}\n\n// Stub with configurable behavior\ntype StubHTTPClient struct {\n    responses map[string]*http.Response\n    errors    map[string]error\n}\n\nfunc (s *StubHTTPClient) Do(req *http.Request) (*http.Response, error) {\n    key := req.Method + \" \" + req.URL.String()\n    \n    if err, ok := s.errors[key]; ok {\n        return nil, err\n    }\n    \n    if resp, ok := s.responses[key]; ok {\n        return resp, nil\n    }\n    \n    return &http.Response{\n        StatusCode: 404,\n        Body:       io.NopCloser(strings.NewReader(\"Not Found\")),\n    }, nil\n}\n```\n\n### Using testify/mock\n```go\nimport (\n    \"github.com/stretchr/testify/mock\"\n    \"github.com/stretchr/testify/assert\"\n)\n\n// Mock using testify\ntype MockRepository struct {\n    mock.Mock\n}\n\nfunc (m *MockRepository) GetUser(id int) (*User, error) {\n    args := m.Called(id)\n    if args.Get(0) == nil {\n        return nil, args.Error(1)\n    }\n    return args.Get(0).(*User), args.Error(1)\n}\n\nfunc (m *MockRepository) SaveUser(user *User) error {\n    args := m.Called(user)\n    return args.Error(0)\n}\n\nfunc TestUserService(t *testing.T) {\n    // Create mock\n    mockRepo := new(MockRepository)\n    \n    // Set expectations\n    mockRepo.On(\"GetUser\", 1).Return(&User{ID: 1, Name: \"Alice\"}, nil)\n    mockRepo.On(\"SaveUser\", mock.Anything).Return(nil)\n    \n    // Create service with mock\n    service := NewUserService(mockRepo)\n    \n    // Test\n    user, err := service.GetUser(1)\n    assert.NoError(t, err)\n    assert.Equal(t, \"Alice\", user.Name)\n    \n    // Verify expectations were met\n    mockRepo.AssertExpectations(t)\n}\n\n// Advanced mocking\nfunc TestComplexInteraction(t *testing.T) {\n    mockRepo := new(MockRepository)\n    \n    // Match specific arguments\n    mockRepo.On(\"GetUser\", mock.MatchedBy(func(id int) bool {\n        return id > 0\n    })).Return(&User{}, nil)\n    \n    // Return different values on successive calls\n    mockRepo.On(\"SaveUser\", mock.Anything).\n        Return(errors.New(\"first error\")).Once()\n    mockRepo.On(\"SaveUser\", mock.Anything).\n        Return(nil).Once()\n    \n    // Run function when called\n    mockRepo.On(\"GetUser\", 2).\n        Run(func(args mock.Arguments) {\n            id := args.Get(0).(int)\n            t.Logf(\"GetUser called with id: %d\", id)\n        }).\n        Return(&User{ID: 2}, nil)\n}\n```\n\n### Using gomock\n```go\n//go:generate mockgen -source=interface.go -destination=mocks/mock_interface.go\n\nimport (\n    \"github.com/golang/mock/gomock\"\n    \"myproject/mocks\"\n)\n\nfunc TestWithGoMock(t *testing.T) {\n    ctrl := gomock.NewController(t)\n    defer ctrl.Finish()\n    \n    mockStore := mocks.NewMockDataStore(ctrl)\n    \n    // Set expectations\n    mockStore.EXPECT().\n        Get(\"key1\").\n        Return(\"value1\", nil).\n        Times(1)\n    \n    mockStore.EXPECT().\n        Set(\"key2\", \"value2\").\n        Return(nil).\n        AnyTimes()\n    \n    // Ordered expectations\n    gomock.InOrder(\n        mockStore.EXPECT().Get(\"first\"),\n        mockStore.EXPECT().Get(\"second\"),\n        mockStore.EXPECT().Get(\"third\"),\n    )\n    \n    // Use mock in test\n    service := NewService(mockStore)\n    result := service.Process()\n    \n    assert.Equal(t, \"expected\", result)\n}\n```\n\n## Fuzz Testing\n\n### Basic Fuzzing\n```go\n// Fuzz test (Go 1.18+)\nfunc FuzzReverse(f *testing.F) {\n    // Add seed corpus\n    f.Add(\"hello\")\n    f.Add(\"world\")\n    f.Add(\"12345\")\n    f.Add(\"\")\n    f.Add(\"a\")\n    \n    // Fuzz target\n    f.Fuzz(func(t *testing.T, input string) {\n        reversed := Reverse(input)\n        doubleReversed := Reverse(reversed)\n        \n        // Property: reversing twice should give original\n        if input != doubleReversed {\n            t.Errorf(\"double reverse failed: input=%q, got=%q\", \n                input, doubleReversed)\n        }\n        \n        // Property: length should be same\n        if len(input) != len(reversed) {\n            t.Errorf(\"length mismatch: input=%d, reversed=%d\", \n                len(input), len(reversed))\n        }\n    })\n}\n\n// Fuzz with multiple inputs\nfunc FuzzAdd(f *testing.F) {\n    // Seed corpus\n    f.Add(int8(1), int8(2))\n    f.Add(int8(127), int8(1))\n    f.Add(int8(-128), int8(-1))\n    \n    f.Fuzz(func(t *testing.T, a, b int8) {\n        result := Add(a, b)\n        \n        // Check for overflow\n        if a > 0 && b > 0 && result < 0 {\n            t.Skip(\"overflow detected\")\n        }\n        if a < 0 && b < 0 && result > 0 {\n            t.Skip(\"underflow detected\")\n        }\n        \n        // Property: addition is commutative\n        if Add(a, b) != Add(b, a) {\n            t.Errorf(\"not commutative: Add(%d,%d) != Add(%d,%d)\", \n                a, b, b, a)\n        }\n    })\n}\n\n// Complex fuzzing\nfunc FuzzJSONParser(f *testing.F) {\n    // Add valid JSON seeds\n    f.Add(`{\"key\": \"value\"}`)\n    f.Add(`[1, 2, 3]`)\n    f.Add(`null`)\n    f.Add(`true`)\n    f.Add(`123.45`)\n    f.Add(`\"string\"`)\n    \n    f.Fuzz(func(t *testing.T, input string) {\n        parsed, err := ParseJSON(input)\n        if err != nil {\n            // Invalid JSON is expected sometimes\n            return\n        }\n        \n        // If parsing succeeded, marshaling should work\n        marshaled, err := json.Marshal(parsed)\n        if err != nil {\n            t.Fatalf(\"failed to marshal parsed JSON: %v\", err)\n        }\n        \n        // Parse again and compare\n        var reparsed interface{}\n        if err := json.Unmarshal(marshaled, &reparsed); err != nil {\n            t.Fatalf(\"failed to unmarshal: %v\", err)\n        }\n        \n        if !reflect.DeepEqual(parsed, reparsed) {\n            t.Errorf(\"roundtrip failed: %v != %v\", parsed, reparsed)\n        }\n    })\n}\n```\n\n## Benchmarks\n\n### Basic Benchmarks\n```go\nfunc BenchmarkAdd(b *testing.B) {\n    for i := 0; i < b.N; i++ {\n        Add(2, 3)\n    }\n}\n\n// Benchmark with setup\nfunc BenchmarkComplexOperation(b *testing.B) {\n    // Setup is not counted in benchmark time\n    data := generateTestData()\n    \n    b.ResetTimer() // Reset timer after setup\n    \n    for i := 0; i < b.N; i++ {\n        ProcessData(data)\n    }\n}\n\n// Benchmark with cleanup\nfunc BenchmarkWithCleanup(b *testing.B) {\n    for i := 0; i < b.N; i++ {\n        b.StopTimer() // Pause timer for cleanup\n        cleanup()\n        b.StartTimer() // Resume timer\n        \n        ExpensiveOperation()\n    }\n}\n\n// Parallel benchmarks\nfunc BenchmarkParallel(b *testing.B) {\n    b.RunParallel(func(pb *testing.PB) {\n        for pb.Next() {\n            ConcurrentOperation()\n        }\n    })\n}\n\n// Sub-benchmarks\nfunc BenchmarkSort(b *testing.B) {\n    sizes := []int{10, 100, 1000, 10000}\n    \n    for _, size := range sizes {\n        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n            data := generateData(size)\n            b.ResetTimer()\n            \n            for i := 0; i < b.N; i++ {\n                b.StopTimer()\n                unsorted := make([]int, len(data))\n                copy(unsorted, data)\n                b.StartTimer()\n                \n                Sort(unsorted)\n            }\n        })\n    }\n}\n\n// Memory allocation benchmarks\nfunc BenchmarkMemory(b *testing.B) {\n    b.ReportAllocs() // Report memory allocations\n    \n    for i := 0; i < b.N; i++ {\n        result := AllocatingFunction()\n        _ = result\n    }\n}\n\n// Custom metrics\nfunc BenchmarkCustomMetric(b *testing.B) {\n    var totalBytes int64\n    \n    for i := 0; i < b.N; i++ {\n        bytes := ProcessFile(\"test.txt\")\n        totalBytes += bytes\n    }\n    \n    b.SetBytes(totalBytes / int64(b.N)) // Bytes processed per operation\n    b.ReportMetric(float64(totalBytes)/float64(b.N), \"bytes/op\")\n}\n\n// Comparative benchmarks\nfunc BenchmarkImplementations(b *testing.B) {\n    b.Run(\"Implementation1\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            Implementation1()\n        }\n    })\n    \n    b.Run(\"Implementation2\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            Implementation2()\n        }\n    })\n    \n    b.Run(\"Implementation3\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            Implementation3()\n        }\n    })\n}\n```\n\n## Coverage\n\n### Running Coverage\n```bash\n# Run tests with coverage\ngo test -cover\n\n# Generate coverage profile\ngo test -coverprofile=coverage.out\n\n# View coverage in browser\ngo tool cover -html=coverage.out\n\n# Coverage for specific functions\ngo tool cover -func=coverage.out\n\n# Coverage with multiple packages\ngo test -coverprofile=coverage.out ./...\n\n# Coverage mode\ngo test -covermode=count -coverprofile=coverage.out\n# Modes: set (default), count, atomic\n\n# Exclude files from coverage\n# Use build tags\n//go:build !test\n```\n\n### Coverage in Code\n```go\n// Ensuring coverage\nfunc TestFullCoverage(t *testing.T) {\n    tests := []struct {\n        name  string\n        input int\n        want  string\n    }{\n        {\"positive\", 1, \"positive\"},\n        {\"negative\", -1, \"negative\"},\n        {\"zero\", 0, \"zero\"}, // Cover all branches\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := Classify(tt.input)\n            if got != tt.want {\n                t.Errorf(\"Classify(%d) = %q, want %q\", \n                    tt.input, got, tt.want)\n            }\n        })\n    }\n}\n\n// Testing error paths for coverage\nfunc TestErrorPaths(t *testing.T) {\n    // Test success path\n    result, err := RiskyOperation(validInput)\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n    \n    // Test error path 1\n    _, err = RiskyOperation(invalidInput1)\n    if err == nil {\n        t.Error(\"expected error for invalid input 1\")\n    }\n    \n    // Test error path 2\n    _, err = RiskyOperation(invalidInput2)\n    if err == nil {\n        t.Error(\"expected error for invalid input 2\")\n    }\n}\n```\n\n## Integration Tests\n\n### Database Integration Tests\n```go\n//go:build integration\n\npackage db_test\n\nimport (\n    \"database/sql\"\n    \"testing\"\n    _ \"github.com/lib/pq\"\n)\n\nfunc TestDatabaseIntegration(t *testing.T) {\n    if testing.Short() {\n        t.Skip(\"skipping integration test in short mode\")\n    }\n    \n    // Connect to test database\n    db, err := sql.Open(\"postgres\", getTestDatabaseURL())\n    if err != nil {\n        t.Fatalf(\"failed to connect: %v\", err)\n    }\n    defer db.Close()\n    \n    // Run migrations\n    if err := runMigrations(db); err != nil {\n        t.Fatalf(\"failed to run migrations: %v\", err)\n    }\n    \n    // Test repository\n    repo := NewUserRepository(db)\n    \n    t.Run(\"Create\", func(t *testing.T) {\n        user := &User{Name: \"Alice\", Email: \"alice@example.com\"}\n        err := repo.Create(user)\n        if err != nil {\n            t.Fatalf(\"failed to create user: %v\", err)\n        }\n        if user.ID == 0 {\n            t.Error(\"expected user ID to be set\")\n        }\n    })\n    \n    t.Run(\"Transaction\", func(t *testing.T) {\n        tx, err := db.Begin()\n        if err != nil {\n            t.Fatal(err)\n        }\n        defer tx.Rollback()\n        \n        // Operations in transaction\n        repoTx := NewUserRepositoryTx(tx)\n        // ... test operations\n        \n        if err := tx.Commit(); err != nil {\n            t.Fatal(err)\n        }\n    })\n}\n\n// HTTP Integration Tests\nfunc TestHTTPIntegration(t *testing.T) {\n    // Start test server\n    server := httptest.NewServer(NewRouter())\n    defer server.Close()\n    \n    client := server.Client()\n    \n    t.Run(\"GET /users\", func(t *testing.T) {\n        resp, err := client.Get(server.URL + \"/users\")\n        if err != nil {\n            t.Fatal(err)\n        }\n        defer resp.Body.Close()\n        \n        if resp.StatusCode != http.StatusOK {\n            t.Errorf(\"expected status 200, got %d\", resp.StatusCode)\n        }\n        \n        var users []User\n        if err := json.NewDecoder(resp.Body).Decode(&users); err != nil {\n            t.Fatal(err)\n        }\n    })\n    \n    t.Run(\"POST /users\", func(t *testing.T) {\n        user := User{Name: \"Bob\", Email: \"bob@example.com\"}\n        body, _ := json.Marshal(user)\n        \n        resp, err := client.Post(\n            server.URL+\"/users\",\n            \"application/json\",\n            bytes.NewReader(body),\n        )\n        if err != nil {\n            t.Fatal(err)\n        }\n        defer resp.Body.Close()\n        \n        if resp.StatusCode != http.StatusCreated {\n            t.Errorf(\"expected status 201, got %d\", resp.StatusCode)\n        }\n    })\n}\n```\n\n### Container Integration Tests\n```go\nimport (\n    \"github.com/testcontainers/testcontainers-go\"\n    \"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nfunc TestWithRedis(t *testing.T) {\n    ctx := context.Background()\n    \n    // Start Redis container\n    req := testcontainers.ContainerRequest{\n        Image:        \"redis:latest\",\n        ExposedPorts: []string{\"6379/tcp\"},\n        WaitingFor:   wait.ForLog(\"Ready to accept connections\"),\n    }\n    \n    redis, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n        ContainerRequest: req,\n        Started:          true,\n    })\n    if err != nil {\n        t.Fatal(err)\n    }\n    defer redis.Terminate(ctx)\n    \n    // Get connection details\n    host, err := redis.Host(ctx)\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    port, err := redis.MappedPort(ctx, \"6379\")\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    // Connect to Redis\n    client := NewRedisClient(host, port.Port())\n    \n    // Run tests\n    t.Run(\"Set and Get\", func(t *testing.T) {\n        err := client.Set(\"key\", \"value\")\n        if err != nil {\n            t.Fatal(err)\n        }\n        \n        val, err := client.Get(\"key\")\n        if err != nil {\n            t.Fatal(err)\n        }\n        \n        if val != \"value\" {\n            t.Errorf(\"got %q, want %q\", val, \"value\")\n        }\n    })\n}\n```\n\n## Test Fixtures and Helpers\n\n### Test Fixtures\n```go\n// fixtures.go\npackage testutil\n\ntype Fixtures struct {\n    Users    []*User\n    Products []*Product\n    Orders   []*Order\n}\n\nfunc LoadFixtures() *Fixtures {\n    return &Fixtures{\n        Users: []*User{\n            {ID: 1, Name: \"Alice\", Email: \"alice@example.com\"},\n            {ID: 2, Name: \"Bob\", Email: \"bob@example.com\"},\n        },\n        Products: []*Product{\n            {ID: 1, Name: \"Widget\", Price: 9.99},\n            {ID: 2, Name: \"Gadget\", Price: 19.99},\n        },\n        Orders: []*Order{\n            {ID: 1, UserID: 1, Total: 29.98},\n        },\n    }\n}\n\n// Test data builders\ntype UserBuilder struct {\n    user User\n}\n\nfunc NewUserBuilder() *UserBuilder {\n    return &UserBuilder{\n        user: User{\n            ID:    1,\n            Name:  \"Test User\",\n            Email: \"test@example.com\",\n        },\n    }\n}\n\nfunc (b *UserBuilder) WithName(name string) *UserBuilder {\n    b.user.Name = name\n    return b\n}\n\nfunc (b *UserBuilder) WithEmail(email string) *UserBuilder {\n    b.user.Email = email\n    return b\n}\n\nfunc (b *UserBuilder) Build() *User {\n    return &b.user\n}\n\n// Usage\nfunc TestWithBuilder(t *testing.T) {\n    user := NewUserBuilder().\n        WithName(\"Alice\").\n        WithEmail(\"alice@test.com\").\n        Build()\n    \n    // Test with user...\n}\n```\n\n### Test Helpers\n```go\n// helpers.go\npackage testutil\n\n// Test database helper\nfunc SetupTestDB(t testing.TB) *sql.DB {\n    t.Helper()\n    \n    db, err := sql.Open(\"sqlite3\", \":memory:\")\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    if err := runMigrations(db); err != nil {\n        t.Fatal(err)\n    }\n    \n    t.Cleanup(func() {\n        db.Close()\n    })\n    \n    return db\n}\n\n// Temporary directory helper\nfunc TempDir(t testing.TB) string {\n    t.Helper()\n    \n    dir, err := os.MkdirTemp(\"\", \"test\")\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    t.Cleanup(func() {\n        os.RemoveAll(dir)\n    })\n    \n    return dir\n}\n\n// Assert helpers\nfunc AssertEqual(t testing.TB, got, want interface{}) {\n    t.Helper()\n    \n    if !reflect.DeepEqual(got, want) {\n        t.Errorf(\"got %v, want %v\", got, want)\n    }\n}\n\nfunc AssertNoError(t testing.TB, err error) {\n    t.Helper()\n    \n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n}\n\nfunc AssertError(t testing.TB, err error) {\n    t.Helper()\n    \n    if err == nil {\n        t.Fatal(\"expected error, got nil\")\n    }\n}\n\n// Golden file helper\nfunc GoldenFile(t testing.TB, name string, got []byte) {\n    t.Helper()\n    \n    golden := filepath.Join(\"testdata\", name+\".golden\")\n    \n    if *update {\n        os.WriteFile(golden, got, 0644)\n        return\n    }\n    \n    want, err := os.ReadFile(golden)\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    if !bytes.Equal(got, want) {\n        t.Errorf(\"output mismatch for %s\", name)\n    }\n}\n```\n\n## Advanced Testing Techniques\n\n### Property-Based Testing\n```go\nimport \"github.com/leanovate/gopter\"\n\nfunc TestPropertyBased(t *testing.T) {\n    properties := gopter.NewProperties(nil)\n    \n    properties.Property(\"reverse twice is identity\", prop.ForAll(\n        func(s string) bool {\n            return s == Reverse(Reverse(s))\n        },\n        gopter.Gen.String(),\n    ))\n    \n    properties.Property(\"list append preserves length\", prop.ForAll(\n        func(list []int, item int) bool {\n            original := len(list)\n            result := append(list, item)\n            return len(result) == original+1\n        },\n        gopter.Gen.SliceOf(gopter.Gen.Int()),\n        gopter.Gen.Int(),\n    ))\n    \n    properties.TestingRun(t)\n}\n```\n\n### Snapshot Testing\n```go\nfunc TestSnapshot(t *testing.T) {\n    data := generateComplexData()\n    output := RenderHTML(data)\n    \n    snapshot := filepath.Join(\"testdata\", t.Name()+\".snapshot\")\n    \n    if *updateSnapshots {\n        if err := os.WriteFile(snapshot, []byte(output), 0644); err != nil {\n            t.Fatal(err)\n        }\n        return\n    }\n    \n    expected, err := os.ReadFile(snapshot)\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    if output != string(expected) {\n        t.Error(\"snapshot mismatch\")\n        // Could use diff library to show differences\n    }\n}\n```\n\n### Contract Testing\n```go\n// Define contract that implementations must satisfy\ntype StorageContract struct {\n    t       testing.TB\n    storage Storage\n}\n\nfunc (c *StorageContract) TestStore() {\n    c.t.Helper()\n    \n    err := c.storage.Store(\"key\", \"value\")\n    if err != nil {\n        c.t.Errorf(\"Store failed: %v\", err)\n    }\n    \n    val, err := c.storage.Retrieve(\"key\")\n    if err != nil {\n        c.t.Errorf(\"Retrieve failed: %v\", err)\n    }\n    \n    if val != \"value\" {\n        c.t.Errorf(\"got %q, want %q\", val, \"value\")\n    }\n}\n\nfunc (c *StorageContract) TestDelete() {\n    c.t.Helper()\n    \n    c.storage.Store(\"key\", \"value\")\n    err := c.storage.Delete(\"key\")\n    if err != nil {\n        c.t.Errorf(\"Delete failed: %v\", err)\n    }\n    \n    _, err = c.storage.Retrieve(\"key\")\n    if err == nil {\n        c.t.Error(\"expected error after delete\")\n    }\n}\n\n// Test different implementations\nfunc TestMemoryStorage(t *testing.T) {\n    storage := NewMemoryStorage()\n    contract := &StorageContract{t: t, storage: storage}\n    contract.TestStore()\n    contract.TestDelete()\n}\n\nfunc TestDiskStorage(t *testing.T) {\n    storage := NewDiskStorage(t.TempDir())\n    contract := &StorageContract{t: t, storage: storage}\n    contract.TestStore()\n    contract.TestDelete()\n}\n```\n\n## Best Practices Summary\n\n1. **Write table-driven tests** - Comprehensive and maintainable\n2. **Use subtests** - Better organization and parallel execution\n3. **Mock external dependencies** - Fast and reliable tests\n4. **Test edge cases** - Empty inputs, nil values, errors\n5. **Benchmark critical paths** - Measure performance\n6. **Aim for high coverage** - But focus on meaningful tests\n7. **Use t.Helper()** - Better error reporting in test helpers\n8. **Cleanup with t.Cleanup()** - Guaranteed cleanup\n9. **Use build tags for integration tests** - Separate slow tests\n10. **Keep tests deterministic** - No random failures","numLines":1322,"startLine":1,"totalLines":1322}}}
{"parentUuid":"71cab5ef-679e-4a7c-9616-758ed72f9c54","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01KUwetBeovEneSyRfaFs7Fu","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_013VPYnApiupZDqvsawRMWXC","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/optimization.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":43874,"cache_read_input_tokens":32637,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5Wi2LARY2Reg78c8CFR","type":"assistant","uuid":"cd798f80-4669-4112-880e-d9b237f00138","timestamp":"2025-08-13T09:59:29.830Z"}
{"parentUuid":"cd798f80-4669-4112-880e-d9b237f00138","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"<tool_use_error>File does not exist.</tool_use_error>","is_error":true,"tool_use_id":"toolu_013VPYnApiupZDqvsawRMWXC"}]},"uuid":"0bc96c11-a2bb-425a-a5ce-a596cfc74ef7","timestamp":"2025-08-13T09:59:29.855Z","toolUseResult":"Error: File does not exist."}
{"parentUuid":"0bc96c11-a2bb-425a-a5ce-a596cfc74ef7","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_015d2J2q5z8JnKf2c23TDjYk","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01J6SJxw96618Ac5iRc6xnF3","name":"Bash","input":{"command":"ls -la /home/aural/Code/bigmeanie/back/.docs/code/","description":"List all files in code docs directory"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":108,"cache_read_input_tokens":76511,"output_tokens":95,"service_tier":"standard"}},"requestId":"req_011CS5WiZ6bPc2Eu4nkthiVc","type":"assistant","uuid":"0cee96cd-6457-4b7a-bdc5-a1030b7f66be","timestamp":"2025-08-13T09:59:34.584Z"}
{"parentUuid":"0cee96cd-6457-4b7a-bdc5-a1030b7f66be","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01J6SJxw96618Ac5iRc6xnF3","type":"tool_result","content":"total 264\ndrwxr-xr-x 2 aural users  4096 Aug 13 04:57 .\ndrwxr-xr-x 7 aural users  4096 Aug 13 03:33 ..\n-rw-r--r-- 1 aural users 32605 Aug 13 02:14 concurrency.md\n-rw-r--r-- 1 aural users 60418 Aug 13 03:32 design-patterns.md\n-rw-r--r-- 1 aural users 31345 Aug 13 02:30 errors.md\n-rw-r--r-- 1 aural users 40287 Aug 13 02:53 fundamentals.md\n-rw-r--r-- 1 aural users 25562 Aug 13 02:27 packages.md\n-rw-r--r-- 1 aural users 29299 Aug 13 02:25 performance.md\n-rw-r--r-- 1 aural users 30742 Aug 13 02:22 testing.md","is_error":false}]},"uuid":"643f3a8b-fc2e-4ab8-ae72-0b9589c38868","timestamp":"2025-08-13T09:59:34.622Z","toolUseResult":{"stdout":"total 264\ndrwxr-xr-x 2 aural users  4096 Aug 13 04:57 .\ndrwxr-xr-x 7 aural users  4096 Aug 13 03:33 ..\n-rw-r--r-- 1 aural users 32605 Aug 13 02:14 concurrency.md\n-rw-r--r-- 1 aural users 60418 Aug 13 03:32 design-patterns.md\n-rw-r--r-- 1 aural users 31345 Aug 13 02:30 errors.md\n-rw-r--r-- 1 aural users 40287 Aug 13 02:53 fundamentals.md\n-rw-r--r-- 1 aural users 25562 Aug 13 02:27 packages.md\n-rw-r--r-- 1 aural users 29299 Aug 13 02:25 performance.md\n-rw-r--r-- 1 aural users 30742 Aug 13 02:22 testing.md","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"643f3a8b-fc2e-4ab8-ae72-0b9589c38868","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01VSUucFTJFfGJDqaoqmESCT","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01PHqs4uJ5AkH9mCCJrgiR9s","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/performance.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":383,"cache_read_input_tokens":76619,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5WiuNjhr7exv57jRRpA","type":"assistant","uuid":"95c96804-6dba-4c53-8370-a7d83c5666fc","timestamp":"2025-08-13T09:59:38.100Z"}
{"parentUuid":"95c96804-6dba-4c53-8370-a7d83c5666fc","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PHqs4uJ5AkH9mCCJrgiR9s","type":"tool_result","content":"     1→# Go Performance - Optimization Mastery\n     2→\n     3→## Table of Contents\n     4→1. [Profiling](#profiling)\n     5→2. [Benchmarking](#benchmarking)\n     6→3. [Memory Management](#memory-management)\n     7→4. [CPU Optimization](#cpu-optimization)\n     8→5. [Compiler Optimizations](#compiler-optimizations)\n     9→6. [Caching Strategies](#caching-strategies)\n    10→7. [Concurrency Performance](#concurrency-performance)\n    11→8. [I/O Optimization](#io-optimization)\n    12→9. [Data Structure Optimization](#data-structure-optimization)\n    13→10. [Performance Best Practices](#performance-best-practices)\n    14→\n    15→## Profiling\n    16→\n    17→### CPU Profiling\n    18→```go\n    19→import (\n    20→    \"runtime/pprof\"\n    21→    \"os\"\n    22→    \"runtime\"\n    23→)\n    24→\n    25→// Basic CPU profiling\n    26→func main() {\n    27→    // Create CPU profile file\n    28→    f, err := os.Create(\"cpu.prof\")\n    29→    if err != nil {\n    30→        log.Fatal(err)\n    31→    }\n    32→    defer f.Close()\n    33→    \n    34→    // Start CPU profiling\n    35→    if err := pprof.StartCPUProfile(f); err != nil {\n    36→        log.Fatal(err)\n    37→    }\n    38→    defer pprof.StopCPUProfile()\n    39→    \n    40→    // Your application code\n    41→    runApplication()\n    42→}\n    43→\n    44→// HTTP profiling server\n    45→import _ \"net/http/pprof\"\n    46→\n    47→func main() {\n    48→    go func() {\n    49→        log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n    50→    }()\n    51→    \n    52→    // Your application code\n    53→    runApplication()\n    54→}\n    55→\n    56→// Analyze profiles:\n    57→// go tool pprof cpu.prof\n    58→// go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n    59→// go tool pprof -http=:8080 cpu.prof  # Web interface\n    60→\n    61→// Profile with benchmarks\n    62→func BenchmarkFunction(b *testing.B) {\n    63→    // Start profiling in benchmark\n    64→    f, _ := os.Create(\"bench.prof\")\n    65→    pprof.StartCPUProfile(f)\n    66→    defer pprof.StopCPUProfile()\n    67→    \n    68→    for i := 0; i < b.N; i++ {\n    69→        FunctionToProfile()\n    70→    }\n    71→}\n    72→```\n    73→\n    74→### Memory Profiling\n    75→```go\n    76→// Memory profiling\n    77→func writeMemProfile() {\n    78→    f, err := os.Create(\"mem.prof\")\n    79→    if err != nil {\n    80→        log.Fatal(err)\n    81→    }\n    82→    defer f.Close()\n    83→    \n    84→    runtime.GC() // Force GC before profiling\n    85→    if err := pprof.WriteHeapProfile(f); err != nil {\n    86→        log.Fatal(err)\n    87→    }\n    88→}\n    89→\n    90→// Allocation profiling\n    91→func writeAllocProfile() {\n    92→    f, err := os.Create(\"alloc.prof\")\n    93→    if err != nil {\n    94→        log.Fatal(err)\n    95→    }\n    96→    defer f.Close()\n    97→    \n    98→    // Profile allocations\n    99→    runtime.MemProfileRate = 1 // Profile every allocation\n   100→    defer func() { runtime.MemProfileRate = 512 * 1024 }() // Reset\n   101→    \n   102→    // Run code\n   103→    runApplication()\n   104→    \n   105→    pprof.Lookup(\"allocs\").WriteTo(f, 0)\n   106→}\n   107→\n   108→// Memory stats\n   109→func printMemStats() {\n   110→    var m runtime.MemStats\n   111→    runtime.ReadMemStats(&m)\n   112→    \n   113→    fmt.Printf(\"Alloc = %v MB\", m.Alloc / 1024 / 1024)\n   114→    fmt.Printf(\"TotalAlloc = %v MB\", m.TotalAlloc / 1024 / 1024)\n   115→    fmt.Printf(\"Sys = %v MB\", m.Sys / 1024 / 1024)\n   116→    fmt.Printf(\"NumGC = %v\\n\", m.NumGC)\n   117→    fmt.Printf(\"HeapAlloc = %v MB\", m.HeapAlloc / 1024 / 1024)\n   118→    fmt.Printf(\"HeapObjects = %v\", m.HeapObjects)\n   119→}\n   120→\n   121→// Track allocations in specific code\n   122→func trackAllocations() {\n   123→    var m1, m2 runtime.MemStats\n   124→    \n   125→    runtime.ReadMemStats(&m1)\n   126→    \n   127→    // Code to measure\n   128→    expensiveOperation()\n   129→    \n   130→    runtime.ReadMemStats(&m2)\n   131→    \n   132→    fmt.Printf(\"Allocated: %d bytes\\n\", m2.Alloc - m1.Alloc)\n   133→    fmt.Printf(\"Total Allocated: %d bytes\\n\", m2.TotalAlloc - m1.TotalAlloc)\n   134→    fmt.Printf(\"Number of allocations: %d\\n\", m2.Mallocs - m1.Mallocs)\n   135→}\n   136→```\n   137→\n   138→### Goroutine Profiling\n   139→```go\n   140→// Goroutine profiling\n   141→func writeGoroutineProfile() {\n   142→    f, err := os.Create(\"goroutine.prof\")\n   143→    if err != nil {\n   144→        log.Fatal(err)\n   145→    }\n   146→    defer f.Close()\n   147→    \n   148→    pprof.Lookup(\"goroutine\").WriteTo(f, 1)\n   149→}\n   150→\n   151→// Monitor goroutine count\n   152→func monitorGoroutines() {\n   153→    ticker := time.NewTicker(1 * time.Second)\n   154→    defer ticker.Stop()\n   155→    \n   156→    for range ticker.C {\n   157→        fmt.Printf(\"Goroutines: %d\\n\", runtime.NumGoroutine())\n   158→    }\n   159→}\n   160→\n   161→// Block profiling (mutex contention)\n   162→func enableBlockProfiling() {\n   163→    runtime.SetBlockProfileRate(1)\n   164→    defer runtime.SetBlockProfileRate(0)\n   165→    \n   166→    // Run application\n   167→    runApplication()\n   168→    \n   169→    f, _ := os.Create(\"block.prof\")\n   170→    defer f.Close()\n   171→    pprof.Lookup(\"block\").WriteTo(f, 0)\n   172→}\n   173→\n   174→// Mutex profiling\n   175→func enableMutexProfiling() {\n   176→    runtime.SetMutexProfileFraction(1)\n   177→    defer runtime.SetMutexProfileFraction(0)\n   178→    \n   179→    // Run application\n   180→    runApplication()\n   181→    \n   182→    f, _ := os.Create(\"mutex.prof\")\n   183→    defer f.Close()\n   184→    pprof.Lookup(\"mutex\").WriteTo(f, 0)\n   185→}\n   186→```\n   187→\n   188→### Trace Profiling\n   189→```go\n   190→import \"runtime/trace\"\n   191→\n   192→// Execution tracing\n   193→func main() {\n   194→    f, err := os.Create(\"trace.out\")\n   195→    if err != nil {\n   196→        log.Fatal(err)\n   197→    }\n   198→    defer f.Close()\n   199→    \n   200→    err = trace.Start(f)\n   201→    if err != nil {\n   202→        log.Fatal(err)\n   203→    }\n   204→    defer trace.Stop()\n   205→    \n   206→    // Your application\n   207→    runApplication()\n   208→}\n   209→\n   210→// Analyze: go tool trace trace.out\n   211→\n   212→// Custom trace regions\n   213→func processRequest(ctx context.Context) {\n   214→    defer trace.StartRegion(ctx, \"processRequest\").End()\n   215→    \n   216→    trace.WithRegion(ctx, \"validate\", func() {\n   217→        validateInput()\n   218→    })\n   219→    \n   220→    trace.WithRegion(ctx, \"compute\", func() {\n   221→        computeResult()\n   222→    })\n   223→    \n   224→    trace.WithRegion(ctx, \"respond\", func() {\n   225→        sendResponse()\n   226→    })\n   227→}\n   228→\n   229→// Trace logging\n   230→func traceLog(ctx context.Context, message string) {\n   231→    trace.Log(ctx, \"app\", message)\n   232→}\n   233→```\n   234→\n   235→## Benchmarking\n   236→\n   237→### Advanced Benchmarking\n   238→```go\n   239→// Benchmark with different inputs\n   240→func BenchmarkSort(b *testing.B) {\n   241→    sizes := []int{10, 100, 1000, 10000}\n   242→    \n   243→    for _, size := range sizes {\n   244→        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n   245→            data := generateRandomSlice(size)\n   246→            \n   247→            b.ResetTimer()\n   248→            for i := 0; i < b.N; i++ {\n   249→                b.StopTimer()\n   250→                tmp := make([]int, len(data))\n   251→                copy(tmp, data)\n   252→                b.StartTimer()\n   253→                \n   254→                sort.Ints(tmp)\n   255→            }\n   256→        })\n   257→    }\n   258→}\n   259→\n   260→// Comparative benchmarks\n   261→func BenchmarkStringBuilding(b *testing.B) {\n   262→    strs := []string{\"hello\", \"world\", \"foo\", \"bar\", \"baz\"}\n   263→    \n   264→    b.Run(\"Concatenation\", func(b *testing.B) {\n   265→        for i := 0; i < b.N; i++ {\n   266→            var result string\n   267→            for _, s := range strs {\n   268→                result += s\n   269→            }\n   270→        }\n   271→    })\n   272→    \n   273→    b.Run(\"StringBuilder\", func(b *testing.B) {\n   274→        for i := 0; i < b.N; i++ {\n   275→            var builder strings.Builder\n   276→            for _, s := range strs {\n   277→                builder.WriteString(s)\n   278→            }\n   279→            _ = builder.String()\n   280→        }\n   281→    })\n   282→    \n   283→    b.Run(\"BytesBuffer\", func(b *testing.B) {\n   284→        for i := 0; i < b.N; i++ {\n   285→            var buffer bytes.Buffer\n   286→            for _, s := range strs {\n   287→                buffer.WriteString(s)\n   288→            }\n   289→            _ = buffer.String()\n   290→        }\n   291→    })\n   292→    \n   293→    b.Run(\"Join\", func(b *testing.B) {\n   294→        for i := 0; i < b.N; i++ {\n   295→            _ = strings.Join(strs, \"\")\n   296→        }\n   297→    })\n   298→}\n   299→\n   300→// Memory benchmarks\n   301→func BenchmarkMemory(b *testing.B) {\n   302→    b.Run(\"WithAllocation\", func(b *testing.B) {\n   303→        b.ReportAllocs()\n   304→        for i := 0; i < b.N; i++ {\n   305→            s := make([]int, 1000)\n   306→            _ = s\n   307→        }\n   308→    })\n   309→    \n   310→    b.Run(\"WithPool\", func(b *testing.B) {\n   311→        b.ReportAllocs()\n   312→        pool := sync.Pool{\n   313→            New: func() interface{} {\n   314→                return make([]int, 1000)\n   315→            },\n   316→        }\n   317→        \n   318→        for i := 0; i < b.N; i++ {\n   319→            s := pool.Get().([]int)\n   320→            pool.Put(s)\n   321→        }\n   322→    })\n   323→}\n   324→\n   325→// Custom metrics\n   326→func BenchmarkThroughput(b *testing.B) {\n   327→    data := make([]byte, 1024*1024) // 1MB\n   328→    \n   329→    b.SetBytes(int64(len(data)))\n   330→    b.ResetTimer()\n   331→    \n   332→    for i := 0; i < b.N; i++ {\n   333→        process(data)\n   334→    }\n   335→    \n   336→    b.ReportMetric(float64(b.N)*float64(len(data))/b.Elapsed().Seconds()/1024/1024, \"MB/s\")\n   337→}\n   338→```\n   339→\n   340→## Memory Management\n   341→\n   342→### Reducing Allocations\n   343→```go\n   344→// Avoid allocations in loops\n   345→// Bad: Allocates in loop\n   346→func bad() []string {\n   347→    var results []string\n   348→    for i := 0; i < 1000; i++ {\n   349→        results = append(results, fmt.Sprintf(\"item-%d\", i))\n   350→    }\n   351→    return results\n   352→}\n   353→\n   354→// Good: Preallocate\n   355→func good() []string {\n   356→    results := make([]string, 0, 1000)\n   357→    for i := 0; i < 1000; i++ {\n   358→        results = append(results, fmt.Sprintf(\"item-%d\", i))\n   359→    }\n   360→    return results\n   361→}\n   362→\n   363→// Reuse buffers\n   364→var bufferPool = sync.Pool{\n   365→    New: func() interface{} {\n   366→        return new(bytes.Buffer)\n   367→    },\n   368→}\n   369→\n   370→func processWithPool(data []byte) string {\n   371→    buf := bufferPool.Get().(*bytes.Buffer)\n   372→    defer func() {\n   373→        buf.Reset()\n   374→        bufferPool.Put(buf)\n   375→    }()\n   376→    \n   377→    buf.Write(data)\n   378→    // Process...\n   379→    return buf.String()\n   380→}\n   381→\n   382→// Avoid string allocations\n   383→func avoidStringAllocs(b []byte) string {\n   384→    // Bad: Multiple allocations\n   385→    s := string(b)\n   386→    s = strings.ToUpper(s)\n   387→    s = strings.TrimSpace(s)\n   388→    \n   389→    // Better: Work with bytes\n   390→    b = bytes.ToUpper(b)\n   391→    b = bytes.TrimSpace(b)\n   392→    return string(b)\n   393→}\n   394→\n   395→// String interning for repeated strings\n   396→type StringInterner struct {\n   397→    mu    sync.RWMutex\n   398→    cache map[string]string\n   399→}\n   400→\n   401→func (si *StringInterner) Intern(s string) string {\n   402→    si.mu.RLock()\n   403→    if interned, ok := si.cache[s]; ok {\n   404→        si.mu.RUnlock()\n   405→        return interned\n   406→    }\n   407→    si.mu.RUnlock()\n   408→    \n   409→    si.mu.Lock()\n   410→    defer si.mu.Unlock()\n   411→    \n   412→    si.cache[s] = s\n   413→    return s\n   414→}\n   415→```\n   416→\n   417→### Memory Layout Optimization\n   418→```go\n   419→// Struct field alignment\n   420→// Bad: 32 bytes due to padding\n   421→type Inefficient struct {\n   422→    a bool    // 1 byte + 7 padding\n   423→    b int64   // 8 bytes\n   424→    c bool    // 1 byte + 7 padding\n   425→    d int64   // 8 bytes\n   426→}\n   427→\n   428→// Good: 24 bytes with better alignment\n   429→type Efficient struct {\n   430→    b int64   // 8 bytes\n   431→    d int64   // 8 bytes\n   432→    a bool    // 1 byte\n   433→    c bool    // 1 byte + 6 padding\n   434→}\n   435→\n   436→// Use smaller types when possible\n   437→type Flags struct {\n   438→    // Bad: 4 bools = potentially 4 bytes + padding\n   439→    IsActive   bool\n   440→    IsVerified bool\n   441→    IsPremium  bool\n   442→    IsAdmin    bool\n   443→}\n   444→\n   445→// Good: 1 byte using bit flags\n   446→type CompactFlags uint8\n   447→\n   448→const (\n   449→    FlagActive CompactFlags = 1 << iota\n   450→    FlagVerified\n   451→    FlagPremium\n   452→    FlagAdmin\n   453→)\n   454→\n   455→func (f CompactFlags) IsActive() bool { return f&FlagActive != 0 }\n   456→func (f CompactFlags) IsVerified() bool { return f&FlagVerified != 0 }\n   457→\n   458→// Array vs slice for fixed size\n   459→type Record struct {\n   460→    // Bad: slice has 24 bytes overhead (pointer, len, cap)\n   461→    IDSlice []byte\n   462→    \n   463→    // Good: array for fixed size, no overhead\n   464→    IDArray [16]byte\n   465→}\n   466→```\n   467→\n   468→### Escape Analysis\n   469→```go\n   470→// Understanding escape analysis\n   471→// go build -gcflags=\"-m\" to see escape analysis\n   472→\n   473→// Doesn't escape - allocated on stack\n   474→func noEscape() int {\n   475→    x := 42\n   476→    return x\n   477→}\n   478→\n   479→// Escapes to heap - returned pointer\n   480→func escapes() *int {\n   481→    x := 42\n   482→    return &x // x escapes to heap\n   483→}\n   484→\n   485→// Avoid unnecessary escapes\n   486→type Data struct {\n   487→    values [1000]int\n   488→}\n   489→\n   490→// Bad: Escapes to heap\n   491→func (d *Data) Sum() int {\n   492→    sum := 0\n   493→    for _, v := range d.values { // d.values escapes\n   494→        sum += v\n   495→    }\n   496→    return sum\n   497→}\n   498→\n   499→// Good: Doesn't escape\n   500→func (d Data) SumValue() int {\n   501→    sum := 0\n   502→    for i := 0; i < len(d.values); i++ {\n   503→        sum += d.values[i]\n   504→    }\n   505→    return sum\n   506→}\n   507→\n   508→// Interface causes escape\n   509→func processInterface(i interface{}) {\n   510→    // i escapes to heap\n   511→}\n   512→\n   513→func avoidEscape() {\n   514→    x := 42\n   515→    processInterface(x) // x escapes\n   516→    \n   517→    // Avoid by not using interface\n   518→    processInt(x) // x doesn't escape\n   519→}\n   520→\n   521→func processInt(i int) {\n   522→    // Process int directly\n   523→}\n   524→```\n   525→\n   526→## CPU Optimization\n   527→\n   528→### Hot Path Optimization\n   529→```go\n   530→// Optimize hot paths\n   531→func processData(data []int) int {\n   532→    // Move invariants out of loop\n   533→    length := len(data)\n   534→    if length == 0 {\n   535→        return 0\n   536→    }\n   537→    \n   538→    sum := 0\n   539→    // Unroll loop for better performance\n   540→    for i := 0; i < length-3; i += 4 {\n   541→        sum += data[i] + data[i+1] + data[i+2] + data[i+3]\n   542→    }\n   543→    \n   544→    // Handle remaining elements\n   545→    for i := length - length%4; i < length; i++ {\n   546→        sum += data[i]\n   547→    }\n   548→    \n   549→    return sum\n   550→}\n   551→\n   552→// Branch prediction optimization\n   553→func findMax(data []int) int {\n   554→    if len(data) == 0 {\n   555→        return 0\n   556→    }\n   557→    \n   558→    max := data[0]\n   559→    for i := 1; i < len(data); i++ {\n   560→        // Branchless max (may be faster)\n   561→        if data[i] > max {\n   562→            max = data[i]\n   563→        }\n   564→    }\n   565→    return max\n   566→}\n   567→\n   568→// Cache-friendly iteration\n   569→func sumMatrix(matrix [][]int) int {\n   570→    sum := 0\n   571→    // Row-major order (cache-friendly)\n   572→    for i := 0; i < len(matrix); i++ {\n   573→        for j := 0; j < len(matrix[i]); j++ {\n   574→            sum += matrix[i][j]\n   575→        }\n   576→    }\n   577→    return sum\n   578→}\n   579→\n   580→// SIMD-friendly code\n   581→func addSlices(a, b []float64) []float64 {\n   582→    result := make([]float64, len(a))\n   583→    \n   584→    // Compiler may vectorize this\n   585→    for i := range a {\n   586→        result[i] = a[i] + b[i]\n   587→    }\n   588→    \n   589→    return result\n   590→}\n   591→```\n   592→\n   593→### Inlining\n   594→```go\n   595→// Encourage inlining for small functions\n   596→//go:inline\n   597→func add(a, b int) int {\n   598→    return a + b\n   599→}\n   600→\n   601→// Prevent inlining for rarely used functions\n   602→//go:noinline\n   603→func rarelyUsedFunction() {\n   604→    // Complex logic\n   605→}\n   606→\n   607→// Check inlining decisions\n   608→// go build -gcflags=\"-m=2\"\n   609→\n   610→// Inline-friendly functions\n   611→func abs(x int) int {\n   612→    if x < 0 {\n   613→        return -x\n   614→    }\n   615→    return x\n   616→}\n   617→\n   618→// Too complex to inline (default threshold ~80 nodes)\n   619→func complexFunction(x int) int {\n   620→    // Many operations...\n   621→    return result\n   622→}\n   623→```\n   624→\n   625→## Compiler Optimizations\n   626→\n   627→### Compiler Directives\n   628→```go\n   629→// Bounds check elimination\n   630→func sumArray(arr []int) int {\n   631→    if len(arr) == 0 {\n   632→        return 0\n   633→    }\n   634→    \n   635→    sum := 0\n   636→    // Compiler can eliminate bounds checks\n   637→    for i := 0; i < len(arr); i++ {\n   638→        sum += arr[i]\n   639→    }\n   640→    return sum\n   641→}\n   642→\n   643→// Help compiler with hints\n   644→func process(data []byte) {\n   645→    // Tell compiler minimum length\n   646→    _ = data[3] // Bounds check once\n   647→    \n   648→    // Now these don't need bounds checks\n   649→    a := data[0]\n   650→    b := data[1]\n   651→    c := data[2]\n   652→    d := data[3]\n   653→    \n   654→    // Process a, b, c, d\n   655→}\n   656→\n   657→// Const propagation\n   658→const bufferSize = 1024\n   659→\n   660→func allocateBuffer() []byte {\n   661→    // Compiler knows size at compile time\n   662→    return make([]byte, bufferSize)\n   663→}\n   664→\n   665→// Dead code elimination\n   666→func example(debug bool) {\n   667→    if false { // Compiler removes this\n   668→        expensiveDebugOperation()\n   669→    }\n   670→    \n   671→    const debugMode = false\n   672→    if debugMode { // Also removed\n   673→        fmt.Println(\"Debug mode\")\n   674→    }\n   675→}\n   676→```\n   677→\n   678→### Build Flags\n   679→```go\n   680→// Build tags for optimization\n   681→//go:build !debug\n   682→\n   683→package main\n   684→\n   685→func log(msg string) {\n   686→    // No-op in release builds\n   687→}\n   688→\n   689→// Alternative file for debug builds\n   690→//go:build debug\n   691→\n   692→package main\n   693→\n   694→func log(msg string) {\n   695→    fmt.Println(msg)\n   696→}\n   697→\n   698→// Compile with optimizations\n   699→// go build -ldflags=\"-s -w\" # Strip debug info\n   700→// go build -tags release\n   701→// GOOS=linux GOARCH=amd64 go build # Cross-compile\n   702→```\n   703→\n   704→## Caching Strategies\n   705→\n   706→### In-Memory Caching\n   707→```go\n   708→// Simple cache with TTL\n   709→type Cache struct {\n   710→    mu      sync.RWMutex\n   711→    items   map[string]*cacheItem\n   712→    ttl     time.Duration\n   713→}\n   714→\n   715→type cacheItem struct {\n   716→    value      interface{}\n   717→    expiration time.Time\n   718→}\n   719→\n   720→func NewCache(ttl time.Duration) *Cache {\n   721→    c := &Cache{\n   722→        items: make(map[string]*cacheItem),\n   723→        ttl:   ttl,\n   724→    }\n   725→    go c.cleanup()\n   726→    return c\n   727→}\n   728→\n   729→func (c *Cache) Set(key string, value interface{}) {\n   730→    c.mu.Lock()\n   731→    defer c.mu.Unlock()\n   732→    \n   733→    c.items[key] = &cacheItem{\n   734→        value:      value,\n   735→        expiration: time.Now().Add(c.ttl),\n   736→    }\n   737→}\n   738→\n   739→func (c *Cache) Get(key string) (interface{}, bool) {\n   740→    c.mu.RLock()\n   741→    defer c.mu.RUnlock()\n   742→    \n   743→    item, found := c.items[key]\n   744→    if !found {\n   745→        return nil, false\n   746→    }\n   747→    \n   748→    if time.Now().After(item.expiration) {\n   749→        return nil, false\n   750→    }\n   751→    \n   752→    return item.value, true\n   753→}\n   754→\n   755→func (c *Cache) cleanup() {\n   756→    ticker := time.NewTicker(c.ttl / 2)\n   757→    defer ticker.Stop()\n   758→    \n   759→    for range ticker.C {\n   760→        c.mu.Lock()\n   761→        now := time.Now()\n   762→        for key, item := range c.items {\n   763→            if now.After(item.expiration) {\n   764→                delete(c.items, key)\n   765→            }\n   766→        }\n   767→        c.mu.Unlock()\n   768→    }\n   769→}\n   770→\n   771→// LRU Cache\n   772→type LRUCache struct {\n   773→    capacity int\n   774→    items    map[string]*list.Element\n   775→    order    *list.List\n   776→    mu       sync.Mutex\n   777→}\n   778→\n   779→type lruItem struct {\n   780→    key   string\n   781→    value interface{}\n   782→}\n   783→\n   784→func NewLRUCache(capacity int) *LRUCache {\n   785→    return &LRUCache{\n   786→        capacity: capacity,\n   787→        items:    make(map[string]*list.Element),\n   788→        order:    list.New(),\n   789→    }\n   790→}\n   791→\n   792→func (c *LRUCache) Get(key string) (interface{}, bool) {\n   793→    c.mu.Lock()\n   794→    defer c.mu.Unlock()\n   795→    \n   796→    if elem, ok := c.items[key]; ok {\n   797→        c.order.MoveToFront(elem)\n   798→        return elem.Value.(*lruItem).value, true\n   799→    }\n   800→    return nil, false\n   801→}\n   802→\n   803→func (c *LRUCache) Set(key string, value interface{}) {\n   804→    c.mu.Lock()\n   805→    defer c.mu.Unlock()\n   806→    \n   807→    if elem, ok := c.items[key]; ok {\n   808→        c.order.MoveToFront(elem)\n   809→        elem.Value.(*lruItem).value = value\n   810→        return\n   811→    }\n   812→    \n   813→    if c.order.Len() >= c.capacity {\n   814→        oldest := c.order.Back()\n   815→        if oldest != nil {\n   816→            c.order.Remove(oldest)\n   817→            delete(c.items, oldest.Value.(*lruItem).key)\n   818→        }\n   819→    }\n   820→    \n   821→    item := &lruItem{key: key, value: value}\n   822→    elem := c.order.PushFront(item)\n   823→    c.items[key] = elem\n   824→}\n   825→```\n   826→\n   827→### Memoization\n   828→```go\n   829→// Function memoization\n   830→type Memoizer struct {\n   831→    mu    sync.RWMutex\n   832→    cache map[string]interface{}\n   833→    fn    func(string) interface{}\n   834→}\n   835→\n   836→func NewMemoizer(fn func(string) interface{}) *Memoizer {\n   837→    return &Memoizer{\n   838→        cache: make(map[string]interface{}),\n   839→        fn:    fn,\n   840→    }\n   841→}\n   842→\n   843→func (m *Memoizer) Get(key string) interface{} {\n   844→    m.mu.RLock()\n   845→    if val, ok := m.cache[key]; ok {\n   846→        m.mu.RUnlock()\n   847→        return val\n   848→    }\n   849→    m.mu.RUnlock()\n   850→    \n   851→    m.mu.Lock()\n   852→    defer m.mu.Unlock()\n   853→    \n   854→    // Double-check\n   855→    if val, ok := m.cache[key]; ok {\n   856→        return val\n   857→    }\n   858→    \n   859→    val := m.fn(key)\n   860→    m.cache[key] = val\n   861→    return val\n   862→}\n   863→\n   864→// Concurrent-safe memoization with singleflight\n   865→import \"golang.org/x/sync/singleflight\"\n   866→\n   867→type ConcurrentMemoizer struct {\n   868→    cache map[string]interface{}\n   869→    mu    sync.RWMutex\n   870→    group singleflight.Group\n   871→}\n   872→\n   873→func (m *ConcurrentMemoizer) Get(key string) (interface{}, error) {\n   874→    m.mu.RLock()\n   875→    if val, ok := m.cache[key]; ok {\n   876→        m.mu.RUnlock()\n   877→        return val, nil\n   878→    }\n   879→    m.mu.RUnlock()\n   880→    \n   881→    // Ensure only one goroutine computes the value\n   882→    val, err, _ := m.group.Do(key, func() (interface{}, error) {\n   883→        result := expensiveComputation(key)\n   884→        \n   885→        m.mu.Lock()\n   886→        m.cache[key] = result\n   887→        m.mu.Unlock()\n   888→        \n   889→        return result, nil\n   890→    })\n   891→    \n   892→    return val, err\n   893→}\n   894→```\n   895→\n   896→## Concurrency Performance\n   897→\n   898→### Goroutine Pool\n   899→```go\n   900→// Efficient goroutine pool\n   901→type WorkerPool struct {\n   902→    workers   int\n   903→    jobQueue  chan Job\n   904→    results   chan Result\n   905→    wg        sync.WaitGroup\n   906→}\n   907→\n   908→func NewWorkerPool(workers int, queueSize int) *WorkerPool {\n   909→    return &WorkerPool{\n   910→        workers:  workers,\n   911→        jobQueue: make(chan Job, queueSize),\n   912→        results:  make(chan Result, queueSize),\n   913→    }\n   914→}\n   915→\n   916→func (p *WorkerPool) Start() {\n   917→    for i := 0; i < p.workers; i++ {\n   918→        p.wg.Add(1)\n   919→        go p.worker(i)\n   920→    }\n   921→}\n   922→\n   923→func (p *WorkerPool) worker(id int) {\n   924→    defer p.wg.Done()\n   925→    \n   926→    for job := range p.jobQueue {\n   927→        result := processJob(job)\n   928→        p.results <- result\n   929→    }\n   930→}\n   931→\n   932→func (p *WorkerPool) Submit(job Job) {\n   933→    p.jobQueue <- job\n   934→}\n   935→\n   936→func (p *WorkerPool) Stop() {\n   937→    close(p.jobQueue)\n   938→    p.wg.Wait()\n   939→    close(p.results)\n   940→}\n   941→\n   942→// Lock-free structures\n   943→type LockFreeStack struct {\n   944→    head atomic.Pointer[node]\n   945→}\n   946→\n   947→type node struct {\n   948→    value interface{}\n   949→    next  *node\n   950→}\n   951→\n   952→func (s *LockFreeStack) Push(v interface{}) {\n   953→    n := &node{value: v}\n   954→    for {\n   955→        head := s.head.Load()\n   956→        n.next = head\n   957→        if s.head.CompareAndSwap(head, n) {\n   958→            return\n   959→        }\n   960→    }\n   961→}\n   962→\n   963→func (s *LockFreeStack) Pop() interface{} {\n   964→    for {\n   965→        head := s.head.Load()\n   966→        if head == nil {\n   967→            return nil\n   968→        }\n   969→        if s.head.CompareAndSwap(head, head.next) {\n   970→            return head.value\n   971→        }\n   972→    }\n   973→}\n   974→```\n   975→\n   976→### Channel Optimization\n   977→```go\n   978→// Buffered channels for performance\n   979→func efficientPipeline() {\n   980→    // Use buffered channels to reduce blocking\n   981→    input := make(chan int, 100)\n   982→    output := make(chan int, 100)\n   983→    \n   984→    // Producer\n   985→    go func() {\n   986→        defer close(input)\n   987→        for i := 0; i < 1000; i++ {\n   988→            input <- i\n   989→        }\n   990→    }()\n   991→    \n   992→    // Workers\n   993→    var wg sync.WaitGroup\n   994→    for i := 0; i < 10; i++ {\n   995→        wg.Add(1)\n   996→        go func() {\n   997→            defer wg.Done()\n   998→            for val := range input {\n   999→                output <- process(val)\n  1000→            }\n  1001→        }()\n  1002→    }\n  1003→    \n  1004→    // Close output when workers done\n  1005→    go func() {\n  1006→        wg.Wait()\n  1007→        close(output)\n  1008→    }()\n  1009→    \n  1010→    // Consumer\n  1011→    for result := range output {\n  1012→        handleResult(result)\n  1013→    }\n  1014→}\n  1015→\n  1016→// Batch processing for efficiency\n  1017→func batchProcessor(input <-chan Item) {\n  1018→    batch := make([]Item, 0, 100)\n  1019→    ticker := time.NewTicker(100 * time.Millisecond)\n  1020→    defer ticker.Stop()\n  1021→    \n  1022→    for {\n  1023→        select {\n  1024→        case item, ok := <-input:\n  1025→            if !ok {\n  1026→                if len(batch) > 0 {\n  1027→                    processBatch(batch)\n  1028→                }\n  1029→                return\n  1030→            }\n  1031→            batch = append(batch, item)\n  1032→            \n  1033→            if len(batch) >= 100 {\n  1034→                processBatch(batch)\n  1035→                batch = batch[:0]\n  1036→            }\n  1037→            \n  1038→        case <-ticker.C:\n  1039→            if len(batch) > 0 {\n  1040→                processBatch(batch)\n  1041→                batch = batch[:0]\n  1042→            }\n  1043→        }\n  1044→    }\n  1045→}\n  1046→```\n  1047→\n  1048→## I/O Optimization\n  1049→\n  1050→### Buffered I/O\n  1051→```go\n  1052→// Use buffered I/O\n  1053→func efficientFileRead(filename string) error {\n  1054→    file, err := os.Open(filename)\n  1055→    if err != nil {\n  1056→        return err\n  1057→    }\n  1058→    defer file.Close()\n  1059→    \n  1060→    // Use buffered reader\n  1061→    reader := bufio.NewReader(file)\n  1062→    \n  1063→    for {\n  1064→        line, err := reader.ReadString('\\n')\n  1065→        if err == io.EOF {\n  1066→            break\n  1067→        }\n  1068→        if err != nil {\n  1069→            return err\n  1070→        }\n  1071→        \n  1072→        processLine(line)\n  1073→    }\n  1074→    \n  1075→    return nil\n  1076→}\n  1077→\n  1078→// Efficient file writing\n  1079→func efficientFileWrite(filename string, data []string) error {\n  1080→    file, err := os.Create(filename)\n  1081→    if err != nil {\n  1082→        return err\n  1083→    }\n  1084→    defer file.Close()\n  1085→    \n  1086→    // Use buffered writer\n  1087→    writer := bufio.NewWriter(file)\n  1088→    defer writer.Flush()\n  1089→    \n  1090→    for _, line := range data {\n  1091→        _, err := writer.WriteString(line + \"\\n\")\n  1092→        if err != nil {\n  1093→            return err\n  1094→        }\n  1095→    }\n  1096→    \n  1097→    return nil\n  1098→}\n  1099→\n  1100→// Memory-mapped files for large files\n  1101→import \"golang.org/x/exp/mmap\"\n  1102→\n  1103→func readLargeFile(filename string) error {\n  1104→    reader, err := mmap.Open(filename)\n  1105→    if err != nil {\n  1106→        return err\n  1107→    }\n  1108→    defer reader.Close()\n  1109→    \n  1110→    // Read without loading entire file into memory\n  1111→    data := make([]byte, 1024)\n  1112→    for offset := int64(0); offset < reader.Len(); offset += 1024 {\n  1113→        n, err := reader.ReadAt(data, offset)\n  1114→        if err != nil && err != io.EOF {\n  1115→            return err\n  1116→        }\n  1117→        \n  1118→        processChunk(data[:n])\n  1119→    }\n  1120→    \n  1121→    return nil\n  1122→}\n  1123→```\n  1124→\n  1125→### Network I/O\n  1126→```go\n  1127→// Connection pooling\n  1128→type ConnectionPool struct {\n  1129→    connections chan net.Conn\n  1130→    factory     func() (net.Conn, error)\n  1131→}\n  1132→\n  1133→func NewConnectionPool(size int, factory func() (net.Conn, error)) (*ConnectionPool, error) {\n  1134→    pool := &ConnectionPool{\n  1135→        connections: make(chan net.Conn, size),\n  1136→        factory:     factory,\n  1137→    }\n  1138→    \n  1139→    for i := 0; i < size; i++ {\n  1140→        conn, err := factory()\n  1141→        if err != nil {\n  1142→            return nil, err\n  1143→        }\n  1144→        pool.connections <- conn\n  1145→    }\n  1146→    \n  1147→    return pool, nil\n  1148→}\n  1149→\n  1150→func (p *ConnectionPool) Get() net.Conn {\n  1151→    return <-p.connections\n  1152→}\n  1153→\n  1154→func (p *ConnectionPool) Put(conn net.Conn) {\n  1155→    p.connections <- conn\n  1156→}\n  1157→\n  1158→// HTTP client optimization\n  1159→var httpClient = &http.Client{\n  1160→    Timeout: 30 * time.Second,\n  1161→    Transport: &http.Transport{\n  1162→        MaxIdleConns:        100,\n  1163→        MaxIdleConnsPerHost: 10,\n  1164→        IdleConnTimeout:     90 * time.Second,\n  1165→        DisableCompression:  false,\n  1166→        DisableKeepAlives:   false,\n  1167→    },\n  1168→}\n  1169→\n  1170→// Batch HTTP requests\n  1171→func batchHTTPRequests(urls []string) []Response {\n  1172→    results := make([]Response, len(urls))\n  1173→    var wg sync.WaitGroup\n  1174→    \n  1175→    // Limit concurrent requests\n  1176→    sem := make(chan struct{}, 10)\n  1177→    \n  1178→    for i, url := range urls {\n  1179→        wg.Add(1)\n  1180→        go func(idx int, u string) {\n  1181→            defer wg.Done()\n  1182→            \n  1183→            sem <- struct{}{}\n  1184→            defer func() { <-sem }()\n  1185→            \n  1186→            resp, err := httpClient.Get(u)\n  1187→            if err != nil {\n  1188→                results[idx] = Response{Error: err}\n  1189→                return\n  1190→            }\n  1191→            defer resp.Body.Close()\n  1192→            \n  1193→            body, _ := io.ReadAll(resp.Body)\n  1194→            results[idx] = Response{Data: body}\n  1195→        }(i, url)\n  1196→    }\n  1197→    \n  1198→    wg.Wait()\n  1199→    return results\n  1200→}\n  1201→```\n  1202→\n  1203→## Data Structure Optimization\n  1204→\n  1205→### Slice Optimization\n  1206→```go\n  1207→// Preallocate slices\n  1208→func optimizedSliceOperations() {\n  1209→    // Know the capacity\n  1210→    slice := make([]int, 0, 1000)\n  1211→    \n  1212→    // Grow efficiently\n  1213→    if cap(slice) < requiredSize {\n  1214→        newSlice := make([]int, len(slice), requiredSize*2)\n  1215→        copy(newSlice, slice)\n  1216→        slice = newSlice\n  1217→    }\n  1218→    \n  1219→    // Clear slice for reuse\n  1220→    slice = slice[:0]\n  1221→    \n  1222→    // Remove element efficiently\n  1223→    func removeAt(s []int, i int) []int {\n  1224→        s[i] = s[len(s)-1]\n  1225→        return s[:len(s)-1]\n  1226→    }\n  1227→}\n  1228→\n  1229→// Custom growing strategy\n  1230→type GrowableBuffer struct {\n  1231→    data []byte\n  1232→}\n  1233→\n  1234→func (b *GrowableBuffer) grow(n int) {\n  1235→    if cap(b.data)-len(b.data) < n {\n  1236→        newCap := cap(b.data) * 2\n  1237→        if newCap < len(b.data)+n {\n  1238→            newCap = len(b.data) + n\n  1239→        }\n  1240→        newData := make([]byte, len(b.data), newCap)\n  1241→        copy(newData, b.data)\n  1242→        b.data = newData\n  1243→    }\n  1244→}\n  1245→```\n  1246→\n  1247→### Map Optimization\n  1248→```go\n  1249→// Preallocate maps\n  1250→m := make(map[string]int, 1000)\n  1251→\n  1252→// Use appropriate key types\n  1253→// Faster: int keys\n  1254→fastMap := make(map[int]string)\n  1255→\n  1256→// Slower: string keys (requires hashing)\n  1257→slowMap := make(map[string]string)\n  1258→\n  1259→// Custom hash map for specific use case\n  1260→type FastStringMap struct {\n  1261→    buckets [][]entry\n  1262→    size    int\n  1263→}\n  1264→\n  1265→type entry struct {\n  1266→    key   string\n  1267→    value interface{}\n  1268→}\n  1269→\n  1270→func (m *FastStringMap) hash(key string) uint32 {\n  1271→    // Fast hash function\n  1272→    h := uint32(2166136261)\n  1273→    for i := 0; i < len(key); i++ {\n  1274→        h *= 16777619\n  1275→        h ^= uint32(key[i])\n  1276→    }\n  1277→    return h\n  1278→}\n  1279→\n  1280→func (m *FastStringMap) Get(key string) (interface{}, bool) {\n  1281→    h := m.hash(key) % uint32(len(m.buckets))\n  1282→    bucket := m.buckets[h]\n  1283→    \n  1284→    for _, e := range bucket {\n  1285→        if e.key == key {\n  1286→            return e.value, true\n  1287→        }\n  1288→    }\n  1289→    return nil, false\n  1290→}\n  1291→```\n  1292→\n  1293→### String Optimization\n  1294→```go\n  1295→// String concatenation optimization\n  1296→func efficientStringConcat(strs []string) string {\n  1297→    // Calculate total length\n  1298→    var totalLen int\n  1299→    for _, s := range strs {\n  1300→        totalLen += len(s)\n  1301→    }\n  1302→    \n  1303→    // Preallocate builder\n  1304→    var builder strings.Builder\n  1305→    builder.Grow(totalLen)\n  1306→    \n  1307→    for _, s := range strs {\n  1308→        builder.WriteString(s)\n  1309→    }\n  1310→    \n  1311→    return builder.String()\n  1312→}\n  1313→\n  1314→// Avoid string copies\n  1315→func stringToBytes(s string) []byte {\n  1316→    // Safe conversion without copy (read-only)\n  1317→    return unsafe.Slice(unsafe.StringData(s), len(s))\n  1318→}\n  1319→\n  1320→func bytesToString(b []byte) string {\n  1321→    // Safe conversion without copy\n  1322→    return unsafe.String(unsafe.SliceData(b), len(b))\n  1323→}\n  1324→```\n  1325→\n  1326→## Performance Best Practices\n  1327→\n  1328→### Measurement and Profiling\n  1329→```go\n  1330→// Always measure before optimizing\n  1331→func measurePerformance() {\n  1332→    start := time.Now()\n  1333→    defer func() {\n  1334→        elapsed := time.Since(start)\n  1335→        log.Printf(\"Operation took %v\", elapsed)\n  1336→    }()\n  1337→    \n  1338→    // Operation to measure\n  1339→}\n  1340→\n  1341→// Use benchmarks for micro-optimizations\n  1342→func BenchmarkOptimization(b *testing.B) {\n  1343→    // Test different approaches\n  1344→}\n  1345→\n  1346→// Profile in production\n  1347→import _ \"net/http/pprof\"\n  1348→// Access profiles at /debug/pprof/\n  1349→```\n  1350→\n  1351→### Common Optimizations\n  1352→```go\n  1353→// 1. Avoid premature optimization\n  1354→// Profile first, optimize bottlenecks\n  1355→\n  1356→// 2. Reduce allocations\n  1357→// Use sync.Pool, preallocate slices\n  1358→\n  1359→// 3. Optimize hot paths\n  1360→// Focus on frequently executed code\n  1361→\n  1362→// 4. Use efficient algorithms\n  1363→// O(n) vs O(n²) matters at scale\n  1364→\n  1365→// 5. Cache computed values\n  1366→// Memoization, lookup tables\n  1367→\n  1368→// 6. Batch operations\n  1369→// Reduce system calls, network requests\n  1370→\n  1371→// 7. Use appropriate data structures\n  1372→// Map vs slice, array vs slice\n  1373→\n  1374→// 8. Leverage concurrency wisely\n  1375→// Don't overuse goroutines\n  1376→\n  1377→// 9. Minimize interface conversions\n  1378→// Interfaces cause allocations\n  1379→\n  1380→// 10. Profile regularly\n  1381→// Performance can degrade over time\n  1382→```\n  1383→\n  1384→## Best Practices Summary\n  1385→\n  1386→1. **Profile before optimizing** - Measure, don't guess\n  1387→2. **Focus on algorithms first** - Better algorithm beats micro-optimizations\n  1388→3. **Reduce allocations** - Use pools, preallocate, reuse\n  1389→4. **Optimize hot paths** - 80/20 rule applies\n  1390→5. **Cache aggressively** - But invalidate correctly\n  1391→6. **Use buffered I/O** - For file and network operations\n  1392→7. **Batch operations** - Amortize overhead\n  1393→8. **Choose right data structures** - Map vs slice matters\n  1394→9. **Leverage compiler optimizations** - Write optimizer-friendly code\n  1395→10. **Monitor production performance** - Use pprof, metrics, tracing\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"480b11d6-d396-4d80-bfc9-c7854a26aaf2","timestamp":"2025-08-13T09:59:38.229Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/performance.md","content":"# Go Performance - Optimization Mastery\n\n## Table of Contents\n1. [Profiling](#profiling)\n2. [Benchmarking](#benchmarking)\n3. [Memory Management](#memory-management)\n4. [CPU Optimization](#cpu-optimization)\n5. [Compiler Optimizations](#compiler-optimizations)\n6. [Caching Strategies](#caching-strategies)\n7. [Concurrency Performance](#concurrency-performance)\n8. [I/O Optimization](#io-optimization)\n9. [Data Structure Optimization](#data-structure-optimization)\n10. [Performance Best Practices](#performance-best-practices)\n\n## Profiling\n\n### CPU Profiling\n```go\nimport (\n    \"runtime/pprof\"\n    \"os\"\n    \"runtime\"\n)\n\n// Basic CPU profiling\nfunc main() {\n    // Create CPU profile file\n    f, err := os.Create(\"cpu.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    // Start CPU profiling\n    if err := pprof.StartCPUProfile(f); err != nil {\n        log.Fatal(err)\n    }\n    defer pprof.StopCPUProfile()\n    \n    // Your application code\n    runApplication()\n}\n\n// HTTP profiling server\nimport _ \"net/http/pprof\"\n\nfunc main() {\n    go func() {\n        log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n    }()\n    \n    // Your application code\n    runApplication()\n}\n\n// Analyze profiles:\n// go tool pprof cpu.prof\n// go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n// go tool pprof -http=:8080 cpu.prof  # Web interface\n\n// Profile with benchmarks\nfunc BenchmarkFunction(b *testing.B) {\n    // Start profiling in benchmark\n    f, _ := os.Create(\"bench.prof\")\n    pprof.StartCPUProfile(f)\n    defer pprof.StopCPUProfile()\n    \n    for i := 0; i < b.N; i++ {\n        FunctionToProfile()\n    }\n}\n```\n\n### Memory Profiling\n```go\n// Memory profiling\nfunc writeMemProfile() {\n    f, err := os.Create(\"mem.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    runtime.GC() // Force GC before profiling\n    if err := pprof.WriteHeapProfile(f); err != nil {\n        log.Fatal(err)\n    }\n}\n\n// Allocation profiling\nfunc writeAllocProfile() {\n    f, err := os.Create(\"alloc.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    // Profile allocations\n    runtime.MemProfileRate = 1 // Profile every allocation\n    defer func() { runtime.MemProfileRate = 512 * 1024 }() // Reset\n    \n    // Run code\n    runApplication()\n    \n    pprof.Lookup(\"allocs\").WriteTo(f, 0)\n}\n\n// Memory stats\nfunc printMemStats() {\n    var m runtime.MemStats\n    runtime.ReadMemStats(&m)\n    \n    fmt.Printf(\"Alloc = %v MB\", m.Alloc / 1024 / 1024)\n    fmt.Printf(\"TotalAlloc = %v MB\", m.TotalAlloc / 1024 / 1024)\n    fmt.Printf(\"Sys = %v MB\", m.Sys / 1024 / 1024)\n    fmt.Printf(\"NumGC = %v\\n\", m.NumGC)\n    fmt.Printf(\"HeapAlloc = %v MB\", m.HeapAlloc / 1024 / 1024)\n    fmt.Printf(\"HeapObjects = %v\", m.HeapObjects)\n}\n\n// Track allocations in specific code\nfunc trackAllocations() {\n    var m1, m2 runtime.MemStats\n    \n    runtime.ReadMemStats(&m1)\n    \n    // Code to measure\n    expensiveOperation()\n    \n    runtime.ReadMemStats(&m2)\n    \n    fmt.Printf(\"Allocated: %d bytes\\n\", m2.Alloc - m1.Alloc)\n    fmt.Printf(\"Total Allocated: %d bytes\\n\", m2.TotalAlloc - m1.TotalAlloc)\n    fmt.Printf(\"Number of allocations: %d\\n\", m2.Mallocs - m1.Mallocs)\n}\n```\n\n### Goroutine Profiling\n```go\n// Goroutine profiling\nfunc writeGoroutineProfile() {\n    f, err := os.Create(\"goroutine.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    pprof.Lookup(\"goroutine\").WriteTo(f, 1)\n}\n\n// Monitor goroutine count\nfunc monitorGoroutines() {\n    ticker := time.NewTicker(1 * time.Second)\n    defer ticker.Stop()\n    \n    for range ticker.C {\n        fmt.Printf(\"Goroutines: %d\\n\", runtime.NumGoroutine())\n    }\n}\n\n// Block profiling (mutex contention)\nfunc enableBlockProfiling() {\n    runtime.SetBlockProfileRate(1)\n    defer runtime.SetBlockProfileRate(0)\n    \n    // Run application\n    runApplication()\n    \n    f, _ := os.Create(\"block.prof\")\n    defer f.Close()\n    pprof.Lookup(\"block\").WriteTo(f, 0)\n}\n\n// Mutex profiling\nfunc enableMutexProfiling() {\n    runtime.SetMutexProfileFraction(1)\n    defer runtime.SetMutexProfileFraction(0)\n    \n    // Run application\n    runApplication()\n    \n    f, _ := os.Create(\"mutex.prof\")\n    defer f.Close()\n    pprof.Lookup(\"mutex\").WriteTo(f, 0)\n}\n```\n\n### Trace Profiling\n```go\nimport \"runtime/trace\"\n\n// Execution tracing\nfunc main() {\n    f, err := os.Create(\"trace.out\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    err = trace.Start(f)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer trace.Stop()\n    \n    // Your application\n    runApplication()\n}\n\n// Analyze: go tool trace trace.out\n\n// Custom trace regions\nfunc processRequest(ctx context.Context) {\n    defer trace.StartRegion(ctx, \"processRequest\").End()\n    \n    trace.WithRegion(ctx, \"validate\", func() {\n        validateInput()\n    })\n    \n    trace.WithRegion(ctx, \"compute\", func() {\n        computeResult()\n    })\n    \n    trace.WithRegion(ctx, \"respond\", func() {\n        sendResponse()\n    })\n}\n\n// Trace logging\nfunc traceLog(ctx context.Context, message string) {\n    trace.Log(ctx, \"app\", message)\n}\n```\n\n## Benchmarking\n\n### Advanced Benchmarking\n```go\n// Benchmark with different inputs\nfunc BenchmarkSort(b *testing.B) {\n    sizes := []int{10, 100, 1000, 10000}\n    \n    for _, size := range sizes {\n        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n            data := generateRandomSlice(size)\n            \n            b.ResetTimer()\n            for i := 0; i < b.N; i++ {\n                b.StopTimer()\n                tmp := make([]int, len(data))\n                copy(tmp, data)\n                b.StartTimer()\n                \n                sort.Ints(tmp)\n            }\n        })\n    }\n}\n\n// Comparative benchmarks\nfunc BenchmarkStringBuilding(b *testing.B) {\n    strs := []string{\"hello\", \"world\", \"foo\", \"bar\", \"baz\"}\n    \n    b.Run(\"Concatenation\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var result string\n            for _, s := range strs {\n                result += s\n            }\n        }\n    })\n    \n    b.Run(\"StringBuilder\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var builder strings.Builder\n            for _, s := range strs {\n                builder.WriteString(s)\n            }\n            _ = builder.String()\n        }\n    })\n    \n    b.Run(\"BytesBuffer\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var buffer bytes.Buffer\n            for _, s := range strs {\n                buffer.WriteString(s)\n            }\n            _ = buffer.String()\n        }\n    })\n    \n    b.Run(\"Join\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            _ = strings.Join(strs, \"\")\n        }\n    })\n}\n\n// Memory benchmarks\nfunc BenchmarkMemory(b *testing.B) {\n    b.Run(\"WithAllocation\", func(b *testing.B) {\n        b.ReportAllocs()\n        for i := 0; i < b.N; i++ {\n            s := make([]int, 1000)\n            _ = s\n        }\n    })\n    \n    b.Run(\"WithPool\", func(b *testing.B) {\n        b.ReportAllocs()\n        pool := sync.Pool{\n            New: func() interface{} {\n                return make([]int, 1000)\n            },\n        }\n        \n        for i := 0; i < b.N; i++ {\n            s := pool.Get().([]int)\n            pool.Put(s)\n        }\n    })\n}\n\n// Custom metrics\nfunc BenchmarkThroughput(b *testing.B) {\n    data := make([]byte, 1024*1024) // 1MB\n    \n    b.SetBytes(int64(len(data)))\n    b.ResetTimer()\n    \n    for i := 0; i < b.N; i++ {\n        process(data)\n    }\n    \n    b.ReportMetric(float64(b.N)*float64(len(data))/b.Elapsed().Seconds()/1024/1024, \"MB/s\")\n}\n```\n\n## Memory Management\n\n### Reducing Allocations\n```go\n// Avoid allocations in loops\n// Bad: Allocates in loop\nfunc bad() []string {\n    var results []string\n    for i := 0; i < 1000; i++ {\n        results = append(results, fmt.Sprintf(\"item-%d\", i))\n    }\n    return results\n}\n\n// Good: Preallocate\nfunc good() []string {\n    results := make([]string, 0, 1000)\n    for i := 0; i < 1000; i++ {\n        results = append(results, fmt.Sprintf(\"item-%d\", i))\n    }\n    return results\n}\n\n// Reuse buffers\nvar bufferPool = sync.Pool{\n    New: func() interface{} {\n        return new(bytes.Buffer)\n    },\n}\n\nfunc processWithPool(data []byte) string {\n    buf := bufferPool.Get().(*bytes.Buffer)\n    defer func() {\n        buf.Reset()\n        bufferPool.Put(buf)\n    }()\n    \n    buf.Write(data)\n    // Process...\n    return buf.String()\n}\n\n// Avoid string allocations\nfunc avoidStringAllocs(b []byte) string {\n    // Bad: Multiple allocations\n    s := string(b)\n    s = strings.ToUpper(s)\n    s = strings.TrimSpace(s)\n    \n    // Better: Work with bytes\n    b = bytes.ToUpper(b)\n    b = bytes.TrimSpace(b)\n    return string(b)\n}\n\n// String interning for repeated strings\ntype StringInterner struct {\n    mu    sync.RWMutex\n    cache map[string]string\n}\n\nfunc (si *StringInterner) Intern(s string) string {\n    si.mu.RLock()\n    if interned, ok := si.cache[s]; ok {\n        si.mu.RUnlock()\n        return interned\n    }\n    si.mu.RUnlock()\n    \n    si.mu.Lock()\n    defer si.mu.Unlock()\n    \n    si.cache[s] = s\n    return s\n}\n```\n\n### Memory Layout Optimization\n```go\n// Struct field alignment\n// Bad: 32 bytes due to padding\ntype Inefficient struct {\n    a bool    // 1 byte + 7 padding\n    b int64   // 8 bytes\n    c bool    // 1 byte + 7 padding\n    d int64   // 8 bytes\n}\n\n// Good: 24 bytes with better alignment\ntype Efficient struct {\n    b int64   // 8 bytes\n    d int64   // 8 bytes\n    a bool    // 1 byte\n    c bool    // 1 byte + 6 padding\n}\n\n// Use smaller types when possible\ntype Flags struct {\n    // Bad: 4 bools = potentially 4 bytes + padding\n    IsActive   bool\n    IsVerified bool\n    IsPremium  bool\n    IsAdmin    bool\n}\n\n// Good: 1 byte using bit flags\ntype CompactFlags uint8\n\nconst (\n    FlagActive CompactFlags = 1 << iota\n    FlagVerified\n    FlagPremium\n    FlagAdmin\n)\n\nfunc (f CompactFlags) IsActive() bool { return f&FlagActive != 0 }\nfunc (f CompactFlags) IsVerified() bool { return f&FlagVerified != 0 }\n\n// Array vs slice for fixed size\ntype Record struct {\n    // Bad: slice has 24 bytes overhead (pointer, len, cap)\n    IDSlice []byte\n    \n    // Good: array for fixed size, no overhead\n    IDArray [16]byte\n}\n```\n\n### Escape Analysis\n```go\n// Understanding escape analysis\n// go build -gcflags=\"-m\" to see escape analysis\n\n// Doesn't escape - allocated on stack\nfunc noEscape() int {\n    x := 42\n    return x\n}\n\n// Escapes to heap - returned pointer\nfunc escapes() *int {\n    x := 42\n    return &x // x escapes to heap\n}\n\n// Avoid unnecessary escapes\ntype Data struct {\n    values [1000]int\n}\n\n// Bad: Escapes to heap\nfunc (d *Data) Sum() int {\n    sum := 0\n    for _, v := range d.values { // d.values escapes\n        sum += v\n    }\n    return sum\n}\n\n// Good: Doesn't escape\nfunc (d Data) SumValue() int {\n    sum := 0\n    for i := 0; i < len(d.values); i++ {\n        sum += d.values[i]\n    }\n    return sum\n}\n\n// Interface causes escape\nfunc processInterface(i interface{}) {\n    // i escapes to heap\n}\n\nfunc avoidEscape() {\n    x := 42\n    processInterface(x) // x escapes\n    \n    // Avoid by not using interface\n    processInt(x) // x doesn't escape\n}\n\nfunc processInt(i int) {\n    // Process int directly\n}\n```\n\n## CPU Optimization\n\n### Hot Path Optimization\n```go\n// Optimize hot paths\nfunc processData(data []int) int {\n    // Move invariants out of loop\n    length := len(data)\n    if length == 0 {\n        return 0\n    }\n    \n    sum := 0\n    // Unroll loop for better performance\n    for i := 0; i < length-3; i += 4 {\n        sum += data[i] + data[i+1] + data[i+2] + data[i+3]\n    }\n    \n    // Handle remaining elements\n    for i := length - length%4; i < length; i++ {\n        sum += data[i]\n    }\n    \n    return sum\n}\n\n// Branch prediction optimization\nfunc findMax(data []int) int {\n    if len(data) == 0 {\n        return 0\n    }\n    \n    max := data[0]\n    for i := 1; i < len(data); i++ {\n        // Branchless max (may be faster)\n        if data[i] > max {\n            max = data[i]\n        }\n    }\n    return max\n}\n\n// Cache-friendly iteration\nfunc sumMatrix(matrix [][]int) int {\n    sum := 0\n    // Row-major order (cache-friendly)\n    for i := 0; i < len(matrix); i++ {\n        for j := 0; j < len(matrix[i]); j++ {\n            sum += matrix[i][j]\n        }\n    }\n    return sum\n}\n\n// SIMD-friendly code\nfunc addSlices(a, b []float64) []float64 {\n    result := make([]float64, len(a))\n    \n    // Compiler may vectorize this\n    for i := range a {\n        result[i] = a[i] + b[i]\n    }\n    \n    return result\n}\n```\n\n### Inlining\n```go\n// Encourage inlining for small functions\n//go:inline\nfunc add(a, b int) int {\n    return a + b\n}\n\n// Prevent inlining for rarely used functions\n//go:noinline\nfunc rarelyUsedFunction() {\n    // Complex logic\n}\n\n// Check inlining decisions\n// go build -gcflags=\"-m=2\"\n\n// Inline-friendly functions\nfunc abs(x int) int {\n    if x < 0 {\n        return -x\n    }\n    return x\n}\n\n// Too complex to inline (default threshold ~80 nodes)\nfunc complexFunction(x int) int {\n    // Many operations...\n    return result\n}\n```\n\n## Compiler Optimizations\n\n### Compiler Directives\n```go\n// Bounds check elimination\nfunc sumArray(arr []int) int {\n    if len(arr) == 0 {\n        return 0\n    }\n    \n    sum := 0\n    // Compiler can eliminate bounds checks\n    for i := 0; i < len(arr); i++ {\n        sum += arr[i]\n    }\n    return sum\n}\n\n// Help compiler with hints\nfunc process(data []byte) {\n    // Tell compiler minimum length\n    _ = data[3] // Bounds check once\n    \n    // Now these don't need bounds checks\n    a := data[0]\n    b := data[1]\n    c := data[2]\n    d := data[3]\n    \n    // Process a, b, c, d\n}\n\n// Const propagation\nconst bufferSize = 1024\n\nfunc allocateBuffer() []byte {\n    // Compiler knows size at compile time\n    return make([]byte, bufferSize)\n}\n\n// Dead code elimination\nfunc example(debug bool) {\n    if false { // Compiler removes this\n        expensiveDebugOperation()\n    }\n    \n    const debugMode = false\n    if debugMode { // Also removed\n        fmt.Println(\"Debug mode\")\n    }\n}\n```\n\n### Build Flags\n```go\n// Build tags for optimization\n//go:build !debug\n\npackage main\n\nfunc log(msg string) {\n    // No-op in release builds\n}\n\n// Alternative file for debug builds\n//go:build debug\n\npackage main\n\nfunc log(msg string) {\n    fmt.Println(msg)\n}\n\n// Compile with optimizations\n// go build -ldflags=\"-s -w\" # Strip debug info\n// go build -tags release\n// GOOS=linux GOARCH=amd64 go build # Cross-compile\n```\n\n## Caching Strategies\n\n### In-Memory Caching\n```go\n// Simple cache with TTL\ntype Cache struct {\n    mu      sync.RWMutex\n    items   map[string]*cacheItem\n    ttl     time.Duration\n}\n\ntype cacheItem struct {\n    value      interface{}\n    expiration time.Time\n}\n\nfunc NewCache(ttl time.Duration) *Cache {\n    c := &Cache{\n        items: make(map[string]*cacheItem),\n        ttl:   ttl,\n    }\n    go c.cleanup()\n    return c\n}\n\nfunc (c *Cache) Set(key string, value interface{}) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    c.items[key] = &cacheItem{\n        value:      value,\n        expiration: time.Now().Add(c.ttl),\n    }\n}\n\nfunc (c *Cache) Get(key string) (interface{}, bool) {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    \n    item, found := c.items[key]\n    if !found {\n        return nil, false\n    }\n    \n    if time.Now().After(item.expiration) {\n        return nil, false\n    }\n    \n    return item.value, true\n}\n\nfunc (c *Cache) cleanup() {\n    ticker := time.NewTicker(c.ttl / 2)\n    defer ticker.Stop()\n    \n    for range ticker.C {\n        c.mu.Lock()\n        now := time.Now()\n        for key, item := range c.items {\n            if now.After(item.expiration) {\n                delete(c.items, key)\n            }\n        }\n        c.mu.Unlock()\n    }\n}\n\n// LRU Cache\ntype LRUCache struct {\n    capacity int\n    items    map[string]*list.Element\n    order    *list.List\n    mu       sync.Mutex\n}\n\ntype lruItem struct {\n    key   string\n    value interface{}\n}\n\nfunc NewLRUCache(capacity int) *LRUCache {\n    return &LRUCache{\n        capacity: capacity,\n        items:    make(map[string]*list.Element),\n        order:    list.New(),\n    }\n}\n\nfunc (c *LRUCache) Get(key string) (interface{}, bool) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    if elem, ok := c.items[key]; ok {\n        c.order.MoveToFront(elem)\n        return elem.Value.(*lruItem).value, true\n    }\n    return nil, false\n}\n\nfunc (c *LRUCache) Set(key string, value interface{}) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    if elem, ok := c.items[key]; ok {\n        c.order.MoveToFront(elem)\n        elem.Value.(*lruItem).value = value\n        return\n    }\n    \n    if c.order.Len() >= c.capacity {\n        oldest := c.order.Back()\n        if oldest != nil {\n            c.order.Remove(oldest)\n            delete(c.items, oldest.Value.(*lruItem).key)\n        }\n    }\n    \n    item := &lruItem{key: key, value: value}\n    elem := c.order.PushFront(item)\n    c.items[key] = elem\n}\n```\n\n### Memoization\n```go\n// Function memoization\ntype Memoizer struct {\n    mu    sync.RWMutex\n    cache map[string]interface{}\n    fn    func(string) interface{}\n}\n\nfunc NewMemoizer(fn func(string) interface{}) *Memoizer {\n    return &Memoizer{\n        cache: make(map[string]interface{}),\n        fn:    fn,\n    }\n}\n\nfunc (m *Memoizer) Get(key string) interface{} {\n    m.mu.RLock()\n    if val, ok := m.cache[key]; ok {\n        m.mu.RUnlock()\n        return val\n    }\n    m.mu.RUnlock()\n    \n    m.mu.Lock()\n    defer m.mu.Unlock()\n    \n    // Double-check\n    if val, ok := m.cache[key]; ok {\n        return val\n    }\n    \n    val := m.fn(key)\n    m.cache[key] = val\n    return val\n}\n\n// Concurrent-safe memoization with singleflight\nimport \"golang.org/x/sync/singleflight\"\n\ntype ConcurrentMemoizer struct {\n    cache map[string]interface{}\n    mu    sync.RWMutex\n    group singleflight.Group\n}\n\nfunc (m *ConcurrentMemoizer) Get(key string) (interface{}, error) {\n    m.mu.RLock()\n    if val, ok := m.cache[key]; ok {\n        m.mu.RUnlock()\n        return val, nil\n    }\n    m.mu.RUnlock()\n    \n    // Ensure only one goroutine computes the value\n    val, err, _ := m.group.Do(key, func() (interface{}, error) {\n        result := expensiveComputation(key)\n        \n        m.mu.Lock()\n        m.cache[key] = result\n        m.mu.Unlock()\n        \n        return result, nil\n    })\n    \n    return val, err\n}\n```\n\n## Concurrency Performance\n\n### Goroutine Pool\n```go\n// Efficient goroutine pool\ntype WorkerPool struct {\n    workers   int\n    jobQueue  chan Job\n    results   chan Result\n    wg        sync.WaitGroup\n}\n\nfunc NewWorkerPool(workers int, queueSize int) *WorkerPool {\n    return &WorkerPool{\n        workers:  workers,\n        jobQueue: make(chan Job, queueSize),\n        results:  make(chan Result, queueSize),\n    }\n}\n\nfunc (p *WorkerPool) Start() {\n    for i := 0; i < p.workers; i++ {\n        p.wg.Add(1)\n        go p.worker(i)\n    }\n}\n\nfunc (p *WorkerPool) worker(id int) {\n    defer p.wg.Done()\n    \n    for job := range p.jobQueue {\n        result := processJob(job)\n        p.results <- result\n    }\n}\n\nfunc (p *WorkerPool) Submit(job Job) {\n    p.jobQueue <- job\n}\n\nfunc (p *WorkerPool) Stop() {\n    close(p.jobQueue)\n    p.wg.Wait()\n    close(p.results)\n}\n\n// Lock-free structures\ntype LockFreeStack struct {\n    head atomic.Pointer[node]\n}\n\ntype node struct {\n    value interface{}\n    next  *node\n}\n\nfunc (s *LockFreeStack) Push(v interface{}) {\n    n := &node{value: v}\n    for {\n        head := s.head.Load()\n        n.next = head\n        if s.head.CompareAndSwap(head, n) {\n            return\n        }\n    }\n}\n\nfunc (s *LockFreeStack) Pop() interface{} {\n    for {\n        head := s.head.Load()\n        if head == nil {\n            return nil\n        }\n        if s.head.CompareAndSwap(head, head.next) {\n            return head.value\n        }\n    }\n}\n```\n\n### Channel Optimization\n```go\n// Buffered channels for performance\nfunc efficientPipeline() {\n    // Use buffered channels to reduce blocking\n    input := make(chan int, 100)\n    output := make(chan int, 100)\n    \n    // Producer\n    go func() {\n        defer close(input)\n        for i := 0; i < 1000; i++ {\n            input <- i\n        }\n    }()\n    \n    // Workers\n    var wg sync.WaitGroup\n    for i := 0; i < 10; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for val := range input {\n                output <- process(val)\n            }\n        }()\n    }\n    \n    // Close output when workers done\n    go func() {\n        wg.Wait()\n        close(output)\n    }()\n    \n    // Consumer\n    for result := range output {\n        handleResult(result)\n    }\n}\n\n// Batch processing for efficiency\nfunc batchProcessor(input <-chan Item) {\n    batch := make([]Item, 0, 100)\n    ticker := time.NewTicker(100 * time.Millisecond)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case item, ok := <-input:\n            if !ok {\n                if len(batch) > 0 {\n                    processBatch(batch)\n                }\n                return\n            }\n            batch = append(batch, item)\n            \n            if len(batch) >= 100 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n            \n        case <-ticker.C:\n            if len(batch) > 0 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n        }\n    }\n}\n```\n\n## I/O Optimization\n\n### Buffered I/O\n```go\n// Use buffered I/O\nfunc efficientFileRead(filename string) error {\n    file, err := os.Open(filename)\n    if err != nil {\n        return err\n    }\n    defer file.Close()\n    \n    // Use buffered reader\n    reader := bufio.NewReader(file)\n    \n    for {\n        line, err := reader.ReadString('\\n')\n        if err == io.EOF {\n            break\n        }\n        if err != nil {\n            return err\n        }\n        \n        processLine(line)\n    }\n    \n    return nil\n}\n\n// Efficient file writing\nfunc efficientFileWrite(filename string, data []string) error {\n    file, err := os.Create(filename)\n    if err != nil {\n        return err\n    }\n    defer file.Close()\n    \n    // Use buffered writer\n    writer := bufio.NewWriter(file)\n    defer writer.Flush()\n    \n    for _, line := range data {\n        _, err := writer.WriteString(line + \"\\n\")\n        if err != nil {\n            return err\n        }\n    }\n    \n    return nil\n}\n\n// Memory-mapped files for large files\nimport \"golang.org/x/exp/mmap\"\n\nfunc readLargeFile(filename string) error {\n    reader, err := mmap.Open(filename)\n    if err != nil {\n        return err\n    }\n    defer reader.Close()\n    \n    // Read without loading entire file into memory\n    data := make([]byte, 1024)\n    for offset := int64(0); offset < reader.Len(); offset += 1024 {\n        n, err := reader.ReadAt(data, offset)\n        if err != nil && err != io.EOF {\n            return err\n        }\n        \n        processChunk(data[:n])\n    }\n    \n    return nil\n}\n```\n\n### Network I/O\n```go\n// Connection pooling\ntype ConnectionPool struct {\n    connections chan net.Conn\n    factory     func() (net.Conn, error)\n}\n\nfunc NewConnectionPool(size int, factory func() (net.Conn, error)) (*ConnectionPool, error) {\n    pool := &ConnectionPool{\n        connections: make(chan net.Conn, size),\n        factory:     factory,\n    }\n    \n    for i := 0; i < size; i++ {\n        conn, err := factory()\n        if err != nil {\n            return nil, err\n        }\n        pool.connections <- conn\n    }\n    \n    return pool, nil\n}\n\nfunc (p *ConnectionPool) Get() net.Conn {\n    return <-p.connections\n}\n\nfunc (p *ConnectionPool) Put(conn net.Conn) {\n    p.connections <- conn\n}\n\n// HTTP client optimization\nvar httpClient = &http.Client{\n    Timeout: 30 * time.Second,\n    Transport: &http.Transport{\n        MaxIdleConns:        100,\n        MaxIdleConnsPerHost: 10,\n        IdleConnTimeout:     90 * time.Second,\n        DisableCompression:  false,\n        DisableKeepAlives:   false,\n    },\n}\n\n// Batch HTTP requests\nfunc batchHTTPRequests(urls []string) []Response {\n    results := make([]Response, len(urls))\n    var wg sync.WaitGroup\n    \n    // Limit concurrent requests\n    sem := make(chan struct{}, 10)\n    \n    for i, url := range urls {\n        wg.Add(1)\n        go func(idx int, u string) {\n            defer wg.Done()\n            \n            sem <- struct{}{}\n            defer func() { <-sem }()\n            \n            resp, err := httpClient.Get(u)\n            if err != nil {\n                results[idx] = Response{Error: err}\n                return\n            }\n            defer resp.Body.Close()\n            \n            body, _ := io.ReadAll(resp.Body)\n            results[idx] = Response{Data: body}\n        }(i, url)\n    }\n    \n    wg.Wait()\n    return results\n}\n```\n\n## Data Structure Optimization\n\n### Slice Optimization\n```go\n// Preallocate slices\nfunc optimizedSliceOperations() {\n    // Know the capacity\n    slice := make([]int, 0, 1000)\n    \n    // Grow efficiently\n    if cap(slice) < requiredSize {\n        newSlice := make([]int, len(slice), requiredSize*2)\n        copy(newSlice, slice)\n        slice = newSlice\n    }\n    \n    // Clear slice for reuse\n    slice = slice[:0]\n    \n    // Remove element efficiently\n    func removeAt(s []int, i int) []int {\n        s[i] = s[len(s)-1]\n        return s[:len(s)-1]\n    }\n}\n\n// Custom growing strategy\ntype GrowableBuffer struct {\n    data []byte\n}\n\nfunc (b *GrowableBuffer) grow(n int) {\n    if cap(b.data)-len(b.data) < n {\n        newCap := cap(b.data) * 2\n        if newCap < len(b.data)+n {\n            newCap = len(b.data) + n\n        }\n        newData := make([]byte, len(b.data), newCap)\n        copy(newData, b.data)\n        b.data = newData\n    }\n}\n```\n\n### Map Optimization\n```go\n// Preallocate maps\nm := make(map[string]int, 1000)\n\n// Use appropriate key types\n// Faster: int keys\nfastMap := make(map[int]string)\n\n// Slower: string keys (requires hashing)\nslowMap := make(map[string]string)\n\n// Custom hash map for specific use case\ntype FastStringMap struct {\n    buckets [][]entry\n    size    int\n}\n\ntype entry struct {\n    key   string\n    value interface{}\n}\n\nfunc (m *FastStringMap) hash(key string) uint32 {\n    // Fast hash function\n    h := uint32(2166136261)\n    for i := 0; i < len(key); i++ {\n        h *= 16777619\n        h ^= uint32(key[i])\n    }\n    return h\n}\n\nfunc (m *FastStringMap) Get(key string) (interface{}, bool) {\n    h := m.hash(key) % uint32(len(m.buckets))\n    bucket := m.buckets[h]\n    \n    for _, e := range bucket {\n        if e.key == key {\n            return e.value, true\n        }\n    }\n    return nil, false\n}\n```\n\n### String Optimization\n```go\n// String concatenation optimization\nfunc efficientStringConcat(strs []string) string {\n    // Calculate total length\n    var totalLen int\n    for _, s := range strs {\n        totalLen += len(s)\n    }\n    \n    // Preallocate builder\n    var builder strings.Builder\n    builder.Grow(totalLen)\n    \n    for _, s := range strs {\n        builder.WriteString(s)\n    }\n    \n    return builder.String()\n}\n\n// Avoid string copies\nfunc stringToBytes(s string) []byte {\n    // Safe conversion without copy (read-only)\n    return unsafe.Slice(unsafe.StringData(s), len(s))\n}\n\nfunc bytesToString(b []byte) string {\n    // Safe conversion without copy\n    return unsafe.String(unsafe.SliceData(b), len(b))\n}\n```\n\n## Performance Best Practices\n\n### Measurement and Profiling\n```go\n// Always measure before optimizing\nfunc measurePerformance() {\n    start := time.Now()\n    defer func() {\n        elapsed := time.Since(start)\n        log.Printf(\"Operation took %v\", elapsed)\n    }()\n    \n    // Operation to measure\n}\n\n// Use benchmarks for micro-optimizations\nfunc BenchmarkOptimization(b *testing.B) {\n    // Test different approaches\n}\n\n// Profile in production\nimport _ \"net/http/pprof\"\n// Access profiles at /debug/pprof/\n```\n\n### Common Optimizations\n```go\n// 1. Avoid premature optimization\n// Profile first, optimize bottlenecks\n\n// 2. Reduce allocations\n// Use sync.Pool, preallocate slices\n\n// 3. Optimize hot paths\n// Focus on frequently executed code\n\n// 4. Use efficient algorithms\n// O(n) vs O(n²) matters at scale\n\n// 5. Cache computed values\n// Memoization, lookup tables\n\n// 6. Batch operations\n// Reduce system calls, network requests\n\n// 7. Use appropriate data structures\n// Map vs slice, array vs slice\n\n// 8. Leverage concurrency wisely\n// Don't overuse goroutines\n\n// 9. Minimize interface conversions\n// Interfaces cause allocations\n\n// 10. Profile regularly\n// Performance can degrade over time\n```\n\n## Best Practices Summary\n\n1. **Profile before optimizing** - Measure, don't guess\n2. **Focus on algorithms first** - Better algorithm beats micro-optimizations\n3. **Reduce allocations** - Use pools, preallocate, reuse\n4. **Optimize hot paths** - 80/20 rule applies\n5. **Cache aggressively** - But invalidate correctly\n6. **Use buffered I/O** - For file and network operations\n7. **Batch operations** - Amortize overhead\n8. **Choose right data structures** - Map vs slice matters\n9. **Leverage compiler optimizations** - Write optimizer-friendly code\n10. **Monitor production performance** - Use pprof, metrics, tracing","numLines":1395,"startLine":1,"totalLines":1395}}}
{"parentUuid":"480b11d6-d396-4d80-bfc9-c7854a26aaf2","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01Dr96yKgnr3Bhx7cmApBUDM","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Now let me check if there are any other documentation files I might have missed:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":14668,"cache_read_input_tokens":77002,"output_tokens":128,"service_tier":"standard"}},"requestId":"req_011CS5Wj9urMGaT3cBvZLYWz","type":"assistant","uuid":"713236ec-8516-40d8-b39f-6dd39c453a82","timestamp":"2025-08-13T09:59:42.254Z"}
{"parentUuid":"713236ec-8516-40d8-b39f-6dd39c453a82","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01Dr96yKgnr3Bhx7cmApBUDM","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01MRmxEtx1LwBnCyustM3WCx","name":"Bash","input":{"command":"find /home/aural/Code/bigmeanie/back/.docs -type f -name \"*.md\" | grep -v \"/code/\" | head -20","description":"Find other markdown files in .docs directory"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":14668,"cache_read_input_tokens":77002,"output_tokens":128,"service_tier":"standard"}},"requestId":"req_011CS5Wj9urMGaT3cBvZLYWz","type":"assistant","uuid":"d22b7700-f52c-4fa9-b84a-d6d55e1e5586","timestamp":"2025-08-13T09:59:44.273Z"}
{"parentUuid":"d22b7700-f52c-4fa9-b84a-d6d55e1e5586","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MRmxEtx1LwBnCyustM3WCx","type":"tool_result","content":"/home/aural/Code/bigmeanie/back/.docs/todo.md\n/home/aural/Code/bigmeanie/back/.docs/plan.md\n/home/aural/Code/bigmeanie/back/.docs/results/README.md","is_error":false}]},"uuid":"9b8a2723-5b24-46c6-b155-551248db51ec","timestamp":"2025-08-13T09:59:44.310Z","toolUseResult":{"stdout":"/home/aural/Code/bigmeanie/back/.docs/todo.md\n/home/aural/Code/bigmeanie/back/.docs/plan.md\n/home/aural/Code/bigmeanie/back/.docs/results/README.md","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"9b8a2723-5b24-46c6-b155-551248db51ec","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01JrnhGUCSA2kAvAtQWfHy4D","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Let me also sample the actual codebase to verify the documentation accuracy:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":200,"cache_read_input_tokens":91670,"output_tokens":160,"service_tier":"standard"}},"requestId":"req_011CS5Wjby1nNgPUPBHLamFP","type":"assistant","uuid":"249881e4-a792-4a69-a432-466a66d88fec","timestamp":"2025-08-13T09:59:48.330Z"}
{"parentUuid":"249881e4-a792-4a69-a432-466a66d88fec","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01JrnhGUCSA2kAvAtQWfHy4D","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01DBFpDkyHbCakGy4Hc5Fqi8","name":"Grep","input":{"pattern":"shopspring/decimal","path":"/home/aural/Code/bigmeanie/back","glob":"*.go","output_mode":"files_with_matches","head_limit":5}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":200,"cache_read_input_tokens":91670,"output_tokens":160,"service_tier":"standard"}},"requestId":"req_011CS5Wjby1nNgPUPBHLamFP","type":"assistant","uuid":"f2f65173-8ef8-4902-a768-a8da6d0a6553","timestamp":"2025-08-13T09:59:50.591Z"}
{"parentUuid":"f2f65173-8ef8-4902-a768-a8da6d0a6553","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DBFpDkyHbCakGy4Hc5Fqi8","type":"tool_result","content":"Found 5 files\n/home/aural/Code/bigmeanie/back/.snippets/worker.go\n/home/aural/Code/bigmeanie/back/.snippets/decimal_cache.go\n/home/aural/Code/bigmeanie/back/.snippets/paramsgen/generator.go\n/home/aural/Code/bigmeanie/back/.snippets/sliding_window.go\n/home/aural/Code/bigmeanie/back/.snippets/fees.go"}]},"uuid":"d09fceb6-84f7-435a-9c77-dc3a13e64a72","timestamp":"2025-08-13T09:59:50.637Z","toolUseResult":{"mode":"files_with_matches","filenames":["/home/aural/Code/bigmeanie/back/.snippets/worker.go","/home/aural/Code/bigmeanie/back/.snippets/decimal_cache.go","/home/aural/Code/bigmeanie/back/.snippets/paramsgen/generator.go","/home/aural/Code/bigmeanie/back/.snippets/sliding_window.go","/home/aural/Code/bigmeanie/back/.snippets/fees.go"],"numFiles":5}}
{"parentUuid":"d09fceb6-84f7-435a-9c77-dc3a13e64a72","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01RYAv2B9WSndEC4MRt56MgY","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_014er4tpSNmcDy5m6HvTZKQc","name":"Grep","input":{"pattern":"func Test.*\\(t \\*testing\\.T\\)","path":"/home/aural/Code/bigmeanie/back","glob":"*_test.go","output_mode":"files_with_matches","head_limit":5}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":290,"cache_read_input_tokens":91870,"output_tokens":155,"service_tier":"standard"}},"requestId":"req_011CS5Wk5zV6UqCtkonRPzEn","type":"assistant","uuid":"fe2555aa-7484-4cec-b249-5b1578942cac","timestamp":"2025-08-13T09:59:56.229Z"}
{"parentUuid":"fe2555aa-7484-4cec-b249-5b1578942cac","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014er4tpSNmcDy5m6HvTZKQc","type":"tool_result","content":"Found 5 files\n/home/aural/Code/bigmeanie/back/pkg/indicators/vol_delta/approximators_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/vol_delta/ohlcv_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/atr_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/cmf_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/mfi_test.go"}]},"uuid":"674db3a3-7348-47e2-9402-af0ffc2200b4","timestamp":"2025-08-13T09:59:56.264Z","toolUseResult":{"mode":"files_with_matches","filenames":["/home/aural/Code/bigmeanie/back/pkg/indicators/vol_delta/approximators_test.go","/home/aural/Code/bigmeanie/back/pkg/indicators/vol_delta/ohlcv_test.go","/home/aural/Code/bigmeanie/back/pkg/indicators/common/atr_test.go","/home/aural/Code/bigmeanie/back/pkg/indicators/common/cmf_test.go","/home/aural/Code/bigmeanie/back/pkg/indicators/common/mfi_test.go"],"numFiles":5}}
{"parentUuid":"674db3a3-7348-47e2-9402-af0ffc2200b4","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01H7QMXaUG6T5G7YcfQyUSg2","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Let me check for interfaces and error handling patterns:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":313,"cache_read_input_tokens":92160,"output_tokens":171,"service_tier":"standard"}},"requestId":"req_011CS5WkV2aMvC4xLZvuZmDg","type":"assistant","uuid":"a359eaa8-d3a4-4759-be9c-f25c9ecbb300","timestamp":"2025-08-13T09:59:59.734Z"}
{"parentUuid":"a359eaa8-d3a4-4759-be9c-f25c9ecbb300","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01H7QMXaUG6T5G7YcfQyUSg2","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01Ejsprd6Uhb5ti8iAycZXQt","name":"Grep","input":{"pattern":"type \\w+er interface","path":"/home/aural/Code/bigmeanie/back","glob":"*.go","output_mode":"content","head_limit":10,"-n":true}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":313,"cache_read_input_tokens":92160,"output_tokens":171,"service_tier":"standard"}},"requestId":"req_011CS5WkV2aMvC4xLZvuZmDg","type":"assistant","uuid":"bdc298fe-e480-4506-9567-7d36eeb7752b","timestamp":"2025-08-13T10:00:02.739Z"}
{"parentUuid":"bdc298fe-e480-4506-9567-7d36eeb7752b","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Ejsprd6Uhb5ti8iAycZXQt","type":"tool_result","content":"No matches found"}]},"uuid":"34ae34b6-d55c-4be1-b4ce-e4aeb721aedd","timestamp":"2025-08-13T10:00:02.774Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"","numLines":0}}
{"parentUuid":"34ae34b6-d55c-4be1-b4ce-e4aeb721aedd","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01DhdU1rst2nZbpkAo1Uss6Q","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01WfydQf7aqNWXF6LCwYEZ7G","name":"Grep","input":{"pattern":"type \\w+ interface","path":"/home/aural/Code/bigmeanie/back","glob":"*.go","output_mode":"content","head_limit":10,"-n":true}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":186,"cache_read_input_tokens":92473,"output_tokens":159,"service_tier":"standard"}},"requestId":"req_011CS5WkxsPcoha1GjrbdXm4","type":"assistant","uuid":"2b98604f-6453-48db-a09f-55469d13e042","timestamp":"2025-08-13T10:00:08.939Z"}
{"parentUuid":"2b98604f-6453-48db-a09f-55469d13e042","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WfydQf7aqNWXF6LCwYEZ7G","type":"tool_result","content":"/home/aural/Code/bigmeanie/back/.snippets/event_pipeline.go:400:type Portfolio interface {\n/home/aural/Code/bigmeanie/back/pkg/goroutine/safe.go:53:type BackoffStrategy interface {\n/home/aural/Code/bigmeanie/back/.snippets/strategy_registry.go:16:type Strategy interface {\n/home/aural/Code/bigmeanie/back/.snippets/crash_recovery.go:265:type WorkerInterface interface {\n/home/aural/Code/bigmeanie/back/.snippets/crash_recovery.go:453:type Database interface {\n/home/aural/Code/bigmeanie/back/.snippets/crash_recovery.go:459:type AlertService interface {\n/home/aural/Code/bigmeanie/back/.snippets/paramsgen/generator.go:95:type Generator interface {\n/home/aural/Code/bigmeanie/back/pkg/clock/clock.go:6:type Clock interface {\n/home/aural/Code/bigmeanie/back/pkg/indicators/interfaces.go:9:type TimeSeries interface {\n/home/aural/Code/bigmeanie/back/pkg/indicators/interfaces.go:27:type Indicator interface {"}]},"uuid":"8ad39a63-ec1b-48b8-9fa1-290c419dd576","timestamp":"2025-08-13T10:00:08.977Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"/home/aural/Code/bigmeanie/back/.snippets/event_pipeline.go:400:type Portfolio interface {\n/home/aural/Code/bigmeanie/back/pkg/goroutine/safe.go:53:type BackoffStrategy interface {\n/home/aural/Code/bigmeanie/back/.snippets/strategy_registry.go:16:type Strategy interface {\n/home/aural/Code/bigmeanie/back/.snippets/crash_recovery.go:265:type WorkerInterface interface {\n/home/aural/Code/bigmeanie/back/.snippets/crash_recovery.go:453:type Database interface {\n/home/aural/Code/bigmeanie/back/.snippets/crash_recovery.go:459:type AlertService interface {\n/home/aural/Code/bigmeanie/back/.snippets/paramsgen/generator.go:95:type Generator interface {\n/home/aural/Code/bigmeanie/back/pkg/clock/clock.go:6:type Clock interface {\n/home/aural/Code/bigmeanie/back/pkg/indicators/interfaces.go:9:type TimeSeries interface {\n/home/aural/Code/bigmeanie/back/pkg/indicators/interfaces.go:27:type Indicator interface {","numLines":10}}
{"parentUuid":"8ad39a63-ec1b-48b8-9fa1-290c419dd576","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01WrKNMbVnJiZrxbAh2D7YYK","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Now let me check the actual project structure:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":477,"cache_read_input_tokens":92659,"output_tokens":97,"service_tier":"standard"}},"requestId":"req_011CS5WmRSJfpg3u34y49N5H","type":"assistant","uuid":"81e8a733-b5c2-449b-88fb-a7cc46b0c99d","timestamp":"2025-08-13T10:00:12.392Z"}
{"parentUuid":"81e8a733-b5c2-449b-88fb-a7cc46b0c99d","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01WrKNMbVnJiZrxbAh2D7YYK","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01GuuH1EiWiGGyJWZBAynKag","name":"Bash","input":{"command":"ls -la /home/aural/Code/bigmeanie/back/","description":"Check project structure"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":477,"cache_read_input_tokens":92659,"output_tokens":97,"service_tier":"standard"}},"requestId":"req_011CS5WmRSJfpg3u34y49N5H","type":"assistant","uuid":"629792db-0e28-4d76-be92-6874e56a1cea","timestamp":"2025-08-13T10:00:13.442Z"}
{"parentUuid":"629792db-0e28-4d76-be92-6874e56a1cea","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GuuH1EiWiGGyJWZBAynKag","type":"tool_result","content":"total 36\ndrwxr-xr-x 6 aural users 4096 Aug 12 23:24 .\ndrwxr-xr-x 6 aural users 4096 Aug 13 04:12 ..\ndrwxr-xr-x 7 aural users 4096 Aug 13 03:33 .docs\n-rw-r--r-- 1 aural users  356 Aug 12 22:53 go.mod\ndrwxr-xr-x 2 aural users 4096 Aug 12 17:31 internal\ndrwxr-xr-x 7 aural users 4096 Aug 12 17:58 pkg\n-rw-r--r-- 1 aural users 7487 Aug 12 23:24 README.md\ndrwxr-xr-x 3 aural users 4096 Aug 12 20:53 .snippets","is_error":false}]},"uuid":"6b3fd97e-1789-45d7-93ff-7bb892e756cd","timestamp":"2025-08-13T10:00:13.483Z","toolUseResult":{"stdout":"total 36\ndrwxr-xr-x 6 aural users 4096 Aug 12 23:24 .\ndrwxr-xr-x 6 aural users 4096 Aug 13 04:12 ..\ndrwxr-xr-x 7 aural users 4096 Aug 13 03:33 .docs\n-rw-r--r-- 1 aural users  356 Aug 12 22:53 go.mod\ndrwxr-xr-x 2 aural users 4096 Aug 12 17:31 internal\ndrwxr-xr-x 7 aural users 4096 Aug 12 17:58 pkg\n-rw-r--r-- 1 aural users 7487 Aug 12 23:24 README.md\ndrwxr-xr-x 3 aural users 4096 Aug 12 20:53 .snippets","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"6b3fd97e-1789-45d7-93ff-7bb892e756cd","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01MwqfJUw5eN83BEMJfE3cHB","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Based on my comprehensive review of the documentation files in `/home/aural/Code/bigmeanie/back/.docs/code/`, here's my analysis:\n\n## Overall Assessment\n\nThe documentation is **well-structured and comprehensive**, covering essential Go development topics with practical examples. The quality is generally high, but there are some gaps and areas for improvement.\n\n## What's Accurate and Well-Documented\n\n### Strengths:\n1. **Excellent coverage of core Go concepts**: The fundamentals, concurrency, testing, and error handling documents are thorough and accurate\n2. **Practical code examples**: Every concept is illustrated with working code examples\n3. **Performance-focused**: Good emphasis on optimization, profiling, and benchmarking\n4. **Best practices sections**: Each document concludes with actionable best practices\n5. **Modern Go features**: Covers Go 1.18+ features like generics and fuzzing\n6. **Table-driven test patterns**: Excellent testing documentation with comprehensive patterns\n\n## What Needs Correction or Updating\n\n### Technical Inaccuracies:\n1. **String conversion without copy (performance.md:1315-1323)**: The unsafe string/byte conversions shown are dangerous and can lead to undefined behavior. Should warn about mutability issues\n2. **Deprecated directives**: Some compiler directives like `//go:inline` don't exist in Go - should be removed\n3. **Missing context on backwards compatibility**: Documentation promotes some patterns but the project explicitly avoids backwards compatibility\n\n## What's Missing\n\n### Critical Gaps:\n1. **shopspring/decimal usage patterns**: Despite being fundamental to the project, there's no documentation on decimal arithmetic patterns\n2. **Project-specific patterns**: Missing documentation on Big Meanie specific conventions like:\n   - Ultra-concise naming (sr not SupportResistance)\n   - No backwards compatibility philosophy\n   - Breaking changes approach\n3. **Architecture decisions**: No documentation on the actual project structure (`/pkg`, `/internal`, `.snippets`)\n4. **Database patterns**: No coverage of database interactions, migrations, or transaction patterns\n5. **Configuration management**: Missing environment variables, config files, and secrets management\n6. **API/HTTP patterns**: No REST API or HTTP server patterns documentation\n7. **Logging and monitoring**: No structured logging or observability patterns\n8. **Security patterns**: Missing input validation, authentication, authorization patterns\n\n## Inconsistencies Found\n\n1. **Interface naming**: Documentation suggests `-er` suffix for single-method interfaces, but actual code uses regular naming\n2. **Test patterns**: Documentation mentions avoiding `t.Skip()` but still shows examples using it\n3. **Package structure**: Documentation shows standard layout but actual project has `.snippets` directory not explained\n4. **Error handling**: Some examples don't follow the wrapped error pattern consistently\n\n## Specific Recommendations for Improvements\n\n### High Priority:\n1. **Create `decimal-patterns.md`**: Document shopspring/decimal usage, common patterns, and gotchas\n2. **Create `project-conventions.md`**: Document Big Meanie specific conventions and philosophy\n3. **Update `performance.md`**: Remove unsafe string conversions or add strong warnings\n4. **Create `database-patterns.md`**: Add PostgreSQL patterns, migrations, transactions\n\n### Medium Priority:\n1. **Add `security.md`**: Cover input validation, SQL injection prevention, crypto patterns\n2. **Add `api-patterns.md`**: REST conventions, middleware, error responses\n3. **Update examples**: Ensure all examples follow project conventions (no backwards compatibility, concise naming)\n4. **Add `configuration.md`**: Environment variables, config loading, secrets management\n\n### Low Priority:\n1. **Add more Big Meanie specific examples**: Replace generic examples with trading-specific ones\n2. **Cross-reference between documents**: Add links between related topics\n3. **Add troubleshooting sections**: Common pitfalls and how to debug them\n4. **Version information**: Note which Go version specific features require\n\n### Structure Improvements:\n1. Consider reorganizing into subdirectories:\n   - `fundamentals/` - Basic Go concepts\n   - `advanced/` - Performance, concurrency, optimization\n   - `project/` - Big Meanie specific patterns\n   - `patterns/` - Design patterns and architectures\n\n## Summary\n\nThe documentation provides a **solid foundation** for Go development with excellent coverage of language fundamentals, concurrency, and testing. However, it lacks project-specific guidance and some critical patterns for production systems. The code examples are high quality but could better reflect the actual project's philosophy and structure.\n\nThe most critical improvements needed are:\n1. Document shopspring/decimal patterns (essential for financial calculations)\n2. Document project-specific conventions and philosophy\n3. Add database and API patterns documentation\n4. Fix the unsafe string conversion examples\n\nWith these additions, the documentation would provide comprehensive guidance for both Go development in general and Big Meanie development specifically."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":418,"cache_read_input_tokens":93136,"output_tokens":1096,"service_tier":"standard"}},"requestId":"req_011CS5Wmmb1SWs7RuoE34mbH","type":"assistant","uuid":"b2f19bc1-adde-443b-972e-b4b3ad21a283","timestamp":"2025-08-13T10:00:44.806Z"}
{"parentUuid":"c80f1bfc-0e27-49cb-86b7-72beb62abe58","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Bd6KCouHcoi937jkuqmkcQ","type":"tool_result","content":[{"type":"text","text":"Based on my comprehensive review of the documentation files in `/home/aural/Code/bigmeanie/back/.docs/code/`, here's my analysis:\n\n## Overall Assessment\n\nThe documentation is **well-structured and comprehensive**, covering essential Go development topics with practical examples. The quality is generally high, but there are some gaps and areas for improvement.\n\n## What's Accurate and Well-Documented\n\n### Strengths:\n1. **Excellent coverage of core Go concepts**: The fundamentals, concurrency, testing, and error handling documents are thorough and accurate\n2. **Practical code examples**: Every concept is illustrated with working code examples\n3. **Performance-focused**: Good emphasis on optimization, profiling, and benchmarking\n4. **Best practices sections**: Each document concludes with actionable best practices\n5. **Modern Go features**: Covers Go 1.18+ features like generics and fuzzing\n6. **Table-driven test patterns**: Excellent testing documentation with comprehensive patterns\n\n## What Needs Correction or Updating\n\n### Technical Inaccuracies:\n1. **String conversion without copy (performance.md:1315-1323)**: The unsafe string/byte conversions shown are dangerous and can lead to undefined behavior. Should warn about mutability issues\n2. **Deprecated directives**: Some compiler directives like `//go:inline` don't exist in Go - should be removed\n3. **Missing context on backwards compatibility**: Documentation promotes some patterns but the project explicitly avoids backwards compatibility\n\n## What's Missing\n\n### Critical Gaps:\n1. **shopspring/decimal usage patterns**: Despite being fundamental to the project, there's no documentation on decimal arithmetic patterns\n2. **Project-specific patterns**: Missing documentation on Big Meanie specific conventions like:\n   - Ultra-concise naming (sr not SupportResistance)\n   - No backwards compatibility philosophy\n   - Breaking changes approach\n3. **Architecture decisions**: No documentation on the actual project structure (`/pkg`, `/internal`, `.snippets`)\n4. **Database patterns**: No coverage of database interactions, migrations, or transaction patterns\n5. **Configuration management**: Missing environment variables, config files, and secrets management\n6. **API/HTTP patterns**: No REST API or HTTP server patterns documentation\n7. **Logging and monitoring**: No structured logging or observability patterns\n8. **Security patterns**: Missing input validation, authentication, authorization patterns\n\n## Inconsistencies Found\n\n1. **Interface naming**: Documentation suggests `-er` suffix for single-method interfaces, but actual code uses regular naming\n2. **Test patterns**: Documentation mentions avoiding `t.Skip()` but still shows examples using it\n3. **Package structure**: Documentation shows standard layout but actual project has `.snippets` directory not explained\n4. **Error handling**: Some examples don't follow the wrapped error pattern consistently\n\n## Specific Recommendations for Improvements\n\n### High Priority:\n1. **Create `decimal-patterns.md`**: Document shopspring/decimal usage, common patterns, and gotchas\n2. **Create `project-conventions.md`**: Document Big Meanie specific conventions and philosophy\n3. **Update `performance.md`**: Remove unsafe string conversions or add strong warnings\n4. **Create `database-patterns.md`**: Add PostgreSQL patterns, migrations, transactions\n\n### Medium Priority:\n1. **Add `security.md`**: Cover input validation, SQL injection prevention, crypto patterns\n2. **Add `api-patterns.md`**: REST conventions, middleware, error responses\n3. **Update examples**: Ensure all examples follow project conventions (no backwards compatibility, concise naming)\n4. **Add `configuration.md`**: Environment variables, config loading, secrets management\n\n### Low Priority:\n1. **Add more Big Meanie specific examples**: Replace generic examples with trading-specific ones\n2. **Cross-reference between documents**: Add links between related topics\n3. **Add troubleshooting sections**: Common pitfalls and how to debug them\n4. **Version information**: Note which Go version specific features require\n\n### Structure Improvements:\n1. Consider reorganizing into subdirectories:\n   - `fundamentals/` - Basic Go concepts\n   - `advanced/` - Performance, concurrency, optimization\n   - `project/` - Big Meanie specific patterns\n   - `patterns/` - Design patterns and architectures\n\n## Summary\n\nThe documentation provides a **solid foundation** for Go development with excellent coverage of language fundamentals, concurrency, and testing. However, it lacks project-specific guidance and some critical patterns for production systems. The code examples are high quality but could better reflect the actual project's philosophy and structure.\n\nThe most critical improvements needed are:\n1. Document shopspring/decimal patterns (essential for financial calculations)\n2. Document project-specific conventions and philosophy\n3. Add database and API patterns documentation\n4. Fix the unsafe string conversion examples\n\nWith these additions, the documentation would provide comprehensive guidance for both Go development in general and Big Meanie development specifically."}]}]},"uuid":"6731000a-46c6-460e-9863-baeadc8cd1f5","timestamp":"2025-08-13T10:00:44.848Z","toolUseResult":{"content":[{"type":"text","text":"Based on my comprehensive review of the documentation files in `/home/aural/Code/bigmeanie/back/.docs/code/`, here's my analysis:\n\n## Overall Assessment\n\nThe documentation is **well-structured and comprehensive**, covering essential Go development topics with practical examples. The quality is generally high, but there are some gaps and areas for improvement.\n\n## What's Accurate and Well-Documented\n\n### Strengths:\n1. **Excellent coverage of core Go concepts**: The fundamentals, concurrency, testing, and error handling documents are thorough and accurate\n2. **Practical code examples**: Every concept is illustrated with working code examples\n3. **Performance-focused**: Good emphasis on optimization, profiling, and benchmarking\n4. **Best practices sections**: Each document concludes with actionable best practices\n5. **Modern Go features**: Covers Go 1.18+ features like generics and fuzzing\n6. **Table-driven test patterns**: Excellent testing documentation with comprehensive patterns\n\n## What Needs Correction or Updating\n\n### Technical Inaccuracies:\n1. **String conversion without copy (performance.md:1315-1323)**: The unsafe string/byte conversions shown are dangerous and can lead to undefined behavior. Should warn about mutability issues\n2. **Deprecated directives**: Some compiler directives like `//go:inline` don't exist in Go - should be removed\n3. **Missing context on backwards compatibility**: Documentation promotes some patterns but the project explicitly avoids backwards compatibility\n\n## What's Missing\n\n### Critical Gaps:\n1. **shopspring/decimal usage patterns**: Despite being fundamental to the project, there's no documentation on decimal arithmetic patterns\n2. **Project-specific patterns**: Missing documentation on Big Meanie specific conventions like:\n   - Ultra-concise naming (sr not SupportResistance)\n   - No backwards compatibility philosophy\n   - Breaking changes approach\n3. **Architecture decisions**: No documentation on the actual project structure (`/pkg`, `/internal`, `.snippets`)\n4. **Database patterns**: No coverage of database interactions, migrations, or transaction patterns\n5. **Configuration management**: Missing environment variables, config files, and secrets management\n6. **API/HTTP patterns**: No REST API or HTTP server patterns documentation\n7. **Logging and monitoring**: No structured logging or observability patterns\n8. **Security patterns**: Missing input validation, authentication, authorization patterns\n\n## Inconsistencies Found\n\n1. **Interface naming**: Documentation suggests `-er` suffix for single-method interfaces, but actual code uses regular naming\n2. **Test patterns**: Documentation mentions avoiding `t.Skip()` but still shows examples using it\n3. **Package structure**: Documentation shows standard layout but actual project has `.snippets` directory not explained\n4. **Error handling**: Some examples don't follow the wrapped error pattern consistently\n\n## Specific Recommendations for Improvements\n\n### High Priority:\n1. **Create `decimal-patterns.md`**: Document shopspring/decimal usage, common patterns, and gotchas\n2. **Create `project-conventions.md`**: Document Big Meanie specific conventions and philosophy\n3. **Update `performance.md`**: Remove unsafe string conversions or add strong warnings\n4. **Create `database-patterns.md`**: Add PostgreSQL patterns, migrations, transactions\n\n### Medium Priority:\n1. **Add `security.md`**: Cover input validation, SQL injection prevention, crypto patterns\n2. **Add `api-patterns.md`**: REST conventions, middleware, error responses\n3. **Update examples**: Ensure all examples follow project conventions (no backwards compatibility, concise naming)\n4. **Add `configuration.md`**: Environment variables, config loading, secrets management\n\n### Low Priority:\n1. **Add more Big Meanie specific examples**: Replace generic examples with trading-specific ones\n2. **Cross-reference between documents**: Add links between related topics\n3. **Add troubleshooting sections**: Common pitfalls and how to debug them\n4. **Version information**: Note which Go version specific features require\n\n### Structure Improvements:\n1. Consider reorganizing into subdirectories:\n   - `fundamentals/` - Basic Go concepts\n   - `advanced/` - Performance, concurrency, optimization\n   - `project/` - Big Meanie specific patterns\n   - `patterns/` - Design patterns and architectures\n\n## Summary\n\nThe documentation provides a **solid foundation** for Go development with excellent coverage of language fundamentals, concurrency, and testing. However, it lacks project-specific guidance and some critical patterns for production systems. The code examples are high quality but could better reflect the actual project's philosophy and structure.\n\nThe most critical improvements needed are:\n1. Document shopspring/decimal patterns (essential for financial calculations)\n2. Document project-specific conventions and philosophy\n3. Add database and API patterns documentation\n4. Fix the unsafe string conversion examples\n\nWith these additions, the documentation would provide comprehensive guidance for both Go development in general and Big Meanie development specifically."}],"totalDurationMs":117908,"totalTokens":94656,"totalToolUseCount":16,"usage":{"input_tokens":6,"cache_creation_input_tokens":418,"cache_read_input_tokens":93136,"output_tokens":1096,"service_tier":"standard"}}}
{"parentUuid":"6731000a-46c6-460e-9863-baeadc8cd1f5","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01K4Nebxc7hcoGPCe9p3VPnz","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"The god agent has completed a thorough review of the code documentation. Here's the summary:\n\n## Key Findings\n\n**Strengths:**\n- Comprehensive coverage of Go fundamentals, concurrency, testing, and error handling\n- Excellent practical code examples throughout\n- Strong focus on performance and optimization\n- Modern Go features (generics, fuzzing) are well-documented\n\n**Critical Issues to Fix:**\n1. **Unsafe string conversions** in performance.md are dangerous and need warnings\n2. **Missing shopspring/decimal documentation** - critical for the trading system\n3. **No project-specific conventions** documented (ultra-concise naming, no backwards compatibility)\n4. **Missing database patterns** documentation\n5. **No API/HTTP patterns** coverage\n\n**Major Gaps:**\n- Configuration management patterns\n- Security patterns (validation, auth)\n- Logging and monitoring\n- Project architecture explanation\n\n**Recommendations:**\n1. Create `decimal-patterns.md` for shopspring/decimal usage\n2. Create `project-conventions.md` for Big Meanie specific rules\n3. Fix unsafe code examples in performance.md\n4. Add database, API, and security documentation\n5. Consider reorganizing docs into subdirectories by topic\n\nThe documentation is solid for general Go development but needs project-specific additions to fully support Big Meanie development."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":1355,"cache_read_input_tokens":36355,"output_tokens":298,"service_tier":"standard"}},"requestId":"req_011CS5Wp5QNxE1xvJ29cCWjq","type":"assistant","uuid":"4ab021ee-3309-44c4-98ed-024cc498fce7","timestamp":"2025-08-13T10:00:56.594Z"}
{"parentUuid":"4ab021ee-3309-44c4-98ed-024cc498fce7","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"system","content":"\u001b[1mStop\u001b[22m [paplay /run/current-system/sw/share/sounds/freedesktop/stereo/bell.oga] completed successfully","isMeta":false,"timestamp":"2025-08-13T10:00:56.897Z","uuid":"69ea8e2a-5108-411b-b794-704110d55293","toolUseID":"a976c9b5-d720-404e-9630-9653f69334e0","level":"info"}
{"parentUuid":"69ea8e2a-5108-411b-b794-704110d55293","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":"/god proceed"},"uuid":"c8b6f48a-6132-4774-b811-4ba3f06b9e15","timestamp":"2025-08-13T10:02:38.455Z"}
{"parentUuid":"c8b6f48a-6132-4774-b811-4ba3f06b9e15","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_014CPicekU24rX92qs8scxT1","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"I'll use the god agent to implement the critical documentation improvements identified in the review."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":307,"cache_read_input_tokens":37710,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CS5WxT84PXmCBJYoBBQqx","type":"assistant","uuid":"8753ab8c-df13-4f84-b77c-dee4f381bbe3","timestamp":"2025-08-13T10:02:41.771Z"}
{"parentUuid":"8753ab8c-df13-4f84-b77c-dee4f381bbe3","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_014CPicekU24rX92qs8scxT1","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_012QySe4Ynt1ZdfXqFKwCs6d","name":"TodoWrite","input":{"todos":[{"id":"1","content":"Create decimal-patterns.md for shopspring/decimal usage","status":"pending"},{"id":"2","content":"Create project-conventions.md for Big Meanie specific rules","status":"pending"},{"id":"3","content":"Fix unsafe string conversions in performance.md","status":"pending"},{"id":"4","content":"Create database-patterns.md for PostgreSQL patterns","status":"pending"},{"id":"5","content":"Create api-patterns.md for REST/HTTP patterns","status":"pending"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":307,"cache_read_input_tokens":37710,"output_tokens":272,"service_tier":"standard"}},"requestId":"req_011CS5WxT84PXmCBJYoBBQqx","type":"assistant","uuid":"be140612-5e19-4a93-bca4-d285a6a53f4f","timestamp":"2025-08-13T10:02:47.624Z"}
{"parentUuid":"be140612-5e19-4a93-bca4-d285a6a53f4f","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012QySe4Ynt1ZdfXqFKwCs6d","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"6e8a7635-f64b-4a20-a23b-48acc74c93db","timestamp":"2025-08-13T10:02:47.650Z","toolUseResult":{"oldTodos":[],"newTodos":[{"content":"Create decimal-patterns.md for shopspring/decimal usage","status":"pending","id":"1"},{"content":"Create project-conventions.md for Big Meanie specific rules","status":"pending","id":"2"},{"content":"Fix unsafe string conversions in performance.md","status":"pending","id":"3"},{"content":"Create database-patterns.md for PostgreSQL patterns","status":"pending","id":"4"},{"content":"Create api-patterns.md for REST/HTTP patterns","status":"pending","id":"5"}]}}
{"parentUuid":"6e8a7635-f64b-4a20-a23b-48acc74c93db","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01Fn4niSpoMSirozpaa8zcua","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01CJmLRo2SqvZBsrD9WE6dW6","name":"Task","input":{"description":"Implement doc improvements","prompt":"Implement the critical documentation improvements for the Big Meanie project. You need to:\n\n1. Create `/home/aural/Code/bigmeanie/back/.docs/code/decimal-patterns.md` - Document shopspring/decimal usage patterns, common operations, gotchas, and best practices for financial calculations in the trading system\n\n2. Create `/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md` - Document Big Meanie specific conventions including:\n   - Ultra-concise naming (sr not SupportResistance)\n   - No backwards compatibility philosophy\n   - Breaking changes approach\n   - Project structure explanation\n   - File management rules (no variant files)\n\n3. Fix the unsafe string conversions in `/home/aural/Code/bigmeanie/back/.docs/code/performance.md` - Add strong warnings or remove the dangerous examples\n\n4. Create `/home/aural/Code/bigmeanie/back/.docs/code/database-patterns.md` - Document PostgreSQL patterns, migrations, transactions, and connection management\n\n5. Create `/home/aural/Code/bigmeanie/back/.docs/code/api-patterns.md` - Document REST conventions, middleware patterns, error responses, and HTTP server patterns\n\nFocus on practical, Big Meanie-specific examples that align with the project's trading system goals. Ensure all documentation follows the project's philosophy of no backwards compatibility and ultra-concise naming.","subagent_type":"god"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":420,"cache_read_input_tokens":38017,"output_tokens":414,"service_tier":"standard"}},"requestId":"req_011CS5Wy9au7f8TzrkX17koN","type":"assistant","uuid":"e9cb45f0-4348-4c87-bfec-59c259eb508e","timestamp":"2025-08-13T10:03:01.119Z"}
{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":"Implement the critical documentation improvements for the Big Meanie project. You need to:\n\n1. Create `/home/aural/Code/bigmeanie/back/.docs/code/decimal-patterns.md` - Document shopspring/decimal usage patterns, common operations, gotchas, and best practices for financial calculations in the trading system\n\n2. Create `/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md` - Document Big Meanie specific conventions including:\n   - Ultra-concise naming (sr not SupportResistance)\n   - No backwards compatibility philosophy\n   - Breaking changes approach\n   - Project structure explanation\n   - File management rules (no variant files)\n\n3. Fix the unsafe string conversions in `/home/aural/Code/bigmeanie/back/.docs/code/performance.md` - Add strong warnings or remove the dangerous examples\n\n4. Create `/home/aural/Code/bigmeanie/back/.docs/code/database-patterns.md` - Document PostgreSQL patterns, migrations, transactions, and connection management\n\n5. Create `/home/aural/Code/bigmeanie/back/.docs/code/api-patterns.md` - Document REST conventions, middleware patterns, error responses, and HTTP server patterns\n\nFocus on practical, Big Meanie-specific examples that align with the project's trading system goals. Ensure all documentation follows the project's philosophy of no backwards compatibility and ultra-concise naming."},"uuid":"049bfdd5-991d-49e3-9342-32a977eac237","timestamp":"2025-08-13T10:03:01.141Z"}
{"parentUuid":"049bfdd5-991d-49e3-9342-32a977eac237","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01NPvUrHxGphUFPbYTyy62G5","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"I'll implement these critical documentation improvements for the Big Meanie project. Let me start by examining the existing documentation structure and then create the required files."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":1749,"cache_read_input_tokens":30920,"output_tokens":99,"service_tier":"standard"}},"requestId":"req_011CS5Wz7mHTYEp5ejA5ZjFK","type":"assistant","uuid":"eacdd8ce-4ffb-45bf-89d8-15ef1de85901","timestamp":"2025-08-13T10:03:04.161Z"}
{"parentUuid":"eacdd8ce-4ffb-45bf-89d8-15ef1de85901","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01NPvUrHxGphUFPbYTyy62G5","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01XSXRuTpxgicUvx36cixW1A","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":1749,"cache_read_input_tokens":30920,"output_tokens":99,"service_tier":"standard"}},"requestId":"req_011CS5Wz7mHTYEp5ejA5ZjFK","type":"assistant","uuid":"f193bc51-419f-4182-ac78-f8a5419c0f12","timestamp":"2025-08-13T10:03:04.985Z"}
{"parentUuid":"f193bc51-419f-4182-ac78-f8a5419c0f12","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"EISDIR: illegal operation on a directory, read","is_error":true,"tool_use_id":"toolu_01XSXRuTpxgicUvx36cixW1A"}]},"uuid":"45f57d93-1f7f-4adf-93ca-d772f3d70fd5","timestamp":"2025-08-13T10:03:05.005Z","toolUseResult":"Error: EISDIR: illegal operation on a directory, read"}
{"parentUuid":"45f57d93-1f7f-4adf-93ca-d772f3d70fd5","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01BGpbc3vdXGkuJviSnxYvaU","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_016onEucuwsZZ4A6s7zYefLu","name":"Bash","input":{"command":"ls -la /home/aural/Code/bigmeanie/back/.docs/code/","description":"List contents of code documentation directory"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":126,"cache_read_input_tokens":32669,"output_tokens":94,"service_tier":"standard"}},"requestId":"req_011CS5WzQhm6L5bTkmEYnnqS","type":"assistant","uuid":"d2edc5c2-e716-4fb1-b046-221292056495","timestamp":"2025-08-13T10:03:09.010Z"}
{"parentUuid":"d2edc5c2-e716-4fb1-b046-221292056495","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"/run/current-system/sw/bin/bash: line 1: /tmp/claude-3278-cwd: Permission denied\n\ntotal 264\ndrwxr-xr-x 2 aural users  4096 Aug 13 04:57 .\ndrwxr-xr-x 7 aural users  4096 Aug 13 05:01 ..\n-rw-r--r-- 1 aural users 32605 Aug 13 02:14 concurrency.md\n-rw-r--r-- 1 aural users 60418 Aug 13 03:32 design-patterns.md\n-rw-r--r-- 1 aural users 31345 Aug 13 02:30 errors.md\n-rw-r--r-- 1 aural users 40287 Aug 13 02:53 fundamentals.md\n-rw-r--r-- 1 aural users 25562 Aug 13 02:27 packages.md\n-rw-r--r-- 1 aural users 29299 Aug 13 02:25 performance.md\n-rw-r--r-- 1 aural users 30742 Aug 13 02:22 testing.md","is_error":true,"tool_use_id":"toolu_016onEucuwsZZ4A6s7zYefLu"}]},"uuid":"a2596a73-b4c4-44f6-88a3-fb2b8d77f22a","timestamp":"2025-08-13T10:03:09.045Z","toolUseResult":"Error: /run/current-system/sw/bin/bash: line 1: /tmp/claude-3278-cwd: Permission denied\n\ntotal 264\ndrwxr-xr-x 2 aural users  4096 Aug 13 04:57 .\ndrwxr-xr-x 7 aural users  4096 Aug 13 05:01 ..\n-rw-r--r-- 1 aural users 32605 Aug 13 02:14 concurrency.md\n-rw-r--r-- 1 aural users 60418 Aug 13 03:32 design-patterns.md\n-rw-r--r-- 1 aural users 31345 Aug 13 02:30 errors.md\n-rw-r--r-- 1 aural users 40287 Aug 13 02:53 fundamentals.md\n-rw-r--r-- 1 aural users 25562 Aug 13 02:27 packages.md\n-rw-r--r-- 1 aural users 29299 Aug 13 02:25 performance.md\n-rw-r--r-- 1 aural users 30742 Aug 13 02:22 testing.md"}
{"parentUuid":"a2596a73-b4c4-44f6-88a3-fb2b8d77f22a","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01KVNGHtREMrYkCVAkD16EhY","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Now let me read the existing performance.md to identify the unsafe string conversions that need fixing:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":419,"cache_read_input_tokens":32795,"output_tokens":94,"service_tier":"standard"}},"requestId":"req_011CS5WzhLtBzTkjYaDY1dD2","type":"assistant","uuid":"96c3483e-8553-49ea-bf05-c0d82630406e","timestamp":"2025-08-13T10:03:12.172Z"}
{"parentUuid":"96c3483e-8553-49ea-bf05-c0d82630406e","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01KVNGHtREMrYkCVAkD16EhY","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01WHek9zamvH8M7J5GrzPbMU","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/performance.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":419,"cache_read_input_tokens":32795,"output_tokens":94,"service_tier":"standard"}},"requestId":"req_011CS5WzhLtBzTkjYaDY1dD2","type":"assistant","uuid":"7e8a1ff3-a8b8-4d91-80ed-cddc129d447d","timestamp":"2025-08-13T10:03:12.785Z"}
{"parentUuid":"7e8a1ff3-a8b8-4d91-80ed-cddc129d447d","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WHek9zamvH8M7J5GrzPbMU","type":"tool_result","content":"     1→# Go Performance - Optimization Mastery\n     2→\n     3→## Table of Contents\n     4→1. [Profiling](#profiling)\n     5→2. [Benchmarking](#benchmarking)\n     6→3. [Memory Management](#memory-management)\n     7→4. [CPU Optimization](#cpu-optimization)\n     8→5. [Compiler Optimizations](#compiler-optimizations)\n     9→6. [Caching Strategies](#caching-strategies)\n    10→7. [Concurrency Performance](#concurrency-performance)\n    11→8. [I/O Optimization](#io-optimization)\n    12→9. [Data Structure Optimization](#data-structure-optimization)\n    13→10. [Performance Best Practices](#performance-best-practices)\n    14→\n    15→## Profiling\n    16→\n    17→### CPU Profiling\n    18→```go\n    19→import (\n    20→    \"runtime/pprof\"\n    21→    \"os\"\n    22→    \"runtime\"\n    23→)\n    24→\n    25→// Basic CPU profiling\n    26→func main() {\n    27→    // Create CPU profile file\n    28→    f, err := os.Create(\"cpu.prof\")\n    29→    if err != nil {\n    30→        log.Fatal(err)\n    31→    }\n    32→    defer f.Close()\n    33→    \n    34→    // Start CPU profiling\n    35→    if err := pprof.StartCPUProfile(f); err != nil {\n    36→        log.Fatal(err)\n    37→    }\n    38→    defer pprof.StopCPUProfile()\n    39→    \n    40→    // Your application code\n    41→    runApplication()\n    42→}\n    43→\n    44→// HTTP profiling server\n    45→import _ \"net/http/pprof\"\n    46→\n    47→func main() {\n    48→    go func() {\n    49→        log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n    50→    }()\n    51→    \n    52→    // Your application code\n    53→    runApplication()\n    54→}\n    55→\n    56→// Analyze profiles:\n    57→// go tool pprof cpu.prof\n    58→// go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n    59→// go tool pprof -http=:8080 cpu.prof  # Web interface\n    60→\n    61→// Profile with benchmarks\n    62→func BenchmarkFunction(b *testing.B) {\n    63→    // Start profiling in benchmark\n    64→    f, _ := os.Create(\"bench.prof\")\n    65→    pprof.StartCPUProfile(f)\n    66→    defer pprof.StopCPUProfile()\n    67→    \n    68→    for i := 0; i < b.N; i++ {\n    69→        FunctionToProfile()\n    70→    }\n    71→}\n    72→```\n    73→\n    74→### Memory Profiling\n    75→```go\n    76→// Memory profiling\n    77→func writeMemProfile() {\n    78→    f, err := os.Create(\"mem.prof\")\n    79→    if err != nil {\n    80→        log.Fatal(err)\n    81→    }\n    82→    defer f.Close()\n    83→    \n    84→    runtime.GC() // Force GC before profiling\n    85→    if err := pprof.WriteHeapProfile(f); err != nil {\n    86→        log.Fatal(err)\n    87→    }\n    88→}\n    89→\n    90→// Allocation profiling\n    91→func writeAllocProfile() {\n    92→    f, err := os.Create(\"alloc.prof\")\n    93→    if err != nil {\n    94→        log.Fatal(err)\n    95→    }\n    96→    defer f.Close()\n    97→    \n    98→    // Profile allocations\n    99→    runtime.MemProfileRate = 1 // Profile every allocation\n   100→    defer func() { runtime.MemProfileRate = 512 * 1024 }() // Reset\n   101→    \n   102→    // Run code\n   103→    runApplication()\n   104→    \n   105→    pprof.Lookup(\"allocs\").WriteTo(f, 0)\n   106→}\n   107→\n   108→// Memory stats\n   109→func printMemStats() {\n   110→    var m runtime.MemStats\n   111→    runtime.ReadMemStats(&m)\n   112→    \n   113→    fmt.Printf(\"Alloc = %v MB\", m.Alloc / 1024 / 1024)\n   114→    fmt.Printf(\"TotalAlloc = %v MB\", m.TotalAlloc / 1024 / 1024)\n   115→    fmt.Printf(\"Sys = %v MB\", m.Sys / 1024 / 1024)\n   116→    fmt.Printf(\"NumGC = %v\\n\", m.NumGC)\n   117→    fmt.Printf(\"HeapAlloc = %v MB\", m.HeapAlloc / 1024 / 1024)\n   118→    fmt.Printf(\"HeapObjects = %v\", m.HeapObjects)\n   119→}\n   120→\n   121→// Track allocations in specific code\n   122→func trackAllocations() {\n   123→    var m1, m2 runtime.MemStats\n   124→    \n   125→    runtime.ReadMemStats(&m1)\n   126→    \n   127→    // Code to measure\n   128→    expensiveOperation()\n   129→    \n   130→    runtime.ReadMemStats(&m2)\n   131→    \n   132→    fmt.Printf(\"Allocated: %d bytes\\n\", m2.Alloc - m1.Alloc)\n   133→    fmt.Printf(\"Total Allocated: %d bytes\\n\", m2.TotalAlloc - m1.TotalAlloc)\n   134→    fmt.Printf(\"Number of allocations: %d\\n\", m2.Mallocs - m1.Mallocs)\n   135→}\n   136→```\n   137→\n   138→### Goroutine Profiling\n   139→```go\n   140→// Goroutine profiling\n   141→func writeGoroutineProfile() {\n   142→    f, err := os.Create(\"goroutine.prof\")\n   143→    if err != nil {\n   144→        log.Fatal(err)\n   145→    }\n   146→    defer f.Close()\n   147→    \n   148→    pprof.Lookup(\"goroutine\").WriteTo(f, 1)\n   149→}\n   150→\n   151→// Monitor goroutine count\n   152→func monitorGoroutines() {\n   153→    ticker := time.NewTicker(1 * time.Second)\n   154→    defer ticker.Stop()\n   155→    \n   156→    for range ticker.C {\n   157→        fmt.Printf(\"Goroutines: %d\\n\", runtime.NumGoroutine())\n   158→    }\n   159→}\n   160→\n   161→// Block profiling (mutex contention)\n   162→func enableBlockProfiling() {\n   163→    runtime.SetBlockProfileRate(1)\n   164→    defer runtime.SetBlockProfileRate(0)\n   165→    \n   166→    // Run application\n   167→    runApplication()\n   168→    \n   169→    f, _ := os.Create(\"block.prof\")\n   170→    defer f.Close()\n   171→    pprof.Lookup(\"block\").WriteTo(f, 0)\n   172→}\n   173→\n   174→// Mutex profiling\n   175→func enableMutexProfiling() {\n   176→    runtime.SetMutexProfileFraction(1)\n   177→    defer runtime.SetMutexProfileFraction(0)\n   178→    \n   179→    // Run application\n   180→    runApplication()\n   181→    \n   182→    f, _ := os.Create(\"mutex.prof\")\n   183→    defer f.Close()\n   184→    pprof.Lookup(\"mutex\").WriteTo(f, 0)\n   185→}\n   186→```\n   187→\n   188→### Trace Profiling\n   189→```go\n   190→import \"runtime/trace\"\n   191→\n   192→// Execution tracing\n   193→func main() {\n   194→    f, err := os.Create(\"trace.out\")\n   195→    if err != nil {\n   196→        log.Fatal(err)\n   197→    }\n   198→    defer f.Close()\n   199→    \n   200→    err = trace.Start(f)\n   201→    if err != nil {\n   202→        log.Fatal(err)\n   203→    }\n   204→    defer trace.Stop()\n   205→    \n   206→    // Your application\n   207→    runApplication()\n   208→}\n   209→\n   210→// Analyze: go tool trace trace.out\n   211→\n   212→// Custom trace regions\n   213→func processRequest(ctx context.Context) {\n   214→    defer trace.StartRegion(ctx, \"processRequest\").End()\n   215→    \n   216→    trace.WithRegion(ctx, \"validate\", func() {\n   217→        validateInput()\n   218→    })\n   219→    \n   220→    trace.WithRegion(ctx, \"compute\", func() {\n   221→        computeResult()\n   222→    })\n   223→    \n   224→    trace.WithRegion(ctx, \"respond\", func() {\n   225→        sendResponse()\n   226→    })\n   227→}\n   228→\n   229→// Trace logging\n   230→func traceLog(ctx context.Context, message string) {\n   231→    trace.Log(ctx, \"app\", message)\n   232→}\n   233→```\n   234→\n   235→## Benchmarking\n   236→\n   237→### Advanced Benchmarking\n   238→```go\n   239→// Benchmark with different inputs\n   240→func BenchmarkSort(b *testing.B) {\n   241→    sizes := []int{10, 100, 1000, 10000}\n   242→    \n   243→    for _, size := range sizes {\n   244→        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n   245→            data := generateRandomSlice(size)\n   246→            \n   247→            b.ResetTimer()\n   248→            for i := 0; i < b.N; i++ {\n   249→                b.StopTimer()\n   250→                tmp := make([]int, len(data))\n   251→                copy(tmp, data)\n   252→                b.StartTimer()\n   253→                \n   254→                sort.Ints(tmp)\n   255→            }\n   256→        })\n   257→    }\n   258→}\n   259→\n   260→// Comparative benchmarks\n   261→func BenchmarkStringBuilding(b *testing.B) {\n   262→    strs := []string{\"hello\", \"world\", \"foo\", \"bar\", \"baz\"}\n   263→    \n   264→    b.Run(\"Concatenation\", func(b *testing.B) {\n   265→        for i := 0; i < b.N; i++ {\n   266→            var result string\n   267→            for _, s := range strs {\n   268→                result += s\n   269→            }\n   270→        }\n   271→    })\n   272→    \n   273→    b.Run(\"StringBuilder\", func(b *testing.B) {\n   274→        for i := 0; i < b.N; i++ {\n   275→            var builder strings.Builder\n   276→            for _, s := range strs {\n   277→                builder.WriteString(s)\n   278→            }\n   279→            _ = builder.String()\n   280→        }\n   281→    })\n   282→    \n   283→    b.Run(\"BytesBuffer\", func(b *testing.B) {\n   284→        for i := 0; i < b.N; i++ {\n   285→            var buffer bytes.Buffer\n   286→            for _, s := range strs {\n   287→                buffer.WriteString(s)\n   288→            }\n   289→            _ = buffer.String()\n   290→        }\n   291→    })\n   292→    \n   293→    b.Run(\"Join\", func(b *testing.B) {\n   294→        for i := 0; i < b.N; i++ {\n   295→            _ = strings.Join(strs, \"\")\n   296→        }\n   297→    })\n   298→}\n   299→\n   300→// Memory benchmarks\n   301→func BenchmarkMemory(b *testing.B) {\n   302→    b.Run(\"WithAllocation\", func(b *testing.B) {\n   303→        b.ReportAllocs()\n   304→        for i := 0; i < b.N; i++ {\n   305→            s := make([]int, 1000)\n   306→            _ = s\n   307→        }\n   308→    })\n   309→    \n   310→    b.Run(\"WithPool\", func(b *testing.B) {\n   311→        b.ReportAllocs()\n   312→        pool := sync.Pool{\n   313→            New: func() interface{} {\n   314→                return make([]int, 1000)\n   315→            },\n   316→        }\n   317→        \n   318→        for i := 0; i < b.N; i++ {\n   319→            s := pool.Get().([]int)\n   320→            pool.Put(s)\n   321→        }\n   322→    })\n   323→}\n   324→\n   325→// Custom metrics\n   326→func BenchmarkThroughput(b *testing.B) {\n   327→    data := make([]byte, 1024*1024) // 1MB\n   328→    \n   329→    b.SetBytes(int64(len(data)))\n   330→    b.ResetTimer()\n   331→    \n   332→    for i := 0; i < b.N; i++ {\n   333→        process(data)\n   334→    }\n   335→    \n   336→    b.ReportMetric(float64(b.N)*float64(len(data))/b.Elapsed().Seconds()/1024/1024, \"MB/s\")\n   337→}\n   338→```\n   339→\n   340→## Memory Management\n   341→\n   342→### Reducing Allocations\n   343→```go\n   344→// Avoid allocations in loops\n   345→// Bad: Allocates in loop\n   346→func bad() []string {\n   347→    var results []string\n   348→    for i := 0; i < 1000; i++ {\n   349→        results = append(results, fmt.Sprintf(\"item-%d\", i))\n   350→    }\n   351→    return results\n   352→}\n   353→\n   354→// Good: Preallocate\n   355→func good() []string {\n   356→    results := make([]string, 0, 1000)\n   357→    for i := 0; i < 1000; i++ {\n   358→        results = append(results, fmt.Sprintf(\"item-%d\", i))\n   359→    }\n   360→    return results\n   361→}\n   362→\n   363→// Reuse buffers\n   364→var bufferPool = sync.Pool{\n   365→    New: func() interface{} {\n   366→        return new(bytes.Buffer)\n   367→    },\n   368→}\n   369→\n   370→func processWithPool(data []byte) string {\n   371→    buf := bufferPool.Get().(*bytes.Buffer)\n   372→    defer func() {\n   373→        buf.Reset()\n   374→        bufferPool.Put(buf)\n   375→    }()\n   376→    \n   377→    buf.Write(data)\n   378→    // Process...\n   379→    return buf.String()\n   380→}\n   381→\n   382→// Avoid string allocations\n   383→func avoidStringAllocs(b []byte) string {\n   384→    // Bad: Multiple allocations\n   385→    s := string(b)\n   386→    s = strings.ToUpper(s)\n   387→    s = strings.TrimSpace(s)\n   388→    \n   389→    // Better: Work with bytes\n   390→    b = bytes.ToUpper(b)\n   391→    b = bytes.TrimSpace(b)\n   392→    return string(b)\n   393→}\n   394→\n   395→// String interning for repeated strings\n   396→type StringInterner struct {\n   397→    mu    sync.RWMutex\n   398→    cache map[string]string\n   399→}\n   400→\n   401→func (si *StringInterner) Intern(s string) string {\n   402→    si.mu.RLock()\n   403→    if interned, ok := si.cache[s]; ok {\n   404→        si.mu.RUnlock()\n   405→        return interned\n   406→    }\n   407→    si.mu.RUnlock()\n   408→    \n   409→    si.mu.Lock()\n   410→    defer si.mu.Unlock()\n   411→    \n   412→    si.cache[s] = s\n   413→    return s\n   414→}\n   415→```\n   416→\n   417→### Memory Layout Optimization\n   418→```go\n   419→// Struct field alignment\n   420→// Bad: 32 bytes due to padding\n   421→type Inefficient struct {\n   422→    a bool    // 1 byte + 7 padding\n   423→    b int64   // 8 bytes\n   424→    c bool    // 1 byte + 7 padding\n   425→    d int64   // 8 bytes\n   426→}\n   427→\n   428→// Good: 24 bytes with better alignment\n   429→type Efficient struct {\n   430→    b int64   // 8 bytes\n   431→    d int64   // 8 bytes\n   432→    a bool    // 1 byte\n   433→    c bool    // 1 byte + 6 padding\n   434→}\n   435→\n   436→// Use smaller types when possible\n   437→type Flags struct {\n   438→    // Bad: 4 bools = potentially 4 bytes + padding\n   439→    IsActive   bool\n   440→    IsVerified bool\n   441→    IsPremium  bool\n   442→    IsAdmin    bool\n   443→}\n   444→\n   445→// Good: 1 byte using bit flags\n   446→type CompactFlags uint8\n   447→\n   448→const (\n   449→    FlagActive CompactFlags = 1 << iota\n   450→    FlagVerified\n   451→    FlagPremium\n   452→    FlagAdmin\n   453→)\n   454→\n   455→func (f CompactFlags) IsActive() bool { return f&FlagActive != 0 }\n   456→func (f CompactFlags) IsVerified() bool { return f&FlagVerified != 0 }\n   457→\n   458→// Array vs slice for fixed size\n   459→type Record struct {\n   460→    // Bad: slice has 24 bytes overhead (pointer, len, cap)\n   461→    IDSlice []byte\n   462→    \n   463→    // Good: array for fixed size, no overhead\n   464→    IDArray [16]byte\n   465→}\n   466→```\n   467→\n   468→### Escape Analysis\n   469→```go\n   470→// Understanding escape analysis\n   471→// go build -gcflags=\"-m\" to see escape analysis\n   472→\n   473→// Doesn't escape - allocated on stack\n   474→func noEscape() int {\n   475→    x := 42\n   476→    return x\n   477→}\n   478→\n   479→// Escapes to heap - returned pointer\n   480→func escapes() *int {\n   481→    x := 42\n   482→    return &x // x escapes to heap\n   483→}\n   484→\n   485→// Avoid unnecessary escapes\n   486→type Data struct {\n   487→    values [1000]int\n   488→}\n   489→\n   490→// Bad: Escapes to heap\n   491→func (d *Data) Sum() int {\n   492→    sum := 0\n   493→    for _, v := range d.values { // d.values escapes\n   494→        sum += v\n   495→    }\n   496→    return sum\n   497→}\n   498→\n   499→// Good: Doesn't escape\n   500→func (d Data) SumValue() int {\n   501→    sum := 0\n   502→    for i := 0; i < len(d.values); i++ {\n   503→        sum += d.values[i]\n   504→    }\n   505→    return sum\n   506→}\n   507→\n   508→// Interface causes escape\n   509→func processInterface(i interface{}) {\n   510→    // i escapes to heap\n   511→}\n   512→\n   513→func avoidEscape() {\n   514→    x := 42\n   515→    processInterface(x) // x escapes\n   516→    \n   517→    // Avoid by not using interface\n   518→    processInt(x) // x doesn't escape\n   519→}\n   520→\n   521→func processInt(i int) {\n   522→    // Process int directly\n   523→}\n   524→```\n   525→\n   526→## CPU Optimization\n   527→\n   528→### Hot Path Optimization\n   529→```go\n   530→// Optimize hot paths\n   531→func processData(data []int) int {\n   532→    // Move invariants out of loop\n   533→    length := len(data)\n   534→    if length == 0 {\n   535→        return 0\n   536→    }\n   537→    \n   538→    sum := 0\n   539→    // Unroll loop for better performance\n   540→    for i := 0; i < length-3; i += 4 {\n   541→        sum += data[i] + data[i+1] + data[i+2] + data[i+3]\n   542→    }\n   543→    \n   544→    // Handle remaining elements\n   545→    for i := length - length%4; i < length; i++ {\n   546→        sum += data[i]\n   547→    }\n   548→    \n   549→    return sum\n   550→}\n   551→\n   552→// Branch prediction optimization\n   553→func findMax(data []int) int {\n   554→    if len(data) == 0 {\n   555→        return 0\n   556→    }\n   557→    \n   558→    max := data[0]\n   559→    for i := 1; i < len(data); i++ {\n   560→        // Branchless max (may be faster)\n   561→        if data[i] > max {\n   562→            max = data[i]\n   563→        }\n   564→    }\n   565→    return max\n   566→}\n   567→\n   568→// Cache-friendly iteration\n   569→func sumMatrix(matrix [][]int) int {\n   570→    sum := 0\n   571→    // Row-major order (cache-friendly)\n   572→    for i := 0; i < len(matrix); i++ {\n   573→        for j := 0; j < len(matrix[i]); j++ {\n   574→            sum += matrix[i][j]\n   575→        }\n   576→    }\n   577→    return sum\n   578→}\n   579→\n   580→// SIMD-friendly code\n   581→func addSlices(a, b []float64) []float64 {\n   582→    result := make([]float64, len(a))\n   583→    \n   584→    // Compiler may vectorize this\n   585→    for i := range a {\n   586→        result[i] = a[i] + b[i]\n   587→    }\n   588→    \n   589→    return result\n   590→}\n   591→```\n   592→\n   593→### Inlining\n   594→```go\n   595→// Encourage inlining for small functions\n   596→//go:inline\n   597→func add(a, b int) int {\n   598→    return a + b\n   599→}\n   600→\n   601→// Prevent inlining for rarely used functions\n   602→//go:noinline\n   603→func rarelyUsedFunction() {\n   604→    // Complex logic\n   605→}\n   606→\n   607→// Check inlining decisions\n   608→// go build -gcflags=\"-m=2\"\n   609→\n   610→// Inline-friendly functions\n   611→func abs(x int) int {\n   612→    if x < 0 {\n   613→        return -x\n   614→    }\n   615→    return x\n   616→}\n   617→\n   618→// Too complex to inline (default threshold ~80 nodes)\n   619→func complexFunction(x int) int {\n   620→    // Many operations...\n   621→    return result\n   622→}\n   623→```\n   624→\n   625→## Compiler Optimizations\n   626→\n   627→### Compiler Directives\n   628→```go\n   629→// Bounds check elimination\n   630→func sumArray(arr []int) int {\n   631→    if len(arr) == 0 {\n   632→        return 0\n   633→    }\n   634→    \n   635→    sum := 0\n   636→    // Compiler can eliminate bounds checks\n   637→    for i := 0; i < len(arr); i++ {\n   638→        sum += arr[i]\n   639→    }\n   640→    return sum\n   641→}\n   642→\n   643→// Help compiler with hints\n   644→func process(data []byte) {\n   645→    // Tell compiler minimum length\n   646→    _ = data[3] // Bounds check once\n   647→    \n   648→    // Now these don't need bounds checks\n   649→    a := data[0]\n   650→    b := data[1]\n   651→    c := data[2]\n   652→    d := data[3]\n   653→    \n   654→    // Process a, b, c, d\n   655→}\n   656→\n   657→// Const propagation\n   658→const bufferSize = 1024\n   659→\n   660→func allocateBuffer() []byte {\n   661→    // Compiler knows size at compile time\n   662→    return make([]byte, bufferSize)\n   663→}\n   664→\n   665→// Dead code elimination\n   666→func example(debug bool) {\n   667→    if false { // Compiler removes this\n   668→        expensiveDebugOperation()\n   669→    }\n   670→    \n   671→    const debugMode = false\n   672→    if debugMode { // Also removed\n   673→        fmt.Println(\"Debug mode\")\n   674→    }\n   675→}\n   676→```\n   677→\n   678→### Build Flags\n   679→```go\n   680→// Build tags for optimization\n   681→//go:build !debug\n   682→\n   683→package main\n   684→\n   685→func log(msg string) {\n   686→    // No-op in release builds\n   687→}\n   688→\n   689→// Alternative file for debug builds\n   690→//go:build debug\n   691→\n   692→package main\n   693→\n   694→func log(msg string) {\n   695→    fmt.Println(msg)\n   696→}\n   697→\n   698→// Compile with optimizations\n   699→// go build -ldflags=\"-s -w\" # Strip debug info\n   700→// go build -tags release\n   701→// GOOS=linux GOARCH=amd64 go build # Cross-compile\n   702→```\n   703→\n   704→## Caching Strategies\n   705→\n   706→### In-Memory Caching\n   707→```go\n   708→// Simple cache with TTL\n   709→type Cache struct {\n   710→    mu      sync.RWMutex\n   711→    items   map[string]*cacheItem\n   712→    ttl     time.Duration\n   713→}\n   714→\n   715→type cacheItem struct {\n   716→    value      interface{}\n   717→    expiration time.Time\n   718→}\n   719→\n   720→func NewCache(ttl time.Duration) *Cache {\n   721→    c := &Cache{\n   722→        items: make(map[string]*cacheItem),\n   723→        ttl:   ttl,\n   724→    }\n   725→    go c.cleanup()\n   726→    return c\n   727→}\n   728→\n   729→func (c *Cache) Set(key string, value interface{}) {\n   730→    c.mu.Lock()\n   731→    defer c.mu.Unlock()\n   732→    \n   733→    c.items[key] = &cacheItem{\n   734→        value:      value,\n   735→        expiration: time.Now().Add(c.ttl),\n   736→    }\n   737→}\n   738→\n   739→func (c *Cache) Get(key string) (interface{}, bool) {\n   740→    c.mu.RLock()\n   741→    defer c.mu.RUnlock()\n   742→    \n   743→    item, found := c.items[key]\n   744→    if !found {\n   745→        return nil, false\n   746→    }\n   747→    \n   748→    if time.Now().After(item.expiration) {\n   749→        return nil, false\n   750→    }\n   751→    \n   752→    return item.value, true\n   753→}\n   754→\n   755→func (c *Cache) cleanup() {\n   756→    ticker := time.NewTicker(c.ttl / 2)\n   757→    defer ticker.Stop()\n   758→    \n   759→    for range ticker.C {\n   760→        c.mu.Lock()\n   761→        now := time.Now()\n   762→        for key, item := range c.items {\n   763→            if now.After(item.expiration) {\n   764→                delete(c.items, key)\n   765→            }\n   766→        }\n   767→        c.mu.Unlock()\n   768→    }\n   769→}\n   770→\n   771→// LRU Cache\n   772→type LRUCache struct {\n   773→    capacity int\n   774→    items    map[string]*list.Element\n   775→    order    *list.List\n   776→    mu       sync.Mutex\n   777→}\n   778→\n   779→type lruItem struct {\n   780→    key   string\n   781→    value interface{}\n   782→}\n   783→\n   784→func NewLRUCache(capacity int) *LRUCache {\n   785→    return &LRUCache{\n   786→        capacity: capacity,\n   787→        items:    make(map[string]*list.Element),\n   788→        order:    list.New(),\n   789→    }\n   790→}\n   791→\n   792→func (c *LRUCache) Get(key string) (interface{}, bool) {\n   793→    c.mu.Lock()\n   794→    defer c.mu.Unlock()\n   795→    \n   796→    if elem, ok := c.items[key]; ok {\n   797→        c.order.MoveToFront(elem)\n   798→        return elem.Value.(*lruItem).value, true\n   799→    }\n   800→    return nil, false\n   801→}\n   802→\n   803→func (c *LRUCache) Set(key string, value interface{}) {\n   804→    c.mu.Lock()\n   805→    defer c.mu.Unlock()\n   806→    \n   807→    if elem, ok := c.items[key]; ok {\n   808→        c.order.MoveToFront(elem)\n   809→        elem.Value.(*lruItem).value = value\n   810→        return\n   811→    }\n   812→    \n   813→    if c.order.Len() >= c.capacity {\n   814→        oldest := c.order.Back()\n   815→        if oldest != nil {\n   816→            c.order.Remove(oldest)\n   817→            delete(c.items, oldest.Value.(*lruItem).key)\n   818→        }\n   819→    }\n   820→    \n   821→    item := &lruItem{key: key, value: value}\n   822→    elem := c.order.PushFront(item)\n   823→    c.items[key] = elem\n   824→}\n   825→```\n   826→\n   827→### Memoization\n   828→```go\n   829→// Function memoization\n   830→type Memoizer struct {\n   831→    mu    sync.RWMutex\n   832→    cache map[string]interface{}\n   833→    fn    func(string) interface{}\n   834→}\n   835→\n   836→func NewMemoizer(fn func(string) interface{}) *Memoizer {\n   837→    return &Memoizer{\n   838→        cache: make(map[string]interface{}),\n   839→        fn:    fn,\n   840→    }\n   841→}\n   842→\n   843→func (m *Memoizer) Get(key string) interface{} {\n   844→    m.mu.RLock()\n   845→    if val, ok := m.cache[key]; ok {\n   846→        m.mu.RUnlock()\n   847→        return val\n   848→    }\n   849→    m.mu.RUnlock()\n   850→    \n   851→    m.mu.Lock()\n   852→    defer m.mu.Unlock()\n   853→    \n   854→    // Double-check\n   855→    if val, ok := m.cache[key]; ok {\n   856→        return val\n   857→    }\n   858→    \n   859→    val := m.fn(key)\n   860→    m.cache[key] = val\n   861→    return val\n   862→}\n   863→\n   864→// Concurrent-safe memoization with singleflight\n   865→import \"golang.org/x/sync/singleflight\"\n   866→\n   867→type ConcurrentMemoizer struct {\n   868→    cache map[string]interface{}\n   869→    mu    sync.RWMutex\n   870→    group singleflight.Group\n   871→}\n   872→\n   873→func (m *ConcurrentMemoizer) Get(key string) (interface{}, error) {\n   874→    m.mu.RLock()\n   875→    if val, ok := m.cache[key]; ok {\n   876→        m.mu.RUnlock()\n   877→        return val, nil\n   878→    }\n   879→    m.mu.RUnlock()\n   880→    \n   881→    // Ensure only one goroutine computes the value\n   882→    val, err, _ := m.group.Do(key, func() (interface{}, error) {\n   883→        result := expensiveComputation(key)\n   884→        \n   885→        m.mu.Lock()\n   886→        m.cache[key] = result\n   887→        m.mu.Unlock()\n   888→        \n   889→        return result, nil\n   890→    })\n   891→    \n   892→    return val, err\n   893→}\n   894→```\n   895→\n   896→## Concurrency Performance\n   897→\n   898→### Goroutine Pool\n   899→```go\n   900→// Efficient goroutine pool\n   901→type WorkerPool struct {\n   902→    workers   int\n   903→    jobQueue  chan Job\n   904→    results   chan Result\n   905→    wg        sync.WaitGroup\n   906→}\n   907→\n   908→func NewWorkerPool(workers int, queueSize int) *WorkerPool {\n   909→    return &WorkerPool{\n   910→        workers:  workers,\n   911→        jobQueue: make(chan Job, queueSize),\n   912→        results:  make(chan Result, queueSize),\n   913→    }\n   914→}\n   915→\n   916→func (p *WorkerPool) Start() {\n   917→    for i := 0; i < p.workers; i++ {\n   918→        p.wg.Add(1)\n   919→        go p.worker(i)\n   920→    }\n   921→}\n   922→\n   923→func (p *WorkerPool) worker(id int) {\n   924→    defer p.wg.Done()\n   925→    \n   926→    for job := range p.jobQueue {\n   927→        result := processJob(job)\n   928→        p.results <- result\n   929→    }\n   930→}\n   931→\n   932→func (p *WorkerPool) Submit(job Job) {\n   933→    p.jobQueue <- job\n   934→}\n   935→\n   936→func (p *WorkerPool) Stop() {\n   937→    close(p.jobQueue)\n   938→    p.wg.Wait()\n   939→    close(p.results)\n   940→}\n   941→\n   942→// Lock-free structures\n   943→type LockFreeStack struct {\n   944→    head atomic.Pointer[node]\n   945→}\n   946→\n   947→type node struct {\n   948→    value interface{}\n   949→    next  *node\n   950→}\n   951→\n   952→func (s *LockFreeStack) Push(v interface{}) {\n   953→    n := &node{value: v}\n   954→    for {\n   955→        head := s.head.Load()\n   956→        n.next = head\n   957→        if s.head.CompareAndSwap(head, n) {\n   958→            return\n   959→        }\n   960→    }\n   961→}\n   962→\n   963→func (s *LockFreeStack) Pop() interface{} {\n   964→    for {\n   965→        head := s.head.Load()\n   966→        if head == nil {\n   967→            return nil\n   968→        }\n   969→        if s.head.CompareAndSwap(head, head.next) {\n   970→            return head.value\n   971→        }\n   972→    }\n   973→}\n   974→```\n   975→\n   976→### Channel Optimization\n   977→```go\n   978→// Buffered channels for performance\n   979→func efficientPipeline() {\n   980→    // Use buffered channels to reduce blocking\n   981→    input := make(chan int, 100)\n   982→    output := make(chan int, 100)\n   983→    \n   984→    // Producer\n   985→    go func() {\n   986→        defer close(input)\n   987→        for i := 0; i < 1000; i++ {\n   988→            input <- i\n   989→        }\n   990→    }()\n   991→    \n   992→    // Workers\n   993→    var wg sync.WaitGroup\n   994→    for i := 0; i < 10; i++ {\n   995→        wg.Add(1)\n   996→        go func() {\n   997→            defer wg.Done()\n   998→            for val := range input {\n   999→                output <- process(val)\n  1000→            }\n  1001→        }()\n  1002→    }\n  1003→    \n  1004→    // Close output when workers done\n  1005→    go func() {\n  1006→        wg.Wait()\n  1007→        close(output)\n  1008→    }()\n  1009→    \n  1010→    // Consumer\n  1011→    for result := range output {\n  1012→        handleResult(result)\n  1013→    }\n  1014→}\n  1015→\n  1016→// Batch processing for efficiency\n  1017→func batchProcessor(input <-chan Item) {\n  1018→    batch := make([]Item, 0, 100)\n  1019→    ticker := time.NewTicker(100 * time.Millisecond)\n  1020→    defer ticker.Stop()\n  1021→    \n  1022→    for {\n  1023→        select {\n  1024→        case item, ok := <-input:\n  1025→            if !ok {\n  1026→                if len(batch) > 0 {\n  1027→                    processBatch(batch)\n  1028→                }\n  1029→                return\n  1030→            }\n  1031→            batch = append(batch, item)\n  1032→            \n  1033→            if len(batch) >= 100 {\n  1034→                processBatch(batch)\n  1035→                batch = batch[:0]\n  1036→            }\n  1037→            \n  1038→        case <-ticker.C:\n  1039→            if len(batch) > 0 {\n  1040→                processBatch(batch)\n  1041→                batch = batch[:0]\n  1042→            }\n  1043→        }\n  1044→    }\n  1045→}\n  1046→```\n  1047→\n  1048→## I/O Optimization\n  1049→\n  1050→### Buffered I/O\n  1051→```go\n  1052→// Use buffered I/O\n  1053→func efficientFileRead(filename string) error {\n  1054→    file, err := os.Open(filename)\n  1055→    if err != nil {\n  1056→        return err\n  1057→    }\n  1058→    defer file.Close()\n  1059→    \n  1060→    // Use buffered reader\n  1061→    reader := bufio.NewReader(file)\n  1062→    \n  1063→    for {\n  1064→        line, err := reader.ReadString('\\n')\n  1065→        if err == io.EOF {\n  1066→            break\n  1067→        }\n  1068→        if err != nil {\n  1069→            return err\n  1070→        }\n  1071→        \n  1072→        processLine(line)\n  1073→    }\n  1074→    \n  1075→    return nil\n  1076→}\n  1077→\n  1078→// Efficient file writing\n  1079→func efficientFileWrite(filename string, data []string) error {\n  1080→    file, err := os.Create(filename)\n  1081→    if err != nil {\n  1082→        return err\n  1083→    }\n  1084→    defer file.Close()\n  1085→    \n  1086→    // Use buffered writer\n  1087→    writer := bufio.NewWriter(file)\n  1088→    defer writer.Flush()\n  1089→    \n  1090→    for _, line := range data {\n  1091→        _, err := writer.WriteString(line + \"\\n\")\n  1092→        if err != nil {\n  1093→            return err\n  1094→        }\n  1095→    }\n  1096→    \n  1097→    return nil\n  1098→}\n  1099→\n  1100→// Memory-mapped files for large files\n  1101→import \"golang.org/x/exp/mmap\"\n  1102→\n  1103→func readLargeFile(filename string) error {\n  1104→    reader, err := mmap.Open(filename)\n  1105→    if err != nil {\n  1106→        return err\n  1107→    }\n  1108→    defer reader.Close()\n  1109→    \n  1110→    // Read without loading entire file into memory\n  1111→    data := make([]byte, 1024)\n  1112→    for offset := int64(0); offset < reader.Len(); offset += 1024 {\n  1113→        n, err := reader.ReadAt(data, offset)\n  1114→        if err != nil && err != io.EOF {\n  1115→            return err\n  1116→        }\n  1117→        \n  1118→        processChunk(data[:n])\n  1119→    }\n  1120→    \n  1121→    return nil\n  1122→}\n  1123→```\n  1124→\n  1125→### Network I/O\n  1126→```go\n  1127→// Connection pooling\n  1128→type ConnectionPool struct {\n  1129→    connections chan net.Conn\n  1130→    factory     func() (net.Conn, error)\n  1131→}\n  1132→\n  1133→func NewConnectionPool(size int, factory func() (net.Conn, error)) (*ConnectionPool, error) {\n  1134→    pool := &ConnectionPool{\n  1135→        connections: make(chan net.Conn, size),\n  1136→        factory:     factory,\n  1137→    }\n  1138→    \n  1139→    for i := 0; i < size; i++ {\n  1140→        conn, err := factory()\n  1141→        if err != nil {\n  1142→            return nil, err\n  1143→        }\n  1144→        pool.connections <- conn\n  1145→    }\n  1146→    \n  1147→    return pool, nil\n  1148→}\n  1149→\n  1150→func (p *ConnectionPool) Get() net.Conn {\n  1151→    return <-p.connections\n  1152→}\n  1153→\n  1154→func (p *ConnectionPool) Put(conn net.Conn) {\n  1155→    p.connections <- conn\n  1156→}\n  1157→\n  1158→// HTTP client optimization\n  1159→var httpClient = &http.Client{\n  1160→    Timeout: 30 * time.Second,\n  1161→    Transport: &http.Transport{\n  1162→        MaxIdleConns:        100,\n  1163→        MaxIdleConnsPerHost: 10,\n  1164→        IdleConnTimeout:     90 * time.Second,\n  1165→        DisableCompression:  false,\n  1166→        DisableKeepAlives:   false,\n  1167→    },\n  1168→}\n  1169→\n  1170→// Batch HTTP requests\n  1171→func batchHTTPRequests(urls []string) []Response {\n  1172→    results := make([]Response, len(urls))\n  1173→    var wg sync.WaitGroup\n  1174→    \n  1175→    // Limit concurrent requests\n  1176→    sem := make(chan struct{}, 10)\n  1177→    \n  1178→    for i, url := range urls {\n  1179→        wg.Add(1)\n  1180→        go func(idx int, u string) {\n  1181→            defer wg.Done()\n  1182→            \n  1183→            sem <- struct{}{}\n  1184→            defer func() { <-sem }()\n  1185→            \n  1186→            resp, err := httpClient.Get(u)\n  1187→            if err != nil {\n  1188→                results[idx] = Response{Error: err}\n  1189→                return\n  1190→            }\n  1191→            defer resp.Body.Close()\n  1192→            \n  1193→            body, _ := io.ReadAll(resp.Body)\n  1194→            results[idx] = Response{Data: body}\n  1195→        }(i, url)\n  1196→    }\n  1197→    \n  1198→    wg.Wait()\n  1199→    return results\n  1200→}\n  1201→```\n  1202→\n  1203→## Data Structure Optimization\n  1204→\n  1205→### Slice Optimization\n  1206→```go\n  1207→// Preallocate slices\n  1208→func optimizedSliceOperations() {\n  1209→    // Know the capacity\n  1210→    slice := make([]int, 0, 1000)\n  1211→    \n  1212→    // Grow efficiently\n  1213→    if cap(slice) < requiredSize {\n  1214→        newSlice := make([]int, len(slice), requiredSize*2)\n  1215→        copy(newSlice, slice)\n  1216→        slice = newSlice\n  1217→    }\n  1218→    \n  1219→    // Clear slice for reuse\n  1220→    slice = slice[:0]\n  1221→    \n  1222→    // Remove element efficiently\n  1223→    func removeAt(s []int, i int) []int {\n  1224→        s[i] = s[len(s)-1]\n  1225→        return s[:len(s)-1]\n  1226→    }\n  1227→}\n  1228→\n  1229→// Custom growing strategy\n  1230→type GrowableBuffer struct {\n  1231→    data []byte\n  1232→}\n  1233→\n  1234→func (b *GrowableBuffer) grow(n int) {\n  1235→    if cap(b.data)-len(b.data) < n {\n  1236→        newCap := cap(b.data) * 2\n  1237→        if newCap < len(b.data)+n {\n  1238→            newCap = len(b.data) + n\n  1239→        }\n  1240→        newData := make([]byte, len(b.data), newCap)\n  1241→        copy(newData, b.data)\n  1242→        b.data = newData\n  1243→    }\n  1244→}\n  1245→```\n  1246→\n  1247→### Map Optimization\n  1248→```go\n  1249→// Preallocate maps\n  1250→m := make(map[string]int, 1000)\n  1251→\n  1252→// Use appropriate key types\n  1253→// Faster: int keys\n  1254→fastMap := make(map[int]string)\n  1255→\n  1256→// Slower: string keys (requires hashing)\n  1257→slowMap := make(map[string]string)\n  1258→\n  1259→// Custom hash map for specific use case\n  1260→type FastStringMap struct {\n  1261→    buckets [][]entry\n  1262→    size    int\n  1263→}\n  1264→\n  1265→type entry struct {\n  1266→    key   string\n  1267→    value interface{}\n  1268→}\n  1269→\n  1270→func (m *FastStringMap) hash(key string) uint32 {\n  1271→    // Fast hash function\n  1272→    h := uint32(2166136261)\n  1273→    for i := 0; i < len(key); i++ {\n  1274→        h *= 16777619\n  1275→        h ^= uint32(key[i])\n  1276→    }\n  1277→    return h\n  1278→}\n  1279→\n  1280→func (m *FastStringMap) Get(key string) (interface{}, bool) {\n  1281→    h := m.hash(key) % uint32(len(m.buckets))\n  1282→    bucket := m.buckets[h]\n  1283→    \n  1284→    for _, e := range bucket {\n  1285→        if e.key == key {\n  1286→            return e.value, true\n  1287→        }\n  1288→    }\n  1289→    return nil, false\n  1290→}\n  1291→```\n  1292→\n  1293→### String Optimization\n  1294→```go\n  1295→// String concatenation optimization\n  1296→func efficientStringConcat(strs []string) string {\n  1297→    // Calculate total length\n  1298→    var totalLen int\n  1299→    for _, s := range strs {\n  1300→        totalLen += len(s)\n  1301→    }\n  1302→    \n  1303→    // Preallocate builder\n  1304→    var builder strings.Builder\n  1305→    builder.Grow(totalLen)\n  1306→    \n  1307→    for _, s := range strs {\n  1308→        builder.WriteString(s)\n  1309→    }\n  1310→    \n  1311→    return builder.String()\n  1312→}\n  1313→\n  1314→// Avoid string copies\n  1315→func stringToBytes(s string) []byte {\n  1316→    // Safe conversion without copy (read-only)\n  1317→    return unsafe.Slice(unsafe.StringData(s), len(s))\n  1318→}\n  1319→\n  1320→func bytesToString(b []byte) string {\n  1321→    // Safe conversion without copy\n  1322→    return unsafe.String(unsafe.SliceData(b), len(b))\n  1323→}\n  1324→```\n  1325→\n  1326→## Performance Best Practices\n  1327→\n  1328→### Measurement and Profiling\n  1329→```go\n  1330→// Always measure before optimizing\n  1331→func measurePerformance() {\n  1332→    start := time.Now()\n  1333→    defer func() {\n  1334→        elapsed := time.Since(start)\n  1335→        log.Printf(\"Operation took %v\", elapsed)\n  1336→    }()\n  1337→    \n  1338→    // Operation to measure\n  1339→}\n  1340→\n  1341→// Use benchmarks for micro-optimizations\n  1342→func BenchmarkOptimization(b *testing.B) {\n  1343→    // Test different approaches\n  1344→}\n  1345→\n  1346→// Profile in production\n  1347→import _ \"net/http/pprof\"\n  1348→// Access profiles at /debug/pprof/\n  1349→```\n  1350→\n  1351→### Common Optimizations\n  1352→```go\n  1353→// 1. Avoid premature optimization\n  1354→// Profile first, optimize bottlenecks\n  1355→\n  1356→// 2. Reduce allocations\n  1357→// Use sync.Pool, preallocate slices\n  1358→\n  1359→// 3. Optimize hot paths\n  1360→// Focus on frequently executed code\n  1361→\n  1362→// 4. Use efficient algorithms\n  1363→// O(n) vs O(n²) matters at scale\n  1364→\n  1365→// 5. Cache computed values\n  1366→// Memoization, lookup tables\n  1367→\n  1368→// 6. Batch operations\n  1369→// Reduce system calls, network requests\n  1370→\n  1371→// 7. Use appropriate data structures\n  1372→// Map vs slice, array vs slice\n  1373→\n  1374→// 8. Leverage concurrency wisely\n  1375→// Don't overuse goroutines\n  1376→\n  1377→// 9. Minimize interface conversions\n  1378→// Interfaces cause allocations\n  1379→\n  1380→// 10. Profile regularly\n  1381→// Performance can degrade over time\n  1382→```\n  1383→\n  1384→## Best Practices Summary\n  1385→\n  1386→1. **Profile before optimizing** - Measure, don't guess\n  1387→2. **Focus on algorithms first** - Better algorithm beats micro-optimizations\n  1388→3. **Reduce allocations** - Use pools, preallocate, reuse\n  1389→4. **Optimize hot paths** - 80/20 rule applies\n  1390→5. **Cache aggressively** - But invalidate correctly\n  1391→6. **Use buffered I/O** - For file and network operations\n  1392→7. **Batch operations** - Amortize overhead\n  1393→8. **Choose right data structures** - Map vs slice matters\n  1394→9. **Leverage compiler optimizations** - Write optimizer-friendly code\n  1395→10. **Monitor production performance** - Use pprof, metrics, tracing\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"517e597a-7e3f-4d39-bc64-dad2791c2711","timestamp":"2025-08-13T10:03:13.039Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/performance.md","content":"# Go Performance - Optimization Mastery\n\n## Table of Contents\n1. [Profiling](#profiling)\n2. [Benchmarking](#benchmarking)\n3. [Memory Management](#memory-management)\n4. [CPU Optimization](#cpu-optimization)\n5. [Compiler Optimizations](#compiler-optimizations)\n6. [Caching Strategies](#caching-strategies)\n7. [Concurrency Performance](#concurrency-performance)\n8. [I/O Optimization](#io-optimization)\n9. [Data Structure Optimization](#data-structure-optimization)\n10. [Performance Best Practices](#performance-best-practices)\n\n## Profiling\n\n### CPU Profiling\n```go\nimport (\n    \"runtime/pprof\"\n    \"os\"\n    \"runtime\"\n)\n\n// Basic CPU profiling\nfunc main() {\n    // Create CPU profile file\n    f, err := os.Create(\"cpu.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    // Start CPU profiling\n    if err := pprof.StartCPUProfile(f); err != nil {\n        log.Fatal(err)\n    }\n    defer pprof.StopCPUProfile()\n    \n    // Your application code\n    runApplication()\n}\n\n// HTTP profiling server\nimport _ \"net/http/pprof\"\n\nfunc main() {\n    go func() {\n        log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n    }()\n    \n    // Your application code\n    runApplication()\n}\n\n// Analyze profiles:\n// go tool pprof cpu.prof\n// go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n// go tool pprof -http=:8080 cpu.prof  # Web interface\n\n// Profile with benchmarks\nfunc BenchmarkFunction(b *testing.B) {\n    // Start profiling in benchmark\n    f, _ := os.Create(\"bench.prof\")\n    pprof.StartCPUProfile(f)\n    defer pprof.StopCPUProfile()\n    \n    for i := 0; i < b.N; i++ {\n        FunctionToProfile()\n    }\n}\n```\n\n### Memory Profiling\n```go\n// Memory profiling\nfunc writeMemProfile() {\n    f, err := os.Create(\"mem.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    runtime.GC() // Force GC before profiling\n    if err := pprof.WriteHeapProfile(f); err != nil {\n        log.Fatal(err)\n    }\n}\n\n// Allocation profiling\nfunc writeAllocProfile() {\n    f, err := os.Create(\"alloc.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    // Profile allocations\n    runtime.MemProfileRate = 1 // Profile every allocation\n    defer func() { runtime.MemProfileRate = 512 * 1024 }() // Reset\n    \n    // Run code\n    runApplication()\n    \n    pprof.Lookup(\"allocs\").WriteTo(f, 0)\n}\n\n// Memory stats\nfunc printMemStats() {\n    var m runtime.MemStats\n    runtime.ReadMemStats(&m)\n    \n    fmt.Printf(\"Alloc = %v MB\", m.Alloc / 1024 / 1024)\n    fmt.Printf(\"TotalAlloc = %v MB\", m.TotalAlloc / 1024 / 1024)\n    fmt.Printf(\"Sys = %v MB\", m.Sys / 1024 / 1024)\n    fmt.Printf(\"NumGC = %v\\n\", m.NumGC)\n    fmt.Printf(\"HeapAlloc = %v MB\", m.HeapAlloc / 1024 / 1024)\n    fmt.Printf(\"HeapObjects = %v\", m.HeapObjects)\n}\n\n// Track allocations in specific code\nfunc trackAllocations() {\n    var m1, m2 runtime.MemStats\n    \n    runtime.ReadMemStats(&m1)\n    \n    // Code to measure\n    expensiveOperation()\n    \n    runtime.ReadMemStats(&m2)\n    \n    fmt.Printf(\"Allocated: %d bytes\\n\", m2.Alloc - m1.Alloc)\n    fmt.Printf(\"Total Allocated: %d bytes\\n\", m2.TotalAlloc - m1.TotalAlloc)\n    fmt.Printf(\"Number of allocations: %d\\n\", m2.Mallocs - m1.Mallocs)\n}\n```\n\n### Goroutine Profiling\n```go\n// Goroutine profiling\nfunc writeGoroutineProfile() {\n    f, err := os.Create(\"goroutine.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    pprof.Lookup(\"goroutine\").WriteTo(f, 1)\n}\n\n// Monitor goroutine count\nfunc monitorGoroutines() {\n    ticker := time.NewTicker(1 * time.Second)\n    defer ticker.Stop()\n    \n    for range ticker.C {\n        fmt.Printf(\"Goroutines: %d\\n\", runtime.NumGoroutine())\n    }\n}\n\n// Block profiling (mutex contention)\nfunc enableBlockProfiling() {\n    runtime.SetBlockProfileRate(1)\n    defer runtime.SetBlockProfileRate(0)\n    \n    // Run application\n    runApplication()\n    \n    f, _ := os.Create(\"block.prof\")\n    defer f.Close()\n    pprof.Lookup(\"block\").WriteTo(f, 0)\n}\n\n// Mutex profiling\nfunc enableMutexProfiling() {\n    runtime.SetMutexProfileFraction(1)\n    defer runtime.SetMutexProfileFraction(0)\n    \n    // Run application\n    runApplication()\n    \n    f, _ := os.Create(\"mutex.prof\")\n    defer f.Close()\n    pprof.Lookup(\"mutex\").WriteTo(f, 0)\n}\n```\n\n### Trace Profiling\n```go\nimport \"runtime/trace\"\n\n// Execution tracing\nfunc main() {\n    f, err := os.Create(\"trace.out\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    err = trace.Start(f)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer trace.Stop()\n    \n    // Your application\n    runApplication()\n}\n\n// Analyze: go tool trace trace.out\n\n// Custom trace regions\nfunc processRequest(ctx context.Context) {\n    defer trace.StartRegion(ctx, \"processRequest\").End()\n    \n    trace.WithRegion(ctx, \"validate\", func() {\n        validateInput()\n    })\n    \n    trace.WithRegion(ctx, \"compute\", func() {\n        computeResult()\n    })\n    \n    trace.WithRegion(ctx, \"respond\", func() {\n        sendResponse()\n    })\n}\n\n// Trace logging\nfunc traceLog(ctx context.Context, message string) {\n    trace.Log(ctx, \"app\", message)\n}\n```\n\n## Benchmarking\n\n### Advanced Benchmarking\n```go\n// Benchmark with different inputs\nfunc BenchmarkSort(b *testing.B) {\n    sizes := []int{10, 100, 1000, 10000}\n    \n    for _, size := range sizes {\n        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n            data := generateRandomSlice(size)\n            \n            b.ResetTimer()\n            for i := 0; i < b.N; i++ {\n                b.StopTimer()\n                tmp := make([]int, len(data))\n                copy(tmp, data)\n                b.StartTimer()\n                \n                sort.Ints(tmp)\n            }\n        })\n    }\n}\n\n// Comparative benchmarks\nfunc BenchmarkStringBuilding(b *testing.B) {\n    strs := []string{\"hello\", \"world\", \"foo\", \"bar\", \"baz\"}\n    \n    b.Run(\"Concatenation\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var result string\n            for _, s := range strs {\n                result += s\n            }\n        }\n    })\n    \n    b.Run(\"StringBuilder\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var builder strings.Builder\n            for _, s := range strs {\n                builder.WriteString(s)\n            }\n            _ = builder.String()\n        }\n    })\n    \n    b.Run(\"BytesBuffer\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var buffer bytes.Buffer\n            for _, s := range strs {\n                buffer.WriteString(s)\n            }\n            _ = buffer.String()\n        }\n    })\n    \n    b.Run(\"Join\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            _ = strings.Join(strs, \"\")\n        }\n    })\n}\n\n// Memory benchmarks\nfunc BenchmarkMemory(b *testing.B) {\n    b.Run(\"WithAllocation\", func(b *testing.B) {\n        b.ReportAllocs()\n        for i := 0; i < b.N; i++ {\n            s := make([]int, 1000)\n            _ = s\n        }\n    })\n    \n    b.Run(\"WithPool\", func(b *testing.B) {\n        b.ReportAllocs()\n        pool := sync.Pool{\n            New: func() interface{} {\n                return make([]int, 1000)\n            },\n        }\n        \n        for i := 0; i < b.N; i++ {\n            s := pool.Get().([]int)\n            pool.Put(s)\n        }\n    })\n}\n\n// Custom metrics\nfunc BenchmarkThroughput(b *testing.B) {\n    data := make([]byte, 1024*1024) // 1MB\n    \n    b.SetBytes(int64(len(data)))\n    b.ResetTimer()\n    \n    for i := 0; i < b.N; i++ {\n        process(data)\n    }\n    \n    b.ReportMetric(float64(b.N)*float64(len(data))/b.Elapsed().Seconds()/1024/1024, \"MB/s\")\n}\n```\n\n## Memory Management\n\n### Reducing Allocations\n```go\n// Avoid allocations in loops\n// Bad: Allocates in loop\nfunc bad() []string {\n    var results []string\n    for i := 0; i < 1000; i++ {\n        results = append(results, fmt.Sprintf(\"item-%d\", i))\n    }\n    return results\n}\n\n// Good: Preallocate\nfunc good() []string {\n    results := make([]string, 0, 1000)\n    for i := 0; i < 1000; i++ {\n        results = append(results, fmt.Sprintf(\"item-%d\", i))\n    }\n    return results\n}\n\n// Reuse buffers\nvar bufferPool = sync.Pool{\n    New: func() interface{} {\n        return new(bytes.Buffer)\n    },\n}\n\nfunc processWithPool(data []byte) string {\n    buf := bufferPool.Get().(*bytes.Buffer)\n    defer func() {\n        buf.Reset()\n        bufferPool.Put(buf)\n    }()\n    \n    buf.Write(data)\n    // Process...\n    return buf.String()\n}\n\n// Avoid string allocations\nfunc avoidStringAllocs(b []byte) string {\n    // Bad: Multiple allocations\n    s := string(b)\n    s = strings.ToUpper(s)\n    s = strings.TrimSpace(s)\n    \n    // Better: Work with bytes\n    b = bytes.ToUpper(b)\n    b = bytes.TrimSpace(b)\n    return string(b)\n}\n\n// String interning for repeated strings\ntype StringInterner struct {\n    mu    sync.RWMutex\n    cache map[string]string\n}\n\nfunc (si *StringInterner) Intern(s string) string {\n    si.mu.RLock()\n    if interned, ok := si.cache[s]; ok {\n        si.mu.RUnlock()\n        return interned\n    }\n    si.mu.RUnlock()\n    \n    si.mu.Lock()\n    defer si.mu.Unlock()\n    \n    si.cache[s] = s\n    return s\n}\n```\n\n### Memory Layout Optimization\n```go\n// Struct field alignment\n// Bad: 32 bytes due to padding\ntype Inefficient struct {\n    a bool    // 1 byte + 7 padding\n    b int64   // 8 bytes\n    c bool    // 1 byte + 7 padding\n    d int64   // 8 bytes\n}\n\n// Good: 24 bytes with better alignment\ntype Efficient struct {\n    b int64   // 8 bytes\n    d int64   // 8 bytes\n    a bool    // 1 byte\n    c bool    // 1 byte + 6 padding\n}\n\n// Use smaller types when possible\ntype Flags struct {\n    // Bad: 4 bools = potentially 4 bytes + padding\n    IsActive   bool\n    IsVerified bool\n    IsPremium  bool\n    IsAdmin    bool\n}\n\n// Good: 1 byte using bit flags\ntype CompactFlags uint8\n\nconst (\n    FlagActive CompactFlags = 1 << iota\n    FlagVerified\n    FlagPremium\n    FlagAdmin\n)\n\nfunc (f CompactFlags) IsActive() bool { return f&FlagActive != 0 }\nfunc (f CompactFlags) IsVerified() bool { return f&FlagVerified != 0 }\n\n// Array vs slice for fixed size\ntype Record struct {\n    // Bad: slice has 24 bytes overhead (pointer, len, cap)\n    IDSlice []byte\n    \n    // Good: array for fixed size, no overhead\n    IDArray [16]byte\n}\n```\n\n### Escape Analysis\n```go\n// Understanding escape analysis\n// go build -gcflags=\"-m\" to see escape analysis\n\n// Doesn't escape - allocated on stack\nfunc noEscape() int {\n    x := 42\n    return x\n}\n\n// Escapes to heap - returned pointer\nfunc escapes() *int {\n    x := 42\n    return &x // x escapes to heap\n}\n\n// Avoid unnecessary escapes\ntype Data struct {\n    values [1000]int\n}\n\n// Bad: Escapes to heap\nfunc (d *Data) Sum() int {\n    sum := 0\n    for _, v := range d.values { // d.values escapes\n        sum += v\n    }\n    return sum\n}\n\n// Good: Doesn't escape\nfunc (d Data) SumValue() int {\n    sum := 0\n    for i := 0; i < len(d.values); i++ {\n        sum += d.values[i]\n    }\n    return sum\n}\n\n// Interface causes escape\nfunc processInterface(i interface{}) {\n    // i escapes to heap\n}\n\nfunc avoidEscape() {\n    x := 42\n    processInterface(x) // x escapes\n    \n    // Avoid by not using interface\n    processInt(x) // x doesn't escape\n}\n\nfunc processInt(i int) {\n    // Process int directly\n}\n```\n\n## CPU Optimization\n\n### Hot Path Optimization\n```go\n// Optimize hot paths\nfunc processData(data []int) int {\n    // Move invariants out of loop\n    length := len(data)\n    if length == 0 {\n        return 0\n    }\n    \n    sum := 0\n    // Unroll loop for better performance\n    for i := 0; i < length-3; i += 4 {\n        sum += data[i] + data[i+1] + data[i+2] + data[i+3]\n    }\n    \n    // Handle remaining elements\n    for i := length - length%4; i < length; i++ {\n        sum += data[i]\n    }\n    \n    return sum\n}\n\n// Branch prediction optimization\nfunc findMax(data []int) int {\n    if len(data) == 0 {\n        return 0\n    }\n    \n    max := data[0]\n    for i := 1; i < len(data); i++ {\n        // Branchless max (may be faster)\n        if data[i] > max {\n            max = data[i]\n        }\n    }\n    return max\n}\n\n// Cache-friendly iteration\nfunc sumMatrix(matrix [][]int) int {\n    sum := 0\n    // Row-major order (cache-friendly)\n    for i := 0; i < len(matrix); i++ {\n        for j := 0; j < len(matrix[i]); j++ {\n            sum += matrix[i][j]\n        }\n    }\n    return sum\n}\n\n// SIMD-friendly code\nfunc addSlices(a, b []float64) []float64 {\n    result := make([]float64, len(a))\n    \n    // Compiler may vectorize this\n    for i := range a {\n        result[i] = a[i] + b[i]\n    }\n    \n    return result\n}\n```\n\n### Inlining\n```go\n// Encourage inlining for small functions\n//go:inline\nfunc add(a, b int) int {\n    return a + b\n}\n\n// Prevent inlining for rarely used functions\n//go:noinline\nfunc rarelyUsedFunction() {\n    // Complex logic\n}\n\n// Check inlining decisions\n// go build -gcflags=\"-m=2\"\n\n// Inline-friendly functions\nfunc abs(x int) int {\n    if x < 0 {\n        return -x\n    }\n    return x\n}\n\n// Too complex to inline (default threshold ~80 nodes)\nfunc complexFunction(x int) int {\n    // Many operations...\n    return result\n}\n```\n\n## Compiler Optimizations\n\n### Compiler Directives\n```go\n// Bounds check elimination\nfunc sumArray(arr []int) int {\n    if len(arr) == 0 {\n        return 0\n    }\n    \n    sum := 0\n    // Compiler can eliminate bounds checks\n    for i := 0; i < len(arr); i++ {\n        sum += arr[i]\n    }\n    return sum\n}\n\n// Help compiler with hints\nfunc process(data []byte) {\n    // Tell compiler minimum length\n    _ = data[3] // Bounds check once\n    \n    // Now these don't need bounds checks\n    a := data[0]\n    b := data[1]\n    c := data[2]\n    d := data[3]\n    \n    // Process a, b, c, d\n}\n\n// Const propagation\nconst bufferSize = 1024\n\nfunc allocateBuffer() []byte {\n    // Compiler knows size at compile time\n    return make([]byte, bufferSize)\n}\n\n// Dead code elimination\nfunc example(debug bool) {\n    if false { // Compiler removes this\n        expensiveDebugOperation()\n    }\n    \n    const debugMode = false\n    if debugMode { // Also removed\n        fmt.Println(\"Debug mode\")\n    }\n}\n```\n\n### Build Flags\n```go\n// Build tags for optimization\n//go:build !debug\n\npackage main\n\nfunc log(msg string) {\n    // No-op in release builds\n}\n\n// Alternative file for debug builds\n//go:build debug\n\npackage main\n\nfunc log(msg string) {\n    fmt.Println(msg)\n}\n\n// Compile with optimizations\n// go build -ldflags=\"-s -w\" # Strip debug info\n// go build -tags release\n// GOOS=linux GOARCH=amd64 go build # Cross-compile\n```\n\n## Caching Strategies\n\n### In-Memory Caching\n```go\n// Simple cache with TTL\ntype Cache struct {\n    mu      sync.RWMutex\n    items   map[string]*cacheItem\n    ttl     time.Duration\n}\n\ntype cacheItem struct {\n    value      interface{}\n    expiration time.Time\n}\n\nfunc NewCache(ttl time.Duration) *Cache {\n    c := &Cache{\n        items: make(map[string]*cacheItem),\n        ttl:   ttl,\n    }\n    go c.cleanup()\n    return c\n}\n\nfunc (c *Cache) Set(key string, value interface{}) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    c.items[key] = &cacheItem{\n        value:      value,\n        expiration: time.Now().Add(c.ttl),\n    }\n}\n\nfunc (c *Cache) Get(key string) (interface{}, bool) {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    \n    item, found := c.items[key]\n    if !found {\n        return nil, false\n    }\n    \n    if time.Now().After(item.expiration) {\n        return nil, false\n    }\n    \n    return item.value, true\n}\n\nfunc (c *Cache) cleanup() {\n    ticker := time.NewTicker(c.ttl / 2)\n    defer ticker.Stop()\n    \n    for range ticker.C {\n        c.mu.Lock()\n        now := time.Now()\n        for key, item := range c.items {\n            if now.After(item.expiration) {\n                delete(c.items, key)\n            }\n        }\n        c.mu.Unlock()\n    }\n}\n\n// LRU Cache\ntype LRUCache struct {\n    capacity int\n    items    map[string]*list.Element\n    order    *list.List\n    mu       sync.Mutex\n}\n\ntype lruItem struct {\n    key   string\n    value interface{}\n}\n\nfunc NewLRUCache(capacity int) *LRUCache {\n    return &LRUCache{\n        capacity: capacity,\n        items:    make(map[string]*list.Element),\n        order:    list.New(),\n    }\n}\n\nfunc (c *LRUCache) Get(key string) (interface{}, bool) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    if elem, ok := c.items[key]; ok {\n        c.order.MoveToFront(elem)\n        return elem.Value.(*lruItem).value, true\n    }\n    return nil, false\n}\n\nfunc (c *LRUCache) Set(key string, value interface{}) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    if elem, ok := c.items[key]; ok {\n        c.order.MoveToFront(elem)\n        elem.Value.(*lruItem).value = value\n        return\n    }\n    \n    if c.order.Len() >= c.capacity {\n        oldest := c.order.Back()\n        if oldest != nil {\n            c.order.Remove(oldest)\n            delete(c.items, oldest.Value.(*lruItem).key)\n        }\n    }\n    \n    item := &lruItem{key: key, value: value}\n    elem := c.order.PushFront(item)\n    c.items[key] = elem\n}\n```\n\n### Memoization\n```go\n// Function memoization\ntype Memoizer struct {\n    mu    sync.RWMutex\n    cache map[string]interface{}\n    fn    func(string) interface{}\n}\n\nfunc NewMemoizer(fn func(string) interface{}) *Memoizer {\n    return &Memoizer{\n        cache: make(map[string]interface{}),\n        fn:    fn,\n    }\n}\n\nfunc (m *Memoizer) Get(key string) interface{} {\n    m.mu.RLock()\n    if val, ok := m.cache[key]; ok {\n        m.mu.RUnlock()\n        return val\n    }\n    m.mu.RUnlock()\n    \n    m.mu.Lock()\n    defer m.mu.Unlock()\n    \n    // Double-check\n    if val, ok := m.cache[key]; ok {\n        return val\n    }\n    \n    val := m.fn(key)\n    m.cache[key] = val\n    return val\n}\n\n// Concurrent-safe memoization with singleflight\nimport \"golang.org/x/sync/singleflight\"\n\ntype ConcurrentMemoizer struct {\n    cache map[string]interface{}\n    mu    sync.RWMutex\n    group singleflight.Group\n}\n\nfunc (m *ConcurrentMemoizer) Get(key string) (interface{}, error) {\n    m.mu.RLock()\n    if val, ok := m.cache[key]; ok {\n        m.mu.RUnlock()\n        return val, nil\n    }\n    m.mu.RUnlock()\n    \n    // Ensure only one goroutine computes the value\n    val, err, _ := m.group.Do(key, func() (interface{}, error) {\n        result := expensiveComputation(key)\n        \n        m.mu.Lock()\n        m.cache[key] = result\n        m.mu.Unlock()\n        \n        return result, nil\n    })\n    \n    return val, err\n}\n```\n\n## Concurrency Performance\n\n### Goroutine Pool\n```go\n// Efficient goroutine pool\ntype WorkerPool struct {\n    workers   int\n    jobQueue  chan Job\n    results   chan Result\n    wg        sync.WaitGroup\n}\n\nfunc NewWorkerPool(workers int, queueSize int) *WorkerPool {\n    return &WorkerPool{\n        workers:  workers,\n        jobQueue: make(chan Job, queueSize),\n        results:  make(chan Result, queueSize),\n    }\n}\n\nfunc (p *WorkerPool) Start() {\n    for i := 0; i < p.workers; i++ {\n        p.wg.Add(1)\n        go p.worker(i)\n    }\n}\n\nfunc (p *WorkerPool) worker(id int) {\n    defer p.wg.Done()\n    \n    for job := range p.jobQueue {\n        result := processJob(job)\n        p.results <- result\n    }\n}\n\nfunc (p *WorkerPool) Submit(job Job) {\n    p.jobQueue <- job\n}\n\nfunc (p *WorkerPool) Stop() {\n    close(p.jobQueue)\n    p.wg.Wait()\n    close(p.results)\n}\n\n// Lock-free structures\ntype LockFreeStack struct {\n    head atomic.Pointer[node]\n}\n\ntype node struct {\n    value interface{}\n    next  *node\n}\n\nfunc (s *LockFreeStack) Push(v interface{}) {\n    n := &node{value: v}\n    for {\n        head := s.head.Load()\n        n.next = head\n        if s.head.CompareAndSwap(head, n) {\n            return\n        }\n    }\n}\n\nfunc (s *LockFreeStack) Pop() interface{} {\n    for {\n        head := s.head.Load()\n        if head == nil {\n            return nil\n        }\n        if s.head.CompareAndSwap(head, head.next) {\n            return head.value\n        }\n    }\n}\n```\n\n### Channel Optimization\n```go\n// Buffered channels for performance\nfunc efficientPipeline() {\n    // Use buffered channels to reduce blocking\n    input := make(chan int, 100)\n    output := make(chan int, 100)\n    \n    // Producer\n    go func() {\n        defer close(input)\n        for i := 0; i < 1000; i++ {\n            input <- i\n        }\n    }()\n    \n    // Workers\n    var wg sync.WaitGroup\n    for i := 0; i < 10; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for val := range input {\n                output <- process(val)\n            }\n        }()\n    }\n    \n    // Close output when workers done\n    go func() {\n        wg.Wait()\n        close(output)\n    }()\n    \n    // Consumer\n    for result := range output {\n        handleResult(result)\n    }\n}\n\n// Batch processing for efficiency\nfunc batchProcessor(input <-chan Item) {\n    batch := make([]Item, 0, 100)\n    ticker := time.NewTicker(100 * time.Millisecond)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case item, ok := <-input:\n            if !ok {\n                if len(batch) > 0 {\n                    processBatch(batch)\n                }\n                return\n            }\n            batch = append(batch, item)\n            \n            if len(batch) >= 100 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n            \n        case <-ticker.C:\n            if len(batch) > 0 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n        }\n    }\n}\n```\n\n## I/O Optimization\n\n### Buffered I/O\n```go\n// Use buffered I/O\nfunc efficientFileRead(filename string) error {\n    file, err := os.Open(filename)\n    if err != nil {\n        return err\n    }\n    defer file.Close()\n    \n    // Use buffered reader\n    reader := bufio.NewReader(file)\n    \n    for {\n        line, err := reader.ReadString('\\n')\n        if err == io.EOF {\n            break\n        }\n        if err != nil {\n            return err\n        }\n        \n        processLine(line)\n    }\n    \n    return nil\n}\n\n// Efficient file writing\nfunc efficientFileWrite(filename string, data []string) error {\n    file, err := os.Create(filename)\n    if err != nil {\n        return err\n    }\n    defer file.Close()\n    \n    // Use buffered writer\n    writer := bufio.NewWriter(file)\n    defer writer.Flush()\n    \n    for _, line := range data {\n        _, err := writer.WriteString(line + \"\\n\")\n        if err != nil {\n            return err\n        }\n    }\n    \n    return nil\n}\n\n// Memory-mapped files for large files\nimport \"golang.org/x/exp/mmap\"\n\nfunc readLargeFile(filename string) error {\n    reader, err := mmap.Open(filename)\n    if err != nil {\n        return err\n    }\n    defer reader.Close()\n    \n    // Read without loading entire file into memory\n    data := make([]byte, 1024)\n    for offset := int64(0); offset < reader.Len(); offset += 1024 {\n        n, err := reader.ReadAt(data, offset)\n        if err != nil && err != io.EOF {\n            return err\n        }\n        \n        processChunk(data[:n])\n    }\n    \n    return nil\n}\n```\n\n### Network I/O\n```go\n// Connection pooling\ntype ConnectionPool struct {\n    connections chan net.Conn\n    factory     func() (net.Conn, error)\n}\n\nfunc NewConnectionPool(size int, factory func() (net.Conn, error)) (*ConnectionPool, error) {\n    pool := &ConnectionPool{\n        connections: make(chan net.Conn, size),\n        factory:     factory,\n    }\n    \n    for i := 0; i < size; i++ {\n        conn, err := factory()\n        if err != nil {\n            return nil, err\n        }\n        pool.connections <- conn\n    }\n    \n    return pool, nil\n}\n\nfunc (p *ConnectionPool) Get() net.Conn {\n    return <-p.connections\n}\n\nfunc (p *ConnectionPool) Put(conn net.Conn) {\n    p.connections <- conn\n}\n\n// HTTP client optimization\nvar httpClient = &http.Client{\n    Timeout: 30 * time.Second,\n    Transport: &http.Transport{\n        MaxIdleConns:        100,\n        MaxIdleConnsPerHost: 10,\n        IdleConnTimeout:     90 * time.Second,\n        DisableCompression:  false,\n        DisableKeepAlives:   false,\n    },\n}\n\n// Batch HTTP requests\nfunc batchHTTPRequests(urls []string) []Response {\n    results := make([]Response, len(urls))\n    var wg sync.WaitGroup\n    \n    // Limit concurrent requests\n    sem := make(chan struct{}, 10)\n    \n    for i, url := range urls {\n        wg.Add(1)\n        go func(idx int, u string) {\n            defer wg.Done()\n            \n            sem <- struct{}{}\n            defer func() { <-sem }()\n            \n            resp, err := httpClient.Get(u)\n            if err != nil {\n                results[idx] = Response{Error: err}\n                return\n            }\n            defer resp.Body.Close()\n            \n            body, _ := io.ReadAll(resp.Body)\n            results[idx] = Response{Data: body}\n        }(i, url)\n    }\n    \n    wg.Wait()\n    return results\n}\n```\n\n## Data Structure Optimization\n\n### Slice Optimization\n```go\n// Preallocate slices\nfunc optimizedSliceOperations() {\n    // Know the capacity\n    slice := make([]int, 0, 1000)\n    \n    // Grow efficiently\n    if cap(slice) < requiredSize {\n        newSlice := make([]int, len(slice), requiredSize*2)\n        copy(newSlice, slice)\n        slice = newSlice\n    }\n    \n    // Clear slice for reuse\n    slice = slice[:0]\n    \n    // Remove element efficiently\n    func removeAt(s []int, i int) []int {\n        s[i] = s[len(s)-1]\n        return s[:len(s)-1]\n    }\n}\n\n// Custom growing strategy\ntype GrowableBuffer struct {\n    data []byte\n}\n\nfunc (b *GrowableBuffer) grow(n int) {\n    if cap(b.data)-len(b.data) < n {\n        newCap := cap(b.data) * 2\n        if newCap < len(b.data)+n {\n            newCap = len(b.data) + n\n        }\n        newData := make([]byte, len(b.data), newCap)\n        copy(newData, b.data)\n        b.data = newData\n    }\n}\n```\n\n### Map Optimization\n```go\n// Preallocate maps\nm := make(map[string]int, 1000)\n\n// Use appropriate key types\n// Faster: int keys\nfastMap := make(map[int]string)\n\n// Slower: string keys (requires hashing)\nslowMap := make(map[string]string)\n\n// Custom hash map for specific use case\ntype FastStringMap struct {\n    buckets [][]entry\n    size    int\n}\n\ntype entry struct {\n    key   string\n    value interface{}\n}\n\nfunc (m *FastStringMap) hash(key string) uint32 {\n    // Fast hash function\n    h := uint32(2166136261)\n    for i := 0; i < len(key); i++ {\n        h *= 16777619\n        h ^= uint32(key[i])\n    }\n    return h\n}\n\nfunc (m *FastStringMap) Get(key string) (interface{}, bool) {\n    h := m.hash(key) % uint32(len(m.buckets))\n    bucket := m.buckets[h]\n    \n    for _, e := range bucket {\n        if e.key == key {\n            return e.value, true\n        }\n    }\n    return nil, false\n}\n```\n\n### String Optimization\n```go\n// String concatenation optimization\nfunc efficientStringConcat(strs []string) string {\n    // Calculate total length\n    var totalLen int\n    for _, s := range strs {\n        totalLen += len(s)\n    }\n    \n    // Preallocate builder\n    var builder strings.Builder\n    builder.Grow(totalLen)\n    \n    for _, s := range strs {\n        builder.WriteString(s)\n    }\n    \n    return builder.String()\n}\n\n// Avoid string copies\nfunc stringToBytes(s string) []byte {\n    // Safe conversion without copy (read-only)\n    return unsafe.Slice(unsafe.StringData(s), len(s))\n}\n\nfunc bytesToString(b []byte) string {\n    // Safe conversion without copy\n    return unsafe.String(unsafe.SliceData(b), len(b))\n}\n```\n\n## Performance Best Practices\n\n### Measurement and Profiling\n```go\n// Always measure before optimizing\nfunc measurePerformance() {\n    start := time.Now()\n    defer func() {\n        elapsed := time.Since(start)\n        log.Printf(\"Operation took %v\", elapsed)\n    }()\n    \n    // Operation to measure\n}\n\n// Use benchmarks for micro-optimizations\nfunc BenchmarkOptimization(b *testing.B) {\n    // Test different approaches\n}\n\n// Profile in production\nimport _ \"net/http/pprof\"\n// Access profiles at /debug/pprof/\n```\n\n### Common Optimizations\n```go\n// 1. Avoid premature optimization\n// Profile first, optimize bottlenecks\n\n// 2. Reduce allocations\n// Use sync.Pool, preallocate slices\n\n// 3. Optimize hot paths\n// Focus on frequently executed code\n\n// 4. Use efficient algorithms\n// O(n) vs O(n²) matters at scale\n\n// 5. Cache computed values\n// Memoization, lookup tables\n\n// 6. Batch operations\n// Reduce system calls, network requests\n\n// 7. Use appropriate data structures\n// Map vs slice, array vs slice\n\n// 8. Leverage concurrency wisely\n// Don't overuse goroutines\n\n// 9. Minimize interface conversions\n// Interfaces cause allocations\n\n// 10. Profile regularly\n// Performance can degrade over time\n```\n\n## Best Practices Summary\n\n1. **Profile before optimizing** - Measure, don't guess\n2. **Focus on algorithms first** - Better algorithm beats micro-optimizations\n3. **Reduce allocations** - Use pools, preallocate, reuse\n4. **Optimize hot paths** - 80/20 rule applies\n5. **Cache aggressively** - But invalidate correctly\n6. **Use buffered I/O** - For file and network operations\n7. **Batch operations** - Amortize overhead\n8. **Choose right data structures** - Map vs slice matters\n9. **Leverage compiler optimizations** - Write optimizer-friendly code\n10. **Monitor production performance** - Use pprof, metrics, tracing","numLines":1395,"startLine":1,"totalLines":1395}}}
{"parentUuid":"517e597a-7e3f-4d39-bc64-dad2791c2711","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01Navrc4LUVzTCaSgeAbyuTz","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Now I'll create the required documentation files. Let me start with the first file - decimal-patterns.md:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":14690,"cache_read_input_tokens":33214,"output_tokens":5153,"service_tier":"standard"}},"requestId":"req_011CS5WzzGrw3snxvoh7Nbq3","type":"assistant","uuid":"d2c467ec-180d-4a9f-af0a-e7a69c537a20","timestamp":"2025-08-13T10:03:16.810Z"}
{"parentUuid":"d2c467ec-180d-4a9f-af0a-e7a69c537a20","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01Navrc4LUVzTCaSgeAbyuTz","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01A9zSthAzSVfZrrcwke2ipy","name":"Write","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/decimal-patterns.md","content":"# Decimal Patterns - shopspring/decimal for Financial Calculations\n\n## Overview\n\nBig Meanie uses shopspring/decimal for ALL numeric operations involving money, prices, quantities, and percentages. This ensures exact decimal arithmetic without floating-point rounding errors that could cost real money in trading operations.\n\n## Table of Contents\n1. [Core Principles](#core-principles)\n2. [Basic Operations](#basic-operations)\n3. [Trading-Specific Patterns](#trading-specific-patterns)\n4. [Common Gotchas](#common-gotchas)\n5. [Performance Considerations](#performance-considerations)\n6. [Best Practices](#best-practices)\n\n## Core Principles\n\n```go\nimport \"github.com/shopspring/decimal\"\n\n// NEVER use float64 for financial calculations\n// BAD\nprice := 100.123  // float64 - NEVER DO THIS\ntotal := price * 1.5\n\n// GOOD\nprice := decimal.NewFromFloat(100.123)\ntotal := price.Mul(decimal.NewFromFloat(1.5))\n\n// BETTER - avoid float entirely\nprice := decimal.RequireFromString(\"100.123\")\nmultiplier := decimal.RequireFromString(\"1.5\")\ntotal := price.Mul(multiplier)\n```\n\n## Basic Operations\n\n### Creation and Initialization\n\n```go\n// From string (PREFERRED for literals)\nprice := decimal.RequireFromString(\"123.456789\")\n\n// From int\nquantity := decimal.NewFromInt(100)\n\n// From float (ONLY when interfacing with external APIs)\n// Always validate precision after conversion\napiPrice := decimal.NewFromFloat(apiResponse.Price)\nif apiPrice.Exponent() < -8 {\n    // Handle precision loss\n}\n\n// Zero and common values\nzero := decimal.Zero\none := decimal.NewFromInt(1)\nhundred := decimal.NewFromInt(100)\n```\n\n### Arithmetic Operations\n\n```go\n// All operations return new decimals (immutable)\na := decimal.RequireFromString(\"100.50\")\nb := decimal.RequireFromString(\"25.25\")\n\nsum := a.Add(b)           // 125.75\ndiff := a.Sub(b)          // 75.25\nproduct := a.Mul(b)       // 2537.625\nquotient := a.Div(b)      // 3.98...\n\n// Chaining operations\ntotal := price.Mul(quantity).Add(fee).Sub(discount)\n\n// Percentage calculations\nprice := decimal.RequireFromString(\"100\")\ntaxRate := decimal.RequireFromString(\"0.08\") // 8%\ntax := price.Mul(taxRate)\ntotalWithTax := price.Add(tax)\n\n// Or as percentage\npct := decimal.RequireFromString(\"8\")\ntax = price.Mul(pct).Div(decimal.NewFromInt(100))\n```\n\n### Comparisons\n\n```go\na := decimal.RequireFromString(\"100.01\")\nb := decimal.RequireFromString(\"100.02\")\n\nif a.Equal(b) {\n    // Exact equality\n}\n\nif a.LessThan(b) {\n    // a < b\n}\n\nif a.LessThanOrEqual(b) {\n    // a <= b\n}\n\nif a.GreaterThan(b) {\n    // a > b\n}\n\nif a.GreaterThanOrEqual(b) {\n    // a >= b\n}\n\n// Compare with zero\nif balance.IsPositive() {\n    // balance > 0\n}\n\nif balance.IsNegative() {\n    // balance < 0\n}\n\nif balance.IsZero() {\n    // balance == 0\n}\n\n// Sign check\nsign := amount.Sign() // Returns -1, 0, or 1\n```\n\n## Trading-Specific Patterns\n\n### Price and Quantity Handling\n\n```go\ntype Order struct {\n    Price    decimal.Decimal\n    Quantity decimal.Decimal\n    Side     string\n}\n\n// Calculate order value\nfunc (o Order) Value() decimal.Decimal {\n    return o.Price.Mul(o.Quantity)\n}\n\n// Apply trading fees\nfunc (o Order) TotalWithFee(feeRate decimal.Decimal) decimal.Decimal {\n    value := o.Value()\n    fee := value.Mul(feeRate)\n    \n    if o.Side == \"BUY\" {\n        return value.Add(fee)\n    }\n    return value.Sub(fee)\n}\n\n// Price tick rounding\nfunc RoundToTick(price, tickSize decimal.Decimal) decimal.Decimal {\n    if tickSize.IsZero() {\n        return price\n    }\n    return price.Div(tickSize).Round(0).Mul(tickSize)\n}\n```\n\n### Portfolio Calculations\n\n```go\ntype Position struct {\n    Symbol   string\n    Quantity decimal.Decimal\n    AvgPrice decimal.Decimal\n}\n\n// Calculate position value\nfunc (p Position) Value(currentPrice decimal.Decimal) decimal.Decimal {\n    return p.Quantity.Mul(currentPrice)\n}\n\n// Calculate P&L\nfunc (p Position) PnL(currentPrice decimal.Decimal) decimal.Decimal {\n    currentValue := p.Value(currentPrice)\n    costBasis := p.Quantity.Mul(p.AvgPrice)\n    return currentValue.Sub(costBasis)\n}\n\n// Calculate P&L percentage\nfunc (p Position) PnLPercent(currentPrice decimal.Decimal) decimal.Decimal {\n    if p.AvgPrice.IsZero() {\n        return decimal.Zero\n    }\n    \n    pnl := currentPrice.Sub(p.AvgPrice)\n    return pnl.Div(p.AvgPrice).Mul(decimal.NewFromInt(100))\n}\n\n// Portfolio totals\nfunc CalculatePortfolioValue(positions []Position, prices map[string]decimal.Decimal) decimal.Decimal {\n    total := decimal.Zero\n    \n    for _, pos := range positions {\n        if price, ok := prices[pos.Symbol]; ok {\n            total = total.Add(pos.Value(price))\n        }\n    }\n    \n    return total\n}\n```\n\n### Technical Indicators\n\n```go\n// Moving average with decimal precision\nfunc SMA(prices []decimal.Decimal, period int) decimal.Decimal {\n    if len(prices) < period {\n        return decimal.Zero\n    }\n    \n    sum := decimal.Zero\n    for i := len(prices) - period; i < len(prices); i++ {\n        sum = sum.Add(prices[i])\n    }\n    \n    return sum.Div(decimal.NewFromInt(int64(period)))\n}\n\n// RSI calculation\nfunc RSI(prices []decimal.Decimal, period int) decimal.Decimal {\n    if len(prices) < period+1 {\n        return decimal.Zero\n    }\n    \n    gains := decimal.Zero\n    losses := decimal.Zero\n    \n    for i := len(prices) - period; i < len(prices); i++ {\n        diff := prices[i].Sub(prices[i-1])\n        if diff.IsPositive() {\n            gains = gains.Add(diff)\n        } else {\n            losses = losses.Add(diff.Abs())\n        }\n    }\n    \n    avgGain := gains.Div(decimal.NewFromInt(int64(period)))\n    avgLoss := losses.Div(decimal.NewFromInt(int64(period)))\n    \n    if avgLoss.IsZero() {\n        return decimal.NewFromInt(100)\n    }\n    \n    rs := avgGain.Div(avgLoss)\n    rsi := decimal.NewFromInt(100).Sub(\n        decimal.NewFromInt(100).Div(\n            decimal.NewFromInt(1).Add(rs),\n        ),\n    )\n    \n    return rsi\n}\n```\n\n### Risk Management\n\n```go\n// Position sizing with Kelly Criterion\nfunc KellySize(winProb, winSize, lossSize decimal.Decimal) decimal.Decimal {\n    if lossSize.IsZero() {\n        return decimal.Zero\n    }\n    \n    // f = (p * b - q) / b\n    // where p = win probability, q = loss probability, b = win/loss ratio\n    q := decimal.NewFromInt(1).Sub(winProb)\n    b := winSize.Div(lossSize)\n    \n    numerator := winProb.Mul(b).Sub(q)\n    kelly := numerator.Div(b)\n    \n    // Never risk more than 25% (Kelly can suggest aggressive sizes)\n    maxSize := decimal.RequireFromString(\"0.25\")\n    if kelly.GreaterThan(maxSize) {\n        return maxSize\n    }\n    \n    if kelly.IsNegative() {\n        return decimal.Zero\n    }\n    \n    return kelly\n}\n\n// Stop loss calculation\nfunc CalculateStopLoss(entry, riskPercent decimal.Decimal, side string) decimal.Decimal {\n    risk := entry.Mul(riskPercent).Div(decimal.NewFromInt(100))\n    \n    if side == \"LONG\" {\n        return entry.Sub(risk)\n    }\n    return entry.Add(risk) // SHORT position\n}\n\n// Position size from risk amount\nfunc PositionSizeFromRisk(riskAmount, entry, stopLoss decimal.Decimal) decimal.Decimal {\n    riskPerUnit := entry.Sub(stopLoss).Abs()\n    if riskPerUnit.IsZero() {\n        return decimal.Zero\n    }\n    \n    return riskAmount.Div(riskPerUnit)\n}\n```\n\n## Common Gotchas\n\n### 1. Division by Zero\n\n```go\n// ALWAYS check for zero before division\nfunc SafeDivide(a, b decimal.Decimal) decimal.Decimal {\n    if b.IsZero() {\n        return decimal.Zero // or handle error appropriately\n    }\n    return a.Div(b)\n}\n\n// In ratio calculations\nfunc PriceToEarnings(price, earnings decimal.Decimal) decimal.Decimal {\n    if earnings.IsZero() || earnings.IsNegative() {\n        return decimal.NewFromInt(-1) // Indicate N/A\n    }\n    return price.Div(earnings)\n}\n```\n\n### 2. Precision and Rounding\n\n```go\n// Round to specific decimal places\nprice := decimal.RequireFromString(\"123.456789\")\nrounded := price.Round(2) // 123.46\n\n// Round for display vs calculation\ntype Price struct {\n    value decimal.Decimal\n}\n\nfunc (p Price) Display() string {\n    // Round to 2 places for display\n    return p.value.Round(2).String()\n}\n\nfunc (p Price) Calculate() decimal.Decimal {\n    // Keep full precision for calculations\n    return p.value\n}\n\n// Exchange-specific precision\nfunc FormatForExchange(price decimal.Decimal, exchange string) string {\n    precisions := map[string]int32{\n        \"binance\":  8,\n        \"coinbase\": 2,\n        \"kraken\":   5,\n    }\n    \n    precision := precisions[exchange]\n    return price.Round(precision).String()\n}\n```\n\n### 3. String Conversion Errors\n\n```go\n// Always handle string parsing errors\nfunc ParsePrice(s string) (decimal.Decimal, error) {\n    price, err := decimal.NewFromString(s)\n    if err != nil {\n        return decimal.Zero, fmt.Errorf(\"invalid price format: %w\", err)\n    }\n    \n    // Validate reasonable bounds\n    maxPrice := decimal.NewFromInt(1000000)\n    if price.IsNegative() || price.GreaterThan(maxPrice) {\n        return decimal.Zero, fmt.Errorf(\"price out of bounds: %s\", s)\n    }\n    \n    return price, nil\n}\n\n// Use RequireFromString only with hardcoded values\nconst FeeRate = \"0.001\" // 0.1%\nvar TradingFee = decimal.RequireFromString(FeeRate)\n```\n\n### 4. JSON Marshaling\n\n```go\n// Decimal fields in JSON\ntype Trade struct {\n    ID       string          `json:\"id\"`\n    Price    decimal.Decimal `json:\"price\"`\n    Quantity decimal.Decimal `json:\"quantity\"`\n    Total    decimal.Decimal `json:\"total\"`\n}\n\n// Custom JSON handling if needed\nfunc (t Trade) MarshalJSON() ([]byte, error) {\n    type Alias Trade\n    return json.Marshal(&struct {\n        Price    string `json:\"price\"`\n        Quantity string `json:\"quantity\"`\n        Total    string `json:\"total\"`\n        *Alias\n    }{\n        Price:    t.Price.String(),\n        Quantity: t.Quantity.String(),\n        Total:    t.Total.String(),\n        Alias:    (*Alias)(&t),\n    })\n}\n```\n\n### 5. Database Storage\n\n```go\n// Store as DECIMAL or NUMERIC in PostgreSQL\nCREATE TABLE trades (\n    id         SERIAL PRIMARY KEY,\n    price      DECIMAL(20, 8) NOT NULL,\n    quantity   DECIMAL(20, 8) NOT NULL,\n    total      DECIMAL(20, 8) NOT NULL,\n    fee        DECIMAL(20, 8) DEFAULT 0\n);\n\n// In Go with sqlx/pgx\nfunc SaveTrade(db *sql.DB, trade Trade) error {\n    query := `\n        INSERT INTO trades (price, quantity, total)\n        VALUES ($1, $2, $3)\n    `\n    _, err := db.Exec(query, \n        trade.Price.String(),\n        trade.Quantity.String(),\n        trade.Total.String(),\n    )\n    return err\n}\n```\n\n## Performance Considerations\n\n### Memory Allocation\n\n```go\n// Reuse decimal values when possible\nvar (\n    // Common constants\n    Zero     = decimal.Zero\n    One      = decimal.NewFromInt(1)\n    Hundred  = decimal.NewFromInt(100)\n    Thousand = decimal.NewFromInt(1000)\n)\n\n// Avoid creating new decimals in hot paths\ntype Calculator struct {\n    // Pre-allocated decimals\n    hundred  decimal.Decimal\n    feeRate  decimal.Decimal\n    tickSize decimal.Decimal\n}\n\nfunc NewCalculator() *Calculator {\n    return &Calculator{\n        hundred:  decimal.NewFromInt(100),\n        feeRate:  decimal.RequireFromString(\"0.001\"),\n        tickSize: decimal.RequireFromString(\"0.01\"),\n    }\n}\n```\n\n### Batch Operations\n\n```go\n// Process multiple calculations efficiently\nfunc CalculateTotals(trades []Trade) decimal.Decimal {\n    total := decimal.Zero\n    \n    // Single allocation for all iterations\n    for i := range trades {\n        total = total.Add(trades[i].Price.Mul(trades[i].Quantity))\n    }\n    \n    return total\n}\n\n// Parallel processing for large datasets\nfunc ParallelSum(values []decimal.Decimal) decimal.Decimal {\n    if len(values) < 1000 {\n        // Serial for small datasets\n        sum := decimal.Zero\n        for _, v := range values {\n            sum = sum.Add(v)\n        }\n        return sum\n    }\n    \n    // Parallel for large datasets\n    numWorkers := runtime.NumCPU()\n    chunkSize := len(values) / numWorkers\n    results := make(chan decimal.Decimal, numWorkers)\n    \n    for i := 0; i < numWorkers; i++ {\n        start := i * chunkSize\n        end := start + chunkSize\n        if i == numWorkers-1 {\n            end = len(values)\n        }\n        \n        go func(chunk []decimal.Decimal) {\n            sum := decimal.Zero\n            for _, v := range chunk {\n                sum = sum.Add(v)\n            }\n            results <- sum\n        }(values[start:end])\n    }\n    \n    total := decimal.Zero\n    for i := 0; i < numWorkers; i++ {\n        total = total.Add(<-results)\n    }\n    \n    return total\n}\n```\n\n## Best Practices\n\n### 1. Type Safety\n\n```go\n// Create domain types for different decimal uses\ntype Price decimal.Decimal\ntype Quantity decimal.Decimal\ntype Percentage decimal.Decimal\n\nfunc (p Price) Mul(q Quantity) decimal.Decimal {\n    return decimal.Decimal(p).Mul(decimal.Decimal(q))\n}\n\n// This prevents mixing incompatible types\n// price.Mul(percentage) // Compile error!\n```\n\n### 2. Validation\n\n```go\nfunc ValidateOrderParams(price, quantity decimal.Decimal) error {\n    if price.IsNegative() || price.IsZero() {\n        return fmt.Errorf(\"invalid price: %s\", price)\n    }\n    \n    if quantity.IsNegative() || quantity.IsZero() {\n        return fmt.Errorf(\"invalid quantity: %s\", quantity)\n    }\n    \n    minNotional := decimal.NewFromInt(10)\n    if price.Mul(quantity).LessThan(minNotional) {\n        return fmt.Errorf(\"order value below minimum: %s\", price.Mul(quantity))\n    }\n    \n    return nil\n}\n```\n\n### 3. Constants\n\n```go\n// Define reusable constants\nvar (\n    BasisPoint = decimal.RequireFromString(\"0.0001\")  // 0.01%\n    Percentage = decimal.RequireFromString(\"0.01\")    // 1%\n    \n    MaxLeverage = decimal.NewFromInt(10)\n    MinOrderSize = decimal.RequireFromString(\"0.001\")\n    \n    MakerFee = decimal.RequireFromString(\"0.001\")     // 0.1%\n    TakerFee = decimal.RequireFromString(\"0.0015\")    // 0.15%\n)\n```\n\n### 4. Error Handling\n\n```go\n// Always validate external inputs\nfunc ProcessTradeRequest(req TradeRequest) error {\n    price, err := decimal.NewFromString(req.Price)\n    if err != nil {\n        return fmt.Errorf(\"invalid price: %w\", err)\n    }\n    \n    quantity, err := decimal.NewFromString(req.Quantity)\n    if err != nil {\n        return fmt.Errorf(\"invalid quantity: %w\", err)\n    }\n    \n    // Validate business rules\n    if err := ValidateOrderParams(price, quantity); err != nil {\n        return err\n    }\n    \n    // Process trade...\n    return nil\n}\n```\n\n### 5. Testing\n\n```go\nfunc TestPriceCalculation(t *testing.T) {\n    tests := []struct {\n        name     string\n        price    string\n        quantity string\n        expected string\n    }{\n        {\n            name:     \"simple multiplication\",\n            price:    \"100.50\",\n            quantity: \"2.5\",\n            expected: \"251.25\",\n        },\n        {\n            name:     \"precision handling\",\n            price:    \"0.00000001\",\n            quantity: \"100000000\",\n            expected: \"1\",\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            price := decimal.RequireFromString(tt.price)\n            quantity := decimal.RequireFromString(tt.quantity)\n            expected := decimal.RequireFromString(tt.expected)\n            \n            result := price.Mul(quantity)\n            \n            if !result.Equal(expected) {\n                t.Errorf(\"got %s, want %s\", result, expected)\n            }\n        })\n    }\n}\n```\n\n## Summary\n\n1. **Always use decimal for money** - Never float64\n2. **Parse from strings** - Avoid NewFromFloat when possible\n3. **Check for zero** - Before division operations\n4. **Validate inputs** - Especially from external sources\n5. **Define constants** - For commonly used values\n6. **Round appropriately** - Different precision for display vs calculation\n7. **Handle errors** - String parsing can fail\n8. **Test thoroughly** - Include edge cases and precision tests\n9. **Use domain types** - Price, Quantity, Percentage for type safety\n10. **Profile if needed** - Decimal ops are slower than float, optimize hot paths"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":14690,"cache_read_input_tokens":33214,"output_tokens":5153,"service_tier":"standard"}},"requestId":"req_011CS5WzzGrw3snxvoh7Nbq3","type":"assistant","uuid":"a8fbeb83-be90-473f-beba-eb084e5b5f8a","timestamp":"2025-08-13T10:05:35.563Z"}
{"parentUuid":"a8fbeb83-be90-473f-beba-eb084e5b5f8a","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01A9zSthAzSVfZrrcwke2ipy","type":"tool_result","content":"File created successfully at: /home/aural/Code/bigmeanie/back/.docs/code/decimal-patterns.md"}]},"uuid":"be7b2358-0834-41c3-843d-c1084537aff3","timestamp":"2025-08-13T10:05:49.696Z","toolUseResult":{"type":"create","filePath":"/home/aural/Code/bigmeanie/back/.docs/code/decimal-patterns.md","content":"# Decimal Patterns - shopspring/decimal for Financial Calculations\n\n## Overview\n\nBig Meanie uses shopspring/decimal for ALL numeric operations involving money, prices, quantities, and percentages. This ensures exact decimal arithmetic without floating-point rounding errors that could cost real money in trading operations.\n\n## Table of Contents\n1. [Core Principles](#core-principles)\n2. [Basic Operations](#basic-operations)\n3. [Trading-Specific Patterns](#trading-specific-patterns)\n4. [Common Gotchas](#common-gotchas)\n5. [Performance Considerations](#performance-considerations)\n6. [Best Practices](#best-practices)\n\n## Core Principles\n\n```go\nimport \"github.com/shopspring/decimal\"\n\n// NEVER use float64 for financial calculations\n// BAD\nprice := 100.123  // float64 - NEVER DO THIS\ntotal := price * 1.5\n\n// GOOD\nprice := decimal.NewFromFloat(100.123)\ntotal := price.Mul(decimal.NewFromFloat(1.5))\n\n// BETTER - avoid float entirely\nprice := decimal.RequireFromString(\"100.123\")\nmultiplier := decimal.RequireFromString(\"1.5\")\ntotal := price.Mul(multiplier)\n```\n\n## Basic Operations\n\n### Creation and Initialization\n\n```go\n// From string (PREFERRED for literals)\nprice := decimal.RequireFromString(\"123.456789\")\n\n// From int\nquantity := decimal.NewFromInt(100)\n\n// From float (ONLY when interfacing with external APIs)\n// Always validate precision after conversion\napiPrice := decimal.NewFromFloat(apiResponse.Price)\nif apiPrice.Exponent() < -8 {\n    // Handle precision loss\n}\n\n// Zero and common values\nzero := decimal.Zero\none := decimal.NewFromInt(1)\nhundred := decimal.NewFromInt(100)\n```\n\n### Arithmetic Operations\n\n```go\n// All operations return new decimals (immutable)\na := decimal.RequireFromString(\"100.50\")\nb := decimal.RequireFromString(\"25.25\")\n\nsum := a.Add(b)           // 125.75\ndiff := a.Sub(b)          // 75.25\nproduct := a.Mul(b)       // 2537.625\nquotient := a.Div(b)      // 3.98...\n\n// Chaining operations\ntotal := price.Mul(quantity).Add(fee).Sub(discount)\n\n// Percentage calculations\nprice := decimal.RequireFromString(\"100\")\ntaxRate := decimal.RequireFromString(\"0.08\") // 8%\ntax := price.Mul(taxRate)\ntotalWithTax := price.Add(tax)\n\n// Or as percentage\npct := decimal.RequireFromString(\"8\")\ntax = price.Mul(pct).Div(decimal.NewFromInt(100))\n```\n\n### Comparisons\n\n```go\na := decimal.RequireFromString(\"100.01\")\nb := decimal.RequireFromString(\"100.02\")\n\nif a.Equal(b) {\n    // Exact equality\n}\n\nif a.LessThan(b) {\n    // a < b\n}\n\nif a.LessThanOrEqual(b) {\n    // a <= b\n}\n\nif a.GreaterThan(b) {\n    // a > b\n}\n\nif a.GreaterThanOrEqual(b) {\n    // a >= b\n}\n\n// Compare with zero\nif balance.IsPositive() {\n    // balance > 0\n}\n\nif balance.IsNegative() {\n    // balance < 0\n}\n\nif balance.IsZero() {\n    // balance == 0\n}\n\n// Sign check\nsign := amount.Sign() // Returns -1, 0, or 1\n```\n\n## Trading-Specific Patterns\n\n### Price and Quantity Handling\n\n```go\ntype Order struct {\n    Price    decimal.Decimal\n    Quantity decimal.Decimal\n    Side     string\n}\n\n// Calculate order value\nfunc (o Order) Value() decimal.Decimal {\n    return o.Price.Mul(o.Quantity)\n}\n\n// Apply trading fees\nfunc (o Order) TotalWithFee(feeRate decimal.Decimal) decimal.Decimal {\n    value := o.Value()\n    fee := value.Mul(feeRate)\n    \n    if o.Side == \"BUY\" {\n        return value.Add(fee)\n    }\n    return value.Sub(fee)\n}\n\n// Price tick rounding\nfunc RoundToTick(price, tickSize decimal.Decimal) decimal.Decimal {\n    if tickSize.IsZero() {\n        return price\n    }\n    return price.Div(tickSize).Round(0).Mul(tickSize)\n}\n```\n\n### Portfolio Calculations\n\n```go\ntype Position struct {\n    Symbol   string\n    Quantity decimal.Decimal\n    AvgPrice decimal.Decimal\n}\n\n// Calculate position value\nfunc (p Position) Value(currentPrice decimal.Decimal) decimal.Decimal {\n    return p.Quantity.Mul(currentPrice)\n}\n\n// Calculate P&L\nfunc (p Position) PnL(currentPrice decimal.Decimal) decimal.Decimal {\n    currentValue := p.Value(currentPrice)\n    costBasis := p.Quantity.Mul(p.AvgPrice)\n    return currentValue.Sub(costBasis)\n}\n\n// Calculate P&L percentage\nfunc (p Position) PnLPercent(currentPrice decimal.Decimal) decimal.Decimal {\n    if p.AvgPrice.IsZero() {\n        return decimal.Zero\n    }\n    \n    pnl := currentPrice.Sub(p.AvgPrice)\n    return pnl.Div(p.AvgPrice).Mul(decimal.NewFromInt(100))\n}\n\n// Portfolio totals\nfunc CalculatePortfolioValue(positions []Position, prices map[string]decimal.Decimal) decimal.Decimal {\n    total := decimal.Zero\n    \n    for _, pos := range positions {\n        if price, ok := prices[pos.Symbol]; ok {\n            total = total.Add(pos.Value(price))\n        }\n    }\n    \n    return total\n}\n```\n\n### Technical Indicators\n\n```go\n// Moving average with decimal precision\nfunc SMA(prices []decimal.Decimal, period int) decimal.Decimal {\n    if len(prices) < period {\n        return decimal.Zero\n    }\n    \n    sum := decimal.Zero\n    for i := len(prices) - period; i < len(prices); i++ {\n        sum = sum.Add(prices[i])\n    }\n    \n    return sum.Div(decimal.NewFromInt(int64(period)))\n}\n\n// RSI calculation\nfunc RSI(prices []decimal.Decimal, period int) decimal.Decimal {\n    if len(prices) < period+1 {\n        return decimal.Zero\n    }\n    \n    gains := decimal.Zero\n    losses := decimal.Zero\n    \n    for i := len(prices) - period; i < len(prices); i++ {\n        diff := prices[i].Sub(prices[i-1])\n        if diff.IsPositive() {\n            gains = gains.Add(diff)\n        } else {\n            losses = losses.Add(diff.Abs())\n        }\n    }\n    \n    avgGain := gains.Div(decimal.NewFromInt(int64(period)))\n    avgLoss := losses.Div(decimal.NewFromInt(int64(period)))\n    \n    if avgLoss.IsZero() {\n        return decimal.NewFromInt(100)\n    }\n    \n    rs := avgGain.Div(avgLoss)\n    rsi := decimal.NewFromInt(100).Sub(\n        decimal.NewFromInt(100).Div(\n            decimal.NewFromInt(1).Add(rs),\n        ),\n    )\n    \n    return rsi\n}\n```\n\n### Risk Management\n\n```go\n// Position sizing with Kelly Criterion\nfunc KellySize(winProb, winSize, lossSize decimal.Decimal) decimal.Decimal {\n    if lossSize.IsZero() {\n        return decimal.Zero\n    }\n    \n    // f = (p * b - q) / b\n    // where p = win probability, q = loss probability, b = win/loss ratio\n    q := decimal.NewFromInt(1).Sub(winProb)\n    b := winSize.Div(lossSize)\n    \n    numerator := winProb.Mul(b).Sub(q)\n    kelly := numerator.Div(b)\n    \n    // Never risk more than 25% (Kelly can suggest aggressive sizes)\n    maxSize := decimal.RequireFromString(\"0.25\")\n    if kelly.GreaterThan(maxSize) {\n        return maxSize\n    }\n    \n    if kelly.IsNegative() {\n        return decimal.Zero\n    }\n    \n    return kelly\n}\n\n// Stop loss calculation\nfunc CalculateStopLoss(entry, riskPercent decimal.Decimal, side string) decimal.Decimal {\n    risk := entry.Mul(riskPercent).Div(decimal.NewFromInt(100))\n    \n    if side == \"LONG\" {\n        return entry.Sub(risk)\n    }\n    return entry.Add(risk) // SHORT position\n}\n\n// Position size from risk amount\nfunc PositionSizeFromRisk(riskAmount, entry, stopLoss decimal.Decimal) decimal.Decimal {\n    riskPerUnit := entry.Sub(stopLoss).Abs()\n    if riskPerUnit.IsZero() {\n        return decimal.Zero\n    }\n    \n    return riskAmount.Div(riskPerUnit)\n}\n```\n\n## Common Gotchas\n\n### 1. Division by Zero\n\n```go\n// ALWAYS check for zero before division\nfunc SafeDivide(a, b decimal.Decimal) decimal.Decimal {\n    if b.IsZero() {\n        return decimal.Zero // or handle error appropriately\n    }\n    return a.Div(b)\n}\n\n// In ratio calculations\nfunc PriceToEarnings(price, earnings decimal.Decimal) decimal.Decimal {\n    if earnings.IsZero() || earnings.IsNegative() {\n        return decimal.NewFromInt(-1) // Indicate N/A\n    }\n    return price.Div(earnings)\n}\n```\n\n### 2. Precision and Rounding\n\n```go\n// Round to specific decimal places\nprice := decimal.RequireFromString(\"123.456789\")\nrounded := price.Round(2) // 123.46\n\n// Round for display vs calculation\ntype Price struct {\n    value decimal.Decimal\n}\n\nfunc (p Price) Display() string {\n    // Round to 2 places for display\n    return p.value.Round(2).String()\n}\n\nfunc (p Price) Calculate() decimal.Decimal {\n    // Keep full precision for calculations\n    return p.value\n}\n\n// Exchange-specific precision\nfunc FormatForExchange(price decimal.Decimal, exchange string) string {\n    precisions := map[string]int32{\n        \"binance\":  8,\n        \"coinbase\": 2,\n        \"kraken\":   5,\n    }\n    \n    precision := precisions[exchange]\n    return price.Round(precision).String()\n}\n```\n\n### 3. String Conversion Errors\n\n```go\n// Always handle string parsing errors\nfunc ParsePrice(s string) (decimal.Decimal, error) {\n    price, err := decimal.NewFromString(s)\n    if err != nil {\n        return decimal.Zero, fmt.Errorf(\"invalid price format: %w\", err)\n    }\n    \n    // Validate reasonable bounds\n    maxPrice := decimal.NewFromInt(1000000)\n    if price.IsNegative() || price.GreaterThan(maxPrice) {\n        return decimal.Zero, fmt.Errorf(\"price out of bounds: %s\", s)\n    }\n    \n    return price, nil\n}\n\n// Use RequireFromString only with hardcoded values\nconst FeeRate = \"0.001\" // 0.1%\nvar TradingFee = decimal.RequireFromString(FeeRate)\n```\n\n### 4. JSON Marshaling\n\n```go\n// Decimal fields in JSON\ntype Trade struct {\n    ID       string          `json:\"id\"`\n    Price    decimal.Decimal `json:\"price\"`\n    Quantity decimal.Decimal `json:\"quantity\"`\n    Total    decimal.Decimal `json:\"total\"`\n}\n\n// Custom JSON handling if needed\nfunc (t Trade) MarshalJSON() ([]byte, error) {\n    type Alias Trade\n    return json.Marshal(&struct {\n        Price    string `json:\"price\"`\n        Quantity string `json:\"quantity\"`\n        Total    string `json:\"total\"`\n        *Alias\n    }{\n        Price:    t.Price.String(),\n        Quantity: t.Quantity.String(),\n        Total:    t.Total.String(),\n        Alias:    (*Alias)(&t),\n    })\n}\n```\n\n### 5. Database Storage\n\n```go\n// Store as DECIMAL or NUMERIC in PostgreSQL\nCREATE TABLE trades (\n    id         SERIAL PRIMARY KEY,\n    price      DECIMAL(20, 8) NOT NULL,\n    quantity   DECIMAL(20, 8) NOT NULL,\n    total      DECIMAL(20, 8) NOT NULL,\n    fee        DECIMAL(20, 8) DEFAULT 0\n);\n\n// In Go with sqlx/pgx\nfunc SaveTrade(db *sql.DB, trade Trade) error {\n    query := `\n        INSERT INTO trades (price, quantity, total)\n        VALUES ($1, $2, $3)\n    `\n    _, err := db.Exec(query, \n        trade.Price.String(),\n        trade.Quantity.String(),\n        trade.Total.String(),\n    )\n    return err\n}\n```\n\n## Performance Considerations\n\n### Memory Allocation\n\n```go\n// Reuse decimal values when possible\nvar (\n    // Common constants\n    Zero     = decimal.Zero\n    One      = decimal.NewFromInt(1)\n    Hundred  = decimal.NewFromInt(100)\n    Thousand = decimal.NewFromInt(1000)\n)\n\n// Avoid creating new decimals in hot paths\ntype Calculator struct {\n    // Pre-allocated decimals\n    hundred  decimal.Decimal\n    feeRate  decimal.Decimal\n    tickSize decimal.Decimal\n}\n\nfunc NewCalculator() *Calculator {\n    return &Calculator{\n        hundred:  decimal.NewFromInt(100),\n        feeRate:  decimal.RequireFromString(\"0.001\"),\n        tickSize: decimal.RequireFromString(\"0.01\"),\n    }\n}\n```\n\n### Batch Operations\n\n```go\n// Process multiple calculations efficiently\nfunc CalculateTotals(trades []Trade) decimal.Decimal {\n    total := decimal.Zero\n    \n    // Single allocation for all iterations\n    for i := range trades {\n        total = total.Add(trades[i].Price.Mul(trades[i].Quantity))\n    }\n    \n    return total\n}\n\n// Parallel processing for large datasets\nfunc ParallelSum(values []decimal.Decimal) decimal.Decimal {\n    if len(values) < 1000 {\n        // Serial for small datasets\n        sum := decimal.Zero\n        for _, v := range values {\n            sum = sum.Add(v)\n        }\n        return sum\n    }\n    \n    // Parallel for large datasets\n    numWorkers := runtime.NumCPU()\n    chunkSize := len(values) / numWorkers\n    results := make(chan decimal.Decimal, numWorkers)\n    \n    for i := 0; i < numWorkers; i++ {\n        start := i * chunkSize\n        end := start + chunkSize\n        if i == numWorkers-1 {\n            end = len(values)\n        }\n        \n        go func(chunk []decimal.Decimal) {\n            sum := decimal.Zero\n            for _, v := range chunk {\n                sum = sum.Add(v)\n            }\n            results <- sum\n        }(values[start:end])\n    }\n    \n    total := decimal.Zero\n    for i := 0; i < numWorkers; i++ {\n        total = total.Add(<-results)\n    }\n    \n    return total\n}\n```\n\n## Best Practices\n\n### 1. Type Safety\n\n```go\n// Create domain types for different decimal uses\ntype Price decimal.Decimal\ntype Quantity decimal.Decimal\ntype Percentage decimal.Decimal\n\nfunc (p Price) Mul(q Quantity) decimal.Decimal {\n    return decimal.Decimal(p).Mul(decimal.Decimal(q))\n}\n\n// This prevents mixing incompatible types\n// price.Mul(percentage) // Compile error!\n```\n\n### 2. Validation\n\n```go\nfunc ValidateOrderParams(price, quantity decimal.Decimal) error {\n    if price.IsNegative() || price.IsZero() {\n        return fmt.Errorf(\"invalid price: %s\", price)\n    }\n    \n    if quantity.IsNegative() || quantity.IsZero() {\n        return fmt.Errorf(\"invalid quantity: %s\", quantity)\n    }\n    \n    minNotional := decimal.NewFromInt(10)\n    if price.Mul(quantity).LessThan(minNotional) {\n        return fmt.Errorf(\"order value below minimum: %s\", price.Mul(quantity))\n    }\n    \n    return nil\n}\n```\n\n### 3. Constants\n\n```go\n// Define reusable constants\nvar (\n    BasisPoint = decimal.RequireFromString(\"0.0001\")  // 0.01%\n    Percentage = decimal.RequireFromString(\"0.01\")    // 1%\n    \n    MaxLeverage = decimal.NewFromInt(10)\n    MinOrderSize = decimal.RequireFromString(\"0.001\")\n    \n    MakerFee = decimal.RequireFromString(\"0.001\")     // 0.1%\n    TakerFee = decimal.RequireFromString(\"0.0015\")    // 0.15%\n)\n```\n\n### 4. Error Handling\n\n```go\n// Always validate external inputs\nfunc ProcessTradeRequest(req TradeRequest) error {\n    price, err := decimal.NewFromString(req.Price)\n    if err != nil {\n        return fmt.Errorf(\"invalid price: %w\", err)\n    }\n    \n    quantity, err := decimal.NewFromString(req.Quantity)\n    if err != nil {\n        return fmt.Errorf(\"invalid quantity: %w\", err)\n    }\n    \n    // Validate business rules\n    if err := ValidateOrderParams(price, quantity); err != nil {\n        return err\n    }\n    \n    // Process trade...\n    return nil\n}\n```\n\n### 5. Testing\n\n```go\nfunc TestPriceCalculation(t *testing.T) {\n    tests := []struct {\n        name     string\n        price    string\n        quantity string\n        expected string\n    }{\n        {\n            name:     \"simple multiplication\",\n            price:    \"100.50\",\n            quantity: \"2.5\",\n            expected: \"251.25\",\n        },\n        {\n            name:     \"precision handling\",\n            price:    \"0.00000001\",\n            quantity: \"100000000\",\n            expected: \"1\",\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            price := decimal.RequireFromString(tt.price)\n            quantity := decimal.RequireFromString(tt.quantity)\n            expected := decimal.RequireFromString(tt.expected)\n            \n            result := price.Mul(quantity)\n            \n            if !result.Equal(expected) {\n                t.Errorf(\"got %s, want %s\", result, expected)\n            }\n        })\n    }\n}\n```\n\n## Summary\n\n1. **Always use decimal for money** - Never float64\n2. **Parse from strings** - Avoid NewFromFloat when possible\n3. **Check for zero** - Before division operations\n4. **Validate inputs** - Especially from external sources\n5. **Define constants** - For commonly used values\n6. **Round appropriately** - Different precision for display vs calculation\n7. **Handle errors** - String parsing can fail\n8. **Test thoroughly** - Include edge cases and precision tests\n9. **Use domain types** - Price, Quantity, Percentage for type safety\n10. **Profile if needed** - Decimal ops are slower than float, optimize hot paths","structuredPatch":[]}}
{"parentUuid":"be7b2358-0834-41c3-843d-c1084537aff3","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01FKGctt4iPzpJgxhkCQSB7E","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Now let's create the project-conventions.md file:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":5192,"cache_read_input_tokens":47904,"output_tokens":3822,"service_tier":"standard"}},"requestId":"req_011CS5XCZ87VrUWJkNw7hCKg","type":"assistant","uuid":"1b8785ba-e947-4684-ad27-958fd71a9c5e","timestamp":"2025-08-13T10:05:52.926Z"}
{"parentUuid":"1b8785ba-e947-4684-ad27-958fd71a9c5e","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01FKGctt4iPzpJgxhkCQSB7E","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01LoyVjVchsDaWXAWwfRxR1c","name":"Write","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md","content":"# Big Meanie Project Conventions\n\n## Philosophy\n\nBig Meanie follows a radical simplicity approach: **break fast, fix immediately**. We prioritize clean breaks over compatibility layers because hidden issues compound exponentially. A breaking change that forces immediate fixes is better than subtle bugs that surface months later in production.\n\n## Table of Contents\n1. [Core Philosophy](#core-philosophy)\n2. [Naming Conventions](#naming-conventions)\n3. [No Backwards Compatibility](#no-backwards-compatibility)\n4. [Project Structure](#project-structure)\n5. [File Management](#file-management)\n6. [Code Organization](#code-organization)\n7. [Testing Standards](#testing-standards)\n8. [Documentation Rules](#documentation-rules)\n\n## Core Philosophy\n\n### The Big Meanie Way\n\n```go\n// We value:\n// 1. Clarity over cleverness\n// 2. Breaking changes over hidden complexity\n// 3. Direct solutions over abstractions\n// 4. Fast failures over graceful degradation\n// 5. Today's correctness over tomorrow's flexibility\n```\n\n### Design Principles\n\n```go\n// BAD: Maintaining compatibility\ntype OrderService interface {\n    PlaceOrder(order Order) error\n    PlaceOrderV2(order OrderV2) error  // NEVER DO THIS\n}\n\n// GOOD: Clean break\ntype OrderService interface {\n    PlaceOrder(order Order) error  // Just change it\n}\n\n// BAD: Migration code\nfunc MigrateData() {\n    if isOldFormat() {\n        convertToNew()  // NEVER DO THIS\n    }\n}\n\n// GOOD: Direct cutover\nfunc LoadData() {\n    // Assume new format only\n    // Old format fails fast\n}\n```\n\n## Naming Conventions\n\n### Ultra-Concise Names\n\nBig Meanie uses ultra-concise naming. We prefer short, clear names over verbose descriptions.\n\n```go\n// BAD: Verbose naming\ntype SupportResistanceCalculator struct {\n    maximumLookbackPeriod int\n    minimumVolumeThreshold decimal.Decimal\n}\n\nfunc CalculateSupportAndResistanceLevels() {}\nfunc GetMovingAverageConvergenceDivergence() {}\n\n// GOOD: Ultra-concise\ntype SR struct {  // Support/Resistance\n    maxLookback int\n    minVol decimal.Decimal\n}\n\nfunc CalcSR() {}\nfunc MACD() {}\n```\n\n### Standard Abbreviations\n\n```go\n// Common trading abbreviations\nSR   // Support/Resistance\nMA   // Moving Average\nEMA  // Exponential Moving Average\nRSI  // Relative Strength Index\nMACD // Moving Average Convergence Divergence\nBB   // Bollinger Bands\nATR  // Average True Range\nOBV  // On-Balance Volume\nMFI  // Money Flow Index\n\n// System abbreviations\ncfg  // config\nctx  // context\nconn // connection\ndb   // database\nerr  // error\nmsg  // message\nreq  // request\nres  // response/result\ntx   // transaction\n\n// Trading specific\nqty  // quantity\nvol  // volume\npos  // position\npnl  // profit and loss\nnav  // net asset value\nliq  // liquidation/liquidity\n```\n\n### Method Names\n\n```go\n// Prefer short verbs\nCalc()  not  Calculate()\nExec()  not  Execute()\nInit()  not  Initialize()\nProc()  not  Process()\nGen()   not  Generate()\n\n// Getters don't use Get\nPrice()     not  GetPrice()\nQuantity()  not  GetQuantity()\n\n// Setters use Set\nSetPrice()\nSetQuantity()\n\n// Boolean methods\nIsValid()   not  CheckIfValid()\nHasData()   not  CheckHasData()\nCanTrade()  not  CheckCanTrade()\n```\n\n## No Backwards Compatibility\n\n### Breaking Changes Are Good\n\n```go\n// BAD: Versioned APIs\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/v1/orders\", ordersV1Handler)\n    api.HandleFunc(\"/v2/orders\", ordersV2Handler)  // NEVER\n}\n\n// GOOD: One version only\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/orders\", ordersHandler)  // Break it, fix it\n}\n\n// BAD: Compatibility fields\ntype Order struct {\n    ID       string\n    Price    decimal.Decimal\n    \n    // Deprecated: Use Price instead\n    PriceStr string  // NEVER KEEP THIS\n}\n\n// GOOD: Clean structure\ntype Order struct {\n    ID    string\n    Price decimal.Decimal  // Changed? Fix all usages\n}\n```\n\n### Migration Anti-Patterns to Avoid\n\n```go\n// NEVER: Gradual migration\nfunc LoadConfig() Config {\n    if FileExists(\"config.yaml\") {\n        return LoadYAML()\n    }\n    // Fallback to old format\n    return LoadJSON()  // NEVER DO THIS\n}\n\n// ALWAYS: Direct cutover\nfunc LoadConfig() Config {\n    return LoadYAML()  // Old format fails immediately\n}\n\n// NEVER: Adapter patterns\ntype LegacyAdapter struct {\n    newService *Service\n}\n\nfunc (a *LegacyAdapter) OldMethod() {\n    a.newService.NewMethod()  // NEVER BUILD ADAPTERS\n}\n\n// ALWAYS: Direct replacement\n// Just change OldMethod to NewMethod everywhere\n```\n\n### Database Migration Rules\n\n```sql\n-- BAD: Maintaining old columns\nALTER TABLE orders ADD COLUMN price_decimal DECIMAL(20,8);\nUPDATE orders SET price_decimal = CAST(price_string AS DECIMAL);\n-- Keep both columns during \"transition\" - NEVER\n\n-- GOOD: Direct replacement\nALTER TABLE orders DROP COLUMN price_string;\nALTER TABLE orders ADD COLUMN price DECIMAL(20,8) NOT NULL;\n-- Breaks immediately, forces data migration\n```\n\n## Project Structure\n\n### Directory Layout\n\n```\nbigmeanie/\n├── back/                 # Backend code\n│   ├── cmd/             # Entry points\n│   │   ├── trade/       # Trading bot\n│   │   ├── backtest/    # Backtesting engine\n│   │   └── api/         # REST API server\n│   ├── internal/        # Private packages\n│   │   ├── engine/      # Trading engine\n│   │   ├── strategy/    # Trading strategies\n│   │   ├── exchange/    # Exchange integrations\n│   │   ├── portfolio/   # Portfolio management\n│   │   └── risk/        # Risk management\n│   ├── pkg/             # Public packages\n│   │   ├── indicators/  # Technical indicators\n│   │   ├── decimal/     # Decimal utilities\n│   │   └── errors/      # Error handling\n│   └── .docs/           # Documentation\n│       ├── code/        # Code patterns\n│       ├── plan.md      # Current planning\n│       └── todo.md      # Task tracking\n└── front/               # Frontend code\n    └── [React/Next.js structure]\n```\n\n### Package Organization\n\n```go\n// Each package has single responsibility\n// internal/engine/engine.go\npackage engine\n\ntype Engine struct {\n    // Only engine-related fields\n}\n\n// internal/strategy/strategy.go\npackage strategy\n\ntype Strategy interface {\n    // Only strategy methods\n}\n\n// Never mix concerns in one package\n// BAD: internal/trading/everything.go\n// GOOD: Separate packages for separate concerns\n```\n\n## File Management\n\n### No Variant Files\n\n```go\n// NEVER create these files:\norder.go\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_enhanced.go // NEVER\norder_refactored.go // NEVER\n\n// ALWAYS update the original:\norder.go  // Just change this file\n```\n\n### File Naming\n\n```go\n// Standard Go conventions\norder.go        // Types and methods\norder_test.go   // Tests\ndoc.go         // Package documentation\n\n// Group by feature, not by type\n// BAD structure:\ntypes.go       // All types\nmethods.go     // All methods\ninterfaces.go  // All interfaces\n\n// GOOD structure:\norder.go       // Order type and methods\ntrade.go       // Trade type and methods\nportfolio.go   // Portfolio type and methods\n```\n\n### Import Organization\n\n```go\nimport (\n    // Standard library\n    \"context\"\n    \"fmt\"\n    \n    // External dependencies\n    \"github.com/shopspring/decimal\"\n    \n    // Internal packages\n    \"bigmeanie/internal/engine\"\n    \"bigmeanie/pkg/indicators\"\n)\n\n// Never use relative imports\n// BAD:  import \"../engine\"\n// GOOD: import \"bigmeanie/internal/engine\"\n```\n\n## Code Organization\n\n### Interface Design\n\n```go\n// Small, focused interfaces\ntype Trader interface {\n    Trade(ctx context.Context, signal Signal) error\n}\n\n// Not large, kitchen-sink interfaces\ntype BadTrader interface {\n    Trade() error\n    GetBalance() decimal.Decimal\n    GetHistory() []Trade\n    Configure(Config) error\n    // ... 20 more methods - NO!\n}\n\n// Compose interfaces when needed\ntype FullTrader interface {\n    Trader\n    Backtester\n    Reporter\n}\n```\n\n### Error Handling\n\n```go\n// Always wrap errors with context\nif err != nil {\n    return fmt.Errorf(\"engine.Start: %w\", err)\n}\n\n// Define sentinel errors\nvar (\n    ErrInsufficientFunds = errors.New(\"insufficient funds\")\n    ErrOrderTooSmall     = errors.New(\"order below minimum\")\n    ErrExchangeDown      = errors.New(\"exchange unavailable\")\n)\n\n// Use errors.Is for checking\nif errors.Is(err, ErrInsufficientFunds) {\n    // Handle specific error\n}\n```\n\n### Concurrency Patterns\n\n```go\n// Always use context for cancellation\nfunc (e *Engine) Run(ctx context.Context) error {\n    for {\n        select {\n        case <-ctx.Done():\n            return ctx.Err()\n        case signal := <-e.signals:\n            e.process(signal)\n        }\n    }\n}\n\n// Protect shared state\ntype Portfolio struct {\n    mu       sync.RWMutex\n    balances map[string]decimal.Decimal\n}\n\nfunc (p *Portfolio) Balance(asset string) decimal.Decimal {\n    p.mu.RLock()\n    defer p.mu.RUnlock()\n    return p.balances[asset]\n}\n```\n\n## Testing Standards\n\n### Test Organization\n\n```go\n// Table-driven tests always\nfunc TestCalcSR(t *testing.T) {\n    tests := []struct {\n        name string\n        data []decimal.Decimal\n        want []Level\n    }{\n        {\n            name: \"basic support\",\n            data: []decimal.Decimal{...},\n            want: []Level{...},\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := CalcSR(tt.data)\n            require.Equal(t, tt.want, got)\n        })\n    }\n}\n\n// NEVER use t.Skip()\n// BAD:\nfunc TestBrokenFeature(t *testing.T) {\n    t.Skip(\"Fix later\")  // NEVER\n}\n\n// GOOD: Fix it or delete it\n```\n\n### Test Coverage\n\n```go\n// Test edge cases\nfunc TestDivision(t *testing.T) {\n    // Test zero division\n    _, err := Divide(decimal.NewFromInt(1), decimal.Zero)\n    require.Error(t, err)\n    \n    // Test negative values\n    result := Divide(decimal.NewFromInt(-10), decimal.NewFromInt(2))\n    require.Equal(t, decimal.NewFromInt(-5), result)\n}\n\n// Benchmark hot paths\nfunc BenchmarkCalcSR(b *testing.B) {\n    data := generatePriceData(1000)\n    b.ResetTimer()\n    \n    for i := 0; i < b.N; i++ {\n        CalcSR(data)\n    }\n}\n```\n\n## Documentation Rules\n\n### Code Comments\n\n```go\n// Document WHY, not WHAT\n// BAD:\n// Increment counter by 1\ncounter++\n\n// GOOD:\n// Retry count for exchange rate limiting\ncounter++\n\n// Document edge cases\n// Returns -1 if no valid price found\nfunc FindPrice(prices []decimal.Decimal) decimal.Decimal {\n    // ...\n}\n\n// Document assumptions\n// Assumes prices are sorted in ascending order\nfunc BinarySearch(prices []decimal.Decimal, target decimal.Decimal) int {\n    // ...\n}\n```\n\n### Package Documentation\n\n```go\n// Package engine implements the core trading engine for Big Meanie.\n//\n// The engine coordinates between strategy signals, risk management,\n// and exchange execution. It runs continuously, processing signals\n// and managing positions according to configured strategies.\n//\n// Basic usage:\n//\n//\tcfg := engine.DefaultConfig()\n//\teng := engine.New(cfg)\n//\terr := eng.Run(ctx)\n//\npackage engine\n```\n\n### README Files\n\n```markdown\n# Component Name\n\n## Purpose\nOne paragraph explaining what this does and why it exists.\n\n## Usage\nCode examples showing common usage patterns.\n\n## Configuration\nEnvironment variables or config files needed.\n\n## Testing\nHow to run tests for this component.\n\nNever create documentation unless explicitly requested.\nDocument in code, not in separate files.\n```\n\n## Anti-Patterns to Avoid\n\n### Never Do These\n\n```go\n// 1. Backwards compatibility layers\ntype Service struct {\n    v1Client *ClientV1\n    v2Client *ClientV2  // NEVER\n}\n\n// 2. Gradual migrations\nif useNewSystem {\n    processNew()\n} else {\n    processOld()  // NEVER\n}\n\n// 3. Deprecation warnings\n// Deprecated: Use NewMethod instead\nfunc OldMethod() {  // Just delete it\n}\n\n// 4. Feature flags for old behavior\nif featureFlag(\"use-old-algorithm\") {  // NEVER\n    oldAlgorithm()\n}\n\n// 5. Compatibility shims\nfunc shimOldToNew(old Old) New {  // NEVER\n    // Convert old format to new\n}\n\n// 6. Variant files\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_temp.go    // NEVER\n\n// 7. TODO comments for compatibility\n// TODO: Remove after all clients updated  // NEVER\n```\n\n## Summary of Conventions\n\n1. **Ultra-concise naming** - SR not SupportResistance\n2. **No backwards compatibility** - Break it cleanly\n3. **No migration code** - Direct cutover only\n4. **No variant files** - Update the original\n5. **Fast failures** - Errors surface immediately\n6. **Single version** - No v1, v2 APIs\n7. **Clean breaks** - Force immediate fixes\n8. **Direct solutions** - No adapter patterns\n9. **Test everything** - Never skip tests\n10. **Document WHY** - Code explains what, comments explain why\n\nRemember: **Every line of compatibility code is technical debt.** Break fast, fix immediately, move forward."}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":5192,"cache_read_input_tokens":47904,"output_tokens":3822,"service_tier":"standard"}},"requestId":"req_011CS5XCZ87VrUWJkNw7hCKg","type":"assistant","uuid":"1c5a0369-581a-4812-b16c-c92c5f907edc","timestamp":"2025-08-13T10:07:46.482Z"}
{"parentUuid":"1c5a0369-581a-4812-b16c-c92c5f907edc","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LoyVjVchsDaWXAWwfRxR1c","type":"tool_result","content":"File created successfully at: /home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md"}]},"uuid":"b5929011-9c44-4b7c-8261-e5273ea3450a","timestamp":"2025-08-13T10:12:37.909Z","toolUseResult":{"type":"create","filePath":"/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md","content":"# Big Meanie Project Conventions\n\n## Philosophy\n\nBig Meanie follows a radical simplicity approach: **break fast, fix immediately**. We prioritize clean breaks over compatibility layers because hidden issues compound exponentially. A breaking change that forces immediate fixes is better than subtle bugs that surface months later in production.\n\n## Table of Contents\n1. [Core Philosophy](#core-philosophy)\n2. [Naming Conventions](#naming-conventions)\n3. [No Backwards Compatibility](#no-backwards-compatibility)\n4. [Project Structure](#project-structure)\n5. [File Management](#file-management)\n6. [Code Organization](#code-organization)\n7. [Testing Standards](#testing-standards)\n8. [Documentation Rules](#documentation-rules)\n\n## Core Philosophy\n\n### The Big Meanie Way\n\n```go\n// We value:\n// 1. Clarity over cleverness\n// 2. Breaking changes over hidden complexity\n// 3. Direct solutions over abstractions\n// 4. Fast failures over graceful degradation\n// 5. Today's correctness over tomorrow's flexibility\n```\n\n### Design Principles\n\n```go\n// BAD: Maintaining compatibility\ntype OrderService interface {\n    PlaceOrder(order Order) error\n    PlaceOrderV2(order OrderV2) error  // NEVER DO THIS\n}\n\n// GOOD: Clean break\ntype OrderService interface {\n    PlaceOrder(order Order) error  // Just change it\n}\n\n// BAD: Migration code\nfunc MigrateData() {\n    if isOldFormat() {\n        convertToNew()  // NEVER DO THIS\n    }\n}\n\n// GOOD: Direct cutover\nfunc LoadData() {\n    // Assume new format only\n    // Old format fails fast\n}\n```\n\n## Naming Conventions\n\n### Ultra-Concise Names\n\nBig Meanie uses ultra-concise naming. We prefer short, clear names over verbose descriptions.\n\n```go\n// BAD: Verbose naming\ntype SupportResistanceCalculator struct {\n    maximumLookbackPeriod int\n    minimumVolumeThreshold decimal.Decimal\n}\n\nfunc CalculateSupportAndResistanceLevels() {}\nfunc GetMovingAverageConvergenceDivergence() {}\n\n// GOOD: Ultra-concise\ntype SR struct {  // Support/Resistance\n    maxLookback int\n    minVol decimal.Decimal\n}\n\nfunc CalcSR() {}\nfunc MACD() {}\n```\n\n### Standard Abbreviations\n\n```go\n// Common trading abbreviations\nSR   // Support/Resistance\nMA   // Moving Average\nEMA  // Exponential Moving Average\nRSI  // Relative Strength Index\nMACD // Moving Average Convergence Divergence\nBB   // Bollinger Bands\nATR  // Average True Range\nOBV  // On-Balance Volume\nMFI  // Money Flow Index\n\n// System abbreviations\ncfg  // config\nctx  // context\nconn // connection\ndb   // database\nerr  // error\nmsg  // message\nreq  // request\nres  // response/result\ntx   // transaction\n\n// Trading specific\nqty  // quantity\nvol  // volume\npos  // position\npnl  // profit and loss\nnav  // net asset value\nliq  // liquidation/liquidity\n```\n\n### Method Names\n\n```go\n// Prefer short verbs\nCalc()  not  Calculate()\nExec()  not  Execute()\nInit()  not  Initialize()\nProc()  not  Process()\nGen()   not  Generate()\n\n// Getters don't use Get\nPrice()     not  GetPrice()\nQuantity()  not  GetQuantity()\n\n// Setters use Set\nSetPrice()\nSetQuantity()\n\n// Boolean methods\nIsValid()   not  CheckIfValid()\nHasData()   not  CheckHasData()\nCanTrade()  not  CheckCanTrade()\n```\n\n## No Backwards Compatibility\n\n### Breaking Changes Are Good\n\n```go\n// BAD: Versioned APIs\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/v1/orders\", ordersV1Handler)\n    api.HandleFunc(\"/v2/orders\", ordersV2Handler)  // NEVER\n}\n\n// GOOD: One version only\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/orders\", ordersHandler)  // Break it, fix it\n}\n\n// BAD: Compatibility fields\ntype Order struct {\n    ID       string\n    Price    decimal.Decimal\n    \n    // Deprecated: Use Price instead\n    PriceStr string  // NEVER KEEP THIS\n}\n\n// GOOD: Clean structure\ntype Order struct {\n    ID    string\n    Price decimal.Decimal  // Changed? Fix all usages\n}\n```\n\n### Migration Anti-Patterns to Avoid\n\n```go\n// NEVER: Gradual migration\nfunc LoadConfig() Config {\n    if FileExists(\"config.yaml\") {\n        return LoadYAML()\n    }\n    // Fallback to old format\n    return LoadJSON()  // NEVER DO THIS\n}\n\n// ALWAYS: Direct cutover\nfunc LoadConfig() Config {\n    return LoadYAML()  // Old format fails immediately\n}\n\n// NEVER: Adapter patterns\ntype LegacyAdapter struct {\n    newService *Service\n}\n\nfunc (a *LegacyAdapter) OldMethod() {\n    a.newService.NewMethod()  // NEVER BUILD ADAPTERS\n}\n\n// ALWAYS: Direct replacement\n// Just change OldMethod to NewMethod everywhere\n```\n\n### Database Migration Rules\n\n```sql\n-- BAD: Maintaining old columns\nALTER TABLE orders ADD COLUMN price_decimal DECIMAL(20,8);\nUPDATE orders SET price_decimal = CAST(price_string AS DECIMAL);\n-- Keep both columns during \"transition\" - NEVER\n\n-- GOOD: Direct replacement\nALTER TABLE orders DROP COLUMN price_string;\nALTER TABLE orders ADD COLUMN price DECIMAL(20,8) NOT NULL;\n-- Breaks immediately, forces data migration\n```\n\n## Project Structure\n\n### Directory Layout\n\n```\nbigmeanie/\n├── back/                 # Backend code\n│   ├── cmd/             # Entry points\n│   │   ├── trade/       # Trading bot\n│   │   ├── backtest/    # Backtesting engine\n│   │   └── api/         # REST API server\n│   ├── internal/        # Private packages\n│   │   ├── engine/      # Trading engine\n│   │   ├── strategy/    # Trading strategies\n│   │   ├── exchange/    # Exchange integrations\n│   │   ├── portfolio/   # Portfolio management\n│   │   └── risk/        # Risk management\n│   ├── pkg/             # Public packages\n│   │   ├── indicators/  # Technical indicators\n│   │   ├── decimal/     # Decimal utilities\n│   │   └── errors/      # Error handling\n│   └── .docs/           # Documentation\n│       ├── code/        # Code patterns\n│       ├── plan.md      # Current planning\n│       └── todo.md      # Task tracking\n└── front/               # Frontend code\n    └── [React/Next.js structure]\n```\n\n### Package Organization\n\n```go\n// Each package has single responsibility\n// internal/engine/engine.go\npackage engine\n\ntype Engine struct {\n    // Only engine-related fields\n}\n\n// internal/strategy/strategy.go\npackage strategy\n\ntype Strategy interface {\n    // Only strategy methods\n}\n\n// Never mix concerns in one package\n// BAD: internal/trading/everything.go\n// GOOD: Separate packages for separate concerns\n```\n\n## File Management\n\n### No Variant Files\n\n```go\n// NEVER create these files:\norder.go\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_enhanced.go // NEVER\norder_refactored.go // NEVER\n\n// ALWAYS update the original:\norder.go  // Just change this file\n```\n\n### File Naming\n\n```go\n// Standard Go conventions\norder.go        // Types and methods\norder_test.go   // Tests\ndoc.go         // Package documentation\n\n// Group by feature, not by type\n// BAD structure:\ntypes.go       // All types\nmethods.go     // All methods\ninterfaces.go  // All interfaces\n\n// GOOD structure:\norder.go       // Order type and methods\ntrade.go       // Trade type and methods\nportfolio.go   // Portfolio type and methods\n```\n\n### Import Organization\n\n```go\nimport (\n    // Standard library\n    \"context\"\n    \"fmt\"\n    \n    // External dependencies\n    \"github.com/shopspring/decimal\"\n    \n    // Internal packages\n    \"bigmeanie/internal/engine\"\n    \"bigmeanie/pkg/indicators\"\n)\n\n// Never use relative imports\n// BAD:  import \"../engine\"\n// GOOD: import \"bigmeanie/internal/engine\"\n```\n\n## Code Organization\n\n### Interface Design\n\n```go\n// Small, focused interfaces\ntype Trader interface {\n    Trade(ctx context.Context, signal Signal) error\n}\n\n// Not large, kitchen-sink interfaces\ntype BadTrader interface {\n    Trade() error\n    GetBalance() decimal.Decimal\n    GetHistory() []Trade\n    Configure(Config) error\n    // ... 20 more methods - NO!\n}\n\n// Compose interfaces when needed\ntype FullTrader interface {\n    Trader\n    Backtester\n    Reporter\n}\n```\n\n### Error Handling\n\n```go\n// Always wrap errors with context\nif err != nil {\n    return fmt.Errorf(\"engine.Start: %w\", err)\n}\n\n// Define sentinel errors\nvar (\n    ErrInsufficientFunds = errors.New(\"insufficient funds\")\n    ErrOrderTooSmall     = errors.New(\"order below minimum\")\n    ErrExchangeDown      = errors.New(\"exchange unavailable\")\n)\n\n// Use errors.Is for checking\nif errors.Is(err, ErrInsufficientFunds) {\n    // Handle specific error\n}\n```\n\n### Concurrency Patterns\n\n```go\n// Always use context for cancellation\nfunc (e *Engine) Run(ctx context.Context) error {\n    for {\n        select {\n        case <-ctx.Done():\n            return ctx.Err()\n        case signal := <-e.signals:\n            e.process(signal)\n        }\n    }\n}\n\n// Protect shared state\ntype Portfolio struct {\n    mu       sync.RWMutex\n    balances map[string]decimal.Decimal\n}\n\nfunc (p *Portfolio) Balance(asset string) decimal.Decimal {\n    p.mu.RLock()\n    defer p.mu.RUnlock()\n    return p.balances[asset]\n}\n```\n\n## Testing Standards\n\n### Test Organization\n\n```go\n// Table-driven tests always\nfunc TestCalcSR(t *testing.T) {\n    tests := []struct {\n        name string\n        data []decimal.Decimal\n        want []Level\n    }{\n        {\n            name: \"basic support\",\n            data: []decimal.Decimal{...},\n            want: []Level{...},\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := CalcSR(tt.data)\n            require.Equal(t, tt.want, got)\n        })\n    }\n}\n\n// NEVER use t.Skip()\n// BAD:\nfunc TestBrokenFeature(t *testing.T) {\n    t.Skip(\"Fix later\")  // NEVER\n}\n\n// GOOD: Fix it or delete it\n```\n\n### Test Coverage\n\n```go\n// Test edge cases\nfunc TestDivision(t *testing.T) {\n    // Test zero division\n    _, err := Divide(decimal.NewFromInt(1), decimal.Zero)\n    require.Error(t, err)\n    \n    // Test negative values\n    result := Divide(decimal.NewFromInt(-10), decimal.NewFromInt(2))\n    require.Equal(t, decimal.NewFromInt(-5), result)\n}\n\n// Benchmark hot paths\nfunc BenchmarkCalcSR(b *testing.B) {\n    data := generatePriceData(1000)\n    b.ResetTimer()\n    \n    for i := 0; i < b.N; i++ {\n        CalcSR(data)\n    }\n}\n```\n\n## Documentation Rules\n\n### Code Comments\n\n```go\n// Document WHY, not WHAT\n// BAD:\n// Increment counter by 1\ncounter++\n\n// GOOD:\n// Retry count for exchange rate limiting\ncounter++\n\n// Document edge cases\n// Returns -1 if no valid price found\nfunc FindPrice(prices []decimal.Decimal) decimal.Decimal {\n    // ...\n}\n\n// Document assumptions\n// Assumes prices are sorted in ascending order\nfunc BinarySearch(prices []decimal.Decimal, target decimal.Decimal) int {\n    // ...\n}\n```\n\n### Package Documentation\n\n```go\n// Package engine implements the core trading engine for Big Meanie.\n//\n// The engine coordinates between strategy signals, risk management,\n// and exchange execution. It runs continuously, processing signals\n// and managing positions according to configured strategies.\n//\n// Basic usage:\n//\n//\tcfg := engine.DefaultConfig()\n//\teng := engine.New(cfg)\n//\terr := eng.Run(ctx)\n//\npackage engine\n```\n\n### README Files\n\n```markdown\n# Component Name\n\n## Purpose\nOne paragraph explaining what this does and why it exists.\n\n## Usage\nCode examples showing common usage patterns.\n\n## Configuration\nEnvironment variables or config files needed.\n\n## Testing\nHow to run tests for this component.\n\nNever create documentation unless explicitly requested.\nDocument in code, not in separate files.\n```\n\n## Anti-Patterns to Avoid\n\n### Never Do These\n\n```go\n// 1. Backwards compatibility layers\ntype Service struct {\n    v1Client *ClientV1\n    v2Client *ClientV2  // NEVER\n}\n\n// 2. Gradual migrations\nif useNewSystem {\n    processNew()\n} else {\n    processOld()  // NEVER\n}\n\n// 3. Deprecation warnings\n// Deprecated: Use NewMethod instead\nfunc OldMethod() {  // Just delete it\n}\n\n// 4. Feature flags for old behavior\nif featureFlag(\"use-old-algorithm\") {  // NEVER\n    oldAlgorithm()\n}\n\n// 5. Compatibility shims\nfunc shimOldToNew(old Old) New {  // NEVER\n    // Convert old format to new\n}\n\n// 6. Variant files\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_temp.go    // NEVER\n\n// 7. TODO comments for compatibility\n// TODO: Remove after all clients updated  // NEVER\n```\n\n## Summary of Conventions\n\n1. **Ultra-concise naming** - SR not SupportResistance\n2. **No backwards compatibility** - Break it cleanly\n3. **No migration code** - Direct cutover only\n4. **No variant files** - Update the original\n5. **Fast failures** - Errors surface immediately\n6. **Single version** - No v1, v2 APIs\n7. **Clean breaks** - Force immediate fixes\n8. **Direct solutions** - No adapter patterns\n9. **Test everything** - Never skip tests\n10. **Document WHY** - Code explains what, comments explain why\n\nRemember: **Every line of compatibility code is technical debt.** Break fast, fix immediately, move forward.","structuredPatch":[]}}
{"parentUuid":"b5929011-9c44-4b7c-8261-e5273ea3450a","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_018H7TvmyvCFQbS8r6WKL5em","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Now let's fix the unsafe string conversions in performance.md:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":56958,"cache_read_input_tokens":0,"output_tokens":601,"service_tier":"standard"}},"requestId":"req_011CS5XieW9hsea7EtVvDfkj","type":"assistant","uuid":"b07b8b7f-f319-4b6b-a8a8-91ad07283abe","timestamp":"2025-08-13T10:12:41.203Z"}
{"parentUuid":"b07b8b7f-f319-4b6b-a8a8-91ad07283abe","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_018H7TvmyvCFQbS8r6WKL5em","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01VtHajUenpQqbiTDFCq6Mht","name":"MultiEdit","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/performance.md","edits":[{"old_string":"// Avoid string copies\nfunc stringToBytes(s string) []byte {\n    // Safe conversion without copy (read-only)\n    return unsafe.Slice(unsafe.StringData(s), len(s))\n}\n\nfunc bytesToString(b []byte) string {\n    // Safe conversion without copy\n    return unsafe.String(unsafe.SliceData(b), len(b))\n}","new_string":"// String/Byte Conversion\n// WARNING: The unsafe package bypasses Go's type safety and memory safety.\n// Only use these patterns if you fully understand the implications.\n\n// DANGEROUS: Zero-copy conversions (USE WITH EXTREME CAUTION)\n// These can cause segmentation faults, data corruption, and crashes.\n// Only use when:\n// 1. Performance is absolutely critical\n// 2. You can guarantee the underlying data won't be modified\n// 3. You've profiled and proven this is a bottleneck\n\n// Example of the DANGEROUS approach (NOT RECOMMENDED):\n// func unsafeStringToBytes(s string) []byte {\n//     // NEVER modify the returned byte slice!\n//     return unsafe.Slice(unsafe.StringData(s), len(s))\n// }\n\n// SAFE approach (RECOMMENDED):\nfunc safeStringToBytes(s string) []byte {\n    // Creates a copy - safe but allocates\n    return []byte(s)\n}\n\nfunc safeBytesToString(b []byte) string {\n    // Creates a copy - safe but allocates\n    return string(b)\n}\n\n// For performance-critical paths, use builders:\nfunc efficientStringBuilding(parts []string) string {\n    var b strings.Builder\n    b.Grow(calculateTotalLen(parts))\n    for _, s := range parts {\n        b.WriteString(s)\n    }\n    return b.String()\n}"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":56958,"cache_read_input_tokens":0,"output_tokens":601,"service_tier":"standard"}},"requestId":"req_011CS5XieW9hsea7EtVvDfkj","type":"assistant","uuid":"fbe66b39-b4ef-458b-b3d0-c25ea052c922","timestamp":"2025-08-13T10:12:56.656Z"}
{"parentUuid":"fbe66b39-b4ef-458b-b3d0-c25ea052c922","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VtHajUenpQqbiTDFCq6Mht","type":"tool_result","content":"Applied 1 edit to /home/aural/Code/bigmeanie/back/.docs/code/performance.md:\n1. Replaced \"// Avoid string copies\nfunc stringToBytes(s string...\" with \"// String/Byte Conversion\n// WARNING: The unsafe p...\""}]},"uuid":"189f8394-8d33-4849-8909-5051ad08d548","timestamp":"2025-08-13T10:13:07.495Z","toolUseResult":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/performance.md","edits":[{"old_string":"// Avoid string copies\nfunc stringToBytes(s string) []byte {\n    // Safe conversion without copy (read-only)\n    return unsafe.Slice(unsafe.StringData(s), len(s))\n}\n\nfunc bytesToString(b []byte) string {\n    // Safe conversion without copy\n    return unsafe.String(unsafe.SliceData(b), len(b))\n}","new_string":"// String/Byte Conversion\n// WARNING: The unsafe package bypasses Go's type safety and memory safety.\n// Only use these patterns if you fully understand the implications.\n\n// DANGEROUS: Zero-copy conversions (USE WITH EXTREME CAUTION)\n// These can cause segmentation faults, data corruption, and crashes.\n// Only use when:\n// 1. Performance is absolutely critical\n// 2. You can guarantee the underlying data won't be modified\n// 3. You've profiled and proven this is a bottleneck\n\n// Example of the DANGEROUS approach (NOT RECOMMENDED):\n// func unsafeStringToBytes(s string) []byte {\n//     // NEVER modify the returned byte slice!\n//     return unsafe.Slice(unsafe.StringData(s), len(s))\n// }\n\n// SAFE approach (RECOMMENDED):\nfunc safeStringToBytes(s string) []byte {\n    // Creates a copy - safe but allocates\n    return []byte(s)\n}\n\nfunc safeBytesToString(b []byte) string {\n    // Creates a copy - safe but allocates\n    return string(b)\n}\n\n// For performance-critical paths, use builders:\nfunc efficientStringBuilding(parts []string) string {\n    var b strings.Builder\n    b.Grow(calculateTotalLen(parts))\n    for _, s := range parts {\n        b.WriteString(s)\n    }\n    return b.String()\n}","replace_all":false}],"originalFileContents":"# Go Performance - Optimization Mastery\n\n## Table of Contents\n1. [Profiling](#profiling)\n2. [Benchmarking](#benchmarking)\n3. [Memory Management](#memory-management)\n4. [CPU Optimization](#cpu-optimization)\n5. [Compiler Optimizations](#compiler-optimizations)\n6. [Caching Strategies](#caching-strategies)\n7. [Concurrency Performance](#concurrency-performance)\n8. [I/O Optimization](#io-optimization)\n9. [Data Structure Optimization](#data-structure-optimization)\n10. [Performance Best Practices](#performance-best-practices)\n\n## Profiling\n\n### CPU Profiling\n```go\nimport (\n    \"runtime/pprof\"\n    \"os\"\n    \"runtime\"\n)\n\n// Basic CPU profiling\nfunc main() {\n    // Create CPU profile file\n    f, err := os.Create(\"cpu.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    // Start CPU profiling\n    if err := pprof.StartCPUProfile(f); err != nil {\n        log.Fatal(err)\n    }\n    defer pprof.StopCPUProfile()\n    \n    // Your application code\n    runApplication()\n}\n\n// HTTP profiling server\nimport _ \"net/http/pprof\"\n\nfunc main() {\n    go func() {\n        log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n    }()\n    \n    // Your application code\n    runApplication()\n}\n\n// Analyze profiles:\n// go tool pprof cpu.prof\n// go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n// go tool pprof -http=:8080 cpu.prof  # Web interface\n\n// Profile with benchmarks\nfunc BenchmarkFunction(b *testing.B) {\n    // Start profiling in benchmark\n    f, _ := os.Create(\"bench.prof\")\n    pprof.StartCPUProfile(f)\n    defer pprof.StopCPUProfile()\n    \n    for i := 0; i < b.N; i++ {\n        FunctionToProfile()\n    }\n}\n```\n\n### Memory Profiling\n```go\n// Memory profiling\nfunc writeMemProfile() {\n    f, err := os.Create(\"mem.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    runtime.GC() // Force GC before profiling\n    if err := pprof.WriteHeapProfile(f); err != nil {\n        log.Fatal(err)\n    }\n}\n\n// Allocation profiling\nfunc writeAllocProfile() {\n    f, err := os.Create(\"alloc.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    // Profile allocations\n    runtime.MemProfileRate = 1 // Profile every allocation\n    defer func() { runtime.MemProfileRate = 512 * 1024 }() // Reset\n    \n    // Run code\n    runApplication()\n    \n    pprof.Lookup(\"allocs\").WriteTo(f, 0)\n}\n\n// Memory stats\nfunc printMemStats() {\n    var m runtime.MemStats\n    runtime.ReadMemStats(&m)\n    \n    fmt.Printf(\"Alloc = %v MB\", m.Alloc / 1024 / 1024)\n    fmt.Printf(\"TotalAlloc = %v MB\", m.TotalAlloc / 1024 / 1024)\n    fmt.Printf(\"Sys = %v MB\", m.Sys / 1024 / 1024)\n    fmt.Printf(\"NumGC = %v\\n\", m.NumGC)\n    fmt.Printf(\"HeapAlloc = %v MB\", m.HeapAlloc / 1024 / 1024)\n    fmt.Printf(\"HeapObjects = %v\", m.HeapObjects)\n}\n\n// Track allocations in specific code\nfunc trackAllocations() {\n    var m1, m2 runtime.MemStats\n    \n    runtime.ReadMemStats(&m1)\n    \n    // Code to measure\n    expensiveOperation()\n    \n    runtime.ReadMemStats(&m2)\n    \n    fmt.Printf(\"Allocated: %d bytes\\n\", m2.Alloc - m1.Alloc)\n    fmt.Printf(\"Total Allocated: %d bytes\\n\", m2.TotalAlloc - m1.TotalAlloc)\n    fmt.Printf(\"Number of allocations: %d\\n\", m2.Mallocs - m1.Mallocs)\n}\n```\n\n### Goroutine Profiling\n```go\n// Goroutine profiling\nfunc writeGoroutineProfile() {\n    f, err := os.Create(\"goroutine.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    pprof.Lookup(\"goroutine\").WriteTo(f, 1)\n}\n\n// Monitor goroutine count\nfunc monitorGoroutines() {\n    ticker := time.NewTicker(1 * time.Second)\n    defer ticker.Stop()\n    \n    for range ticker.C {\n        fmt.Printf(\"Goroutines: %d\\n\", runtime.NumGoroutine())\n    }\n}\n\n// Block profiling (mutex contention)\nfunc enableBlockProfiling() {\n    runtime.SetBlockProfileRate(1)\n    defer runtime.SetBlockProfileRate(0)\n    \n    // Run application\n    runApplication()\n    \n    f, _ := os.Create(\"block.prof\")\n    defer f.Close()\n    pprof.Lookup(\"block\").WriteTo(f, 0)\n}\n\n// Mutex profiling\nfunc enableMutexProfiling() {\n    runtime.SetMutexProfileFraction(1)\n    defer runtime.SetMutexProfileFraction(0)\n    \n    // Run application\n    runApplication()\n    \n    f, _ := os.Create(\"mutex.prof\")\n    defer f.Close()\n    pprof.Lookup(\"mutex\").WriteTo(f, 0)\n}\n```\n\n### Trace Profiling\n```go\nimport \"runtime/trace\"\n\n// Execution tracing\nfunc main() {\n    f, err := os.Create(\"trace.out\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    err = trace.Start(f)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer trace.Stop()\n    \n    // Your application\n    runApplication()\n}\n\n// Analyze: go tool trace trace.out\n\n// Custom trace regions\nfunc processRequest(ctx context.Context) {\n    defer trace.StartRegion(ctx, \"processRequest\").End()\n    \n    trace.WithRegion(ctx, \"validate\", func() {\n        validateInput()\n    })\n    \n    trace.WithRegion(ctx, \"compute\", func() {\n        computeResult()\n    })\n    \n    trace.WithRegion(ctx, \"respond\", func() {\n        sendResponse()\n    })\n}\n\n// Trace logging\nfunc traceLog(ctx context.Context, message string) {\n    trace.Log(ctx, \"app\", message)\n}\n```\n\n## Benchmarking\n\n### Advanced Benchmarking\n```go\n// Benchmark with different inputs\nfunc BenchmarkSort(b *testing.B) {\n    sizes := []int{10, 100, 1000, 10000}\n    \n    for _, size := range sizes {\n        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n            data := generateRandomSlice(size)\n            \n            b.ResetTimer()\n            for i := 0; i < b.N; i++ {\n                b.StopTimer()\n                tmp := make([]int, len(data))\n                copy(tmp, data)\n                b.StartTimer()\n                \n                sort.Ints(tmp)\n            }\n        })\n    }\n}\n\n// Comparative benchmarks\nfunc BenchmarkStringBuilding(b *testing.B) {\n    strs := []string{\"hello\", \"world\", \"foo\", \"bar\", \"baz\"}\n    \n    b.Run(\"Concatenation\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var result string\n            for _, s := range strs {\n                result += s\n            }\n        }\n    })\n    \n    b.Run(\"StringBuilder\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var builder strings.Builder\n            for _, s := range strs {\n                builder.WriteString(s)\n            }\n            _ = builder.String()\n        }\n    })\n    \n    b.Run(\"BytesBuffer\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var buffer bytes.Buffer\n            for _, s := range strs {\n                buffer.WriteString(s)\n            }\n            _ = buffer.String()\n        }\n    })\n    \n    b.Run(\"Join\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            _ = strings.Join(strs, \"\")\n        }\n    })\n}\n\n// Memory benchmarks\nfunc BenchmarkMemory(b *testing.B) {\n    b.Run(\"WithAllocation\", func(b *testing.B) {\n        b.ReportAllocs()\n        for i := 0; i < b.N; i++ {\n            s := make([]int, 1000)\n            _ = s\n        }\n    })\n    \n    b.Run(\"WithPool\", func(b *testing.B) {\n        b.ReportAllocs()\n        pool := sync.Pool{\n            New: func() interface{} {\n                return make([]int, 1000)\n            },\n        }\n        \n        for i := 0; i < b.N; i++ {\n            s := pool.Get().([]int)\n            pool.Put(s)\n        }\n    })\n}\n\n// Custom metrics\nfunc BenchmarkThroughput(b *testing.B) {\n    data := make([]byte, 1024*1024) // 1MB\n    \n    b.SetBytes(int64(len(data)))\n    b.ResetTimer()\n    \n    for i := 0; i < b.N; i++ {\n        process(data)\n    }\n    \n    b.ReportMetric(float64(b.N)*float64(len(data))/b.Elapsed().Seconds()/1024/1024, \"MB/s\")\n}\n```\n\n## Memory Management\n\n### Reducing Allocations\n```go\n// Avoid allocations in loops\n// Bad: Allocates in loop\nfunc bad() []string {\n    var results []string\n    for i := 0; i < 1000; i++ {\n        results = append(results, fmt.Sprintf(\"item-%d\", i))\n    }\n    return results\n}\n\n// Good: Preallocate\nfunc good() []string {\n    results := make([]string, 0, 1000)\n    for i := 0; i < 1000; i++ {\n        results = append(results, fmt.Sprintf(\"item-%d\", i))\n    }\n    return results\n}\n\n// Reuse buffers\nvar bufferPool = sync.Pool{\n    New: func() interface{} {\n        return new(bytes.Buffer)\n    },\n}\n\nfunc processWithPool(data []byte) string {\n    buf := bufferPool.Get().(*bytes.Buffer)\n    defer func() {\n        buf.Reset()\n        bufferPool.Put(buf)\n    }()\n    \n    buf.Write(data)\n    // Process...\n    return buf.String()\n}\n\n// Avoid string allocations\nfunc avoidStringAllocs(b []byte) string {\n    // Bad: Multiple allocations\n    s := string(b)\n    s = strings.ToUpper(s)\n    s = strings.TrimSpace(s)\n    \n    // Better: Work with bytes\n    b = bytes.ToUpper(b)\n    b = bytes.TrimSpace(b)\n    return string(b)\n}\n\n// String interning for repeated strings\ntype StringInterner struct {\n    mu    sync.RWMutex\n    cache map[string]string\n}\n\nfunc (si *StringInterner) Intern(s string) string {\n    si.mu.RLock()\n    if interned, ok := si.cache[s]; ok {\n        si.mu.RUnlock()\n        return interned\n    }\n    si.mu.RUnlock()\n    \n    si.mu.Lock()\n    defer si.mu.Unlock()\n    \n    si.cache[s] = s\n    return s\n}\n```\n\n### Memory Layout Optimization\n```go\n// Struct field alignment\n// Bad: 32 bytes due to padding\ntype Inefficient struct {\n    a bool    // 1 byte + 7 padding\n    b int64   // 8 bytes\n    c bool    // 1 byte + 7 padding\n    d int64   // 8 bytes\n}\n\n// Good: 24 bytes with better alignment\ntype Efficient struct {\n    b int64   // 8 bytes\n    d int64   // 8 bytes\n    a bool    // 1 byte\n    c bool    // 1 byte + 6 padding\n}\n\n// Use smaller types when possible\ntype Flags struct {\n    // Bad: 4 bools = potentially 4 bytes + padding\n    IsActive   bool\n    IsVerified bool\n    IsPremium  bool\n    IsAdmin    bool\n}\n\n// Good: 1 byte using bit flags\ntype CompactFlags uint8\n\nconst (\n    FlagActive CompactFlags = 1 << iota\n    FlagVerified\n    FlagPremium\n    FlagAdmin\n)\n\nfunc (f CompactFlags) IsActive() bool { return f&FlagActive != 0 }\nfunc (f CompactFlags) IsVerified() bool { return f&FlagVerified != 0 }\n\n// Array vs slice for fixed size\ntype Record struct {\n    // Bad: slice has 24 bytes overhead (pointer, len, cap)\n    IDSlice []byte\n    \n    // Good: array for fixed size, no overhead\n    IDArray [16]byte\n}\n```\n\n### Escape Analysis\n```go\n// Understanding escape analysis\n// go build -gcflags=\"-m\" to see escape analysis\n\n// Doesn't escape - allocated on stack\nfunc noEscape() int {\n    x := 42\n    return x\n}\n\n// Escapes to heap - returned pointer\nfunc escapes() *int {\n    x := 42\n    return &x // x escapes to heap\n}\n\n// Avoid unnecessary escapes\ntype Data struct {\n    values [1000]int\n}\n\n// Bad: Escapes to heap\nfunc (d *Data) Sum() int {\n    sum := 0\n    for _, v := range d.values { // d.values escapes\n        sum += v\n    }\n    return sum\n}\n\n// Good: Doesn't escape\nfunc (d Data) SumValue() int {\n    sum := 0\n    for i := 0; i < len(d.values); i++ {\n        sum += d.values[i]\n    }\n    return sum\n}\n\n// Interface causes escape\nfunc processInterface(i interface{}) {\n    // i escapes to heap\n}\n\nfunc avoidEscape() {\n    x := 42\n    processInterface(x) // x escapes\n    \n    // Avoid by not using interface\n    processInt(x) // x doesn't escape\n}\n\nfunc processInt(i int) {\n    // Process int directly\n}\n```\n\n## CPU Optimization\n\n### Hot Path Optimization\n```go\n// Optimize hot paths\nfunc processData(data []int) int {\n    // Move invariants out of loop\n    length := len(data)\n    if length == 0 {\n        return 0\n    }\n    \n    sum := 0\n    // Unroll loop for better performance\n    for i := 0; i < length-3; i += 4 {\n        sum += data[i] + data[i+1] + data[i+2] + data[i+3]\n    }\n    \n    // Handle remaining elements\n    for i := length - length%4; i < length; i++ {\n        sum += data[i]\n    }\n    \n    return sum\n}\n\n// Branch prediction optimization\nfunc findMax(data []int) int {\n    if len(data) == 0 {\n        return 0\n    }\n    \n    max := data[0]\n    for i := 1; i < len(data); i++ {\n        // Branchless max (may be faster)\n        if data[i] > max {\n            max = data[i]\n        }\n    }\n    return max\n}\n\n// Cache-friendly iteration\nfunc sumMatrix(matrix [][]int) int {\n    sum := 0\n    // Row-major order (cache-friendly)\n    for i := 0; i < len(matrix); i++ {\n        for j := 0; j < len(matrix[i]); j++ {\n            sum += matrix[i][j]\n        }\n    }\n    return sum\n}\n\n// SIMD-friendly code\nfunc addSlices(a, b []float64) []float64 {\n    result := make([]float64, len(a))\n    \n    // Compiler may vectorize this\n    for i := range a {\n        result[i] = a[i] + b[i]\n    }\n    \n    return result\n}\n```\n\n### Inlining\n```go\n// Encourage inlining for small functions\n//go:inline\nfunc add(a, b int) int {\n    return a + b\n}\n\n// Prevent inlining for rarely used functions\n//go:noinline\nfunc rarelyUsedFunction() {\n    // Complex logic\n}\n\n// Check inlining decisions\n// go build -gcflags=\"-m=2\"\n\n// Inline-friendly functions\nfunc abs(x int) int {\n    if x < 0 {\n        return -x\n    }\n    return x\n}\n\n// Too complex to inline (default threshold ~80 nodes)\nfunc complexFunction(x int) int {\n    // Many operations...\n    return result\n}\n```\n\n## Compiler Optimizations\n\n### Compiler Directives\n```go\n// Bounds check elimination\nfunc sumArray(arr []int) int {\n    if len(arr) == 0 {\n        return 0\n    }\n    \n    sum := 0\n    // Compiler can eliminate bounds checks\n    for i := 0; i < len(arr); i++ {\n        sum += arr[i]\n    }\n    return sum\n}\n\n// Help compiler with hints\nfunc process(data []byte) {\n    // Tell compiler minimum length\n    _ = data[3] // Bounds check once\n    \n    // Now these don't need bounds checks\n    a := data[0]\n    b := data[1]\n    c := data[2]\n    d := data[3]\n    \n    // Process a, b, c, d\n}\n\n// Const propagation\nconst bufferSize = 1024\n\nfunc allocateBuffer() []byte {\n    // Compiler knows size at compile time\n    return make([]byte, bufferSize)\n}\n\n// Dead code elimination\nfunc example(debug bool) {\n    if false { // Compiler removes this\n        expensiveDebugOperation()\n    }\n    \n    const debugMode = false\n    if debugMode { // Also removed\n        fmt.Println(\"Debug mode\")\n    }\n}\n```\n\n### Build Flags\n```go\n// Build tags for optimization\n//go:build !debug\n\npackage main\n\nfunc log(msg string) {\n    // No-op in release builds\n}\n\n// Alternative file for debug builds\n//go:build debug\n\npackage main\n\nfunc log(msg string) {\n    fmt.Println(msg)\n}\n\n// Compile with optimizations\n// go build -ldflags=\"-s -w\" # Strip debug info\n// go build -tags release\n// GOOS=linux GOARCH=amd64 go build # Cross-compile\n```\n\n## Caching Strategies\n\n### In-Memory Caching\n```go\n// Simple cache with TTL\ntype Cache struct {\n    mu      sync.RWMutex\n    items   map[string]*cacheItem\n    ttl     time.Duration\n}\n\ntype cacheItem struct {\n    value      interface{}\n    expiration time.Time\n}\n\nfunc NewCache(ttl time.Duration) *Cache {\n    c := &Cache{\n        items: make(map[string]*cacheItem),\n        ttl:   ttl,\n    }\n    go c.cleanup()\n    return c\n}\n\nfunc (c *Cache) Set(key string, value interface{}) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    c.items[key] = &cacheItem{\n        value:      value,\n        expiration: time.Now().Add(c.ttl),\n    }\n}\n\nfunc (c *Cache) Get(key string) (interface{}, bool) {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    \n    item, found := c.items[key]\n    if !found {\n        return nil, false\n    }\n    \n    if time.Now().After(item.expiration) {\n        return nil, false\n    }\n    \n    return item.value, true\n}\n\nfunc (c *Cache) cleanup() {\n    ticker := time.NewTicker(c.ttl / 2)\n    defer ticker.Stop()\n    \n    for range ticker.C {\n        c.mu.Lock()\n        now := time.Now()\n        for key, item := range c.items {\n            if now.After(item.expiration) {\n                delete(c.items, key)\n            }\n        }\n        c.mu.Unlock()\n    }\n}\n\n// LRU Cache\ntype LRUCache struct {\n    capacity int\n    items    map[string]*list.Element\n    order    *list.List\n    mu       sync.Mutex\n}\n\ntype lruItem struct {\n    key   string\n    value interface{}\n}\n\nfunc NewLRUCache(capacity int) *LRUCache {\n    return &LRUCache{\n        capacity: capacity,\n        items:    make(map[string]*list.Element),\n        order:    list.New(),\n    }\n}\n\nfunc (c *LRUCache) Get(key string) (interface{}, bool) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    if elem, ok := c.items[key]; ok {\n        c.order.MoveToFront(elem)\n        return elem.Value.(*lruItem).value, true\n    }\n    return nil, false\n}\n\nfunc (c *LRUCache) Set(key string, value interface{}) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    if elem, ok := c.items[key]; ok {\n        c.order.MoveToFront(elem)\n        elem.Value.(*lruItem).value = value\n        return\n    }\n    \n    if c.order.Len() >= c.capacity {\n        oldest := c.order.Back()\n        if oldest != nil {\n            c.order.Remove(oldest)\n            delete(c.items, oldest.Value.(*lruItem).key)\n        }\n    }\n    \n    item := &lruItem{key: key, value: value}\n    elem := c.order.PushFront(item)\n    c.items[key] = elem\n}\n```\n\n### Memoization\n```go\n// Function memoization\ntype Memoizer struct {\n    mu    sync.RWMutex\n    cache map[string]interface{}\n    fn    func(string) interface{}\n}\n\nfunc NewMemoizer(fn func(string) interface{}) *Memoizer {\n    return &Memoizer{\n        cache: make(map[string]interface{}),\n        fn:    fn,\n    }\n}\n\nfunc (m *Memoizer) Get(key string) interface{} {\n    m.mu.RLock()\n    if val, ok := m.cache[key]; ok {\n        m.mu.RUnlock()\n        return val\n    }\n    m.mu.RUnlock()\n    \n    m.mu.Lock()\n    defer m.mu.Unlock()\n    \n    // Double-check\n    if val, ok := m.cache[key]; ok {\n        return val\n    }\n    \n    val := m.fn(key)\n    m.cache[key] = val\n    return val\n}\n\n// Concurrent-safe memoization with singleflight\nimport \"golang.org/x/sync/singleflight\"\n\ntype ConcurrentMemoizer struct {\n    cache map[string]interface{}\n    mu    sync.RWMutex\n    group singleflight.Group\n}\n\nfunc (m *ConcurrentMemoizer) Get(key string) (interface{}, error) {\n    m.mu.RLock()\n    if val, ok := m.cache[key]; ok {\n        m.mu.RUnlock()\n        return val, nil\n    }\n    m.mu.RUnlock()\n    \n    // Ensure only one goroutine computes the value\n    val, err, _ := m.group.Do(key, func() (interface{}, error) {\n        result := expensiveComputation(key)\n        \n        m.mu.Lock()\n        m.cache[key] = result\n        m.mu.Unlock()\n        \n        return result, nil\n    })\n    \n    return val, err\n}\n```\n\n## Concurrency Performance\n\n### Goroutine Pool\n```go\n// Efficient goroutine pool\ntype WorkerPool struct {\n    workers   int\n    jobQueue  chan Job\n    results   chan Result\n    wg        sync.WaitGroup\n}\n\nfunc NewWorkerPool(workers int, queueSize int) *WorkerPool {\n    return &WorkerPool{\n        workers:  workers,\n        jobQueue: make(chan Job, queueSize),\n        results:  make(chan Result, queueSize),\n    }\n}\n\nfunc (p *WorkerPool) Start() {\n    for i := 0; i < p.workers; i++ {\n        p.wg.Add(1)\n        go p.worker(i)\n    }\n}\n\nfunc (p *WorkerPool) worker(id int) {\n    defer p.wg.Done()\n    \n    for job := range p.jobQueue {\n        result := processJob(job)\n        p.results <- result\n    }\n}\n\nfunc (p *WorkerPool) Submit(job Job) {\n    p.jobQueue <- job\n}\n\nfunc (p *WorkerPool) Stop() {\n    close(p.jobQueue)\n    p.wg.Wait()\n    close(p.results)\n}\n\n// Lock-free structures\ntype LockFreeStack struct {\n    head atomic.Pointer[node]\n}\n\ntype node struct {\n    value interface{}\n    next  *node\n}\n\nfunc (s *LockFreeStack) Push(v interface{}) {\n    n := &node{value: v}\n    for {\n        head := s.head.Load()\n        n.next = head\n        if s.head.CompareAndSwap(head, n) {\n            return\n        }\n    }\n}\n\nfunc (s *LockFreeStack) Pop() interface{} {\n    for {\n        head := s.head.Load()\n        if head == nil {\n            return nil\n        }\n        if s.head.CompareAndSwap(head, head.next) {\n            return head.value\n        }\n    }\n}\n```\n\n### Channel Optimization\n```go\n// Buffered channels for performance\nfunc efficientPipeline() {\n    // Use buffered channels to reduce blocking\n    input := make(chan int, 100)\n    output := make(chan int, 100)\n    \n    // Producer\n    go func() {\n        defer close(input)\n        for i := 0; i < 1000; i++ {\n            input <- i\n        }\n    }()\n    \n    // Workers\n    var wg sync.WaitGroup\n    for i := 0; i < 10; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for val := range input {\n                output <- process(val)\n            }\n        }()\n    }\n    \n    // Close output when workers done\n    go func() {\n        wg.Wait()\n        close(output)\n    }()\n    \n    // Consumer\n    for result := range output {\n        handleResult(result)\n    }\n}\n\n// Batch processing for efficiency\nfunc batchProcessor(input <-chan Item) {\n    batch := make([]Item, 0, 100)\n    ticker := time.NewTicker(100 * time.Millisecond)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case item, ok := <-input:\n            if !ok {\n                if len(batch) > 0 {\n                    processBatch(batch)\n                }\n                return\n            }\n            batch = append(batch, item)\n            \n            if len(batch) >= 100 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n            \n        case <-ticker.C:\n            if len(batch) > 0 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n        }\n    }\n}\n```\n\n## I/O Optimization\n\n### Buffered I/O\n```go\n// Use buffered I/O\nfunc efficientFileRead(filename string) error {\n    file, err := os.Open(filename)\n    if err != nil {\n        return err\n    }\n    defer file.Close()\n    \n    // Use buffered reader\n    reader := bufio.NewReader(file)\n    \n    for {\n        line, err := reader.ReadString('\\n')\n        if err == io.EOF {\n            break\n        }\n        if err != nil {\n            return err\n        }\n        \n        processLine(line)\n    }\n    \n    return nil\n}\n\n// Efficient file writing\nfunc efficientFileWrite(filename string, data []string) error {\n    file, err := os.Create(filename)\n    if err != nil {\n        return err\n    }\n    defer file.Close()\n    \n    // Use buffered writer\n    writer := bufio.NewWriter(file)\n    defer writer.Flush()\n    \n    for _, line := range data {\n        _, err := writer.WriteString(line + \"\\n\")\n        if err != nil {\n            return err\n        }\n    }\n    \n    return nil\n}\n\n// Memory-mapped files for large files\nimport \"golang.org/x/exp/mmap\"\n\nfunc readLargeFile(filename string) error {\n    reader, err := mmap.Open(filename)\n    if err != nil {\n        return err\n    }\n    defer reader.Close()\n    \n    // Read without loading entire file into memory\n    data := make([]byte, 1024)\n    for offset := int64(0); offset < reader.Len(); offset += 1024 {\n        n, err := reader.ReadAt(data, offset)\n        if err != nil && err != io.EOF {\n            return err\n        }\n        \n        processChunk(data[:n])\n    }\n    \n    return nil\n}\n```\n\n### Network I/O\n```go\n// Connection pooling\ntype ConnectionPool struct {\n    connections chan net.Conn\n    factory     func() (net.Conn, error)\n}\n\nfunc NewConnectionPool(size int, factory func() (net.Conn, error)) (*ConnectionPool, error) {\n    pool := &ConnectionPool{\n        connections: make(chan net.Conn, size),\n        factory:     factory,\n    }\n    \n    for i := 0; i < size; i++ {\n        conn, err := factory()\n        if err != nil {\n            return nil, err\n        }\n        pool.connections <- conn\n    }\n    \n    return pool, nil\n}\n\nfunc (p *ConnectionPool) Get() net.Conn {\n    return <-p.connections\n}\n\nfunc (p *ConnectionPool) Put(conn net.Conn) {\n    p.connections <- conn\n}\n\n// HTTP client optimization\nvar httpClient = &http.Client{\n    Timeout: 30 * time.Second,\n    Transport: &http.Transport{\n        MaxIdleConns:        100,\n        MaxIdleConnsPerHost: 10,\n        IdleConnTimeout:     90 * time.Second,\n        DisableCompression:  false,\n        DisableKeepAlives:   false,\n    },\n}\n\n// Batch HTTP requests\nfunc batchHTTPRequests(urls []string) []Response {\n    results := make([]Response, len(urls))\n    var wg sync.WaitGroup\n    \n    // Limit concurrent requests\n    sem := make(chan struct{}, 10)\n    \n    for i, url := range urls {\n        wg.Add(1)\n        go func(idx int, u string) {\n            defer wg.Done()\n            \n            sem <- struct{}{}\n            defer func() { <-sem }()\n            \n            resp, err := httpClient.Get(u)\n            if err != nil {\n                results[idx] = Response{Error: err}\n                return\n            }\n            defer resp.Body.Close()\n            \n            body, _ := io.ReadAll(resp.Body)\n            results[idx] = Response{Data: body}\n        }(i, url)\n    }\n    \n    wg.Wait()\n    return results\n}\n```\n\n## Data Structure Optimization\n\n### Slice Optimization\n```go\n// Preallocate slices\nfunc optimizedSliceOperations() {\n    // Know the capacity\n    slice := make([]int, 0, 1000)\n    \n    // Grow efficiently\n    if cap(slice) < requiredSize {\n        newSlice := make([]int, len(slice), requiredSize*2)\n        copy(newSlice, slice)\n        slice = newSlice\n    }\n    \n    // Clear slice for reuse\n    slice = slice[:0]\n    \n    // Remove element efficiently\n    func removeAt(s []int, i int) []int {\n        s[i] = s[len(s)-1]\n        return s[:len(s)-1]\n    }\n}\n\n// Custom growing strategy\ntype GrowableBuffer struct {\n    data []byte\n}\n\nfunc (b *GrowableBuffer) grow(n int) {\n    if cap(b.data)-len(b.data) < n {\n        newCap := cap(b.data) * 2\n        if newCap < len(b.data)+n {\n            newCap = len(b.data) + n\n        }\n        newData := make([]byte, len(b.data), newCap)\n        copy(newData, b.data)\n        b.data = newData\n    }\n}\n```\n\n### Map Optimization\n```go\n// Preallocate maps\nm := make(map[string]int, 1000)\n\n// Use appropriate key types\n// Faster: int keys\nfastMap := make(map[int]string)\n\n// Slower: string keys (requires hashing)\nslowMap := make(map[string]string)\n\n// Custom hash map for specific use case\ntype FastStringMap struct {\n    buckets [][]entry\n    size    int\n}\n\ntype entry struct {\n    key   string\n    value interface{}\n}\n\nfunc (m *FastStringMap) hash(key string) uint32 {\n    // Fast hash function\n    h := uint32(2166136261)\n    for i := 0; i < len(key); i++ {\n        h *= 16777619\n        h ^= uint32(key[i])\n    }\n    return h\n}\n\nfunc (m *FastStringMap) Get(key string) (interface{}, bool) {\n    h := m.hash(key) % uint32(len(m.buckets))\n    bucket := m.buckets[h]\n    \n    for _, e := range bucket {\n        if e.key == key {\n            return e.value, true\n        }\n    }\n    return nil, false\n}\n```\n\n### String Optimization\n```go\n// String concatenation optimization\nfunc efficientStringConcat(strs []string) string {\n    // Calculate total length\n    var totalLen int\n    for _, s := range strs {\n        totalLen += len(s)\n    }\n    \n    // Preallocate builder\n    var builder strings.Builder\n    builder.Grow(totalLen)\n    \n    for _, s := range strs {\n        builder.WriteString(s)\n    }\n    \n    return builder.String()\n}\n\n// Avoid string copies\nfunc stringToBytes(s string) []byte {\n    // Safe conversion without copy (read-only)\n    return unsafe.Slice(unsafe.StringData(s), len(s))\n}\n\nfunc bytesToString(b []byte) string {\n    // Safe conversion without copy\n    return unsafe.String(unsafe.SliceData(b), len(b))\n}\n```\n\n## Performance Best Practices\n\n### Measurement and Profiling\n```go\n// Always measure before optimizing\nfunc measurePerformance() {\n    start := time.Now()\n    defer func() {\n        elapsed := time.Since(start)\n        log.Printf(\"Operation took %v\", elapsed)\n    }()\n    \n    // Operation to measure\n}\n\n// Use benchmarks for micro-optimizations\nfunc BenchmarkOptimization(b *testing.B) {\n    // Test different approaches\n}\n\n// Profile in production\nimport _ \"net/http/pprof\"\n// Access profiles at /debug/pprof/\n```\n\n### Common Optimizations\n```go\n// 1. Avoid premature optimization\n// Profile first, optimize bottlenecks\n\n// 2. Reduce allocations\n// Use sync.Pool, preallocate slices\n\n// 3. Optimize hot paths\n// Focus on frequently executed code\n\n// 4. Use efficient algorithms\n// O(n) vs O(n²) matters at scale\n\n// 5. Cache computed values\n// Memoization, lookup tables\n\n// 6. Batch operations\n// Reduce system calls, network requests\n\n// 7. Use appropriate data structures\n// Map vs slice, array vs slice\n\n// 8. Leverage concurrency wisely\n// Don't overuse goroutines\n\n// 9. Minimize interface conversions\n// Interfaces cause allocations\n\n// 10. Profile regularly\n// Performance can degrade over time\n```\n\n## Best Practices Summary\n\n1. **Profile before optimizing** - Measure, don't guess\n2. **Focus on algorithms first** - Better algorithm beats micro-optimizations\n3. **Reduce allocations** - Use pools, preallocate, reuse\n4. **Optimize hot paths** - 80/20 rule applies\n5. **Cache aggressively** - But invalidate correctly\n6. **Use buffered I/O** - For file and network operations\n7. **Batch operations** - Amortize overhead\n8. **Choose right data structures** - Map vs slice matters\n9. **Leverage compiler optimizations** - Write optimizer-friendly code\n10. **Monitor production performance** - Use pprof, metrics, tracing","structuredPatch":[{"oldStart":1311,"oldLines":16,"newStart":1311,"newLines":43,"lines":["     return builder.String()"," }"," ","-// Avoid string copies","-func stringToBytes(s string) []byte {","-    // Safe conversion without copy (read-only)","-    return unsafe.Slice(unsafe.StringData(s), len(s))","+// String/Byte Conversion","+// WARNING: The unsafe package bypasses Go's type safety and memory safety.","+// Only use these patterns if you fully understand the implications.","+","+// DANGEROUS: Zero-copy conversions (USE WITH EXTREME CAUTION)","+// These can cause segmentation faults, data corruption, and crashes.","+// Only use when:","+// 1. Performance is absolutely critical","+// 2. You can guarantee the underlying data won't be modified","+// 3. You've profiled and proven this is a bottleneck","+","+// Example of the DANGEROUS approach (NOT RECOMMENDED):","+// func unsafeStringToBytes(s string) []byte {","+//     // NEVER modify the returned byte slice!","+//     return unsafe.Slice(unsafe.StringData(s), len(s))","+// }","+","+// SAFE approach (RECOMMENDED):","+func safeStringToBytes(s string) []byte {","+    // Creates a copy - safe but allocates","+    return []byte(s)"," }"," ","-func bytesToString(b []byte) string {","-    // Safe conversion without copy","-    return unsafe.String(unsafe.SliceData(b), len(b))","+func safeBytesToString(b []byte) string {","+    // Creates a copy - safe but allocates","+    return string(b)"," }","+","+// For performance-critical paths, use builders:","+func efficientStringBuilding(parts []string) string {","+    var b strings.Builder","+    b.Grow(calculateTotalLen(parts))","+    for _, s := range parts {","+        b.WriteString(s)","+    }","+    return b.String()","+}"," ```"," "," ## Performance Best Practices"]}],"userModified":false}}
{"parentUuid":"189f8394-8d33-4849-8909-5051ad08d548","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_015jKS1YBD9AdfXAw4ZsWdPJ","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Now let's create the database-patterns.md file:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":667,"cache_read_input_tokens":56958,"output_tokens":8068,"service_tier":"standard"}},"requestId":"req_011CS5XkqWVQ6Unu8HXByzgP","type":"assistant","uuid":"ac4b6b0e-58cd-4cb4-9a72-c5adb4337f1a","timestamp":"2025-08-13T10:13:10.828Z"}
{"parentUuid":"ac4b6b0e-58cd-4cb4-9a72-c5adb4337f1a","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_015jKS1YBD9AdfXAw4ZsWdPJ","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01H4ryhBnJePDFNpjw1eQ4kL","name":"Write","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/database-patterns.md","content":"# Database Patterns - PostgreSQL for Big Meanie\n\n## Overview\n\nBig Meanie uses PostgreSQL as its primary database for storing trading data, backtesting results, and system state. We use pgx/v5 for its performance and PostgreSQL-specific features.\n\n## Table of Contents\n1. [Connection Management](#connection-management)\n2. [Migration Patterns](#migration-patterns)\n3. [Transaction Patterns](#transaction-patterns)\n4. [Query Patterns](#query-patterns)\n5. [Trading-Specific Schemas](#trading-specific-schemas)\n6. [Performance Optimization](#performance-optimization)\n7. [Error Handling](#error-handling)\n8. [Testing Patterns](#testing-patterns)\n\n## Connection Management\n\n### Database Configuration\n\n```go\npackage database\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n    \n    \"github.com/jackc/pgx/v5/pgxpool\"\n    \"github.com/shopspring/decimal\"\n)\n\ntype Config struct {\n    Host     string\n    Port     int\n    User     string\n    Password string\n    Database string\n    SSLMode  string\n    \n    // Pool settings\n    MaxConns        int32\n    MinConns        int32\n    MaxConnLifetime time.Duration\n    MaxConnIdleTime time.Duration\n}\n\nfunc NewPool(ctx context.Context, cfg Config) (*pgxpool.Pool, error) {\n    dsn := fmt.Sprintf(\n        \"host=%s port=%d user=%s password=%s dbname=%s sslmode=%s\",\n        cfg.Host, cfg.Port, cfg.User, cfg.Password, cfg.Database, cfg.SSLMode,\n    )\n    \n    poolCfg, err := pgxpool.ParseConfig(dsn)\n    if err != nil {\n        return nil, fmt.Errorf(\"parse config: %w\", err)\n    }\n    \n    // Configure pool\n    poolCfg.MaxConns = cfg.MaxConns\n    poolCfg.MinConns = cfg.MinConns\n    poolCfg.MaxConnLifetime = cfg.MaxConnLifetime\n    poolCfg.MaxConnIdleTime = cfg.MaxConnIdleTime\n    \n    // Configure types\n    poolCfg.AfterConnect = func(ctx context.Context, conn *pgx.Conn) error {\n        // Register decimal type\n        RegisterDecimalType(conn.TypeMap())\n        return nil\n    }\n    \n    pool, err := pgxpool.NewWithConfig(ctx, poolCfg)\n    if err != nil {\n        return nil, fmt.Errorf(\"create pool: %w\", err)\n    }\n    \n    // Verify connection\n    if err := pool.Ping(ctx); err != nil {\n        return nil, fmt.Errorf(\"ping database: %w\", err)\n    }\n    \n    return pool, nil\n}\n\n// Graceful shutdown\nfunc ClosePool(pool *pgxpool.Pool) {\n    pool.Close()\n}\n```\n\n### Connection Lifecycle\n\n```go\ntype DB struct {\n    pool *pgxpool.Pool\n}\n\nfunc New(pool *pgxpool.Pool) *DB {\n    return &DB{pool: pool}\n}\n\n// Use pool connections - automatically managed\nfunc (db *DB) GetPrice(ctx context.Context, symbol string) (decimal.Decimal, error) {\n    var price decimal.Decimal\n    \n    query := `SELECT price FROM prices WHERE symbol = $1 ORDER BY timestamp DESC LIMIT 1`\n    \n    err := db.pool.QueryRow(ctx, query, symbol).Scan(&price)\n    if err != nil {\n        return decimal.Zero, fmt.Errorf(\"get price: %w\", err)\n    }\n    \n    return price, nil\n}\n\n// For long operations, use a dedicated connection\nfunc (db *DB) BulkInsert(ctx context.Context, trades []Trade) error {\n    conn, err := db.pool.Acquire(ctx)\n    if err != nil {\n        return fmt.Errorf(\"acquire conn: %w\", err)\n    }\n    defer conn.Release()\n    \n    // Use conn for bulk operations\n    _, err = conn.CopyFrom(\n        ctx,\n        pgx.Identifier{\"trades\"},\n        []string{\"symbol\", \"price\", \"quantity\", \"timestamp\"},\n        pgx.CopyFromSlice(len(trades), func(i int) ([]interface{}, error) {\n            return []interface{}{\n                trades[i].Symbol,\n                trades[i].Price.String(),\n                trades[i].Quantity.String(),\n                trades[i].Timestamp,\n            }, nil\n        }),\n    )\n    \n    return err\n}\n```\n\n## Migration Patterns\n\n### Schema Versioning\n\n```sql\n-- migrations/001_initial_schema.sql\nCREATE TABLE IF NOT EXISTS schema_migrations (\n    version INTEGER PRIMARY KEY,\n    applied_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\n\n-- Trading tables\nCREATE TABLE IF NOT EXISTS exchanges (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(50) UNIQUE NOT NULL,\n    active BOOLEAN DEFAULT true,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS symbols (\n    id SERIAL PRIMARY KEY,\n    exchange_id INTEGER REFERENCES exchanges(id),\n    symbol VARCHAR(20) NOT NULL,\n    base_asset VARCHAR(10) NOT NULL,\n    quote_asset VARCHAR(10) NOT NULL,\n    active BOOLEAN DEFAULT true,\n    min_qty DECIMAL(20, 8),\n    max_qty DECIMAL(20, 8),\n    tick_size DECIMAL(20, 8),\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    UNIQUE(exchange_id, symbol)\n);\n\nCREATE TABLE IF NOT EXISTS candles (\n    id BIGSERIAL PRIMARY KEY,\n    symbol_id INTEGER REFERENCES symbols(id),\n    timeframe VARCHAR(10) NOT NULL,\n    open_time TIMESTAMP NOT NULL,\n    open DECIMAL(20, 8) NOT NULL,\n    high DECIMAL(20, 8) NOT NULL,\n    low DECIMAL(20, 8) NOT NULL,\n    close DECIMAL(20, 8) NOT NULL,\n    volume DECIMAL(20, 8) NOT NULL,\n    close_time TIMESTAMP NOT NULL,\n    trades INTEGER,\n    UNIQUE(symbol_id, timeframe, open_time)\n);\n\nCREATE INDEX idx_candles_symbol_time ON candles(symbol_id, open_time DESC);\nCREATE INDEX idx_candles_timeframe ON candles(timeframe, open_time DESC);\n```\n\n### Migration Runner\n\n```go\npackage migration\n\nimport (\n    \"context\"\n    \"embed\"\n    \"fmt\"\n    \"sort\"\n    \n    \"github.com/jackc/pgx/v5\"\n)\n\n//go:embed migrations/*.sql\nvar migrations embed.FS\n\ntype Migration struct {\n    Version int\n    Name    string\n    SQL     string\n}\n\nfunc Run(ctx context.Context, db *pgx.Conn) error {\n    // Create migrations table\n    if err := createMigrationsTable(ctx, db); err != nil {\n        return err\n    }\n    \n    // Get current version\n    current, err := getCurrentVersion(ctx, db)\n    if err != nil {\n        return err\n    }\n    \n    // Load migrations\n    available, err := loadMigrations()\n    if err != nil {\n        return err\n    }\n    \n    // Apply pending migrations\n    for _, m := range available {\n        if m.Version <= current {\n            continue\n        }\n        \n        if err := applyMigration(ctx, db, m); err != nil {\n            return fmt.Errorf(\"apply migration %d: %w\", m.Version, err)\n        }\n    }\n    \n    return nil\n}\n\nfunc applyMigration(ctx context.Context, db *pgx.Conn, m Migration) error {\n    tx, err := db.Begin(ctx)\n    if err != nil {\n        return err\n    }\n    defer tx.Rollback(ctx)\n    \n    // Execute migration\n    if _, err := tx.Exec(ctx, m.SQL); err != nil {\n        return fmt.Errorf(\"exec sql: %w\", err)\n    }\n    \n    // Record migration\n    query := `INSERT INTO schema_migrations (version) VALUES ($1)`\n    if _, err := tx.Exec(ctx, query, m.Version); err != nil {\n        return fmt.Errorf(\"record migration: %w\", err)\n    }\n    \n    return tx.Commit(ctx)\n}\n```\n\n## Transaction Patterns\n\n### Basic Transactions\n\n```go\nfunc (db *DB) TransferFunds(ctx context.Context, from, to string, amount decimal.Decimal) error {\n    tx, err := db.pool.Begin(ctx)\n    if err != nil {\n        return fmt.Errorf(\"begin tx: %w\", err)\n    }\n    defer tx.Rollback(ctx) // No-op if committed\n    \n    // Debit from account\n    query := `UPDATE accounts SET balance = balance - $1 WHERE id = $2 AND balance >= $1`\n    result, err := tx.Exec(ctx, query, amount.String(), from)\n    if err != nil {\n        return fmt.Errorf(\"debit account: %w\", err)\n    }\n    \n    if result.RowsAffected() == 0 {\n        return fmt.Errorf(\"insufficient funds\")\n    }\n    \n    // Credit to account\n    query = `UPDATE accounts SET balance = balance + $1 WHERE id = $2`\n    _, err = tx.Exec(ctx, query, amount.String(), to)\n    if err != nil {\n        return fmt.Errorf(\"credit account: %w\", err)\n    }\n    \n    // Record transfer\n    query = `INSERT INTO transfers (from_id, to_id, amount, timestamp) VALUES ($1, $2, $3, NOW())`\n    _, err = tx.Exec(ctx, query, from, to, amount.String())\n    if err != nil {\n        return fmt.Errorf(\"record transfer: %w\", err)\n    }\n    \n    return tx.Commit(ctx)\n}\n```\n\n### Nested Transactions (Savepoints)\n\n```go\nfunc (db *DB) ProcessTrade(ctx context.Context, trade Trade) error {\n    tx, err := db.pool.Begin(ctx)\n    if err != nil {\n        return err\n    }\n    defer tx.Rollback(ctx)\n    \n    // Create savepoint for position update\n    _, err = tx.Exec(ctx, \"SAVEPOINT update_position\")\n    if err != nil {\n        return err\n    }\n    \n    // Try to update position\n    err = updatePosition(ctx, tx, trade)\n    if err != nil {\n        // Rollback to savepoint, continue transaction\n        _, _ = tx.Exec(ctx, \"ROLLBACK TO SAVEPOINT update_position\")\n        \n        // Try alternative approach\n        err = createNewPosition(ctx, tx, trade)\n        if err != nil {\n            return err\n        }\n    }\n    \n    // Record trade\n    err = recordTrade(ctx, tx, trade)\n    if err != nil {\n        return err\n    }\n    \n    return tx.Commit(ctx)\n}\n```\n\n### Distributed Transactions\n\n```go\n// Use saga pattern for distributed transactions\ntype TradeSaga struct {\n    db       *DB\n    exchange Exchange\n}\n\nfunc (s *TradeSaga) ExecuteTrade(ctx context.Context, order Order) error {\n    // Step 1: Reserve funds in database\n    reservationID, err := s.reserveFunds(ctx, order)\n    if err != nil {\n        return err\n    }\n    \n    // Step 2: Place order on exchange\n    exchangeOrderID, err := s.exchange.PlaceOrder(ctx, order)\n    if err != nil {\n        // Compensate: Release reserved funds\n        _ = s.releaseFunds(ctx, reservationID)\n        return err\n    }\n    \n    // Step 3: Record order in database\n    err = s.recordOrder(ctx, order, exchangeOrderID)\n    if err != nil {\n        // Compensate: Cancel exchange order and release funds\n        _ = s.exchange.CancelOrder(ctx, exchangeOrderID)\n        _ = s.releaseFunds(ctx, reservationID)\n        return err\n    }\n    \n    // Step 4: Commit reservation\n    return s.commitReservation(ctx, reservationID)\n}\n```\n\n## Query Patterns\n\n### Parameterized Queries\n\n```go\n// ALWAYS use parameterized queries\nfunc (db *DB) GetTrades(ctx context.Context, filter TradeFilter) ([]Trade, error) {\n    query := `\n        SELECT id, symbol, side, price, quantity, timestamp\n        FROM trades\n        WHERE symbol = $1\n          AND timestamp >= $2\n          AND timestamp < $3\n        ORDER BY timestamp DESC\n        LIMIT $4\n    `\n    \n    rows, err := db.pool.Query(ctx, query,\n        filter.Symbol,\n        filter.StartTime,\n        filter.EndTime,\n        filter.Limit,\n    )\n    if err != nil {\n        return nil, err\n    }\n    defer rows.Close()\n    \n    var trades []Trade\n    for rows.Next() {\n        var t Trade\n        err := rows.Scan(\n            &t.ID,\n            &t.Symbol,\n            &t.Side,\n            &t.Price,\n            &t.Quantity,\n            &t.Timestamp,\n        )\n        if err != nil {\n            return nil, err\n        }\n        trades = append(trades, t)\n    }\n    \n    return trades, rows.Err()\n}\n```\n\n### Dynamic Query Building\n\n```go\nimport \"github.com/Masterminds/squirrel\"\n\nfunc (db *DB) SearchTrades(ctx context.Context, criteria SearchCriteria) ([]Trade, error) {\n    // Build query dynamically\n    qb := squirrel.Select(\"id\", \"symbol\", \"price\", \"quantity\", \"timestamp\").\n        From(\"trades\").\n        PlaceholderFormat(squirrel.Dollar)\n    \n    if criteria.Symbol != \"\" {\n        qb = qb.Where(squirrel.Eq{\"symbol\": criteria.Symbol})\n    }\n    \n    if !criteria.MinPrice.IsZero() {\n        qb = qb.Where(squirrel.GtOrEq{\"price\": criteria.MinPrice.String()})\n    }\n    \n    if !criteria.MaxPrice.IsZero() {\n        qb = qb.Where(squirrel.LtOrEq{\"price\": criteria.MaxPrice.String()})\n    }\n    \n    if criteria.Side != \"\" {\n        qb = qb.Where(squirrel.Eq{\"side\": criteria.Side})\n    }\n    \n    sql, args, err := qb.ToSql()\n    if err != nil {\n        return nil, err\n    }\n    \n    rows, err := db.pool.Query(ctx, sql, args...)\n    // ... scan rows\n}\n```\n\n### Batch Operations\n\n```go\nfunc (db *DB) BatchInsertCandles(ctx context.Context, candles []Candle) error {\n    // Use COPY for best performance\n    _, err := db.pool.CopyFrom(\n        ctx,\n        pgx.Identifier{\"candles\"},\n        []string{\"symbol_id\", \"timeframe\", \"open_time\", \"open\", \"high\", \"low\", \"close\", \"volume\"},\n        pgx.CopyFromSlice(len(candles), func(i int) ([]interface{}, error) {\n            c := candles[i]\n            return []interface{}{\n                c.SymbolID,\n                c.Timeframe,\n                c.OpenTime,\n                c.Open.String(),\n                c.High.String(),\n                c.Low.String(),\n                c.Close.String(),\n                c.Volume.String(),\n            }, nil\n        }),\n    )\n    return err\n}\n\n// Batch updates\nfunc (db *DB) UpdatePrices(ctx context.Context, updates map[string]decimal.Decimal) error {\n    tx, err := db.pool.Begin(ctx)\n    if err != nil {\n        return err\n    }\n    defer tx.Rollback(ctx)\n    \n    // Prepare statement\n    stmt := `UPDATE symbols SET last_price = $1, updated_at = NOW() WHERE symbol = $2`\n    \n    batch := &pgx.Batch{}\n    for symbol, price := range updates {\n        batch.Queue(stmt, price.String(), symbol)\n    }\n    \n    results := tx.SendBatch(ctx, batch)\n    defer results.Close()\n    \n    // Check results\n    for i := 0; i < batch.Len(); i++ {\n        _, err := results.Exec()\n        if err != nil {\n            return fmt.Errorf(\"update batch item %d: %w\", i, err)\n        }\n    }\n    \n    return tx.Commit(ctx)\n}\n```\n\n## Trading-Specific Schemas\n\n### Order Management\n\n```sql\n-- Orders table with proper constraints\nCREATE TABLE orders (\n    id BIGSERIAL PRIMARY KEY,\n    exchange_order_id VARCHAR(100) UNIQUE,\n    symbol_id INTEGER REFERENCES symbols(id),\n    side VARCHAR(4) CHECK (side IN ('BUY', 'SELL')),\n    type VARCHAR(10) CHECK (type IN ('MARKET', 'LIMIT', 'STOP', 'STOP_LIMIT')),\n    status VARCHAR(20) CHECK (status IN ('NEW', 'PARTIAL', 'FILLED', 'CANCELLED', 'REJECTED')),\n    price DECIMAL(20, 8),\n    quantity DECIMAL(20, 8) NOT NULL,\n    filled_qty DECIMAL(20, 8) DEFAULT 0,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    \n    CONSTRAINT positive_quantity CHECK (quantity > 0),\n    CONSTRAINT positive_price CHECK (price IS NULL OR price > 0),\n    CONSTRAINT filled_not_exceed CHECK (filled_qty <= quantity)\n);\n\n-- Positions tracking\nCREATE TABLE positions (\n    id BIGSERIAL PRIMARY KEY,\n    symbol_id INTEGER REFERENCES symbols(id),\n    side VARCHAR(5) CHECK (side IN ('LONG', 'SHORT')),\n    quantity DECIMAL(20, 8) NOT NULL,\n    entry_price DECIMAL(20, 8) NOT NULL,\n    current_price DECIMAL(20, 8),\n    realized_pnl DECIMAL(20, 8) DEFAULT 0,\n    unrealized_pnl DECIMAL(20, 8) DEFAULT 0,\n    opened_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    closed_at TIMESTAMP,\n    \n    CONSTRAINT positive_position_qty CHECK (quantity >= 0),\n    CONSTRAINT position_close_check CHECK (\n        (quantity = 0 AND closed_at IS NOT NULL) OR\n        (quantity > 0 AND closed_at IS NULL)\n    )\n);\n\n-- Trade executions\nCREATE TABLE executions (\n    id BIGSERIAL PRIMARY KEY,\n    order_id BIGINT REFERENCES orders(id),\n    exchange_trade_id VARCHAR(100) UNIQUE,\n    price DECIMAL(20, 8) NOT NULL,\n    quantity DECIMAL(20, 8) NOT NULL,\n    commission DECIMAL(20, 8) DEFAULT 0,\n    commission_asset VARCHAR(10),\n    executed_at TIMESTAMP NOT NULL,\n    \n    CONSTRAINT positive_execution CHECK (price > 0 AND quantity > 0)\n);\n```\n\n### Performance Metrics\n\n```sql\n-- Strategy performance tracking\nCREATE TABLE strategy_metrics (\n    id BIGSERIAL PRIMARY KEY,\n    strategy_name VARCHAR(50) NOT NULL,\n    period_start TIMESTAMP NOT NULL,\n    period_end TIMESTAMP NOT NULL,\n    total_trades INTEGER DEFAULT 0,\n    winning_trades INTEGER DEFAULT 0,\n    losing_trades INTEGER DEFAULT 0,\n    gross_profit DECIMAL(20, 8) DEFAULT 0,\n    gross_loss DECIMAL(20, 8) DEFAULT 0,\n    max_drawdown DECIMAL(20, 8) DEFAULT 0,\n    sharpe_ratio DECIMAL(10, 4),\n    calculated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    \n    UNIQUE(strategy_name, period_start, period_end)\n);\n\n-- Daily account snapshots\nCREATE TABLE account_snapshots (\n    id BIGSERIAL PRIMARY KEY,\n    snapshot_date DATE NOT NULL,\n    total_value DECIMAL(20, 8) NOT NULL,\n    cash_balance DECIMAL(20, 8) NOT NULL,\n    positions_value DECIMAL(20, 8) NOT NULL,\n    daily_pnl DECIMAL(20, 8),\n    cumulative_pnl DECIMAL(20, 8),\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    \n    UNIQUE(snapshot_date)\n);\n```\n\n## Performance Optimization\n\n### Indexing Strategy\n\n```sql\n-- Composite indexes for common queries\nCREATE INDEX idx_trades_symbol_time ON trades(symbol, timestamp DESC);\nCREATE INDEX idx_orders_status_time ON orders(status, created_at DESC) WHERE status IN ('NEW', 'PARTIAL');\nCREATE INDEX idx_positions_open ON positions(symbol_id, side) WHERE closed_at IS NULL;\n\n-- Partial indexes for active records\nCREATE INDEX idx_symbols_active ON symbols(exchange_id, symbol) WHERE active = true;\n\n-- BRIN indexes for time-series data\nCREATE INDEX idx_candles_time_brin ON candles USING BRIN(open_time);\n\n-- GIN indexes for JSONB data\nCREATE INDEX idx_order_metadata ON orders USING GIN(metadata) WHERE metadata IS NOT NULL;\n```\n\n### Query Optimization\n\n```go\n// Use EXPLAIN to analyze queries\nfunc (db *DB) AnalyzeQuery(ctx context.Context, query string, args ...interface{}) error {\n    rows, err := db.pool.Query(ctx, \"EXPLAIN ANALYZE \"+query, args...)\n    if err != nil {\n        return err\n    }\n    defer rows.Close()\n    \n    for rows.Next() {\n        var plan string\n        rows.Scan(&plan)\n        fmt.Println(plan)\n    }\n    \n    return rows.Err()\n}\n\n// Optimize pagination with cursors\nfunc (db *DB) GetTradesCursor(ctx context.Context, cursor string, limit int) ([]Trade, string, error) {\n    var trades []Trade\n    var lastID int64\n    \n    if cursor != \"\" {\n        // Decode cursor\n        fmt.Sscanf(cursor, \"%d\", &lastID)\n    }\n    \n    query := `\n        SELECT id, symbol, price, quantity, timestamp\n        FROM trades\n        WHERE id > $1\n        ORDER BY id\n        LIMIT $2\n    `\n    \n    rows, err := db.pool.Query(ctx, query, lastID, limit+1)\n    if err != nil {\n        return nil, \"\", err\n    }\n    defer rows.Close()\n    \n    for rows.Next() {\n        var t Trade\n        err := rows.Scan(&t.ID, &t.Symbol, &t.Price, &t.Quantity, &t.Timestamp)\n        if err != nil {\n            return nil, \"\", err\n        }\n        \n        if len(trades) < limit {\n            trades = append(trades, t)\n            lastID = t.ID\n        }\n    }\n    \n    nextCursor := \"\"\n    if len(trades) == limit {\n        nextCursor = fmt.Sprintf(\"%d\", lastID)\n    }\n    \n    return trades, nextCursor, nil\n}\n```\n\n### Connection Pooling\n\n```go\n// Optimal pool configuration for trading system\nfunc OptimalPoolConfig() *pgxpool.Config {\n    cfg, _ := pgxpool.ParseConfig(os.Getenv(\"DATABASE_URL\"))\n    \n    // Pool size based on workload\n    cfg.MaxConns = 25        // Limit connections\n    cfg.MinConns = 5         // Keep minimum ready\n    cfg.MaxConnLifetime = time.Hour\n    cfg.MaxConnIdleTime = time.Minute * 30\n    \n    // Health check\n    cfg.HealthCheckPeriod = time.Minute\n    \n    // Statement cache\n    cfg.ConnConfig.DefaultQueryExecMode = pgx.QueryExecModeCacheStatement\n    \n    return cfg\n}\n```\n\n## Error Handling\n\n### Database Error Types\n\n```go\nimport \"github.com/jackc/pgx/v5/pgconn\"\n\nfunc handleDBError(err error) error {\n    var pgErr *pgconn.PgError\n    if errors.As(err, &pgErr) {\n        switch pgErr.Code {\n        case \"23505\": // unique_violation\n            return fmt.Errorf(\"duplicate entry: %s\", pgErr.Detail)\n        case \"23503\": // foreign_key_violation\n            return fmt.Errorf(\"foreign key violation: %s\", pgErr.Detail)\n        case \"23502\": // not_null_violation\n            return fmt.Errorf(\"required field missing: %s\", pgErr.ColumnName)\n        case \"23514\": // check_violation\n            return fmt.Errorf(\"constraint violation: %s\", pgErr.ConstraintName)\n        case \"40001\": // serialization_failure\n            return fmt.Errorf(\"transaction conflict, retry needed\")\n        case \"53300\": // too_many_connections\n            return fmt.Errorf(\"database connection limit reached\")\n        default:\n            return fmt.Errorf(\"database error %s: %s\", pgErr.Code, pgErr.Message)\n        }\n    }\n    \n    if errors.Is(err, pgx.ErrNoRows) {\n        return fmt.Errorf(\"not found\")\n    }\n    \n    return err\n}\n```\n\n### Retry Logic\n\n```go\nfunc (db *DB) WithRetry(ctx context.Context, fn func(context.Context) error) error {\n    maxRetries := 3\n    backoff := time.Millisecond * 100\n    \n    for i := 0; i < maxRetries; i++ {\n        err := fn(ctx)\n        if err == nil {\n            return nil\n        }\n        \n        // Check if retryable\n        var pgErr *pgconn.PgError\n        if errors.As(err, &pgErr) {\n            if pgErr.Code == \"40001\" { // serialization failure\n                time.Sleep(backoff)\n                backoff *= 2\n                continue\n            }\n        }\n        \n        // Non-retryable error\n        return err\n    }\n    \n    return fmt.Errorf(\"max retries exceeded\")\n}\n```\n\n## Testing Patterns\n\n### Test Database Setup\n\n```go\nfunc SetupTestDB(t *testing.T) *DB {\n    // Use separate test database\n    testDB := os.Getenv(\"TEST_DATABASE_URL\")\n    if testDB == \"\" {\n        testDB = \"postgres://test:test@localhost:5432/bigmeanie_test\"\n    }\n    \n    ctx := context.Background()\n    pool, err := pgxpool.New(ctx, testDB)\n    require.NoError(t, err)\n    \n    // Clean database\n    _, err = pool.Exec(ctx, \"TRUNCATE TABLE trades, orders, positions CASCADE\")\n    require.NoError(t, err)\n    \n    // Run migrations\n    err = migration.Run(ctx, pool)\n    require.NoError(t, err)\n    \n    t.Cleanup(func() {\n        pool.Close()\n    })\n    \n    return &DB{pool: pool}\n}\n```\n\n### Test Fixtures\n\n```go\nfunc InsertTestData(t *testing.T, db *DB) {\n    ctx := context.Background()\n    \n    // Insert test trades\n    trades := []Trade{\n        {Symbol: \"BTC-USD\", Price: decimal.NewFromInt(50000), Quantity: decimal.NewFromFloat(0.1)},\n        {Symbol: \"ETH-USD\", Price: decimal.NewFromInt(3000), Quantity: decimal.NewFromInt(1)},\n    }\n    \n    for _, trade := range trades {\n        query := `INSERT INTO trades (symbol, price, quantity) VALUES ($1, $2, $3)`\n        _, err := db.pool.Exec(ctx, query, trade.Symbol, trade.Price.String(), trade.Quantity.String())\n        require.NoError(t, err)\n    }\n}\n```\n\n### Integration Tests\n\n```go\nfunc TestTradeExecution(t *testing.T) {\n    db := SetupTestDB(t)\n    ctx := context.Background()\n    \n    // Test transaction\n    order := Order{\n        Symbol:   \"BTC-USD\",\n        Side:     \"BUY\",\n        Quantity: decimal.NewFromFloat(0.1),\n        Price:    decimal.NewFromInt(50000),\n    }\n    \n    err := db.ExecuteOrder(ctx, order)\n    require.NoError(t, err)\n    \n    // Verify order created\n    var count int\n    err = db.pool.QueryRow(ctx, \"SELECT COUNT(*) FROM orders WHERE symbol = $1\", order.Symbol).Scan(&count)\n    require.NoError(t, err)\n    require.Equal(t, 1, count)\n    \n    // Verify position updated\n    var position Position\n    query := `SELECT quantity, entry_price FROM positions WHERE symbol = $1`\n    err = db.pool.QueryRow(ctx, query, order.Symbol).Scan(&position.Quantity, &position.EntryPrice)\n    require.NoError(t, err)\n    require.True(t, position.Quantity.Equal(order.Quantity))\n}\n```\n\n## Best Practices\n\n### 1. Always Use Context\n\n```go\n// Pass context for cancellation\nfunc (db *DB) LongRunningQuery(ctx context.Context) error {\n    ctx, cancel := context.WithTimeout(ctx, 30*time.Second)\n    defer cancel()\n    \n    return db.pool.QueryRow(ctx, \"SELECT pg_sleep(10)\").Scan(nil)\n}\n```\n\n### 2. Prepare Statements\n\n```go\n// Cache prepared statements\ntype Queries struct {\n    getPrice   *pgx.Stmt\n    updatePrice *pgx.Stmt\n}\n\nfunc (db *DB) PrepareQueries(ctx context.Context) (*Queries, error) {\n    conn, err := db.pool.Acquire(ctx)\n    if err != nil {\n        return nil, err\n    }\n    defer conn.Release()\n    \n    q := &Queries{}\n    \n    q.getPrice, err = conn.Prepare(ctx, \"get_price\", \n        \"SELECT price FROM prices WHERE symbol = $1\")\n    if err != nil {\n        return nil, err\n    }\n    \n    return q, nil\n}\n```\n\n### 3. Monitor Performance\n\n```go\n// Log slow queries\nfunc (db *DB) logSlowQueries(ctx context.Context, threshold time.Duration) {\n    query := `\n        SELECT query, calls, mean_exec_time\n        FROM pg_stat_statements\n        WHERE mean_exec_time > $1\n        ORDER BY mean_exec_time DESC\n        LIMIT 10\n    `\n    \n    rows, _ := db.pool.Query(ctx, query, threshold.Milliseconds())\n    defer rows.Close()\n    \n    for rows.Next() {\n        var query string\n        var calls int64\n        var meanTime float64\n        rows.Scan(&query, &calls, &meanTime)\n        log.Printf(\"Slow query: %s (calls: %d, avg: %.2fms)\", query, calls, meanTime)\n    }\n}\n```\n\n## Summary\n\n1. **Use connection pools** - Let pgx manage connections\n2. **Always use transactions** - For data consistency\n3. **Parameterize queries** - Prevent SQL injection\n4. **Handle errors properly** - Check constraint violations\n5. **Index strategically** - Based on query patterns\n6. **Use COPY for bulk inserts** - Much faster than INSERT\n7. **Monitor performance** - Use EXPLAIN and pg_stat_statements\n8. **Test with real data** - Include edge cases\n9. **Use context everywhere** - For timeout and cancellation\n10. **Keep migrations simple** - One change per migration"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":667,"cache_read_input_tokens":56958,"output_tokens":8068,"service_tier":"standard"}},"requestId":"req_011CS5XkqWVQ6Unu8HXByzgP","type":"assistant","uuid":"c776d44c-3859-42d5-809a-a2e88dbb49fc","timestamp":"2025-08-13T10:16:50.591Z"}
{"parentUuid":"c776d44c-3859-42d5-809a-a2e88dbb49fc","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01H4ryhBnJePDFNpjw1eQ4kL","type":"tool_result","content":"File created successfully at: /home/aural/Code/bigmeanie/back/.docs/code/database-patterns.md"}]},"uuid":"ef8d0eb2-8fcd-429d-9663-fe574085115d","timestamp":"2025-08-13T10:17:40.044Z","toolUseResult":{"type":"create","filePath":"/home/aural/Code/bigmeanie/back/.docs/code/database-patterns.md","content":"# Database Patterns - PostgreSQL for Big Meanie\n\n## Overview\n\nBig Meanie uses PostgreSQL as its primary database for storing trading data, backtesting results, and system state. We use pgx/v5 for its performance and PostgreSQL-specific features.\n\n## Table of Contents\n1. [Connection Management](#connection-management)\n2. [Migration Patterns](#migration-patterns)\n3. [Transaction Patterns](#transaction-patterns)\n4. [Query Patterns](#query-patterns)\n5. [Trading-Specific Schemas](#trading-specific-schemas)\n6. [Performance Optimization](#performance-optimization)\n7. [Error Handling](#error-handling)\n8. [Testing Patterns](#testing-patterns)\n\n## Connection Management\n\n### Database Configuration\n\n```go\npackage database\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n    \n    \"github.com/jackc/pgx/v5/pgxpool\"\n    \"github.com/shopspring/decimal\"\n)\n\ntype Config struct {\n    Host     string\n    Port     int\n    User     string\n    Password string\n    Database string\n    SSLMode  string\n    \n    // Pool settings\n    MaxConns        int32\n    MinConns        int32\n    MaxConnLifetime time.Duration\n    MaxConnIdleTime time.Duration\n}\n\nfunc NewPool(ctx context.Context, cfg Config) (*pgxpool.Pool, error) {\n    dsn := fmt.Sprintf(\n        \"host=%s port=%d user=%s password=%s dbname=%s sslmode=%s\",\n        cfg.Host, cfg.Port, cfg.User, cfg.Password, cfg.Database, cfg.SSLMode,\n    )\n    \n    poolCfg, err := pgxpool.ParseConfig(dsn)\n    if err != nil {\n        return nil, fmt.Errorf(\"parse config: %w\", err)\n    }\n    \n    // Configure pool\n    poolCfg.MaxConns = cfg.MaxConns\n    poolCfg.MinConns = cfg.MinConns\n    poolCfg.MaxConnLifetime = cfg.MaxConnLifetime\n    poolCfg.MaxConnIdleTime = cfg.MaxConnIdleTime\n    \n    // Configure types\n    poolCfg.AfterConnect = func(ctx context.Context, conn *pgx.Conn) error {\n        // Register decimal type\n        RegisterDecimalType(conn.TypeMap())\n        return nil\n    }\n    \n    pool, err := pgxpool.NewWithConfig(ctx, poolCfg)\n    if err != nil {\n        return nil, fmt.Errorf(\"create pool: %w\", err)\n    }\n    \n    // Verify connection\n    if err := pool.Ping(ctx); err != nil {\n        return nil, fmt.Errorf(\"ping database: %w\", err)\n    }\n    \n    return pool, nil\n}\n\n// Graceful shutdown\nfunc ClosePool(pool *pgxpool.Pool) {\n    pool.Close()\n}\n```\n\n### Connection Lifecycle\n\n```go\ntype DB struct {\n    pool *pgxpool.Pool\n}\n\nfunc New(pool *pgxpool.Pool) *DB {\n    return &DB{pool: pool}\n}\n\n// Use pool connections - automatically managed\nfunc (db *DB) GetPrice(ctx context.Context, symbol string) (decimal.Decimal, error) {\n    var price decimal.Decimal\n    \n    query := `SELECT price FROM prices WHERE symbol = $1 ORDER BY timestamp DESC LIMIT 1`\n    \n    err := db.pool.QueryRow(ctx, query, symbol).Scan(&price)\n    if err != nil {\n        return decimal.Zero, fmt.Errorf(\"get price: %w\", err)\n    }\n    \n    return price, nil\n}\n\n// For long operations, use a dedicated connection\nfunc (db *DB) BulkInsert(ctx context.Context, trades []Trade) error {\n    conn, err := db.pool.Acquire(ctx)\n    if err != nil {\n        return fmt.Errorf(\"acquire conn: %w\", err)\n    }\n    defer conn.Release()\n    \n    // Use conn for bulk operations\n    _, err = conn.CopyFrom(\n        ctx,\n        pgx.Identifier{\"trades\"},\n        []string{\"symbol\", \"price\", \"quantity\", \"timestamp\"},\n        pgx.CopyFromSlice(len(trades), func(i int) ([]interface{}, error) {\n            return []interface{}{\n                trades[i].Symbol,\n                trades[i].Price.String(),\n                trades[i].Quantity.String(),\n                trades[i].Timestamp,\n            }, nil\n        }),\n    )\n    \n    return err\n}\n```\n\n## Migration Patterns\n\n### Schema Versioning\n\n```sql\n-- migrations/001_initial_schema.sql\nCREATE TABLE IF NOT EXISTS schema_migrations (\n    version INTEGER PRIMARY KEY,\n    applied_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\n\n-- Trading tables\nCREATE TABLE IF NOT EXISTS exchanges (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(50) UNIQUE NOT NULL,\n    active BOOLEAN DEFAULT true,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS symbols (\n    id SERIAL PRIMARY KEY,\n    exchange_id INTEGER REFERENCES exchanges(id),\n    symbol VARCHAR(20) NOT NULL,\n    base_asset VARCHAR(10) NOT NULL,\n    quote_asset VARCHAR(10) NOT NULL,\n    active BOOLEAN DEFAULT true,\n    min_qty DECIMAL(20, 8),\n    max_qty DECIMAL(20, 8),\n    tick_size DECIMAL(20, 8),\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    UNIQUE(exchange_id, symbol)\n);\n\nCREATE TABLE IF NOT EXISTS candles (\n    id BIGSERIAL PRIMARY KEY,\n    symbol_id INTEGER REFERENCES symbols(id),\n    timeframe VARCHAR(10) NOT NULL,\n    open_time TIMESTAMP NOT NULL,\n    open DECIMAL(20, 8) NOT NULL,\n    high DECIMAL(20, 8) NOT NULL,\n    low DECIMAL(20, 8) NOT NULL,\n    close DECIMAL(20, 8) NOT NULL,\n    volume DECIMAL(20, 8) NOT NULL,\n    close_time TIMESTAMP NOT NULL,\n    trades INTEGER,\n    UNIQUE(symbol_id, timeframe, open_time)\n);\n\nCREATE INDEX idx_candles_symbol_time ON candles(symbol_id, open_time DESC);\nCREATE INDEX idx_candles_timeframe ON candles(timeframe, open_time DESC);\n```\n\n### Migration Runner\n\n```go\npackage migration\n\nimport (\n    \"context\"\n    \"embed\"\n    \"fmt\"\n    \"sort\"\n    \n    \"github.com/jackc/pgx/v5\"\n)\n\n//go:embed migrations/*.sql\nvar migrations embed.FS\n\ntype Migration struct {\n    Version int\n    Name    string\n    SQL     string\n}\n\nfunc Run(ctx context.Context, db *pgx.Conn) error {\n    // Create migrations table\n    if err := createMigrationsTable(ctx, db); err != nil {\n        return err\n    }\n    \n    // Get current version\n    current, err := getCurrentVersion(ctx, db)\n    if err != nil {\n        return err\n    }\n    \n    // Load migrations\n    available, err := loadMigrations()\n    if err != nil {\n        return err\n    }\n    \n    // Apply pending migrations\n    for _, m := range available {\n        if m.Version <= current {\n            continue\n        }\n        \n        if err := applyMigration(ctx, db, m); err != nil {\n            return fmt.Errorf(\"apply migration %d: %w\", m.Version, err)\n        }\n    }\n    \n    return nil\n}\n\nfunc applyMigration(ctx context.Context, db *pgx.Conn, m Migration) error {\n    tx, err := db.Begin(ctx)\n    if err != nil {\n        return err\n    }\n    defer tx.Rollback(ctx)\n    \n    // Execute migration\n    if _, err := tx.Exec(ctx, m.SQL); err != nil {\n        return fmt.Errorf(\"exec sql: %w\", err)\n    }\n    \n    // Record migration\n    query := `INSERT INTO schema_migrations (version) VALUES ($1)`\n    if _, err := tx.Exec(ctx, query, m.Version); err != nil {\n        return fmt.Errorf(\"record migration: %w\", err)\n    }\n    \n    return tx.Commit(ctx)\n}\n```\n\n## Transaction Patterns\n\n### Basic Transactions\n\n```go\nfunc (db *DB) TransferFunds(ctx context.Context, from, to string, amount decimal.Decimal) error {\n    tx, err := db.pool.Begin(ctx)\n    if err != nil {\n        return fmt.Errorf(\"begin tx: %w\", err)\n    }\n    defer tx.Rollback(ctx) // No-op if committed\n    \n    // Debit from account\n    query := `UPDATE accounts SET balance = balance - $1 WHERE id = $2 AND balance >= $1`\n    result, err := tx.Exec(ctx, query, amount.String(), from)\n    if err != nil {\n        return fmt.Errorf(\"debit account: %w\", err)\n    }\n    \n    if result.RowsAffected() == 0 {\n        return fmt.Errorf(\"insufficient funds\")\n    }\n    \n    // Credit to account\n    query = `UPDATE accounts SET balance = balance + $1 WHERE id = $2`\n    _, err = tx.Exec(ctx, query, amount.String(), to)\n    if err != nil {\n        return fmt.Errorf(\"credit account: %w\", err)\n    }\n    \n    // Record transfer\n    query = `INSERT INTO transfers (from_id, to_id, amount, timestamp) VALUES ($1, $2, $3, NOW())`\n    _, err = tx.Exec(ctx, query, from, to, amount.String())\n    if err != nil {\n        return fmt.Errorf(\"record transfer: %w\", err)\n    }\n    \n    return tx.Commit(ctx)\n}\n```\n\n### Nested Transactions (Savepoints)\n\n```go\nfunc (db *DB) ProcessTrade(ctx context.Context, trade Trade) error {\n    tx, err := db.pool.Begin(ctx)\n    if err != nil {\n        return err\n    }\n    defer tx.Rollback(ctx)\n    \n    // Create savepoint for position update\n    _, err = tx.Exec(ctx, \"SAVEPOINT update_position\")\n    if err != nil {\n        return err\n    }\n    \n    // Try to update position\n    err = updatePosition(ctx, tx, trade)\n    if err != nil {\n        // Rollback to savepoint, continue transaction\n        _, _ = tx.Exec(ctx, \"ROLLBACK TO SAVEPOINT update_position\")\n        \n        // Try alternative approach\n        err = createNewPosition(ctx, tx, trade)\n        if err != nil {\n            return err\n        }\n    }\n    \n    // Record trade\n    err = recordTrade(ctx, tx, trade)\n    if err != nil {\n        return err\n    }\n    \n    return tx.Commit(ctx)\n}\n```\n\n### Distributed Transactions\n\n```go\n// Use saga pattern for distributed transactions\ntype TradeSaga struct {\n    db       *DB\n    exchange Exchange\n}\n\nfunc (s *TradeSaga) ExecuteTrade(ctx context.Context, order Order) error {\n    // Step 1: Reserve funds in database\n    reservationID, err := s.reserveFunds(ctx, order)\n    if err != nil {\n        return err\n    }\n    \n    // Step 2: Place order on exchange\n    exchangeOrderID, err := s.exchange.PlaceOrder(ctx, order)\n    if err != nil {\n        // Compensate: Release reserved funds\n        _ = s.releaseFunds(ctx, reservationID)\n        return err\n    }\n    \n    // Step 3: Record order in database\n    err = s.recordOrder(ctx, order, exchangeOrderID)\n    if err != nil {\n        // Compensate: Cancel exchange order and release funds\n        _ = s.exchange.CancelOrder(ctx, exchangeOrderID)\n        _ = s.releaseFunds(ctx, reservationID)\n        return err\n    }\n    \n    // Step 4: Commit reservation\n    return s.commitReservation(ctx, reservationID)\n}\n```\n\n## Query Patterns\n\n### Parameterized Queries\n\n```go\n// ALWAYS use parameterized queries\nfunc (db *DB) GetTrades(ctx context.Context, filter TradeFilter) ([]Trade, error) {\n    query := `\n        SELECT id, symbol, side, price, quantity, timestamp\n        FROM trades\n        WHERE symbol = $1\n          AND timestamp >= $2\n          AND timestamp < $3\n        ORDER BY timestamp DESC\n        LIMIT $4\n    `\n    \n    rows, err := db.pool.Query(ctx, query,\n        filter.Symbol,\n        filter.StartTime,\n        filter.EndTime,\n        filter.Limit,\n    )\n    if err != nil {\n        return nil, err\n    }\n    defer rows.Close()\n    \n    var trades []Trade\n    for rows.Next() {\n        var t Trade\n        err := rows.Scan(\n            &t.ID,\n            &t.Symbol,\n            &t.Side,\n            &t.Price,\n            &t.Quantity,\n            &t.Timestamp,\n        )\n        if err != nil {\n            return nil, err\n        }\n        trades = append(trades, t)\n    }\n    \n    return trades, rows.Err()\n}\n```\n\n### Dynamic Query Building\n\n```go\nimport \"github.com/Masterminds/squirrel\"\n\nfunc (db *DB) SearchTrades(ctx context.Context, criteria SearchCriteria) ([]Trade, error) {\n    // Build query dynamically\n    qb := squirrel.Select(\"id\", \"symbol\", \"price\", \"quantity\", \"timestamp\").\n        From(\"trades\").\n        PlaceholderFormat(squirrel.Dollar)\n    \n    if criteria.Symbol != \"\" {\n        qb = qb.Where(squirrel.Eq{\"symbol\": criteria.Symbol})\n    }\n    \n    if !criteria.MinPrice.IsZero() {\n        qb = qb.Where(squirrel.GtOrEq{\"price\": criteria.MinPrice.String()})\n    }\n    \n    if !criteria.MaxPrice.IsZero() {\n        qb = qb.Where(squirrel.LtOrEq{\"price\": criteria.MaxPrice.String()})\n    }\n    \n    if criteria.Side != \"\" {\n        qb = qb.Where(squirrel.Eq{\"side\": criteria.Side})\n    }\n    \n    sql, args, err := qb.ToSql()\n    if err != nil {\n        return nil, err\n    }\n    \n    rows, err := db.pool.Query(ctx, sql, args...)\n    // ... scan rows\n}\n```\n\n### Batch Operations\n\n```go\nfunc (db *DB) BatchInsertCandles(ctx context.Context, candles []Candle) error {\n    // Use COPY for best performance\n    _, err := db.pool.CopyFrom(\n        ctx,\n        pgx.Identifier{\"candles\"},\n        []string{\"symbol_id\", \"timeframe\", \"open_time\", \"open\", \"high\", \"low\", \"close\", \"volume\"},\n        pgx.CopyFromSlice(len(candles), func(i int) ([]interface{}, error) {\n            c := candles[i]\n            return []interface{}{\n                c.SymbolID,\n                c.Timeframe,\n                c.OpenTime,\n                c.Open.String(),\n                c.High.String(),\n                c.Low.String(),\n                c.Close.String(),\n                c.Volume.String(),\n            }, nil\n        }),\n    )\n    return err\n}\n\n// Batch updates\nfunc (db *DB) UpdatePrices(ctx context.Context, updates map[string]decimal.Decimal) error {\n    tx, err := db.pool.Begin(ctx)\n    if err != nil {\n        return err\n    }\n    defer tx.Rollback(ctx)\n    \n    // Prepare statement\n    stmt := `UPDATE symbols SET last_price = $1, updated_at = NOW() WHERE symbol = $2`\n    \n    batch := &pgx.Batch{}\n    for symbol, price := range updates {\n        batch.Queue(stmt, price.String(), symbol)\n    }\n    \n    results := tx.SendBatch(ctx, batch)\n    defer results.Close()\n    \n    // Check results\n    for i := 0; i < batch.Len(); i++ {\n        _, err := results.Exec()\n        if err != nil {\n            return fmt.Errorf(\"update batch item %d: %w\", i, err)\n        }\n    }\n    \n    return tx.Commit(ctx)\n}\n```\n\n## Trading-Specific Schemas\n\n### Order Management\n\n```sql\n-- Orders table with proper constraints\nCREATE TABLE orders (\n    id BIGSERIAL PRIMARY KEY,\n    exchange_order_id VARCHAR(100) UNIQUE,\n    symbol_id INTEGER REFERENCES symbols(id),\n    side VARCHAR(4) CHECK (side IN ('BUY', 'SELL')),\n    type VARCHAR(10) CHECK (type IN ('MARKET', 'LIMIT', 'STOP', 'STOP_LIMIT')),\n    status VARCHAR(20) CHECK (status IN ('NEW', 'PARTIAL', 'FILLED', 'CANCELLED', 'REJECTED')),\n    price DECIMAL(20, 8),\n    quantity DECIMAL(20, 8) NOT NULL,\n    filled_qty DECIMAL(20, 8) DEFAULT 0,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    \n    CONSTRAINT positive_quantity CHECK (quantity > 0),\n    CONSTRAINT positive_price CHECK (price IS NULL OR price > 0),\n    CONSTRAINT filled_not_exceed CHECK (filled_qty <= quantity)\n);\n\n-- Positions tracking\nCREATE TABLE positions (\n    id BIGSERIAL PRIMARY KEY,\n    symbol_id INTEGER REFERENCES symbols(id),\n    side VARCHAR(5) CHECK (side IN ('LONG', 'SHORT')),\n    quantity DECIMAL(20, 8) NOT NULL,\n    entry_price DECIMAL(20, 8) NOT NULL,\n    current_price DECIMAL(20, 8),\n    realized_pnl DECIMAL(20, 8) DEFAULT 0,\n    unrealized_pnl DECIMAL(20, 8) DEFAULT 0,\n    opened_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    closed_at TIMESTAMP,\n    \n    CONSTRAINT positive_position_qty CHECK (quantity >= 0),\n    CONSTRAINT position_close_check CHECK (\n        (quantity = 0 AND closed_at IS NOT NULL) OR\n        (quantity > 0 AND closed_at IS NULL)\n    )\n);\n\n-- Trade executions\nCREATE TABLE executions (\n    id BIGSERIAL PRIMARY KEY,\n    order_id BIGINT REFERENCES orders(id),\n    exchange_trade_id VARCHAR(100) UNIQUE,\n    price DECIMAL(20, 8) NOT NULL,\n    quantity DECIMAL(20, 8) NOT NULL,\n    commission DECIMAL(20, 8) DEFAULT 0,\n    commission_asset VARCHAR(10),\n    executed_at TIMESTAMP NOT NULL,\n    \n    CONSTRAINT positive_execution CHECK (price > 0 AND quantity > 0)\n);\n```\n\n### Performance Metrics\n\n```sql\n-- Strategy performance tracking\nCREATE TABLE strategy_metrics (\n    id BIGSERIAL PRIMARY KEY,\n    strategy_name VARCHAR(50) NOT NULL,\n    period_start TIMESTAMP NOT NULL,\n    period_end TIMESTAMP NOT NULL,\n    total_trades INTEGER DEFAULT 0,\n    winning_trades INTEGER DEFAULT 0,\n    losing_trades INTEGER DEFAULT 0,\n    gross_profit DECIMAL(20, 8) DEFAULT 0,\n    gross_loss DECIMAL(20, 8) DEFAULT 0,\n    max_drawdown DECIMAL(20, 8) DEFAULT 0,\n    sharpe_ratio DECIMAL(10, 4),\n    calculated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    \n    UNIQUE(strategy_name, period_start, period_end)\n);\n\n-- Daily account snapshots\nCREATE TABLE account_snapshots (\n    id BIGSERIAL PRIMARY KEY,\n    snapshot_date DATE NOT NULL,\n    total_value DECIMAL(20, 8) NOT NULL,\n    cash_balance DECIMAL(20, 8) NOT NULL,\n    positions_value DECIMAL(20, 8) NOT NULL,\n    daily_pnl DECIMAL(20, 8),\n    cumulative_pnl DECIMAL(20, 8),\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    \n    UNIQUE(snapshot_date)\n);\n```\n\n## Performance Optimization\n\n### Indexing Strategy\n\n```sql\n-- Composite indexes for common queries\nCREATE INDEX idx_trades_symbol_time ON trades(symbol, timestamp DESC);\nCREATE INDEX idx_orders_status_time ON orders(status, created_at DESC) WHERE status IN ('NEW', 'PARTIAL');\nCREATE INDEX idx_positions_open ON positions(symbol_id, side) WHERE closed_at IS NULL;\n\n-- Partial indexes for active records\nCREATE INDEX idx_symbols_active ON symbols(exchange_id, symbol) WHERE active = true;\n\n-- BRIN indexes for time-series data\nCREATE INDEX idx_candles_time_brin ON candles USING BRIN(open_time);\n\n-- GIN indexes for JSONB data\nCREATE INDEX idx_order_metadata ON orders USING GIN(metadata) WHERE metadata IS NOT NULL;\n```\n\n### Query Optimization\n\n```go\n// Use EXPLAIN to analyze queries\nfunc (db *DB) AnalyzeQuery(ctx context.Context, query string, args ...interface{}) error {\n    rows, err := db.pool.Query(ctx, \"EXPLAIN ANALYZE \"+query, args...)\n    if err != nil {\n        return err\n    }\n    defer rows.Close()\n    \n    for rows.Next() {\n        var plan string\n        rows.Scan(&plan)\n        fmt.Println(plan)\n    }\n    \n    return rows.Err()\n}\n\n// Optimize pagination with cursors\nfunc (db *DB) GetTradesCursor(ctx context.Context, cursor string, limit int) ([]Trade, string, error) {\n    var trades []Trade\n    var lastID int64\n    \n    if cursor != \"\" {\n        // Decode cursor\n        fmt.Sscanf(cursor, \"%d\", &lastID)\n    }\n    \n    query := `\n        SELECT id, symbol, price, quantity, timestamp\n        FROM trades\n        WHERE id > $1\n        ORDER BY id\n        LIMIT $2\n    `\n    \n    rows, err := db.pool.Query(ctx, query, lastID, limit+1)\n    if err != nil {\n        return nil, \"\", err\n    }\n    defer rows.Close()\n    \n    for rows.Next() {\n        var t Trade\n        err := rows.Scan(&t.ID, &t.Symbol, &t.Price, &t.Quantity, &t.Timestamp)\n        if err != nil {\n            return nil, \"\", err\n        }\n        \n        if len(trades) < limit {\n            trades = append(trades, t)\n            lastID = t.ID\n        }\n    }\n    \n    nextCursor := \"\"\n    if len(trades) == limit {\n        nextCursor = fmt.Sprintf(\"%d\", lastID)\n    }\n    \n    return trades, nextCursor, nil\n}\n```\n\n### Connection Pooling\n\n```go\n// Optimal pool configuration for trading system\nfunc OptimalPoolConfig() *pgxpool.Config {\n    cfg, _ := pgxpool.ParseConfig(os.Getenv(\"DATABASE_URL\"))\n    \n    // Pool size based on workload\n    cfg.MaxConns = 25        // Limit connections\n    cfg.MinConns = 5         // Keep minimum ready\n    cfg.MaxConnLifetime = time.Hour\n    cfg.MaxConnIdleTime = time.Minute * 30\n    \n    // Health check\n    cfg.HealthCheckPeriod = time.Minute\n    \n    // Statement cache\n    cfg.ConnConfig.DefaultQueryExecMode = pgx.QueryExecModeCacheStatement\n    \n    return cfg\n}\n```\n\n## Error Handling\n\n### Database Error Types\n\n```go\nimport \"github.com/jackc/pgx/v5/pgconn\"\n\nfunc handleDBError(err error) error {\n    var pgErr *pgconn.PgError\n    if errors.As(err, &pgErr) {\n        switch pgErr.Code {\n        case \"23505\": // unique_violation\n            return fmt.Errorf(\"duplicate entry: %s\", pgErr.Detail)\n        case \"23503\": // foreign_key_violation\n            return fmt.Errorf(\"foreign key violation: %s\", pgErr.Detail)\n        case \"23502\": // not_null_violation\n            return fmt.Errorf(\"required field missing: %s\", pgErr.ColumnName)\n        case \"23514\": // check_violation\n            return fmt.Errorf(\"constraint violation: %s\", pgErr.ConstraintName)\n        case \"40001\": // serialization_failure\n            return fmt.Errorf(\"transaction conflict, retry needed\")\n        case \"53300\": // too_many_connections\n            return fmt.Errorf(\"database connection limit reached\")\n        default:\n            return fmt.Errorf(\"database error %s: %s\", pgErr.Code, pgErr.Message)\n        }\n    }\n    \n    if errors.Is(err, pgx.ErrNoRows) {\n        return fmt.Errorf(\"not found\")\n    }\n    \n    return err\n}\n```\n\n### Retry Logic\n\n```go\nfunc (db *DB) WithRetry(ctx context.Context, fn func(context.Context) error) error {\n    maxRetries := 3\n    backoff := time.Millisecond * 100\n    \n    for i := 0; i < maxRetries; i++ {\n        err := fn(ctx)\n        if err == nil {\n            return nil\n        }\n        \n        // Check if retryable\n        var pgErr *pgconn.PgError\n        if errors.As(err, &pgErr) {\n            if pgErr.Code == \"40001\" { // serialization failure\n                time.Sleep(backoff)\n                backoff *= 2\n                continue\n            }\n        }\n        \n        // Non-retryable error\n        return err\n    }\n    \n    return fmt.Errorf(\"max retries exceeded\")\n}\n```\n\n## Testing Patterns\n\n### Test Database Setup\n\n```go\nfunc SetupTestDB(t *testing.T) *DB {\n    // Use separate test database\n    testDB := os.Getenv(\"TEST_DATABASE_URL\")\n    if testDB == \"\" {\n        testDB = \"postgres://test:test@localhost:5432/bigmeanie_test\"\n    }\n    \n    ctx := context.Background()\n    pool, err := pgxpool.New(ctx, testDB)\n    require.NoError(t, err)\n    \n    // Clean database\n    _, err = pool.Exec(ctx, \"TRUNCATE TABLE trades, orders, positions CASCADE\")\n    require.NoError(t, err)\n    \n    // Run migrations\n    err = migration.Run(ctx, pool)\n    require.NoError(t, err)\n    \n    t.Cleanup(func() {\n        pool.Close()\n    })\n    \n    return &DB{pool: pool}\n}\n```\n\n### Test Fixtures\n\n```go\nfunc InsertTestData(t *testing.T, db *DB) {\n    ctx := context.Background()\n    \n    // Insert test trades\n    trades := []Trade{\n        {Symbol: \"BTC-USD\", Price: decimal.NewFromInt(50000), Quantity: decimal.NewFromFloat(0.1)},\n        {Symbol: \"ETH-USD\", Price: decimal.NewFromInt(3000), Quantity: decimal.NewFromInt(1)},\n    }\n    \n    for _, trade := range trades {\n        query := `INSERT INTO trades (symbol, price, quantity) VALUES ($1, $2, $3)`\n        _, err := db.pool.Exec(ctx, query, trade.Symbol, trade.Price.String(), trade.Quantity.String())\n        require.NoError(t, err)\n    }\n}\n```\n\n### Integration Tests\n\n```go\nfunc TestTradeExecution(t *testing.T) {\n    db := SetupTestDB(t)\n    ctx := context.Background()\n    \n    // Test transaction\n    order := Order{\n        Symbol:   \"BTC-USD\",\n        Side:     \"BUY\",\n        Quantity: decimal.NewFromFloat(0.1),\n        Price:    decimal.NewFromInt(50000),\n    }\n    \n    err := db.ExecuteOrder(ctx, order)\n    require.NoError(t, err)\n    \n    // Verify order created\n    var count int\n    err = db.pool.QueryRow(ctx, \"SELECT COUNT(*) FROM orders WHERE symbol = $1\", order.Symbol).Scan(&count)\n    require.NoError(t, err)\n    require.Equal(t, 1, count)\n    \n    // Verify position updated\n    var position Position\n    query := `SELECT quantity, entry_price FROM positions WHERE symbol = $1`\n    err = db.pool.QueryRow(ctx, query, order.Symbol).Scan(&position.Quantity, &position.EntryPrice)\n    require.NoError(t, err)\n    require.True(t, position.Quantity.Equal(order.Quantity))\n}\n```\n\n## Best Practices\n\n### 1. Always Use Context\n\n```go\n// Pass context for cancellation\nfunc (db *DB) LongRunningQuery(ctx context.Context) error {\n    ctx, cancel := context.WithTimeout(ctx, 30*time.Second)\n    defer cancel()\n    \n    return db.pool.QueryRow(ctx, \"SELECT pg_sleep(10)\").Scan(nil)\n}\n```\n\n### 2. Prepare Statements\n\n```go\n// Cache prepared statements\ntype Queries struct {\n    getPrice   *pgx.Stmt\n    updatePrice *pgx.Stmt\n}\n\nfunc (db *DB) PrepareQueries(ctx context.Context) (*Queries, error) {\n    conn, err := db.pool.Acquire(ctx)\n    if err != nil {\n        return nil, err\n    }\n    defer conn.Release()\n    \n    q := &Queries{}\n    \n    q.getPrice, err = conn.Prepare(ctx, \"get_price\", \n        \"SELECT price FROM prices WHERE symbol = $1\")\n    if err != nil {\n        return nil, err\n    }\n    \n    return q, nil\n}\n```\n\n### 3. Monitor Performance\n\n```go\n// Log slow queries\nfunc (db *DB) logSlowQueries(ctx context.Context, threshold time.Duration) {\n    query := `\n        SELECT query, calls, mean_exec_time\n        FROM pg_stat_statements\n        WHERE mean_exec_time > $1\n        ORDER BY mean_exec_time DESC\n        LIMIT 10\n    `\n    \n    rows, _ := db.pool.Query(ctx, query, threshold.Milliseconds())\n    defer rows.Close()\n    \n    for rows.Next() {\n        var query string\n        var calls int64\n        var meanTime float64\n        rows.Scan(&query, &calls, &meanTime)\n        log.Printf(\"Slow query: %s (calls: %d, avg: %.2fms)\", query, calls, meanTime)\n    }\n}\n```\n\n## Summary\n\n1. **Use connection pools** - Let pgx manage connections\n2. **Always use transactions** - For data consistency\n3. **Parameterize queries** - Prevent SQL injection\n4. **Handle errors properly** - Check constraint violations\n5. **Index strategically** - Based on query patterns\n6. **Use COPY for bulk inserts** - Much faster than INSERT\n7. **Monitor performance** - Use EXPLAIN and pg_stat_statements\n8. **Test with real data** - Include edge cases\n9. **Use context everywhere** - For timeout and cancellation\n10. **Keep migrations simple** - One change per migration","structuredPatch":[]}}
{"parentUuid":"ef8d0eb2-8fcd-429d-9663-fe574085115d","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01YMWtofMKBUUwM2FFVUpd1a","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Finally, let's create the api-patterns.md file:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":8108,"cache_read_input_tokens":57625,"output_tokens":9011,"service_tier":"standard"}},"requestId":"req_011CS5Y6vZQSztKFYNLjqLJW","type":"assistant","uuid":"55603c9f-1f8c-4c71-a624-b77633d310e0","timestamp":"2025-08-13T10:17:43.562Z"}
{"parentUuid":"55603c9f-1f8c-4c71-a624-b77633d310e0","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01YMWtofMKBUUwM2FFVUpd1a","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_01VSuQpX9NEAngpLTPvFwx2p","name":"Write","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/api-patterns.md","content":"# API Patterns - REST and WebSocket for Big Meanie\n\n## Overview\n\nBig Meanie exposes REST APIs for control operations and WebSocket connections for real-time data streams. We use standard library HTTP with chi router for REST and gorilla/websocket for WebSocket connections.\n\n## Table of Contents\n1. [REST API Design](#rest-api-design)\n2. [HTTP Server Setup](#http-server-setup)\n3. [Middleware Patterns](#middleware-patterns)\n4. [Error Handling](#error-handling)\n5. [Request/Response Patterns](#requestresponse-patterns)\n6. [WebSocket Patterns](#websocket-patterns)\n7. [Authentication & Security](#authentication--security)\n8. [Rate Limiting](#rate-limiting)\n9. [API Documentation](#api-documentation)\n10. [Testing Patterns](#testing-patterns)\n\n## REST API Design\n\n### URL Structure\n\n```go\n// RESTful resource naming\n// Pattern: /api/v1/{resource}/{id}/{action}\n\n// Good URL patterns for trading system:\nGET    /api/v1/accounts              // List accounts\nGET    /api/v1/accounts/{id}         // Get account\nPOST   /api/v1/accounts              // Create account\n\nGET    /api/v1/positions             // List positions\nGET    /api/v1/positions/{symbol}    // Get position for symbol\nDELETE /api/v1/positions/{symbol}    // Close position\n\nPOST   /api/v1/orders                // Place order\nGET    /api/v1/orders/{id}           // Get order\nDELETE /api/v1/orders/{id}           // Cancel order\n\nGET    /api/v1/trades                // List trades\nGET    /api/v1/candles/{symbol}      // Get candles\nGET    /api/v1/orderbook/{symbol}    // Get orderbook\n\n// Action endpoints (use POST for non-CRUD operations)\nPOST   /api/v1/strategies/{id}/start // Start strategy\nPOST   /api/v1/strategies/{id}/stop  // Stop strategy\nPOST   /api/v1/backtest/run          // Run backtest\n```\n\n### HTTP Status Codes\n\n```go\n// Use appropriate status codes\n200 OK              // Successful GET, PUT\n201 Created         // Successful POST creating resource\n204 No Content      // Successful DELETE\n400 Bad Request     // Invalid request data\n401 Unauthorized    // Missing/invalid auth\n403 Forbidden       // Valid auth but no permission\n404 Not Found       // Resource doesn't exist\n409 Conflict        // Resource already exists\n422 Unprocessable   // Validation errors\n429 Too Many Req    // Rate limited\n500 Internal Error  // Server error\n503 Service Unavail // Temporary unavailable\n```\n\n## HTTP Server Setup\n\n### Basic Server Configuration\n\n```go\npackage api\n\nimport (\n    \"context\"\n    \"net/http\"\n    \"time\"\n    \n    \"github.com/go-chi/chi/v5\"\n    \"github.com/go-chi/chi/v5/middleware\"\n)\n\ntype Server struct {\n    router *chi.Mux\n    srv    *http.Server\n    db     *DB\n    engine *Engine\n}\n\nfunc NewServer(cfg Config, db *DB, engine *Engine) *Server {\n    s := &Server{\n        router: chi.NewRouter(),\n        db:     db,\n        engine: engine,\n    }\n    \n    // Configure server\n    s.srv = &http.Server{\n        Addr:         cfg.Address,\n        Handler:      s.router,\n        ReadTimeout:  15 * time.Second,\n        WriteTimeout: 15 * time.Second,\n        IdleTimeout:  60 * time.Second,\n    }\n    \n    s.setupRoutes()\n    return s\n}\n\nfunc (s *Server) setupRoutes() {\n    r := s.router\n    \n    // Global middleware\n    r.Use(middleware.RequestID)\n    r.Use(middleware.RealIP)\n    r.Use(middleware.Logger)\n    r.Use(middleware.Recoverer)\n    r.Use(middleware.Timeout(60 * time.Second))\n    \n    // API routes\n    r.Route(\"/api/v1\", func(r chi.Router) {\n        // Auth middleware for API\n        r.Use(s.authenticate)\n        r.Use(s.rateLimit)\n        \n        // Resources\n        r.Route(\"/orders\", s.orderRoutes)\n        r.Route(\"/positions\", s.positionRoutes)\n        r.Route(\"/accounts\", s.accountRoutes)\n    })\n    \n    // Health check (no auth)\n    r.Get(\"/health\", s.healthCheck)\n}\n\nfunc (s *Server) Start() error {\n    return s.srv.ListenAndServe()\n}\n\nfunc (s *Server) Shutdown(ctx context.Context) error {\n    return s.srv.Shutdown(ctx)\n}\n```\n\n### Graceful Shutdown\n\n```go\nfunc RunServer(ctx context.Context, cfg Config) error {\n    server := NewServer(cfg, db, engine)\n    \n    // Start server in goroutine\n    errChan := make(chan error, 1)\n    go func() {\n        if err := server.Start(); err != nil && err != http.ErrServerClosed {\n            errChan <- err\n        }\n    }()\n    \n    // Wait for context cancellation or error\n    select {\n    case <-ctx.Done():\n        // Graceful shutdown\n        shutdownCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n        defer cancel()\n        \n        return server.Shutdown(shutdownCtx)\n        \n    case err := <-errChan:\n        return err\n    }\n}\n```\n\n## Middleware Patterns\n\n### Request Context\n\n```go\n// Add values to request context\ntype contextKey string\n\nconst (\n    userIDKey contextKey = \"userID\"\n    tradeIDKey contextKey = \"tradeID\"\n)\n\nfunc (s *Server) authenticate(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        token := r.Header.Get(\"Authorization\")\n        if token == \"\" {\n            s.respondError(w, http.StatusUnauthorized, \"missing auth token\")\n            return\n        }\n        \n        // Validate token\n        userID, err := s.validateToken(token)\n        if err != nil {\n            s.respondError(w, http.StatusUnauthorized, \"invalid token\")\n            return\n        }\n        \n        // Add to context\n        ctx := context.WithValue(r.Context(), userIDKey, userID)\n        next.ServeHTTP(w, r.WithContext(ctx))\n    })\n}\n\n// Extract from context\nfunc getUserID(ctx context.Context) (string, bool) {\n    userID, ok := ctx.Value(userIDKey).(string)\n    return userID, ok\n}\n```\n\n### Logging Middleware\n\n```go\nfunc loggingMiddleware(logger *log.Logger) func(http.Handler) http.Handler {\n    return func(next http.Handler) http.Handler {\n        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n            start := time.Now()\n            \n            // Wrap response writer to capture status\n            wrapped := &responseWriter{\n                ResponseWriter: w,\n                status:        200,\n            }\n            \n            next.ServeHTTP(wrapped, r)\n            \n            logger.Printf(\n                \"%s %s %d %v\",\n                r.Method,\n                r.URL.Path,\n                wrapped.status,\n                time.Since(start),\n            )\n        })\n    }\n}\n\ntype responseWriter struct {\n    http.ResponseWriter\n    status int\n}\n\nfunc (w *responseWriter) WriteHeader(status int) {\n    w.status = status\n    w.ResponseWriter.WriteHeader(status)\n}\n```\n\n### CORS Middleware\n\n```go\nfunc corsMiddleware(allowedOrigins []string) func(http.Handler) http.Handler {\n    return func(next http.Handler) http.Handler {\n        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n            origin := r.Header.Get(\"Origin\")\n            \n            // Check if origin is allowed\n            for _, allowed := range allowedOrigins {\n                if origin == allowed || allowed == \"*\" {\n                    w.Header().Set(\"Access-Control-Allow-Origin\", origin)\n                    w.Header().Set(\"Access-Control-Allow-Credentials\", \"true\")\n                    break\n                }\n            }\n            \n            // Handle preflight\n            if r.Method == \"OPTIONS\" {\n                w.Header().Set(\"Access-Control-Allow-Methods\", \"GET, POST, PUT, DELETE, OPTIONS\")\n                w.Header().Set(\"Access-Control-Allow-Headers\", \"Authorization, Content-Type\")\n                w.Header().Set(\"Access-Control-Max-Age\", \"86400\")\n                w.WriteHeader(http.StatusNoContent)\n                return\n            }\n            \n            next.ServeHTTP(w, r)\n        })\n    }\n}\n```\n\n## Error Handling\n\n### Error Response Structure\n\n```go\ntype ErrorResponse struct {\n    Error   string            `json:\"error\"`\n    Message string            `json:\"message\"`\n    Code    string            `json:\"code,omitempty\"`\n    Details map[string]string `json:\"details,omitempty\"`\n}\n\nfunc (s *Server) respondError(w http.ResponseWriter, status int, message string) {\n    s.respondJSON(w, status, ErrorResponse{\n        Error:   http.StatusText(status),\n        Message: message,\n    })\n}\n\nfunc (s *Server) respondValidationError(w http.ResponseWriter, errors map[string]string) {\n    s.respondJSON(w, http.StatusUnprocessableEntity, ErrorResponse{\n        Error:   \"Validation Failed\",\n        Message: \"The request contains invalid fields\",\n        Details: errors,\n    })\n}\n\nfunc (s *Server) respondJSON(w http.ResponseWriter, status int, data interface{}) {\n    w.Header().Set(\"Content-Type\", \"application/json\")\n    w.WriteHeader(status)\n    \n    if err := json.NewEncoder(w).Encode(data); err != nil {\n        log.Printf(\"Failed to encode response: %v\", err)\n    }\n}\n```\n\n### Business Error Handling\n\n```go\n// Define business errors\nvar (\n    ErrInsufficientFunds = &APIError{Code: \"INSUFFICIENT_FUNDS\", Message: \"Insufficient funds for order\"}\n    ErrOrderTooSmall     = &APIError{Code: \"ORDER_TOO_SMALL\", Message: \"Order size below minimum\"}\n    ErrSymbolNotFound    = &APIError{Code: \"SYMBOL_NOT_FOUND\", Message: \"Trading symbol not found\"}\n    ErrStrategyRunning   = &APIError{Code: \"STRATEGY_RUNNING\", Message: \"Strategy already running\"}\n)\n\ntype APIError struct {\n    Code    string\n    Message string\n}\n\nfunc (e *APIError) Error() string {\n    return e.Message\n}\n\n// Handle business errors in handlers\nfunc (s *Server) placeOrder(w http.ResponseWriter, r *http.Request) {\n    var req OrderRequest\n    if err := json.NewDecoder(r.Body).Decode(&req); err != nil {\n        s.respondError(w, http.StatusBadRequest, \"Invalid request body\")\n        return\n    }\n    \n    order, err := s.engine.PlaceOrder(r.Context(), req)\n    if err != nil {\n        var apiErr *APIError\n        if errors.As(err, &apiErr) {\n            s.respondJSON(w, http.StatusBadRequest, ErrorResponse{\n                Error:   \"Business Rule Violation\",\n                Code:    apiErr.Code,\n                Message: apiErr.Message,\n            })\n            return\n        }\n        \n        s.respondError(w, http.StatusInternalServerError, \"Failed to place order\")\n        return\n    }\n    \n    s.respondJSON(w, http.StatusCreated, order)\n}\n```\n\n## Request/Response Patterns\n\n### Request Validation\n\n```go\nimport \"github.com/go-playground/validator/v10\"\n\nvar validate = validator.New()\n\ntype OrderRequest struct {\n    Symbol   string          `json:\"symbol\" validate:\"required\"`\n    Side     string          `json:\"side\" validate:\"required,oneof=BUY SELL\"`\n    Type     string          `json:\"type\" validate:\"required,oneof=MARKET LIMIT\"`\n    Quantity decimal.Decimal `json:\"quantity\" validate:\"required,gt=0\"`\n    Price    decimal.Decimal `json:\"price\" validate:\"required_if=Type LIMIT,gt=0\"`\n}\n\nfunc (s *Server) validateRequest(r *http.Request, dst interface{}) error {\n    if err := json.NewDecoder(r.Body).Decode(dst); err != nil {\n        return fmt.Errorf(\"invalid JSON: %w\", err)\n    }\n    \n    if err := validate.Struct(dst); err != nil {\n        return fmt.Errorf(\"validation failed: %w\", err)\n    }\n    \n    return nil\n}\n\n// Use in handler\nfunc (s *Server) createOrder(w http.ResponseWriter, r *http.Request) {\n    var req OrderRequest\n    if err := s.validateRequest(r, &req); err != nil {\n        s.respondError(w, http.StatusBadRequest, err.Error())\n        return\n    }\n    \n    // Process valid request\n}\n```\n\n### Pagination\n\n```go\ntype PaginationParams struct {\n    Page  int `json:\"page\"`\n    Limit int `json:\"limit\"`\n}\n\ntype PaginatedResponse struct {\n    Data       interface{} `json:\"data\"`\n    Pagination Pagination  `json:\"pagination\"`\n}\n\ntype Pagination struct {\n    Page       int  `json:\"page\"`\n    Limit      int  `json:\"limit\"`\n    Total      int  `json:\"total\"`\n    TotalPages int  `json:\"total_pages\"`\n    HasNext    bool `json:\"has_next\"`\n    HasPrev    bool `json:\"has_prev\"`\n}\n\nfunc (s *Server) getPaginationParams(r *http.Request) PaginationParams {\n    params := PaginationParams{\n        Page:  1,\n        Limit: 20,\n    }\n    \n    if page := r.URL.Query().Get(\"page\"); page != \"\" {\n        if p, err := strconv.Atoi(page); err == nil && p > 0 {\n            params.Page = p\n        }\n    }\n    \n    if limit := r.URL.Query().Get(\"limit\"); limit != \"\" {\n        if l, err := strconv.Atoi(limit); err == nil && l > 0 && l <= 100 {\n            params.Limit = l\n        }\n    }\n    \n    return params\n}\n\nfunc (s *Server) listTrades(w http.ResponseWriter, r *http.Request) {\n    params := s.getPaginationParams(r)\n    \n    trades, total, err := s.db.GetTrades(r.Context(), params.Page, params.Limit)\n    if err != nil {\n        s.respondError(w, http.StatusInternalServerError, \"Failed to fetch trades\")\n        return\n    }\n    \n    totalPages := (total + params.Limit - 1) / params.Limit\n    \n    s.respondJSON(w, http.StatusOK, PaginatedResponse{\n        Data: trades,\n        Pagination: Pagination{\n            Page:       params.Page,\n            Limit:      params.Limit,\n            Total:      total,\n            TotalPages: totalPages,\n            HasNext:    params.Page < totalPages,\n            HasPrev:    params.Page > 1,\n        },\n    })\n}\n```\n\n### Filtering and Sorting\n\n```go\ntype TradeFilter struct {\n    Symbol    string\n    Side      string\n    StartTime time.Time\n    EndTime   time.Time\n    MinPrice  decimal.Decimal\n    MaxPrice  decimal.Decimal\n    SortBy    string\n    SortOrder string\n}\n\nfunc (s *Server) parseTradeFilter(r *http.Request) TradeFilter {\n    filter := TradeFilter{\n        SortBy:    \"timestamp\",\n        SortOrder: \"desc\",\n    }\n    \n    q := r.URL.Query()\n    \n    filter.Symbol = q.Get(\"symbol\")\n    filter.Side = q.Get(\"side\")\n    \n    if start := q.Get(\"start_time\"); start != \"\" {\n        if t, err := time.Parse(time.RFC3339, start); err == nil {\n            filter.StartTime = t\n        }\n    }\n    \n    if end := q.Get(\"end_time\"); end != \"\" {\n        if t, err := time.Parse(time.RFC3339, end); err == nil {\n            filter.EndTime = t\n        }\n    }\n    \n    if min := q.Get(\"min_price\"); min != \"\" {\n        if p, err := decimal.NewFromString(min); err == nil {\n            filter.MinPrice = p\n        }\n    }\n    \n    if sort := q.Get(\"sort\"); sort != \"\" {\n        filter.SortBy = sort\n    }\n    \n    if order := q.Get(\"order\"); order == \"asc\" {\n        filter.SortOrder = \"asc\"\n    }\n    \n    return filter\n}\n```\n\n## WebSocket Patterns\n\n### WebSocket Server\n\n```go\nimport \"github.com/gorilla/websocket\"\n\nvar upgrader = websocket.Upgrader{\n    ReadBufferSize:  1024,\n    WriteBufferSize: 1024,\n    CheckOrigin: func(r *http.Request) bool {\n        // Configure origin checking\n        return true\n    },\n}\n\ntype WSHub struct {\n    clients    map[*WSClient]bool\n    broadcast  chan []byte\n    register   chan *WSClient\n    unregister chan *WSClient\n    mu         sync.RWMutex\n}\n\ntype WSClient struct {\n    hub  *WSHub\n    conn *websocket.Conn\n    send chan []byte\n    subs map[string]bool // Subscriptions\n}\n\nfunc NewWSHub() *WSHub {\n    return &WSHub{\n        clients:    make(map[*WSClient]bool),\n        broadcast:  make(chan []byte),\n        register:   make(chan *WSClient),\n        unregister: make(chan *WSClient),\n    }\n}\n\nfunc (h *WSHub) Run() {\n    for {\n        select {\n        case client := <-h.register:\n            h.mu.Lock()\n            h.clients[client] = true\n            h.mu.Unlock()\n            \n        case client := <-h.unregister:\n            h.mu.Lock()\n            if _, ok := h.clients[client]; ok {\n                delete(h.clients, client)\n                close(client.send)\n            }\n            h.mu.Unlock()\n            \n        case message := <-h.broadcast:\n            h.mu.RLock()\n            for client := range h.clients {\n                select {\n                case client.send <- message:\n                default:\n                    // Client's send channel is full, close it\n                    close(client.send)\n                    delete(h.clients, client)\n                }\n            }\n            h.mu.RUnlock()\n        }\n    }\n}\n\nfunc (s *Server) handleWebSocket(w http.ResponseWriter, r *http.Request) {\n    conn, err := upgrader.Upgrade(w, r, nil)\n    if err != nil {\n        log.Printf(\"WebSocket upgrade failed: %v\", err)\n        return\n    }\n    \n    client := &WSClient{\n        hub:  s.wsHub,\n        conn: conn,\n        send: make(chan []byte, 256),\n        subs: make(map[string]bool),\n    }\n    \n    client.hub.register <- client\n    \n    go client.writePump()\n    go client.readPump()\n}\n```\n\n### WebSocket Message Protocol\n\n```go\n// Message types\ntype WSMessage struct {\n    Type string          `json:\"type\"`\n    Data json.RawMessage `json:\"data\"`\n}\n\n// Subscription message\ntype SubMessage struct {\n    Channel string   `json:\"channel\"`\n    Symbols []string `json:\"symbols\"`\n}\n\n// Market data message\ntype MarketDataMessage struct {\n    Channel   string          `json:\"channel\"`\n    Symbol    string          `json:\"symbol\"`\n    Price     decimal.Decimal `json:\"price\"`\n    Volume    decimal.Decimal `json:\"volume\"`\n    Timestamp time.Time       `json:\"timestamp\"`\n}\n\nfunc (c *WSClient) readPump() {\n    defer func() {\n        c.hub.unregister <- c\n        c.conn.Close()\n    }()\n    \n    c.conn.SetReadDeadline(time.Now().Add(60 * time.Second))\n    c.conn.SetPongHandler(func(string) error {\n        c.conn.SetReadDeadline(time.Now().Add(60 * time.Second))\n        return nil\n    })\n    \n    for {\n        var msg WSMessage\n        err := c.conn.ReadJSON(&msg)\n        if err != nil {\n            break\n        }\n        \n        switch msg.Type {\n        case \"subscribe\":\n            var sub SubMessage\n            json.Unmarshal(msg.Data, &sub)\n            c.handleSubscribe(sub)\n            \n        case \"unsubscribe\":\n            var sub SubMessage\n            json.Unmarshal(msg.Data, &sub)\n            c.handleUnsubscribe(sub)\n            \n        case \"ping\":\n            c.send <- []byte(`{\"type\":\"pong\"}`)\n        }\n    }\n}\n\nfunc (c *WSClient) writePump() {\n    ticker := time.NewTicker(54 * time.Second)\n    defer func() {\n        ticker.Stop()\n        c.conn.Close()\n    }()\n    \n    for {\n        select {\n        case message, ok := <-c.send:\n            c.conn.SetWriteDeadline(time.Now().Add(10 * time.Second))\n            if !ok {\n                c.conn.WriteMessage(websocket.CloseMessage, []byte{})\n                return\n            }\n            \n            c.conn.WriteMessage(websocket.TextMessage, message)\n            \n        case <-ticker.C:\n            c.conn.SetWriteDeadline(time.Now().Add(10 * time.Second))\n            if err := c.conn.WriteMessage(websocket.PingMessage, nil); err != nil {\n                return\n            }\n        }\n    }\n}\n```\n\n## Authentication & Security\n\n### JWT Authentication\n\n```go\nimport \"github.com/golang-jwt/jwt/v5\"\n\ntype Claims struct {\n    UserID string `json:\"user_id\"`\n    Email  string `json:\"email\"`\n    jwt.RegisteredClaims\n}\n\nfunc (s *Server) generateToken(userID, email string) (string, error) {\n    claims := Claims{\n        UserID: userID,\n        Email:  email,\n        RegisteredClaims: jwt.RegisteredClaims{\n            ExpiresAt: jwt.NewNumericDate(time.Now().Add(24 * time.Hour)),\n            IssuedAt:  jwt.NewNumericDate(time.Now()),\n            NotBefore: jwt.NewNumericDate(time.Now()),\n        },\n    }\n    \n    token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)\n    return token.SignedString([]byte(s.jwtSecret))\n}\n\nfunc (s *Server) validateToken(tokenString string) (string, error) {\n    token, err := jwt.ParseWithClaims(tokenString, &Claims{}, func(token *jwt.Token) (interface{}, error) {\n        if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n            return nil, fmt.Errorf(\"unexpected signing method\")\n        }\n        return []byte(s.jwtSecret), nil\n    })\n    \n    if err != nil {\n        return \"\", err\n    }\n    \n    if claims, ok := token.Claims.(*Claims); ok && token.Valid {\n        return claims.UserID, nil\n    }\n    \n    return \"\", fmt.Errorf(\"invalid token\")\n}\n```\n\n### API Key Authentication\n\n```go\nfunc (s *Server) apiKeyAuth(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        apiKey := r.Header.Get(\"X-API-Key\")\n        if apiKey == \"\" {\n            s.respondError(w, http.StatusUnauthorized, \"Missing API key\")\n            return\n        }\n        \n        // Validate API key\n        user, err := s.db.GetUserByAPIKey(r.Context(), apiKey)\n        if err != nil {\n            s.respondError(w, http.StatusUnauthorized, \"Invalid API key\")\n            return\n        }\n        \n        // Check permissions\n        if !user.HasPermission(r.Method, r.URL.Path) {\n            s.respondError(w, http.StatusForbidden, \"Insufficient permissions\")\n            return\n        }\n        \n        ctx := context.WithValue(r.Context(), userIDKey, user.ID)\n        next.ServeHTTP(w, r.WithContext(ctx))\n    })\n}\n```\n\n## Rate Limiting\n\n### Token Bucket Rate Limiter\n\n```go\nimport \"golang.org/x/time/rate\"\n\ntype RateLimiter struct {\n    limiters map[string]*rate.Limiter\n    mu       sync.RWMutex\n    rate     int\n    burst    int\n}\n\nfunc NewRateLimiter(r, b int) *RateLimiter {\n    return &RateLimiter{\n        limiters: make(map[string]*rate.Limiter),\n        rate:     r,\n        burst:    b,\n    }\n}\n\nfunc (rl *RateLimiter) getLimiter(key string) *rate.Limiter {\n    rl.mu.RLock()\n    limiter, exists := rl.limiters[key]\n    rl.mu.RUnlock()\n    \n    if !exists {\n        rl.mu.Lock()\n        limiter = rate.NewLimiter(rate.Limit(rl.rate), rl.burst)\n        rl.limiters[key] = limiter\n        rl.mu.Unlock()\n    }\n    \n    return limiter\n}\n\nfunc (s *Server) rateLimit(next http.Handler) http.Handler {\n    limiter := NewRateLimiter(100, 10) // 100 req/s, burst of 10\n    \n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        // Rate limit by IP or user ID\n        key := r.RemoteAddr\n        if userID, ok := getUserID(r.Context()); ok {\n            key = userID\n        }\n        \n        if !limiter.getLimiter(key).Allow() {\n            s.respondError(w, http.StatusTooManyRequests, \"Rate limit exceeded\")\n            return\n        }\n        \n        next.ServeHTTP(w, r)\n    })\n}\n```\n\n## API Documentation\n\n### OpenAPI/Swagger\n\n```go\n// Use swaggo/swag for auto-generation\n\n// @title Big Meanie Trading API\n// @version 1.0\n// @description Trading bot API for cryptocurrency markets\n// @host localhost:8080\n// @BasePath /api/v1\n\n// @securityDefinitions.apikey ApiKeyAuth\n// @in header\n// @name X-API-Key\n\n// PlaceOrder godoc\n// @Summary Place a new order\n// @Description Create a new buy or sell order\n// @Tags orders\n// @Accept json\n// @Produce json\n// @Param order body OrderRequest true \"Order details\"\n// @Success 201 {object} OrderResponse\n// @Failure 400 {object} ErrorResponse\n// @Failure 401 {object} ErrorResponse\n// @Router /orders [post]\n// @Security ApiKeyAuth\nfunc (s *Server) placeOrder(w http.ResponseWriter, r *http.Request) {\n    // Implementation\n}\n```\n\n### API Versioning\n\n```go\nfunc (s *Server) setupVersionedRoutes() {\n    s.router.Route(\"/api\", func(r chi.Router) {\n        // Version 1\n        r.Route(\"/v1\", func(r chi.Router) {\n            r.Use(s.v1Middleware)\n            r.Mount(\"/orders\", s.v1OrderRoutes())\n        })\n        \n        // Future versions would go here\n        // But remember: Big Meanie philosophy - break cleanly instead\n    })\n}\n\nfunc (s *Server) v1Middleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        w.Header().Set(\"API-Version\", \"1.0\")\n        next.ServeHTTP(w, r)\n    })\n}\n```\n\n## Testing Patterns\n\n### API Integration Tests\n\n```go\nfunc TestOrderAPI(t *testing.T) {\n    // Setup test server\n    server := NewTestServer(t)\n    defer server.Close()\n    \n    // Test placing order\n    t.Run(\"PlaceOrder\", func(t *testing.T) {\n        order := OrderRequest{\n            Symbol:   \"BTC-USD\",\n            Side:     \"BUY\",\n            Type:     \"LIMIT\",\n            Quantity: decimal.NewFromFloat(0.1),\n            Price:    decimal.NewFromInt(50000),\n        }\n        \n        body, _ := json.Marshal(order)\n        req := httptest.NewRequest(\"POST\", \"/api/v1/orders\", bytes.NewReader(body))\n        req.Header.Set(\"X-API-Key\", \"test-key\")\n        req.Header.Set(\"Content-Type\", \"application/json\")\n        \n        rec := httptest.NewRecorder()\n        server.ServeHTTP(rec, req)\n        \n        require.Equal(t, http.StatusCreated, rec.Code)\n        \n        var response OrderResponse\n        err := json.Unmarshal(rec.Body.Bytes(), &response)\n        require.NoError(t, err)\n        require.NotEmpty(t, response.ID)\n    })\n}\n```\n\n### Mock HTTP Client\n\n```go\ntype MockHTTPClient struct {\n    responses map[string]*http.Response\n}\n\nfunc (m *MockHTTPClient) Do(req *http.Request) (*http.Response, error) {\n    key := fmt.Sprintf(\"%s %s\", req.Method, req.URL.Path)\n    if resp, ok := m.responses[key]; ok {\n        return resp, nil\n    }\n    return nil, fmt.Errorf(\"no mock response for %s\", key)\n}\n\nfunc TestExchangeClient(t *testing.T) {\n    mock := &MockHTTPClient{\n        responses: map[string]*http.Response{\n            \"GET /api/ticker\": {\n                StatusCode: 200,\n                Body: io.NopCloser(strings.NewReader(`{\n                    \"symbol\": \"BTC-USD\",\n                    \"price\": \"50000.00\"\n                }`)),\n            },\n        },\n    }\n    \n    client := NewExchangeClient(mock)\n    ticker, err := client.GetTicker(\"BTC-USD\")\n    require.NoError(t, err)\n    require.Equal(t, \"50000.00\", ticker.Price)\n}\n```\n\n### WebSocket Testing\n\n```go\nfunc TestWebSocket(t *testing.T) {\n    server := httptest.NewServer(http.HandlerFunc(handleWebSocket))\n    defer server.Close()\n    \n    // Connect to WebSocket\n    wsURL := \"ws\" + strings.TrimPrefix(server.URL, \"http\") + \"/ws\"\n    ws, _, err := websocket.DefaultDialer.Dial(wsURL, nil)\n    require.NoError(t, err)\n    defer ws.Close()\n    \n    // Send subscription\n    sub := WSMessage{\n        Type: \"subscribe\",\n        Data: json.RawMessage(`{\"channel\":\"trades\",\"symbols\":[\"BTC-USD\"]}`),\n    }\n    err = ws.WriteJSON(sub)\n    require.NoError(t, err)\n    \n    // Read response\n    var msg WSMessage\n    err = ws.ReadJSON(&msg)\n    require.NoError(t, err)\n    require.Equal(t, \"subscribed\", msg.Type)\n}\n```\n\n## Best Practices\n\n### 1. Use Context Everywhere\n\n```go\nfunc (s *Server) handler(w http.ResponseWriter, r *http.Request) {\n    ctx := r.Context()\n    \n    // Pass context to all operations\n    data, err := s.db.GetData(ctx)\n    if err != nil {\n        s.respondError(w, http.StatusInternalServerError, err.Error())\n        return\n    }\n    \n    s.respondJSON(w, http.StatusOK, data)\n}\n```\n\n### 2. Structured Logging\n\n```go\nfunc (s *Server) logRequest(r *http.Request, status int, duration time.Duration) {\n    log.WithFields(log.Fields{\n        \"method\":     r.Method,\n        \"path\":       r.URL.Path,\n        \"status\":     status,\n        \"duration\":   duration,\n        \"ip\":         r.RemoteAddr,\n        \"user_agent\": r.UserAgent(),\n    }).Info(\"API request\")\n}\n```\n\n### 3. Health Checks\n\n```go\nfunc (s *Server) healthCheck(w http.ResponseWriter, r *http.Request) {\n    checks := map[string]string{\n        \"database\": \"healthy\",\n        \"exchange\": \"healthy\",\n    }\n    \n    // Check database\n    if err := s.db.Ping(r.Context()); err != nil {\n        checks[\"database\"] = \"unhealthy\"\n    }\n    \n    // Check exchange connection\n    if err := s.exchange.Ping(); err != nil {\n        checks[\"exchange\"] = \"unhealthy\"\n    }\n    \n    status := http.StatusOK\n    for _, check := range checks {\n        if check != \"healthy\" {\n            status = http.StatusServiceUnavailable\n            break\n        }\n    }\n    \n    s.respondJSON(w, status, checks)\n}\n```\n\n### 4. Request Tracing\n\n```go\nfunc (s *Server) traceMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        traceID := r.Header.Get(\"X-Trace-ID\")\n        if traceID == \"\" {\n            traceID = generateTraceID()\n        }\n        \n        ctx := context.WithValue(r.Context(), \"traceID\", traceID)\n        w.Header().Set(\"X-Trace-ID\", traceID)\n        \n        next.ServeHTTP(w, r.WithContext(ctx))\n    })\n}\n```\n\n## Summary\n\n1. **Use standard library** - With chi router for simplicity\n2. **RESTful design** - Clear resource-based URLs\n3. **Proper status codes** - Communicate intent clearly\n4. **Middleware chain** - Auth, logging, rate limiting\n5. **Context propagation** - Pass request context everywhere\n6. **Structured errors** - Consistent error responses\n7. **WebSocket for real-time** - Market data streaming\n8. **Rate limiting** - Protect against abuse\n9. **Health checks** - Monitor service health\n10. **Comprehensive testing** - Unit and integration tests"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":8108,"cache_read_input_tokens":57625,"output_tokens":9011,"service_tier":"standard"}},"requestId":"req_011CS5Y6vZQSztKFYNLjqLJW","type":"assistant","uuid":"a7bb303b-b295-4da4-8dc5-e309bfe46542","timestamp":"2025-08-13T10:21:53.248Z"}
{"parentUuid":"a7bb303b-b295-4da4-8dc5-e309bfe46542","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VSuQpX9NEAngpLTPvFwx2p","type":"tool_result","content":"File created successfully at: /home/aural/Code/bigmeanie/back/.docs/code/api-patterns.md"}]},"uuid":"fd8b889e-8850-43ab-9b36-bb1b8f37e8fc","timestamp":"2025-08-13T10:23:54.836Z","toolUseResult":{"type":"create","filePath":"/home/aural/Code/bigmeanie/back/.docs/code/api-patterns.md","content":"# API Patterns - REST and WebSocket for Big Meanie\n\n## Overview\n\nBig Meanie exposes REST APIs for control operations and WebSocket connections for real-time data streams. We use standard library HTTP with chi router for REST and gorilla/websocket for WebSocket connections.\n\n## Table of Contents\n1. [REST API Design](#rest-api-design)\n2. [HTTP Server Setup](#http-server-setup)\n3. [Middleware Patterns](#middleware-patterns)\n4. [Error Handling](#error-handling)\n5. [Request/Response Patterns](#requestresponse-patterns)\n6. [WebSocket Patterns](#websocket-patterns)\n7. [Authentication & Security](#authentication--security)\n8. [Rate Limiting](#rate-limiting)\n9. [API Documentation](#api-documentation)\n10. [Testing Patterns](#testing-patterns)\n\n## REST API Design\n\n### URL Structure\n\n```go\n// RESTful resource naming\n// Pattern: /api/v1/{resource}/{id}/{action}\n\n// Good URL patterns for trading system:\nGET    /api/v1/accounts              // List accounts\nGET    /api/v1/accounts/{id}         // Get account\nPOST   /api/v1/accounts              // Create account\n\nGET    /api/v1/positions             // List positions\nGET    /api/v1/positions/{symbol}    // Get position for symbol\nDELETE /api/v1/positions/{symbol}    // Close position\n\nPOST   /api/v1/orders                // Place order\nGET    /api/v1/orders/{id}           // Get order\nDELETE /api/v1/orders/{id}           // Cancel order\n\nGET    /api/v1/trades                // List trades\nGET    /api/v1/candles/{symbol}      // Get candles\nGET    /api/v1/orderbook/{symbol}    // Get orderbook\n\n// Action endpoints (use POST for non-CRUD operations)\nPOST   /api/v1/strategies/{id}/start // Start strategy\nPOST   /api/v1/strategies/{id}/stop  // Stop strategy\nPOST   /api/v1/backtest/run          // Run backtest\n```\n\n### HTTP Status Codes\n\n```go\n// Use appropriate status codes\n200 OK              // Successful GET, PUT\n201 Created         // Successful POST creating resource\n204 No Content      // Successful DELETE\n400 Bad Request     // Invalid request data\n401 Unauthorized    // Missing/invalid auth\n403 Forbidden       // Valid auth but no permission\n404 Not Found       // Resource doesn't exist\n409 Conflict        // Resource already exists\n422 Unprocessable   // Validation errors\n429 Too Many Req    // Rate limited\n500 Internal Error  // Server error\n503 Service Unavail // Temporary unavailable\n```\n\n## HTTP Server Setup\n\n### Basic Server Configuration\n\n```go\npackage api\n\nimport (\n    \"context\"\n    \"net/http\"\n    \"time\"\n    \n    \"github.com/go-chi/chi/v5\"\n    \"github.com/go-chi/chi/v5/middleware\"\n)\n\ntype Server struct {\n    router *chi.Mux\n    srv    *http.Server\n    db     *DB\n    engine *Engine\n}\n\nfunc NewServer(cfg Config, db *DB, engine *Engine) *Server {\n    s := &Server{\n        router: chi.NewRouter(),\n        db:     db,\n        engine: engine,\n    }\n    \n    // Configure server\n    s.srv = &http.Server{\n        Addr:         cfg.Address,\n        Handler:      s.router,\n        ReadTimeout:  15 * time.Second,\n        WriteTimeout: 15 * time.Second,\n        IdleTimeout:  60 * time.Second,\n    }\n    \n    s.setupRoutes()\n    return s\n}\n\nfunc (s *Server) setupRoutes() {\n    r := s.router\n    \n    // Global middleware\n    r.Use(middleware.RequestID)\n    r.Use(middleware.RealIP)\n    r.Use(middleware.Logger)\n    r.Use(middleware.Recoverer)\n    r.Use(middleware.Timeout(60 * time.Second))\n    \n    // API routes\n    r.Route(\"/api/v1\", func(r chi.Router) {\n        // Auth middleware for API\n        r.Use(s.authenticate)\n        r.Use(s.rateLimit)\n        \n        // Resources\n        r.Route(\"/orders\", s.orderRoutes)\n        r.Route(\"/positions\", s.positionRoutes)\n        r.Route(\"/accounts\", s.accountRoutes)\n    })\n    \n    // Health check (no auth)\n    r.Get(\"/health\", s.healthCheck)\n}\n\nfunc (s *Server) Start() error {\n    return s.srv.ListenAndServe()\n}\n\nfunc (s *Server) Shutdown(ctx context.Context) error {\n    return s.srv.Shutdown(ctx)\n}\n```\n\n### Graceful Shutdown\n\n```go\nfunc RunServer(ctx context.Context, cfg Config) error {\n    server := NewServer(cfg, db, engine)\n    \n    // Start server in goroutine\n    errChan := make(chan error, 1)\n    go func() {\n        if err := server.Start(); err != nil && err != http.ErrServerClosed {\n            errChan <- err\n        }\n    }()\n    \n    // Wait for context cancellation or error\n    select {\n    case <-ctx.Done():\n        // Graceful shutdown\n        shutdownCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n        defer cancel()\n        \n        return server.Shutdown(shutdownCtx)\n        \n    case err := <-errChan:\n        return err\n    }\n}\n```\n\n## Middleware Patterns\n\n### Request Context\n\n```go\n// Add values to request context\ntype contextKey string\n\nconst (\n    userIDKey contextKey = \"userID\"\n    tradeIDKey contextKey = \"tradeID\"\n)\n\nfunc (s *Server) authenticate(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        token := r.Header.Get(\"Authorization\")\n        if token == \"\" {\n            s.respondError(w, http.StatusUnauthorized, \"missing auth token\")\n            return\n        }\n        \n        // Validate token\n        userID, err := s.validateToken(token)\n        if err != nil {\n            s.respondError(w, http.StatusUnauthorized, \"invalid token\")\n            return\n        }\n        \n        // Add to context\n        ctx := context.WithValue(r.Context(), userIDKey, userID)\n        next.ServeHTTP(w, r.WithContext(ctx))\n    })\n}\n\n// Extract from context\nfunc getUserID(ctx context.Context) (string, bool) {\n    userID, ok := ctx.Value(userIDKey).(string)\n    return userID, ok\n}\n```\n\n### Logging Middleware\n\n```go\nfunc loggingMiddleware(logger *log.Logger) func(http.Handler) http.Handler {\n    return func(next http.Handler) http.Handler {\n        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n            start := time.Now()\n            \n            // Wrap response writer to capture status\n            wrapped := &responseWriter{\n                ResponseWriter: w,\n                status:        200,\n            }\n            \n            next.ServeHTTP(wrapped, r)\n            \n            logger.Printf(\n                \"%s %s %d %v\",\n                r.Method,\n                r.URL.Path,\n                wrapped.status,\n                time.Since(start),\n            )\n        })\n    }\n}\n\ntype responseWriter struct {\n    http.ResponseWriter\n    status int\n}\n\nfunc (w *responseWriter) WriteHeader(status int) {\n    w.status = status\n    w.ResponseWriter.WriteHeader(status)\n}\n```\n\n### CORS Middleware\n\n```go\nfunc corsMiddleware(allowedOrigins []string) func(http.Handler) http.Handler {\n    return func(next http.Handler) http.Handler {\n        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n            origin := r.Header.Get(\"Origin\")\n            \n            // Check if origin is allowed\n            for _, allowed := range allowedOrigins {\n                if origin == allowed || allowed == \"*\" {\n                    w.Header().Set(\"Access-Control-Allow-Origin\", origin)\n                    w.Header().Set(\"Access-Control-Allow-Credentials\", \"true\")\n                    break\n                }\n            }\n            \n            // Handle preflight\n            if r.Method == \"OPTIONS\" {\n                w.Header().Set(\"Access-Control-Allow-Methods\", \"GET, POST, PUT, DELETE, OPTIONS\")\n                w.Header().Set(\"Access-Control-Allow-Headers\", \"Authorization, Content-Type\")\n                w.Header().Set(\"Access-Control-Max-Age\", \"86400\")\n                w.WriteHeader(http.StatusNoContent)\n                return\n            }\n            \n            next.ServeHTTP(w, r)\n        })\n    }\n}\n```\n\n## Error Handling\n\n### Error Response Structure\n\n```go\ntype ErrorResponse struct {\n    Error   string            `json:\"error\"`\n    Message string            `json:\"message\"`\n    Code    string            `json:\"code,omitempty\"`\n    Details map[string]string `json:\"details,omitempty\"`\n}\n\nfunc (s *Server) respondError(w http.ResponseWriter, status int, message string) {\n    s.respondJSON(w, status, ErrorResponse{\n        Error:   http.StatusText(status),\n        Message: message,\n    })\n}\n\nfunc (s *Server) respondValidationError(w http.ResponseWriter, errors map[string]string) {\n    s.respondJSON(w, http.StatusUnprocessableEntity, ErrorResponse{\n        Error:   \"Validation Failed\",\n        Message: \"The request contains invalid fields\",\n        Details: errors,\n    })\n}\n\nfunc (s *Server) respondJSON(w http.ResponseWriter, status int, data interface{}) {\n    w.Header().Set(\"Content-Type\", \"application/json\")\n    w.WriteHeader(status)\n    \n    if err := json.NewEncoder(w).Encode(data); err != nil {\n        log.Printf(\"Failed to encode response: %v\", err)\n    }\n}\n```\n\n### Business Error Handling\n\n```go\n// Define business errors\nvar (\n    ErrInsufficientFunds = &APIError{Code: \"INSUFFICIENT_FUNDS\", Message: \"Insufficient funds for order\"}\n    ErrOrderTooSmall     = &APIError{Code: \"ORDER_TOO_SMALL\", Message: \"Order size below minimum\"}\n    ErrSymbolNotFound    = &APIError{Code: \"SYMBOL_NOT_FOUND\", Message: \"Trading symbol not found\"}\n    ErrStrategyRunning   = &APIError{Code: \"STRATEGY_RUNNING\", Message: \"Strategy already running\"}\n)\n\ntype APIError struct {\n    Code    string\n    Message string\n}\n\nfunc (e *APIError) Error() string {\n    return e.Message\n}\n\n// Handle business errors in handlers\nfunc (s *Server) placeOrder(w http.ResponseWriter, r *http.Request) {\n    var req OrderRequest\n    if err := json.NewDecoder(r.Body).Decode(&req); err != nil {\n        s.respondError(w, http.StatusBadRequest, \"Invalid request body\")\n        return\n    }\n    \n    order, err := s.engine.PlaceOrder(r.Context(), req)\n    if err != nil {\n        var apiErr *APIError\n        if errors.As(err, &apiErr) {\n            s.respondJSON(w, http.StatusBadRequest, ErrorResponse{\n                Error:   \"Business Rule Violation\",\n                Code:    apiErr.Code,\n                Message: apiErr.Message,\n            })\n            return\n        }\n        \n        s.respondError(w, http.StatusInternalServerError, \"Failed to place order\")\n        return\n    }\n    \n    s.respondJSON(w, http.StatusCreated, order)\n}\n```\n\n## Request/Response Patterns\n\n### Request Validation\n\n```go\nimport \"github.com/go-playground/validator/v10\"\n\nvar validate = validator.New()\n\ntype OrderRequest struct {\n    Symbol   string          `json:\"symbol\" validate:\"required\"`\n    Side     string          `json:\"side\" validate:\"required,oneof=BUY SELL\"`\n    Type     string          `json:\"type\" validate:\"required,oneof=MARKET LIMIT\"`\n    Quantity decimal.Decimal `json:\"quantity\" validate:\"required,gt=0\"`\n    Price    decimal.Decimal `json:\"price\" validate:\"required_if=Type LIMIT,gt=0\"`\n}\n\nfunc (s *Server) validateRequest(r *http.Request, dst interface{}) error {\n    if err := json.NewDecoder(r.Body).Decode(dst); err != nil {\n        return fmt.Errorf(\"invalid JSON: %w\", err)\n    }\n    \n    if err := validate.Struct(dst); err != nil {\n        return fmt.Errorf(\"validation failed: %w\", err)\n    }\n    \n    return nil\n}\n\n// Use in handler\nfunc (s *Server) createOrder(w http.ResponseWriter, r *http.Request) {\n    var req OrderRequest\n    if err := s.validateRequest(r, &req); err != nil {\n        s.respondError(w, http.StatusBadRequest, err.Error())\n        return\n    }\n    \n    // Process valid request\n}\n```\n\n### Pagination\n\n```go\ntype PaginationParams struct {\n    Page  int `json:\"page\"`\n    Limit int `json:\"limit\"`\n}\n\ntype PaginatedResponse struct {\n    Data       interface{} `json:\"data\"`\n    Pagination Pagination  `json:\"pagination\"`\n}\n\ntype Pagination struct {\n    Page       int  `json:\"page\"`\n    Limit      int  `json:\"limit\"`\n    Total      int  `json:\"total\"`\n    TotalPages int  `json:\"total_pages\"`\n    HasNext    bool `json:\"has_next\"`\n    HasPrev    bool `json:\"has_prev\"`\n}\n\nfunc (s *Server) getPaginationParams(r *http.Request) PaginationParams {\n    params := PaginationParams{\n        Page:  1,\n        Limit: 20,\n    }\n    \n    if page := r.URL.Query().Get(\"page\"); page != \"\" {\n        if p, err := strconv.Atoi(page); err == nil && p > 0 {\n            params.Page = p\n        }\n    }\n    \n    if limit := r.URL.Query().Get(\"limit\"); limit != \"\" {\n        if l, err := strconv.Atoi(limit); err == nil && l > 0 && l <= 100 {\n            params.Limit = l\n        }\n    }\n    \n    return params\n}\n\nfunc (s *Server) listTrades(w http.ResponseWriter, r *http.Request) {\n    params := s.getPaginationParams(r)\n    \n    trades, total, err := s.db.GetTrades(r.Context(), params.Page, params.Limit)\n    if err != nil {\n        s.respondError(w, http.StatusInternalServerError, \"Failed to fetch trades\")\n        return\n    }\n    \n    totalPages := (total + params.Limit - 1) / params.Limit\n    \n    s.respondJSON(w, http.StatusOK, PaginatedResponse{\n        Data: trades,\n        Pagination: Pagination{\n            Page:       params.Page,\n            Limit:      params.Limit,\n            Total:      total,\n            TotalPages: totalPages,\n            HasNext:    params.Page < totalPages,\n            HasPrev:    params.Page > 1,\n        },\n    })\n}\n```\n\n### Filtering and Sorting\n\n```go\ntype TradeFilter struct {\n    Symbol    string\n    Side      string\n    StartTime time.Time\n    EndTime   time.Time\n    MinPrice  decimal.Decimal\n    MaxPrice  decimal.Decimal\n    SortBy    string\n    SortOrder string\n}\n\nfunc (s *Server) parseTradeFilter(r *http.Request) TradeFilter {\n    filter := TradeFilter{\n        SortBy:    \"timestamp\",\n        SortOrder: \"desc\",\n    }\n    \n    q := r.URL.Query()\n    \n    filter.Symbol = q.Get(\"symbol\")\n    filter.Side = q.Get(\"side\")\n    \n    if start := q.Get(\"start_time\"); start != \"\" {\n        if t, err := time.Parse(time.RFC3339, start); err == nil {\n            filter.StartTime = t\n        }\n    }\n    \n    if end := q.Get(\"end_time\"); end != \"\" {\n        if t, err := time.Parse(time.RFC3339, end); err == nil {\n            filter.EndTime = t\n        }\n    }\n    \n    if min := q.Get(\"min_price\"); min != \"\" {\n        if p, err := decimal.NewFromString(min); err == nil {\n            filter.MinPrice = p\n        }\n    }\n    \n    if sort := q.Get(\"sort\"); sort != \"\" {\n        filter.SortBy = sort\n    }\n    \n    if order := q.Get(\"order\"); order == \"asc\" {\n        filter.SortOrder = \"asc\"\n    }\n    \n    return filter\n}\n```\n\n## WebSocket Patterns\n\n### WebSocket Server\n\n```go\nimport \"github.com/gorilla/websocket\"\n\nvar upgrader = websocket.Upgrader{\n    ReadBufferSize:  1024,\n    WriteBufferSize: 1024,\n    CheckOrigin: func(r *http.Request) bool {\n        // Configure origin checking\n        return true\n    },\n}\n\ntype WSHub struct {\n    clients    map[*WSClient]bool\n    broadcast  chan []byte\n    register   chan *WSClient\n    unregister chan *WSClient\n    mu         sync.RWMutex\n}\n\ntype WSClient struct {\n    hub  *WSHub\n    conn *websocket.Conn\n    send chan []byte\n    subs map[string]bool // Subscriptions\n}\n\nfunc NewWSHub() *WSHub {\n    return &WSHub{\n        clients:    make(map[*WSClient]bool),\n        broadcast:  make(chan []byte),\n        register:   make(chan *WSClient),\n        unregister: make(chan *WSClient),\n    }\n}\n\nfunc (h *WSHub) Run() {\n    for {\n        select {\n        case client := <-h.register:\n            h.mu.Lock()\n            h.clients[client] = true\n            h.mu.Unlock()\n            \n        case client := <-h.unregister:\n            h.mu.Lock()\n            if _, ok := h.clients[client]; ok {\n                delete(h.clients, client)\n                close(client.send)\n            }\n            h.mu.Unlock()\n            \n        case message := <-h.broadcast:\n            h.mu.RLock()\n            for client := range h.clients {\n                select {\n                case client.send <- message:\n                default:\n                    // Client's send channel is full, close it\n                    close(client.send)\n                    delete(h.clients, client)\n                }\n            }\n            h.mu.RUnlock()\n        }\n    }\n}\n\nfunc (s *Server) handleWebSocket(w http.ResponseWriter, r *http.Request) {\n    conn, err := upgrader.Upgrade(w, r, nil)\n    if err != nil {\n        log.Printf(\"WebSocket upgrade failed: %v\", err)\n        return\n    }\n    \n    client := &WSClient{\n        hub:  s.wsHub,\n        conn: conn,\n        send: make(chan []byte, 256),\n        subs: make(map[string]bool),\n    }\n    \n    client.hub.register <- client\n    \n    go client.writePump()\n    go client.readPump()\n}\n```\n\n### WebSocket Message Protocol\n\n```go\n// Message types\ntype WSMessage struct {\n    Type string          `json:\"type\"`\n    Data json.RawMessage `json:\"data\"`\n}\n\n// Subscription message\ntype SubMessage struct {\n    Channel string   `json:\"channel\"`\n    Symbols []string `json:\"symbols\"`\n}\n\n// Market data message\ntype MarketDataMessage struct {\n    Channel   string          `json:\"channel\"`\n    Symbol    string          `json:\"symbol\"`\n    Price     decimal.Decimal `json:\"price\"`\n    Volume    decimal.Decimal `json:\"volume\"`\n    Timestamp time.Time       `json:\"timestamp\"`\n}\n\nfunc (c *WSClient) readPump() {\n    defer func() {\n        c.hub.unregister <- c\n        c.conn.Close()\n    }()\n    \n    c.conn.SetReadDeadline(time.Now().Add(60 * time.Second))\n    c.conn.SetPongHandler(func(string) error {\n        c.conn.SetReadDeadline(time.Now().Add(60 * time.Second))\n        return nil\n    })\n    \n    for {\n        var msg WSMessage\n        err := c.conn.ReadJSON(&msg)\n        if err != nil {\n            break\n        }\n        \n        switch msg.Type {\n        case \"subscribe\":\n            var sub SubMessage\n            json.Unmarshal(msg.Data, &sub)\n            c.handleSubscribe(sub)\n            \n        case \"unsubscribe\":\n            var sub SubMessage\n            json.Unmarshal(msg.Data, &sub)\n            c.handleUnsubscribe(sub)\n            \n        case \"ping\":\n            c.send <- []byte(`{\"type\":\"pong\"}`)\n        }\n    }\n}\n\nfunc (c *WSClient) writePump() {\n    ticker := time.NewTicker(54 * time.Second)\n    defer func() {\n        ticker.Stop()\n        c.conn.Close()\n    }()\n    \n    for {\n        select {\n        case message, ok := <-c.send:\n            c.conn.SetWriteDeadline(time.Now().Add(10 * time.Second))\n            if !ok {\n                c.conn.WriteMessage(websocket.CloseMessage, []byte{})\n                return\n            }\n            \n            c.conn.WriteMessage(websocket.TextMessage, message)\n            \n        case <-ticker.C:\n            c.conn.SetWriteDeadline(time.Now().Add(10 * time.Second))\n            if err := c.conn.WriteMessage(websocket.PingMessage, nil); err != nil {\n                return\n            }\n        }\n    }\n}\n```\n\n## Authentication & Security\n\n### JWT Authentication\n\n```go\nimport \"github.com/golang-jwt/jwt/v5\"\n\ntype Claims struct {\n    UserID string `json:\"user_id\"`\n    Email  string `json:\"email\"`\n    jwt.RegisteredClaims\n}\n\nfunc (s *Server) generateToken(userID, email string) (string, error) {\n    claims := Claims{\n        UserID: userID,\n        Email:  email,\n        RegisteredClaims: jwt.RegisteredClaims{\n            ExpiresAt: jwt.NewNumericDate(time.Now().Add(24 * time.Hour)),\n            IssuedAt:  jwt.NewNumericDate(time.Now()),\n            NotBefore: jwt.NewNumericDate(time.Now()),\n        },\n    }\n    \n    token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)\n    return token.SignedString([]byte(s.jwtSecret))\n}\n\nfunc (s *Server) validateToken(tokenString string) (string, error) {\n    token, err := jwt.ParseWithClaims(tokenString, &Claims{}, func(token *jwt.Token) (interface{}, error) {\n        if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n            return nil, fmt.Errorf(\"unexpected signing method\")\n        }\n        return []byte(s.jwtSecret), nil\n    })\n    \n    if err != nil {\n        return \"\", err\n    }\n    \n    if claims, ok := token.Claims.(*Claims); ok && token.Valid {\n        return claims.UserID, nil\n    }\n    \n    return \"\", fmt.Errorf(\"invalid token\")\n}\n```\n\n### API Key Authentication\n\n```go\nfunc (s *Server) apiKeyAuth(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        apiKey := r.Header.Get(\"X-API-Key\")\n        if apiKey == \"\" {\n            s.respondError(w, http.StatusUnauthorized, \"Missing API key\")\n            return\n        }\n        \n        // Validate API key\n        user, err := s.db.GetUserByAPIKey(r.Context(), apiKey)\n        if err != nil {\n            s.respondError(w, http.StatusUnauthorized, \"Invalid API key\")\n            return\n        }\n        \n        // Check permissions\n        if !user.HasPermission(r.Method, r.URL.Path) {\n            s.respondError(w, http.StatusForbidden, \"Insufficient permissions\")\n            return\n        }\n        \n        ctx := context.WithValue(r.Context(), userIDKey, user.ID)\n        next.ServeHTTP(w, r.WithContext(ctx))\n    })\n}\n```\n\n## Rate Limiting\n\n### Token Bucket Rate Limiter\n\n```go\nimport \"golang.org/x/time/rate\"\n\ntype RateLimiter struct {\n    limiters map[string]*rate.Limiter\n    mu       sync.RWMutex\n    rate     int\n    burst    int\n}\n\nfunc NewRateLimiter(r, b int) *RateLimiter {\n    return &RateLimiter{\n        limiters: make(map[string]*rate.Limiter),\n        rate:     r,\n        burst:    b,\n    }\n}\n\nfunc (rl *RateLimiter) getLimiter(key string) *rate.Limiter {\n    rl.mu.RLock()\n    limiter, exists := rl.limiters[key]\n    rl.mu.RUnlock()\n    \n    if !exists {\n        rl.mu.Lock()\n        limiter = rate.NewLimiter(rate.Limit(rl.rate), rl.burst)\n        rl.limiters[key] = limiter\n        rl.mu.Unlock()\n    }\n    \n    return limiter\n}\n\nfunc (s *Server) rateLimit(next http.Handler) http.Handler {\n    limiter := NewRateLimiter(100, 10) // 100 req/s, burst of 10\n    \n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        // Rate limit by IP or user ID\n        key := r.RemoteAddr\n        if userID, ok := getUserID(r.Context()); ok {\n            key = userID\n        }\n        \n        if !limiter.getLimiter(key).Allow() {\n            s.respondError(w, http.StatusTooManyRequests, \"Rate limit exceeded\")\n            return\n        }\n        \n        next.ServeHTTP(w, r)\n    })\n}\n```\n\n## API Documentation\n\n### OpenAPI/Swagger\n\n```go\n// Use swaggo/swag for auto-generation\n\n// @title Big Meanie Trading API\n// @version 1.0\n// @description Trading bot API for cryptocurrency markets\n// @host localhost:8080\n// @BasePath /api/v1\n\n// @securityDefinitions.apikey ApiKeyAuth\n// @in header\n// @name X-API-Key\n\n// PlaceOrder godoc\n// @Summary Place a new order\n// @Description Create a new buy or sell order\n// @Tags orders\n// @Accept json\n// @Produce json\n// @Param order body OrderRequest true \"Order details\"\n// @Success 201 {object} OrderResponse\n// @Failure 400 {object} ErrorResponse\n// @Failure 401 {object} ErrorResponse\n// @Router /orders [post]\n// @Security ApiKeyAuth\nfunc (s *Server) placeOrder(w http.ResponseWriter, r *http.Request) {\n    // Implementation\n}\n```\n\n### API Versioning\n\n```go\nfunc (s *Server) setupVersionedRoutes() {\n    s.router.Route(\"/api\", func(r chi.Router) {\n        // Version 1\n        r.Route(\"/v1\", func(r chi.Router) {\n            r.Use(s.v1Middleware)\n            r.Mount(\"/orders\", s.v1OrderRoutes())\n        })\n        \n        // Future versions would go here\n        // But remember: Big Meanie philosophy - break cleanly instead\n    })\n}\n\nfunc (s *Server) v1Middleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        w.Header().Set(\"API-Version\", \"1.0\")\n        next.ServeHTTP(w, r)\n    })\n}\n```\n\n## Testing Patterns\n\n### API Integration Tests\n\n```go\nfunc TestOrderAPI(t *testing.T) {\n    // Setup test server\n    server := NewTestServer(t)\n    defer server.Close()\n    \n    // Test placing order\n    t.Run(\"PlaceOrder\", func(t *testing.T) {\n        order := OrderRequest{\n            Symbol:   \"BTC-USD\",\n            Side:     \"BUY\",\n            Type:     \"LIMIT\",\n            Quantity: decimal.NewFromFloat(0.1),\n            Price:    decimal.NewFromInt(50000),\n        }\n        \n        body, _ := json.Marshal(order)\n        req := httptest.NewRequest(\"POST\", \"/api/v1/orders\", bytes.NewReader(body))\n        req.Header.Set(\"X-API-Key\", \"test-key\")\n        req.Header.Set(\"Content-Type\", \"application/json\")\n        \n        rec := httptest.NewRecorder()\n        server.ServeHTTP(rec, req)\n        \n        require.Equal(t, http.StatusCreated, rec.Code)\n        \n        var response OrderResponse\n        err := json.Unmarshal(rec.Body.Bytes(), &response)\n        require.NoError(t, err)\n        require.NotEmpty(t, response.ID)\n    })\n}\n```\n\n### Mock HTTP Client\n\n```go\ntype MockHTTPClient struct {\n    responses map[string]*http.Response\n}\n\nfunc (m *MockHTTPClient) Do(req *http.Request) (*http.Response, error) {\n    key := fmt.Sprintf(\"%s %s\", req.Method, req.URL.Path)\n    if resp, ok := m.responses[key]; ok {\n        return resp, nil\n    }\n    return nil, fmt.Errorf(\"no mock response for %s\", key)\n}\n\nfunc TestExchangeClient(t *testing.T) {\n    mock := &MockHTTPClient{\n        responses: map[string]*http.Response{\n            \"GET /api/ticker\": {\n                StatusCode: 200,\n                Body: io.NopCloser(strings.NewReader(`{\n                    \"symbol\": \"BTC-USD\",\n                    \"price\": \"50000.00\"\n                }`)),\n            },\n        },\n    }\n    \n    client := NewExchangeClient(mock)\n    ticker, err := client.GetTicker(\"BTC-USD\")\n    require.NoError(t, err)\n    require.Equal(t, \"50000.00\", ticker.Price)\n}\n```\n\n### WebSocket Testing\n\n```go\nfunc TestWebSocket(t *testing.T) {\n    server := httptest.NewServer(http.HandlerFunc(handleWebSocket))\n    defer server.Close()\n    \n    // Connect to WebSocket\n    wsURL := \"ws\" + strings.TrimPrefix(server.URL, \"http\") + \"/ws\"\n    ws, _, err := websocket.DefaultDialer.Dial(wsURL, nil)\n    require.NoError(t, err)\n    defer ws.Close()\n    \n    // Send subscription\n    sub := WSMessage{\n        Type: \"subscribe\",\n        Data: json.RawMessage(`{\"channel\":\"trades\",\"symbols\":[\"BTC-USD\"]}`),\n    }\n    err = ws.WriteJSON(sub)\n    require.NoError(t, err)\n    \n    // Read response\n    var msg WSMessage\n    err = ws.ReadJSON(&msg)\n    require.NoError(t, err)\n    require.Equal(t, \"subscribed\", msg.Type)\n}\n```\n\n## Best Practices\n\n### 1. Use Context Everywhere\n\n```go\nfunc (s *Server) handler(w http.ResponseWriter, r *http.Request) {\n    ctx := r.Context()\n    \n    // Pass context to all operations\n    data, err := s.db.GetData(ctx)\n    if err != nil {\n        s.respondError(w, http.StatusInternalServerError, err.Error())\n        return\n    }\n    \n    s.respondJSON(w, http.StatusOK, data)\n}\n```\n\n### 2. Structured Logging\n\n```go\nfunc (s *Server) logRequest(r *http.Request, status int, duration time.Duration) {\n    log.WithFields(log.Fields{\n        \"method\":     r.Method,\n        \"path\":       r.URL.Path,\n        \"status\":     status,\n        \"duration\":   duration,\n        \"ip\":         r.RemoteAddr,\n        \"user_agent\": r.UserAgent(),\n    }).Info(\"API request\")\n}\n```\n\n### 3. Health Checks\n\n```go\nfunc (s *Server) healthCheck(w http.ResponseWriter, r *http.Request) {\n    checks := map[string]string{\n        \"database\": \"healthy\",\n        \"exchange\": \"healthy\",\n    }\n    \n    // Check database\n    if err := s.db.Ping(r.Context()); err != nil {\n        checks[\"database\"] = \"unhealthy\"\n    }\n    \n    // Check exchange connection\n    if err := s.exchange.Ping(); err != nil {\n        checks[\"exchange\"] = \"unhealthy\"\n    }\n    \n    status := http.StatusOK\n    for _, check := range checks {\n        if check != \"healthy\" {\n            status = http.StatusServiceUnavailable\n            break\n        }\n    }\n    \n    s.respondJSON(w, status, checks)\n}\n```\n\n### 4. Request Tracing\n\n```go\nfunc (s *Server) traceMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        traceID := r.Header.Get(\"X-Trace-ID\")\n        if traceID == \"\" {\n            traceID = generateTraceID()\n        }\n        \n        ctx := context.WithValue(r.Context(), \"traceID\", traceID)\n        w.Header().Set(\"X-Trace-ID\", traceID)\n        \n        next.ServeHTTP(w, r.WithContext(ctx))\n    })\n}\n```\n\n## Summary\n\n1. **Use standard library** - With chi router for simplicity\n2. **RESTful design** - Clear resource-based URLs\n3. **Proper status codes** - Communicate intent clearly\n4. **Middleware chain** - Auth, logging, rate limiting\n5. **Context propagation** - Pass request context everywhere\n6. **Structured errors** - Consistent error responses\n7. **WebSocket for real-time** - Market data streaming\n8. **Rate limiting** - Protect against abuse\n9. **Health checks** - Monitor service health\n10. **Comprehensive testing** - Unit and integration tests","structuredPatch":[]}}
{"parentUuid":"fd8b889e-8850-43ab-9b36-bb1b8f37e8fc","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01Ea2ESRSgNbjJJyvTPtukUy","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"Perfect! I've successfully implemented all the critical documentation improvements for the Big Meanie project:\n\n## ✅ Completed Documentation\n\n### 1. **decimal-patterns.md** - Comprehensive shopspring/decimal guide\n- Core principles for financial calculations\n- Basic operations and arithmetic\n- Trading-specific patterns (orders, portfolios, indicators)\n- Common gotchas (division by zero, precision, JSON/DB handling)\n- Performance considerations\n- Best practices with real trading examples\n\n### 2. **project-conventions.md** - Big Meanie philosophy and conventions\n- Core philosophy: \"break fast, fix immediately\"\n- Ultra-concise naming conventions (sr not SupportResistance)\n- No backwards compatibility approach\n- Project structure explanation\n- File management rules (no variant files)\n- Code organization patterns\n- Testing standards\n- Anti-patterns to avoid\n\n### 3. **performance.md** - Fixed unsafe string conversions\n- Added strong warnings about unsafe package usage\n- Replaced dangerous zero-copy examples with safe alternatives\n- Emphasized when unsafe patterns should never be used\n- Provided safe string/byte conversion methods\n- Added recommendation to use string builders for performance\n\n### 4. **database-patterns.md** - PostgreSQL patterns for trading\n- Connection pool management with pgx/v5\n- Migration patterns and schema versioning\n- Transaction patterns (basic, nested, distributed)\n- Query patterns and parameterization\n- Trading-specific schemas (orders, positions, executions)\n- Performance optimization and indexing\n- Error handling\n- Testing patterns\n\n### 5. **api-patterns.md** - REST and WebSocket patterns\n- RESTful API design with proper URLs and status codes\n- HTTP server setup with chi router\n- Middleware patterns (auth, logging, CORS, rate limiting)\n- Error handling with structured responses\n- Request/response patterns (validation, pagination, filtering)\n- WebSocket implementation for real-time data\n- Authentication (JWT, API keys)\n- Testing patterns\n\nAll documentation follows the Big Meanie philosophy of:\n- **No backwards compatibility** - Breaking changes force immediate fixes\n- **Ultra-concise naming** - Clear, short names\n- **Practical examples** - Real trading system code\n- **Performance focus** - Optimized for 24/7 trading operations\n- **Type safety** - shopspring/decimal for all financial calculations\n\nThe documentation is now comprehensive, practical, and aligned with the project's goals of building a robust cryptocurrency trading system in Go."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":74784,"cache_read_input_tokens":0,"output_tokens":555,"service_tier":"standard"}},"requestId":"req_011CS5YaYi34NwoUK8zHnga9","type":"assistant","uuid":"a034efff-e676-445e-b88b-fc218384df68","timestamp":"2025-08-13T10:24:14.027Z"}
{"parentUuid":"e9cb45f0-4348-4c87-bfec-59c259eb508e","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CJmLRo2SqvZBsrD9WE6dW6","type":"tool_result","content":[{"type":"text","text":"Perfect! I've successfully implemented all the critical documentation improvements for the Big Meanie project:\n\n## ✅ Completed Documentation\n\n### 1. **decimal-patterns.md** - Comprehensive shopspring/decimal guide\n- Core principles for financial calculations\n- Basic operations and arithmetic\n- Trading-specific patterns (orders, portfolios, indicators)\n- Common gotchas (division by zero, precision, JSON/DB handling)\n- Performance considerations\n- Best practices with real trading examples\n\n### 2. **project-conventions.md** - Big Meanie philosophy and conventions\n- Core philosophy: \"break fast, fix immediately\"\n- Ultra-concise naming conventions (sr not SupportResistance)\n- No backwards compatibility approach\n- Project structure explanation\n- File management rules (no variant files)\n- Code organization patterns\n- Testing standards\n- Anti-patterns to avoid\n\n### 3. **performance.md** - Fixed unsafe string conversions\n- Added strong warnings about unsafe package usage\n- Replaced dangerous zero-copy examples with safe alternatives\n- Emphasized when unsafe patterns should never be used\n- Provided safe string/byte conversion methods\n- Added recommendation to use string builders for performance\n\n### 4. **database-patterns.md** - PostgreSQL patterns for trading\n- Connection pool management with pgx/v5\n- Migration patterns and schema versioning\n- Transaction patterns (basic, nested, distributed)\n- Query patterns and parameterization\n- Trading-specific schemas (orders, positions, executions)\n- Performance optimization and indexing\n- Error handling\n- Testing patterns\n\n### 5. **api-patterns.md** - REST and WebSocket patterns\n- RESTful API design with proper URLs and status codes\n- HTTP server setup with chi router\n- Middleware patterns (auth, logging, CORS, rate limiting)\n- Error handling with structured responses\n- Request/response patterns (validation, pagination, filtering)\n- WebSocket implementation for real-time data\n- Authentication (JWT, API keys)\n- Testing patterns\n\nAll documentation follows the Big Meanie philosophy of:\n- **No backwards compatibility** - Breaking changes force immediate fixes\n- **Ultra-concise naming** - Clear, short names\n- **Practical examples** - Real trading system code\n- **Performance focus** - Optimized for 24/7 trading operations\n- **Type safety** - shopspring/decimal for all financial calculations\n\nThe documentation is now comprehensive, practical, and aligned with the project's goals of building a robust cryptocurrency trading system in Go."}]}]},"uuid":"85dcd693-188b-42ae-a49a-17defe276ac9","timestamp":"2025-08-13T10:24:14.073Z","toolUseResult":{"content":[{"type":"text","text":"Perfect! I've successfully implemented all the critical documentation improvements for the Big Meanie project:\n\n## ✅ Completed Documentation\n\n### 1. **decimal-patterns.md** - Comprehensive shopspring/decimal guide\n- Core principles for financial calculations\n- Basic operations and arithmetic\n- Trading-specific patterns (orders, portfolios, indicators)\n- Common gotchas (division by zero, precision, JSON/DB handling)\n- Performance considerations\n- Best practices with real trading examples\n\n### 2. **project-conventions.md** - Big Meanie philosophy and conventions\n- Core philosophy: \"break fast, fix immediately\"\n- Ultra-concise naming conventions (sr not SupportResistance)\n- No backwards compatibility approach\n- Project structure explanation\n- File management rules (no variant files)\n- Code organization patterns\n- Testing standards\n- Anti-patterns to avoid\n\n### 3. **performance.md** - Fixed unsafe string conversions\n- Added strong warnings about unsafe package usage\n- Replaced dangerous zero-copy examples with safe alternatives\n- Emphasized when unsafe patterns should never be used\n- Provided safe string/byte conversion methods\n- Added recommendation to use string builders for performance\n\n### 4. **database-patterns.md** - PostgreSQL patterns for trading\n- Connection pool management with pgx/v5\n- Migration patterns and schema versioning\n- Transaction patterns (basic, nested, distributed)\n- Query patterns and parameterization\n- Trading-specific schemas (orders, positions, executions)\n- Performance optimization and indexing\n- Error handling\n- Testing patterns\n\n### 5. **api-patterns.md** - REST and WebSocket patterns\n- RESTful API design with proper URLs and status codes\n- HTTP server setup with chi router\n- Middleware patterns (auth, logging, CORS, rate limiting)\n- Error handling with structured responses\n- Request/response patterns (validation, pagination, filtering)\n- WebSocket implementation for real-time data\n- Authentication (JWT, API keys)\n- Testing patterns\n\nAll documentation follows the Big Meanie philosophy of:\n- **No backwards compatibility** - Breaking changes force immediate fixes\n- **Ultra-concise naming** - Clear, short names\n- **Practical examples** - Real trading system code\n- **Performance focus** - Optimized for 24/7 trading operations\n- **Type safety** - shopspring/decimal for all financial calculations\n\nThe documentation is now comprehensive, practical, and aligned with the project's goals of building a robust cryptocurrency trading system in Go."}],"totalDurationMs":1272932,"totalTokens":75346,"totalToolUseCount":8,"usage":{"input_tokens":7,"cache_creation_input_tokens":74784,"cache_read_input_tokens":0,"output_tokens":555,"service_tier":"standard"}}}
{"parentUuid":"85dcd693-188b-42ae-a49a-17defe276ac9","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"system","content":"Claude Opus limit reached, now using Sonnet 4","isMeta":false,"timestamp":"2025-08-13T10:24:14.100Z","uuid":"e9affa25-3009-4aa4-8f70-cbb41afb4ae2","level":"warning"}
{"parentUuid":"e9affa25-3009-4aa4-8f70-cbb41afb4ae2","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01YCAHwGEcvfZAnTLroFSNWZ","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01Czw4FCQeCHNPGMAcUUD8BX","name":"TodoWrite","input":{"todos":[{"id":"1","content":"Create decimal-patterns.md for shopspring/decimal usage","status":"completed"},{"id":"2","content":"Create project-conventions.md for Big Meanie specific rules","status":"completed"},{"id":"3","content":"Fix unsafe string conversions in performance.md","status":"completed"},{"id":"4","content":"Create database-patterns.md for PostgreSQL patterns","status":"completed"},{"id":"5","content":"Create api-patterns.md for REST/HTTP patterns","status":"completed"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":27744,"cache_read_input_tokens":11669,"output_tokens":197,"service_tier":"standard"}},"requestId":"req_011CS5Ybwq7XMTPTS2tmhXua","type":"assistant","uuid":"2a8ee12c-55a1-463d-b5df-5b5b2dd6339e","timestamp":"2025-08-13T10:24:17.981Z"}
{"parentUuid":"2a8ee12c-55a1-463d-b5df-5b5b2dd6339e","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Czw4FCQeCHNPGMAcUUD8BX","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"9f8d2967-a817-4aa9-ac69-a9a2c85424b8","timestamp":"2025-08-13T10:24:18.032Z","toolUseResult":{"oldTodos":[{"content":"Create decimal-patterns.md for shopspring/decimal usage","status":"pending","id":"1"},{"content":"Create project-conventions.md for Big Meanie specific rules","status":"pending","id":"2"},{"content":"Fix unsafe string conversions in performance.md","status":"pending","id":"3"},{"content":"Create database-patterns.md for PostgreSQL patterns","status":"pending","id":"4"},{"content":"Create api-patterns.md for REST/HTTP patterns","status":"pending","id":"5"}],"newTodos":[{"content":"Create decimal-patterns.md for shopspring/decimal usage","status":"completed","id":"1"},{"content":"Create project-conventions.md for Big Meanie specific rules","status":"completed","id":"2"},{"content":"Fix unsafe string conversions in performance.md","status":"completed","id":"3"},{"content":"Create database-patterns.md for PostgreSQL patterns","status":"completed","id":"4"},{"content":"Create api-patterns.md for REST/HTTP patterns","status":"completed","id":"5"}]}}
{"parentUuid":"9f8d2967-a817-4aa9-ac69-a9a2c85424b8","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01WXN3Pp3ZUNaEtC26uVzzw2","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"All critical documentation improvements have been completed. The god agent has successfully:\n\n✅ **Created comprehensive documentation** covering the major gaps identified in the review\n✅ **Fixed safety issues** in the performance documentation  \n✅ **Added Big Meanie-specific conventions** and patterns\n✅ **Provided practical trading system examples** throughout\n\nThe code documentation is now complete with project-specific guidance for shopspring/decimal usage, database patterns, API development, and the unique Big Meanie development philosophy."}],"stop_reason":"end_turn","stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":405,"cache_read_input_tokens":39413,"output_tokens":112,"service_tier":"standard"}},"requestId":"req_011CS5YcEvGaTPMhW9KJ7EAi","type":"assistant","uuid":"b27e2a38-2f32-47dd-8425-7437cbca2e3f","timestamp":"2025-08-13T10:24:22.710Z"}
{"parentUuid":"b27e2a38-2f32-47dd-8425-7437cbca2e3f","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"system","content":"\u001b[1mStop\u001b[22m [paplay /run/current-system/sw/share/sounds/freedesktop/stereo/bell.oga] completed successfully","isMeta":false,"timestamp":"2025-08-13T10:24:23.020Z","uuid":"c2afa057-fdf5-481c-918b-40bc1fdf0624","toolUseID":"6d3d1725-b82a-40e9-acba-d50ccec88873","level":"info"}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":"<command-message>prime is running…</command-message>\n<command-name>/prime</command-name>"},"uuid":"0e94a5de-e78f-45e9-a137-a84d5c72705a","timestamp":"2025-08-13T10:25:51.156Z"}
{"parentUuid":"0e94a5de-e78f-45e9-a137-a84d5c72705a","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"type":"text","text":"# Prime\n\nThis command loads essential context for a new agent session by examining the codebase structure and reading the project README.\n\n## Instructions\n- Run `git ls-files` to understand the codebase structure and file organization\n- Read the README.md to understand the project purpose, setup instructions, and key information\n- Provide a concise overview of the project based on the gathered context\n\n## Context\n- Codebase structure git accessible: .claude/agents/gad.md\n.claude/agents/go-debugger.md\n.claude/agents/go-learn.md\n.claude/agents/go-project-agent.md\n.claude/agents/go-reviewer.md\n.claude/agents/god.md\n.claude/agents/horror-writer.md\n.claude/agents/llm-ai-agents-and-eng-research.md\n.claude/agents/meta-agent.md\n.claude/agents/performance-toptimizer.md\n.claude/agents/prompt-engineer-agent.md\n.claude/agents/rick-sanchez-coder.md\n.claude/agents/work-completion-summary.md\n.claude/commands/all_tools.md\n.claude/commands/arch.md\n.claude/commands/gad.md\n.claude/commands/gcode.md\n.claude/commands/git_status.md\n.claude/commands/glearn.md\n.claude/commands/gpa.md\n.claude/commands/prime.md\n.claude/commands/start.md\n.claude/settings.local.json\n.direnv/nix-profile-25.05-98gzmfn1rhwhia8z\n.direnv/nix-profile-25.05-98gzmfn1rhwhia8z.rc\n.gitignore\nCLAUDE.md\nback/.docs/README.md\nback/.docs/TODO.md\nback/.docs/archive/bak/GAPS_PLAN.md\nback/.docs/archive/bak/PLAN_BAK.md\nback/.docs/archive/bak/PLAN_CONFIG_AND_MODELS.md\nback/.docs/archive/bak/PLAN_GENETIC_EVOLUTION.md\nback/.docs/archive/bak/PLAN_YAML_REFACTOR.md\nback/.docs/archive/bak/PLAN_modelrefactor.md\nback/.docs/archive/bak/parameter-system.md\nback/.docs/archive/bak/plan.md\nback/.docs/code/practices-patterns.md\nback/.docs/pinescripts/AVOP.pine\nback/.docs/pinescripts/FVGP.pine\nback/.docs/pinescripts/MLAS.pine\nback/.docs/pinescripts/MTO.pine\nback/.docs/pinescripts/VolumeDelta.pine\nback/.docs/pinescripts/ZLTS-MTF.pine\nback/.docs/pinescripts/ZeroLagLiquidity.pine\nback/.docs/temp\nback/.docs/todo.md\nback/.snippets/README.md\nback/.snippets/context.go\nback/.snippets/crash_recovery.go\nback/.snippets/decimal_cache.go\nback/.snippets/event_pipeline.go\nback/.snippets/fees.go\nback/.snippets/ledger.go\nback/.snippets/paramsgen/architecture.md\nback/.snippets/paramsgen/contract.md\nback/.snippets/paramsgen/generator.go\nback/.snippets/paramsgen/summary.md\nback/.snippets/sliding_window.go\nback/.snippets/strategy_registry.go\nback/.snippets/worker.go\nbackend-code/.direnv/nix-profile-25.05-98gzmfn1rhwhia8z\nbackend-code/.direnv/nix-profile-25.05-98gzmfn1rhwhia8z.rc\nbackend-code/.env.development\nbackend-code/.env.example\nbackend-code/.golangci.yml\nbackend-code/Makefile\nbackend-code/README.md\nbackend-code/backtest\nbackend-code/cmd/backtest/main.go\nbackend-code/cmd/backtest/migration_test.go\nbackend-code/cmd/dash/main.go\nbackend-code/cmd/menu/main.go\nbackend-code/cmd/test-api/main.go\nbackend-code/cmd/test-coinapi/main.go\nbackend-code/cmd/trade/main.go\nbackend-code/config/backtest.yaml\nbackend-code/config/exchange.yaml\nbackend-code/config/pairs.yaml\nbackend-code/config/strategy.yaml\nbackend-code/config/trading.yaml\nbackend-code/docker-compose.yml\nbackend-code/genreport\nbackend-code/go.mod\nbackend-code/go.sum\nbackend-code/internal/_api/README.md\nbackend-code/internal/_api/TODOS.md\nbackend-code/internal/_api/account_client.go\nbackend-code/internal/_api/api_integration_test.go\nbackend-code/internal/_api/auth.go\nbackend-code/internal/_api/client.go\nbackend-code/internal/_api/client_accounts_test.go\nbackend-code/internal/_api/client_order_test.go\nbackend-code/internal/_api/client_preview_test.go\nbackend-code/internal/_api/client_test.go\nbackend-code/internal/_api/client_url_test.go\nbackend-code/internal/_api/config.go\nbackend-code/internal/_api/http_client.go\nbackend-code/internal/_api/market_data_client.go\nbackend-code/internal/_api/trading_client.go\nbackend-code/internal/_api/types.go\nbackend-code/internal/_monitoring/interfaces.go\nbackend-code/internal/_monitoring/realtime_monitor.go\nbackend-code/internal/_monitoring/realtime_monitor_goroutines_test.go\nbackend-code/internal/_monitoring/realtime_monitor_test.go\nbackend-code/internal/_monitoring/websocket_server.go\nbackend-code/internal/_monitoring/websocket_server_test.go\nbackend-code/internal/_shadow/README.md\nbackend-code/internal/_shadow/api_interfaces.go\nbackend-code/internal/_shadow/balance_provider.go\nbackend-code/internal/_shadow/config_interfaces.go\nbackend-code/internal/_shadow/engine.go\nbackend-code/internal/_shadow/evolution.go\nbackend-code/internal/_shadow/fitness.go\nbackend-code/internal/_shadow/operators.go\nbackend-code/internal/_shadow/types.go\nbackend-code/internal/_strategy/interfaces.go\nbackend-code/internal/_websocket/client.go\nbackend-code/internal/_websocket/client_extended_test.go\nbackend-code/internal/_websocket/client_url_test.go\nbackend-code/internal/_websocket/messages.go\nbackend-code/internal/_websocket/parsers.go\nbackend-code/internal/_websocket/parsers_test.go\nbackend-code/internal/_websocket/websocket_integration_test.go\nbackend-code/internal/backtest/boss.go\nbackend-code/internal/backtest/boss_test.go\nbackend-code/internal/backtest/config.go\nbackend-code/internal/backtest/config_test.go\nbackend-code/internal/backtest/worker.go\nbackend-code/internal/backtest/worker_test.go\nbackend-code/internal/common/README.md\nbackend-code/internal/common/errors.go\nbackend-code/internal/common/errors_test.go\nbackend-code/internal/common/fees.go\nbackend-code/internal/common/fees_test.go\nbackend-code/internal/common/position.go\nbackend-code/internal/common/position_test.go\nbackend-code/internal/common/signal.go\nbackend-code/internal/common/signal_test.go\nbackend-code/internal/common/trade.go\nbackend-code/internal/common/trade_test.go\nbackend-code/internal/common/types.go\nbackend-code/internal/config/global.go\nbackend-code/internal/config/types.go\nbackend-code/internal/data/hist_provider.go\nbackend-code/internal/data/live_provider.go\nbackend-code/internal/data/provider.go\nbackend-code/internal/database/config.go\nbackend-code/internal/database/config_interfaces.go\nbackend-code/internal/database/connection.go\nbackend-code/internal/database/db_interfaces.go\nbackend-code/internal/database/migrations/create_trades_table.sql\nbackend-code/internal/metrics/calculator.go\nbackend-code/internal/metrics/types.go\nbackend-code/internal/models/backtest.go\nbackend-code/internal/models/candle.go\nbackend-code/internal/models/trade.go\nbackend-code/internal/portfolio/ledger.go\nbackend-code/internal/portfolio/simulated.go\nbackend-code/internal/providers/coinapi/client.go\nbackend-code/internal/providers/coinapi/config.go\nbackend-code/internal/providers/coinapi/types.go\nbackend-code/internal/signals/big_meanie_legacy.go\nbackend-code/internal/yaml/decoder.go\nbackend-code/internal/yaml/finder.go\nbackend-code/internal/yaml/loader.go\nbackend-code/internal/yaml/validator.go\nbackend-code/pkg/clock/clock.go\nbackend-code/pkg/clock/clock_test.go\nbackend-code/pkg/clock/mock.go\nbackend-code/pkg/errors/README.md\nbackend-code/pkg/errors/errors.go\nbackend-code/pkg/errors/errors_test.go\nbackend-code/pkg/errors/examples_test.go\nbackend-code/pkg/goroutine/safe.go\nbackend-code/pkg/goroutine/safe_test.go\nbackend-code/pkg/indicators/common/atr.go\nbackend-code/pkg/indicators/common/atr_test.go\nbackend-code/pkg/indicators/common/cmf.go\nbackend-code/pkg/indicators/common/cmf_test.go\nbackend-code/pkg/indicators/common/mfi.go\nbackend-code/pkg/indicators/common/mfi_test.go\nbackend-code/pkg/indicators/common/obv.go\nbackend-code/pkg/indicators/common/obv_test.go\nbackend-code/pkg/indicators/common/rsi.go\nbackend-code/pkg/indicators/common/rsi_test.go\nbackend-code/pkg/indicators/common/sr.go\nbackend-code/pkg/indicators/common/sr_test.go\nbackend-code/pkg/indicators/common/vol_ma.go\nbackend-code/pkg/indicators/common/vol_ma_test.go\nbackend-code/pkg/indicators/common/vroc.go\nbackend-code/pkg/indicators/common/vroc_test.go\nbackend-code/pkg/indicators/common/vwap.go\nbackend-code/pkg/indicators/common/vwap_test.go\nbackend-code/pkg/indicators/indicator.go\nbackend-code/pkg/indicators/interfaces.go\nbackend-code/pkg/indicators/misc/avop.go\nbackend-code/pkg/indicators/misc/avop_test.go\nbackend-code/pkg/indicators/misc/fvgp.go\nbackend-code/pkg/indicators/misc/fvgp_test.go\nbackend-code/pkg/indicators/misc/liq_zones.go\nbackend-code/pkg/indicators/misc/liq_zones_test.go\nbackend-code/pkg/indicators/misc/mlas.go\nbackend-code/pkg/indicators/misc/mlas_test.go\nbackend-code/pkg/indicators/misc/mto.go\nbackend-code/pkg/indicators/misc/mto_test.go\nbackend-code/pkg/indicators/misc/zlts.go\nbackend-code/pkg/indicators/misc/zlts_test.go\nbackend-code/pkg/indicators/vol_delta/approximators.go\nbackend-code/pkg/indicators/vol_delta/approximators_test.go\nbackend-code/pkg/indicators/vol_delta/factory.go\nbackend-code/pkg/indicators/vol_delta/interfaces.go\nbackend-code/pkg/indicators/vol_delta/ohlcv.go\nbackend-code/pkg/indicators/vol_delta/ohlcv_test.go\nbackend-code/pkg/logger/logger.go\nbackend-code/pkg/logger/logger_test.go\nbackend-code/pkg/math/decimal_math.go\nbackend-code/pkg/testutil/assertions.go\nbackend-code/pkg/testutil/config.go\nbackend-code/pkg/testutil/data.go\nbackend-code/pkg/testutil/database.go\nbackend-code/pkg/testutil/doc.go\nbackend-code/pkg/testutil/environment.go\nbackend-code/pkg/testutil/gomock.go\nbackend-code/pkg/testutil/helpers.go\nbackend-code/pkg/testutil/integration.go\nbackend-code/pkg/testutil/mocks.go\nbackend-code/pkg/testutil/suite.go\nbackend-code/pkg/timeseries/timeseries.go\nbackend-code/pkg/timeseries/timeseries_concurrent_test.go\nbackend-code/pkg/timeseries/timeseries_test.go\nbackend-code/pkg/types/indicators.go\nbackend-code/pkg/types/market.go\nbackend-code/pkg/types/orders.go\nbackend-code/report/Makefile\nbackend-code/report/report.yaml\nbackend-code/shell.nix\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/01/76/c78dfbb424fb1973a3e8338b8b7bfad3d208c2b9224a9c96609a71d0d990d901f8bb077cd097645126d777a855702c5443ca8eafe846d95f77d800fb3979\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/01/e4/2710ea693112f59c2bcc98d8e00cc98a83cff7526ff53d6f194f46fa5f0d8d85096ca8fea4df7e8a9c040332c9acae6a21ee553119ea3dcddf0e21c3ccf3\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/02/1a/d581a69701bf147b4bb69ee456c2e82dd1d2f95264604bd2d77b41e1cf8f776bc285799554139e911885778406bab47ce6015ede228a9c59342fc7394979\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/02/4e/b636db27a1a5295babeccff4ea17f31f3e8d574031517ecf9b73e6939f5bcb767048149bda7b53d77bc6fe1aed94058f125ba5a779f4875eb875cfa77b31\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/03/ce/bfbd63df368e8784a559351645b6cbca9bafaa27284a2411e666ce80a45e84f5c0e312b83c3e1b7baa3fc129549f52e73c2315eb53f76450d07a8dc45ba2\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/04/df/8881c8a9f125fd41ea2b3be20d7843389daee710088f5994b0ddc6a86fbcea1e531279a63f27d4f9a19438714f5324fddba023072409ff0ee53f2369b88a\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/05/54/3af5ddf3fd795e8ef8634415d376cdeb7818c3ae0e26ac92c0d1db2954019762e7ebc596a84ae6424eab8303aa6dd1b4bf218b28c9b80962d5b9a4fbf780\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/05/ac/a25c74122395ebefefc86ef9f7883ec61cf1ac1135837b2e05a3cbaec5352bf83d6aa99e32750baf93d56f3f06411445339c099635dbf56968f787c60955\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/05/ca/c24e6e7832e89170ffb6e976f1757879d5c7bad32426ca895723864e4369b6e946cae8de6d0221b1c326fa1b0124e34abc1fd7ea0c1ab4653c8caffabbd4\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/06/38/8f396ea4b3dd142a5ed3c0cbfba0d40c9f353eb7fc24f668080e2e9bd6d5e951e93b316d256cd3941e9bda9bda5ede55427f8c4f153fa52bbb3e7be7eced\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/07/a0/e91d92b5340dab52bf4a6b2d3fa07b3ecb157dec0ee9fc3083d6afafc1cb53c3f31c81981e9d6c4ad923d778bfd71545d9a51a90a9d39ab470aa7da8f061\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/08/ba/506947bb891b883a95479215ca228cf7796e0f8997bc5278754d5231bb2a2907df224f13ba4fe03d42f08a90d9db00faab5502c5c07d11c80231e0198167\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/09/54/624f584eec2d54ef3dc2cf72f1a80d0944fbda8b5c48ebe4c98abe06da424c0e69cde03243c91d92e3cef56009ab22bd37ee2ab7df4bcaed4d225c54a43a\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/09/ab/7ade6c6c54997362f379d499955c880da14a24ac8693db32dc9425e345df1ba19d34d38538282b3fb13a09ef90bab1d941c96c696276f906889fd554857b\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/09/d6/00fe739d338e34fe0ac0130e7cfc5f30677a9e9f9976ded0472460bb8f1fc7c065823f9890be926c4463b8933010e01a35fbb08c70e46c24960d19ccfa92\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/09/e7/b6c38d4686f2663f1aa95961986febd42d3162a916ee2d22b81d6764b2e2328bf3c411b4c90f7b25dc56243f5f8e394c3b2eb06f762b665734026f92d91c\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0a/08/b5696e0114667d3076e92a540aaee9ad9e8a3e0c46b4b066694b0a24efb47a1d44f9c96c3a35d6171d82ead94b1c13acab02c2c7e0f8db5a3eafb76848e1\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0b/e1/64145efc36f086a6d687b3575ee42db7693a41847f4b6ea133be71fef22f76455125c3aa809ee7f82e314dbb3ab409cb3a2ea4e045dcaa73f819778c671b\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0c/6d/e3a1212f0bd8308f24bbc435653aa24fe1a2444692af8d49fb5c137806a0e696e1f15f184023d7dce6ef74f1c29f63482ce4e8ff0f7df49b8cbe070884cf\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0c/ca/155889504ca7156409d3657b784173e4b80f4414352192c30e23c38b5c806ade2f96fa514213e92be691836f4bf2d1ff9666fab43343e0edaf0afaf3713c\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0c/ec/6c514e50ad8b13c4acdd67b0b9fbc05644bf5316518d658b6e4b65c2e6580eb18f67c679bbd8857def7f739f56b52f7c1e212d73b431508b6250dc88b9f5\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0d/21/09817f5114cc2c9eee23cefcd5ea91c0f77c11b87f47d884a0ccd627f1df3af5fdc41c0417edb6f4cec7e8d4b4271c29e76dd9f5172bd93a3986ae0f3861\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0d/4a/476b51e978e404b7afb79e17947ea557468836922be45c7521a2a262291df748ee31f9ae6e34e324578f3b58f7ab4242f4bd4b91beaffb2614602d6dd2fb\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0d/8e/47062a1582f4a20a5f4d0ad810146e741999122fadfd5d9ef16f0a243b1ce3062f25127d906e1516bd4a85d8b96bfa52709df4bc48c2a293b2014f7aad56\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0e/14/bfc3ab7e2c132c519016f536ae9e52dcf952ba812ecc314eab2eed4ed53a3e5711ac392042b2b464bf5a8681477ade9085966097474509b9a916b9fefb81\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0e/31/1b269d3817895b0bd10dd768afcf88fade1b30ca007b87e92e2a5619a3379cd03717db08d5facccc404311360e334c18f3aecd32bac2460403d3e7703904\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0e/58/0ace8908a3eb1ff84858e60d6cca7877b821c8399e816d54be968b25f09809911eb572ec8b61230b676505dd59f4d1ede4ab19d0963547cf16c8d6ca471f\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0e/5c/716b1cc145dfb0da202016bd9d3a8edeaedf620c4a1f4eee5fd1d8612ae4f1847bc873de001f2985df9c8b801897d3f2c574b4497d044a917a7f63edb21e\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0f/68/4ff5e03e4aac75901660cf1661d32d6dadbb94f89a03922130aa1437ea7a1d62a270c842213d274c35dee53a6ff88a8ef696e4cf587db461d6b4c4eb94a3\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/0f/ea/068a557db7c6ef79faad157f19ce7a1815e8b6611a00221863d5deef5494fa42eab206333336181f9da20a21f9cf219a4316ff84e4378fe31b4dd7e711a6\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/10/18/f9486f17c9ea42946159da41e6fa81e476ff36ac8ef0127f7733b10b145a1df23760d4679402b625524de9a5f8fad802dbe390582371a128d04fa6356efc\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/14/f6/5fd5afbbd9bda509ba1a5cefb9bf6846c8058b817242cafec6edacaa2c17eb5232c917b673023771499640fbb2ed8f742ea8341493e0bdb837626b182e36\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/15/f9/9d1d3ad784876e5b2cae928d584dc18bba27156e15324633b71db5c4e1a3fae79c8a66075321f32167f579558f5b1eec6ffdf18487739dd4bbefd8e0cd4e\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/16/ee/2125dbf37b29427d03e9f5219689da73accb3bb53ae5bba55bf1719a446724f1048d649269e77f16adbeb42dac787cfc11eb8562638ebc3885136d194666\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/17/af/cdb42410c9256162b1e1157e71cf7a88c4c09713a2fefad4a89a6b77336d9fcee21fe350c56722112b061880adb2d9f89642960e791fd51a8fcd948fbc6e\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/18/f7/f197d2d4c5141c0a8b625c37dce9fd77b99254151fee87352a0d165dfbe10e742ca4dc1b17b186ea986a752a5aaec8ce6e872c70a668fd050fef47c1f647\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/1a/2e/ec1153a534bded6034df05125cdac0caaf70bad9a3e19cb246fed4a1d74407a024af867cb5e8fc7db1a8290b4712f7928079763bf61b0967c14a395a6473\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/1b/2d/387aaa3e125b2eeb419a684e1e456c03c6f9ccf9bb76eec6e601fcce34040e82790db7c54c81a4b49dd627d82307ecfc13f73aac90d1a3d87592909fa941\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/1d/bb/c299977302edd51a2fe95989b952df8a77d9a7d591e79f82f91bc90e4133ecfc8c0802626806b9989367242c0ae0317663d005b79f90807a32d43be3e175\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/1e/28/f0e51db93e9a65fe7c4e0b8f586bc566ff769fba1df2a9de09b3424f0b57e096ec07b75d134a7d64d0a2ac236355d0d9c30682a3ef643d5f7ff43022c81e\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/20/d8/524a5d75fe440eabf63d89a147c9df6297508e15b2bedf280b14c76ea8772e125d3da0acab949e1736e546f3e89cc1f7166107988b22d045be703f80e91c\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/21/3f/1476d381ccb0ec3561eee1c90eb596884845b396604926c7c5db75f32d591c9866b2ab614a52874c18a5ffd44de1bcc4d1e1e5c8ac76a48df2a8140ec8be\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/22/26/c5c7b718383ad60416c59da0ed566533eff12430cb3778969cdd6f17f124b9575dcc10a3276054caf3fb848e6ab3a6a1950465f540c3445acd0395e76158\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/22/31/15f8d938e73d022c28581f98c11ba4f6d353262a685e68447ad8a2a8334a542115ad786776e4544c8a3c2adce58acb5a0812b42d3fd0daae2f767954eb21\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/23/07/c1a6d6ad94ef90089528d7d02abeb3cdaa554ca56f5810bd8b21563e469bf6aac8c21b16832cd460786b1058985f22d79bb8986c1922e36816cd490fa27a\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/25/c6/b951d7bac943aecb38e7cf9ee883b12ddda5e36f00920dfffca272c7490830d6a5b700b97d9ab3166976f91663d5915dc4b640f617ff8d913e951f23eef4\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/26/3e/5af515287b9adaf8c13211190328bc135d5bbab3768008fe759e47e72bdc094eb6820bc20c7b7b2739f00b92b8d361dd86d55884d612028f47d9ec02c13c\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/29/4f/186af6ec7b263603b67f4adcca3ab82a8dd1dcab651ac7a076c448e7e7ec3936a9ed81019876c72a1c89672312e7258a924986e3b6d113d7084a3ef177ef\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/29/b1/807159f961fa7d029565d76f1ff42df435c8f14604f2687f6a13b0e3ed22485eb7325ec23a8bef299a4d1df4319457e115e3577a02a0f0a69882f9a8d178\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/2a/57/f85314bac72de87fce8a7d783b0de546e217b04f88330a395879a32a5e1a7f6d9ace82e4560deb351691aff8e84781195bda481890b61051b2095050ef90\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/2a/b1/e3330820e165b748be169777dc7086a566fca0ba5c5c6ede90362ff3f324bf536b71d10715e782b05bb59eb1c6e85f030a9698f667f26ae70ac278c9bab4\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/2a/df/4b3a6317efdde8de4e21c463f6dcb324daed9b671fdd93078f2d43e10873841c413322df8634a7fb90a5c174f71899d562d0697006b70a3607f5a5a3eb87\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/2b/32/1b1fff6d5dab76bb7d237feb26330142b27a38c0755d366cc5c8bf93fcbdd41aaaa4e8929f56a3853991296521c00c7d64e3469be8d5085d9ab8db6a2fdd\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/2b/d9/270213adae00193b595b2e782a61550f39b36f8f8162bda9967aa04aa17b9ce84b7727eb0844d4b3a9e97259e08c30b8b842ea42d455d539746fd2d6d56a\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/2d/19/5eaeb318a080eb4fa8e0a5e67661897f2fc12e9514ede6141c623cb90089e1ec75972a29a9ab1ebc6a49c116918bdbefc872881371ac9d24481a4e63a90e\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/2d/61/0c08fcee0e00977cdb349f5b4d6e1f765e7e0c30aa4dd8a11836523cb700cc28e10b4ae22bca9ad9d6fcd8d489645d949163d6d7424681526d32b3630455\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/2e/02/cf33de80382c0772a0b8c1e4ec36fb40e40ec5326b39191b0e356909ed98c07d03c9bb01026aa0e2ce9ad56f06f98d0cb89dc484a20fc9fea784a473e312\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/2e/90/5bbbf1d1a2682d648f3f48a01a57c8a18af55d88f7f23048cfe8ea325d017724bb3142af14cc6543a7e49f0f10835ca6df8e32ca007705d4441120980b0d\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/2f/f3/ea5b37d33fd973cc46ba08ab349369c04714dd65dbb0df3ca1f1dd8d5419eccaf1e3497e135ac7b7f3c62bad029bbc8f30db47c68c6961813f7a5b02b293\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/30/8b/353e65ae441cd4504885482f874a65b6b1ab086df5688e2742f9c6b934f3d2ea52100c27d44b975df54e650d933348a401163a239a43443f11325d7f7672\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/30/97/ca40384e3100f915cf0f713b427455f4a017ff9ca55fa7af5271d10a2175b425710b5f95762dde3912c8d2862f1a27a0cd85d0ed48366f2ae0e790388a9f\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/31/1d/38baf0fed3b73097fca156e55602dc3edc6391fe49e52f9e4d77fc0075b964dbb18256dde5aa94e2bf2fed909719a0d3f34f04b563e28ca2394b0e1a13ce\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/31/3d/e5733cb0f94caf9ddbfd94e5c5249111825d48225aa57d3aa51dbd843e15e3c15d92a8edda0cb8c70f45fcfe8523f181067adf96bccae5c57f9ed14d4999\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/33/5b/9090c97cad02bfb330f42cd86dab120f2e98a61a6f2c381c14ee52e70a949b4f2637c9e53555cee5e0a4f9cd3e2cff23b11c7e4eeed22eb8b3829cb00347\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/33/d9/0efb87fd10d58834b596138a80c34322ea16cd2a6193f66b6e1462c17b35fa75480650fffca1badf5649bbc90190fa6dbf6a4e8c6b08a66e28c2e682c1b5\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/35/bd/4123cbefcdfb393797c5bc537dba8c6186336231e774586a27d5cb56b9fecfe92f45c8574d5453cedf25c997e764ec154fed10d0d596863469864f714d9c\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/35/ca/afde6304c70f2a364d186d8c29a2bbf0d5dc414ba24f3698fc71ac9cbaecc26755b175246579a0419cc2fcd8b5c65bac176221c52d153b505d651b9fb373\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/36/51/b37865a30085b49bf366968d5ed07f669b6ebc36f3261827fb6560d4e8b564dc5159de2049474d96ac47585e34a8adf411c45c98f20322fbefb00c2918b6\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/37/c4/a97cf527529d5b2be3cc616f2a496765f54fb0c0d588e102b13980f2f4902ba3758c5fba7639e55117dbfedf8ee99da90d7af3e688784d999d876c503beb\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/39/09/f523dd16a8bf7c5dddd547737957b74351275bddb3b75973de2e8f3b528fd9dd897f2f2e523411ab6109fb0c9cdf0b30f6dde12c84b4bca05ef8e2047645\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/3a/0b/8f76275bf9f6c74125384386622ca9f35a8f16c2c7f96d97dbbeeefffdaf684d8a2a0ff7d6a5ef7a36e1e4a12f61d1c7063937b40b83465ddb52d2239b3b\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/3c/17/d69a443c37156ee5f8f6fd32342562c019f803293ceac54ae8216f9eb29a62aa18293dbf6c042a68e2994a75088fa3fc0b8ea12d6d75ef829e8437a10934\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/3c/41/a5030ac6f325c65d18d6df67c66e0eba24094e0306ce6eea95a09a6ffe6460a160d07e01f5c033efb735b25123405c119293c87be796036db704cb7487d9\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/3e/7a/a7043c5cccd389b4d74c4de1c7db791a349a0443d98d1e464ae161d52f34edc971cdf4b6e159ee6ec45bd9749cd37aed9998e7607d1ae0286b7f9837a82a\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/3e/f2/072d4a168126c31bbccb1ea4aa682a19bc78ba34d99f5453aa3be3a7c2fa8ccffb6a42bdc5b86592f2e7e5b8d75d93b64b04960cae3730d5ce97cd1d7698\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/40/5b/009ac5f515522c08958b264f95453910547eb0c86607cd7845e79e02daccb949a86fe029790eb2f24102a2cc12049b34d4eaa18268d0e48d3996514ce9e9\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/40/66/0a12e52c613f7290a04230e1032ec53925139b590bac02894531e928fed60fb9f36445f7c10108c813ef7d8db03cef1bfa1609a32edc2387dc0159a8f000\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/40/82/6d35eef9d5583750262fab21e3cb96b84e926c18e05890851a132e77d2b0afb6d5060103d8d003620eda3ec77d1742570a7b871e430cd10b681cd58f315f\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/40/fb/56300289f85f03973ce6f1076095d6198e5dc64d83b247fb7d66a32cbcf7ed9b9d18cb81b5dd7dfafafb5fae95b50897b19fe4788d3cf5f02477e0894931\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/41/21/d12cdc2f84f714af232867bae654413d6fb3f41aa10ca165c50269e01369e09d0d3f7a540ad71015dbc1e473083d72ff72f01547fec8516ef6fe172b1067\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/41/31/f3b067751216d9b3802c436d095f5ac2ddc3a5b7f21626bba4f3ddc37cb46be7b95c9ce78c6961b82b426b46d6b89882592ad87602ede6337bb4dff2562b\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/41/3f/a919e7820e193bca8676b45798ce68a32f85b048fdd4e5c1ad269d87f5a5c88d623398c106c1629a3b45c425095319a44b500356611c95ff8ff1b0442549\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/41/6e/22bff4b7bdc7d282a9e33079249fbd07d343b87aa660f6b665eef18fbc39c8bc96e92a55b875779e811fec6f5021ad57225d2b8be372a137976f9a179638\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/41/fa/ebb793ac347e51fb9b49ff7b9804166fdd2b869a744f7a357d22521b147dc74c62c3964aa01f29809739255662818c06959a43e4ca290057fb10d7048bfb\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/42/f0/e888861798804d14afb2e9fb75e37ffde2c3bc8d664446cf77140cc409de59e2cdcdc25316d57a7dd67e749e11abc07dee0f9a37af86f5ffe98d012151f8\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/43/9c/18ebaa879f44b003b4da6b46836c7889bda1492ce2721e6a2843bcbc865c3040b43fe56c027285f483b8a2d38422d832651ec7745d7cc9f18a70f7ef5899\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/44/67/608d05196dae69e90105015c763866fcad00cbfdc3d11bb1a279d47331c275b589d400d0677236d20753511b06ef8dc3de8a4440073da7b21c8f9356e15a\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/44/c6/d4e8d4d4ef4fbe0752725496cd6de1642be03e43bcbd5ca13610ce0d2c69b658547cc7d31b02d5b13cf2dd9b4c1492e66ff6dae9c1f4a52fab637486b5f8\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/45/03/dd0984daf00ebcb8cda3c31a18f38db10e1bf1dc4e4b14bd4bc6fc4234c7afe28e662eea247338738c0806c1464102638a6649c0ad2c4b2a65ed222d80c5\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/45/5e/f1a290c11270dbe636bfb73a5641e7d8c21806c2d5433f6b61f3570116017618f263dc8bc4f85dfdaa6be9fafef4f97e5c29faf7eb38e404c2b33c67e214\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/45/69/88aa17057f5951601bcd9abeea4cdbb20adffbfe7b368dba69d7e3da96013fac341c053d1f8a848c52927dde2ae55210b986b838718a9ee94fb42265b4ac\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/45/f9/24fcca7f0cbec95637b7bb5f05c45ba34254cd476aba41f312301ec0bc2071f753468ff6dade409fcdad1fe9d5436f0ed89517ff9c3ae7ee942b082c90ff\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/46/02/d7efca2360ead38491eb2223f34f81d6df27d06b40fb2be310f35ae1c6a68dc8d06ee05d6bfbbd8b347607fd9fb2f48d4cae3addfdcfd47b9cdf0e00048d\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/46/92/62a517a546f3c6bc53836fac8455aa1d6ae9d27216f233ff86401eae05a50b484ab8f732f728a5585d6c864588eb82c98011ed8e90c150b7d36b1de9744b\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/46/93/e9d1ab13ffab9f466fff009570a558996c633f3248d017125c710447988485ff6d8d06db07a805a62fefe99a43d6a08509756c9e565793975c3274701355\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/47/53/ddf5e17e303e496030d23c0a7fab5a2e80a8259b5e2e1243ccbd0ff4e511a6c7a1bdc2f98b4eb4c8fd0e623cd24b62a35db0343ba9318870d591f85ac798\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/48/8e/3de16e57eb409a530822f2ee2ae26e2cdd80054b1967dedccd8ce498aaae78c25560cf4fcd6db5c46f799d2dba8c073b5c992edb553684776c34a8c99f7a\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/49/8a/0bfc59cd3887d8e7f498d2b6010d097444646a622529434975f0a3ac133280e1f80b232a680a86a2f3b7c72fd3cd86192973a038d5511c32958a8db330fb\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/4a/e9/c08306bd09a98b71108f9cf1f1d55daec5d430246a9bd5cad8ad15a4b5651d95dd3e0762b26a43447959f99659f857278db56d7b21aed5eea056c8cfd293\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/4b/fa/926a1e87d021e646c26f8fcdf578d871cad80efe7bc24fce736ee65107b167b9152fc0f59a4c5a6a80b8545085b9601feb98047c85ebf28c7afbf7504e36\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/4c/68/02331826d6ca90757fe9e8275cdaae33a0bc6676ec7b769078581081c7fff99a605954d2d58c07867cefc441f28918310a007e178555026f5505d09dd310\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/4e/8b/4c000e12bb43b98bfde75079b313760fde7d8c520d216e85d5609b1017ca8179dede42fd6d9629cff4e558a69756761cbcb59ffa8deed5d38aa273fa5026\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/4f/01/19f97fb20899987cbed33d439cbc167841fa13e587a742226e5ffff4b61e770c4eb0d31c4b12d7cade2cabc9015d757baf908939d44120ac943458990e99\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/50/0c/74362f92970731533912d1324536907429b659b7b250fd7419dc9a9d6e1f8e7a7336e15693d5582b4c01976461bc6dc76759f02e8bfd6b5ad3b38d0f56fe\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/50/d6/c25dc069aadcd4b9cc44c704d27c07bc8249c0278f3935f3cdea8d738879ba9e7c71f7ba6221b70143779dc3cdb74de8f65b1bb50b4c41634e8a81e67b80\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/51/3e/960006840f27138c6fd3c8bd3ce3e88aebd7973694595a0c39b33646f53a52bf74a787239da6fc8ad67ee841e2d4285cbd7cae19197156a5671d797d3dd4\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/51/75/8c2a12cec1529bef6f0852d40f5f17d853ebac7726ed52b2bff2e184f0240cbeb84ea70bf30c1c23d108522fb31073bbc8b084811bc550f3e203431a5f40\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/54/1c/4887f93a4d131ed2b9d24f36dfe0ccf76bd83b060375097df9170a7e8710e94ee18215bc3a9ba703e5d993ad5f76a8b38b8e38abd3f5dcc25342718de370\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/54/48/79c48b630af2d692497a538e17068a79af0e2969825e01b43e70f99de0413fa8c91e509453adcc90b043a6aa9d301616c20857bb21cf80f4646c40aad16d\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/55/25/8efd6ea73507723f9db41759a17fe2dcd9ff298c640eb681c79bb65ef06a35917eda929548aed4dad1f9fe1c1d102440d569c97a68ed3c604d0f8177dd9d\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/55/3d/be1b5550b3ff68cf4efc6cbad86de71d64ab3dd76cd09647a5629b9ff925c5f90bd90d82656f1fcb4b1fa679203074316717c1555d6f760158e39159a017\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/56/39/cea6741ff16b82119b4d51d8e3c0651bb4054ab9991543fe5c1f2feda2355544846d956318563c968713a622ad3902548ebfbdb3ee144d4465418103a5d3\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/57/48/631f87463e1f40a39a74328458e8156ab700a3873eaf2392d3f00279e47fb883dff8bdb1f1d48e787d2d17b9c94b8431c0acf40288c8c3c6368bf1f3f187\nbackend-docs/.npm-cache/_cacache/content-v2/sha512/57/52/e1402bc092211d4f4c331d2bb45d8f90e1c9feb4383c0fc982d7914656948360a0dc674715c3\n\n... [661 lines truncated] ...\n- Codebase structure all: .\n├── back\n│   ├── go.mod\n│   ├── internal\n│   ├── pkg\n│   │   ├── clock\n│   │   │   ├── clock.go\n│   │   │   ├── clock_test.go\n│   │   │   ├── mock.go\n│   │   │   └── README.md\n│   │   ├── decimal_math\n│   │   │   ├── decimal_math.go\n│   │   │   └── README.md\n│   │   ├── errors\n│   │   │   ├── errors.go\n│   │   │   ├── errors_test.go\n│   │   │   └── README.md\n│   │   ├── goroutine\n│   │   │   ├── README.md\n│   │   │   ├── safe.go\n│   │   │   └── safe_test.go\n│   │   └── indicators\n│   │       ├── common\n│   │       │   ├── atr.go\n│   │       │   ├── atr_test.go\n│   │       │   ├── cmf.go\n│   │       │   ├── cmf_test.go\n│   │       │   ├── mfi.go\n│   │       │   ├── mfi_test.go\n│   │       │   ├── obv.go\n│   │       │   ├── obv_test.go\n│   │       │   ├── rsi.go\n│   │       │   ├── rsi_test.go\n│   │       │   ├── sr.go\n│   │       │   ├── sr_test.go\n│   │       │   ├── vol_ma.go\n│   │       │   ├── vol_ma_test.go\n│   │       │   ├── vroc.go\n│   │       │   ├── vroc_test.go\n│   │       │   ├── vwap.go\n│   │       │   └── vwap_test.go\n│   │       ├── indicator.go\n│   │       ├── interfaces.go\n│   │       ├── pinescript\n│   │       │   ├── avop.go\n│   │       │   ├── avop_test.go\n│   │       │   ├── fvgp.go\n│   │       │   ├── fvgp_test.go\n│   │       │   ├── liq_zones.go\n│   │       │   ├── liq_zones_test.go\n│   │       │   ├── mlas.go\n│   │       │   ├── mlas_test.go\n│   │       │   ├── mto.go\n│   │       │   ├── mto_test.go\n│   │       │   ├── zlts.go\n│   │       │   └── zlts_test.go\n│   │       ├── README.md\n│   │       └── vol_delta\n│   │           ├── approximators.go\n│   │           ├── approximators_test.go\n│   │           ├── factory.go\n│   │           ├── interfaces.go\n│   │           ├── ohlcv.go\n│   │           └── ohlcv_test.go\n│   └── README.md\n├── CLAUDE.md\n└── front\n    └── README.md\n- Project README: @README.md\n- Documentation: \n  - @ai_docs/cc_hooks_docs.md\n  - @ai_docs/uv-single-file-scripts.md\n  - @ai_docs/anthropic_custom_slash_commands_2025-08-02.md"}]},"isMeta":true,"uuid":"614a0ecd-2bac-42dc-9f1f-1359230c0b88","timestamp":"2025-08-13T10:25:51.156Z"}
{"parentUuid":"614a0ecd-2bac-42dc-9f1f-1359230c0b88","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_017RgXpGuLGzyZGQyRfw4CLp","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Let me examine the project structure and README to provide context."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":40005,"cache_read_input_tokens":11669,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CS5Yj7u3QSbbP59Pv8Hum","type":"assistant","uuid":"5fbfe2da-5794-4d34-a92b-0af68c065859","timestamp":"2025-08-13T10:25:56.584Z"}
{"parentUuid":"5fbfe2da-5794-4d34-a92b-0af68c065859","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_017RgXpGuLGzyZGQyRfw4CLp","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01WGmxmCY9x3TE856y1cvWd9","name":"Bash","input":{"command":"find . -name \"README.md\" -type f | head -5","description":"Find README files in project"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":40005,"cache_read_input_tokens":11669,"output_tokens":101,"service_tier":"standard"}},"requestId":"req_011CS5Yj7u3QSbbP59Pv8Hum","type":"assistant","uuid":"62014e92-a68d-4c29-8655-ac6314c88815","timestamp":"2025-08-13T10:25:57.025Z"}
{"parentUuid":"62014e92-a68d-4c29-8655-ac6314c88815","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WGmxmCY9x3TE856y1cvWd9","type":"tool_result","content":"./front/README.md\n./back/pkg/clock/README.md\n./back/pkg/errors/README.md\n./back/pkg/decimal_math/README.md\n./back/pkg/indicators/README.md","is_error":false}]},"uuid":"be6da4ee-9d67-427b-bc29-af1c37fe7bdd","timestamp":"2025-08-13T10:25:57.087Z","toolUseResult":{"stdout":"./front/README.md\n./back/pkg/clock/README.md\n./back/pkg/errors/README.md\n./back/pkg/decimal_math/README.md\n./back/pkg/indicators/README.md","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"be6da4ee-9d67-427b-bc29-af1c37fe7bdd","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01UkWv6NSQW6Rn7ZH2vei9sP","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01A43VshJsbaNpTxzVn9a4tc","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/front/README.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":162,"cache_read_input_tokens":51674,"output_tokens":27,"service_tier":"standard"}},"requestId":"req_011CS5YjYAYb8doVzfHCAAot","type":"assistant","uuid":"51c667bf-527b-4f54-ab8e-e9da1fbb1c53","timestamp":"2025-08-13T10:26:00.625Z"}
{"parentUuid":"51c667bf-527b-4f54-ab8e-e9da1fbb1c53","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01UkWv6NSQW6Rn7ZH2vei9sP","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_014eDiFWf9KmnTAWfUthxWQK","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/README.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":162,"cache_read_input_tokens":51674,"output_tokens":121,"service_tier":"standard"}},"requestId":"req_011CS5YjYAYb8doVzfHCAAot","type":"assistant","uuid":"84fe46b1-9be2-4662-b74b-610a3fb67cca","timestamp":"2025-08-13T10:26:00.804Z"}
{"parentUuid":"84fe46b1-9be2-4662-b74b-610a3fb67cca","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01A43VshJsbaNpTxzVn9a4tc","type":"tool_result","content":"     1→There is currently no frontend. Focus is on backend.\n     2→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"2cb9e851-def3-41ec-86d9-b805dab820ec","timestamp":"2025-08-13T10:26:00.858Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/front/README.md","content":"There is currently no frontend. Focus is on backend.\n","numLines":2,"startLine":1,"totalLines":2}}}
{"parentUuid":"2cb9e851-def3-41ec-86d9-b805dab820ec","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014eDiFWf9KmnTAWfUthxWQK","type":"tool_result","content":"     1→# Backend Code\n     2→\n     3→Core Go packages and code patterns for the Big Meanie trading system. This directory contains production-ready packages and reference implementations for building high-performance trading applications.\n     4→\n     5→## Structure\n     6→\n     7→```\n     8→back/\n     9→├── .docs/               # Documentation (hidden)\n    10→│   ├── archive/        # Historical docs (DO NOT REFERENCE)\n    11→│   ├── code/           # Developer guidelines\n    12→│   ├── pinescripts/    # TradingView source scripts (in .docs)\n    13→│   └── work-summary/   # Session records\n    14→├── .snippets/          # Code patterns and examples (hidden)\n    15→│   ├── context_patterns.go\n    16→│   ├── crash_recovery.go\n    17→│   ├── decimal_cache.go\n    18→│   ├── event_pipeline.go\n    19→│   ├── fees.go\n    20→│   ├── ledger.go\n    21→│   ├── optimized_worker.go\n    22→│   ├── param_generation.go\n    23→│   ├── sliding_window.go\n    24→│   └── strategy_registry.go\n    25→├── internal/           # Internal packages (currently empty)\n    26→├── pkg/                # Reusable Go packages\n    27→│   ├── clock/          # Time abstraction for testing\n    28→│   ├── decimal_math/   # High-precision math utilities\n    29→│   ├── errors/         # Structured error handling framework\n    30→│   ├── goroutine/      # Safe goroutine management for 24/7 operations\n    31→│   └── indicators/     # Technical analysis indicators\n    32→│       ├── common/     # Standard indicators (RSI, ATR, VWAP)\n    33→│       ├── pinescript/        # Advanced indicators (ZLTS, MTO, AVOP)\n    34→│       └── vol_delta/  # Volume delta calculations\n    35→└── README.md\n    36→```\n    37→\n    38→## Package Overview\n    39→\n    40→### Core Packages (pkg/)\n    41→\n    42→#### clock\n    43→Time abstraction layer enabling deterministic testing and time mocking. Essential for testing time-dependent logic without sleep statements.\n    44→\n    45→**Key Features**:\n    46→- Mockable time for unit tests\n    47→- Deterministic backtesting\n    48→- Simple interface (Now, Since, Until)\n    49→\n    50→#### decimal_math\n    51→Mathematical utilities for decimal operations, ensuring financial calculation accuracy without floating-point errors.\n    52→\n    53→**Key Features**:\n    54→- Square root calculation using Newton's method\n    55→- Standard deviation for risk metrics\n    56→- Downside deviation for Sortino ratio\n    57→- Full decimal precision throughout\n    58→\n    59→#### errors\n    60→Comprehensive error handling framework designed for trading operations with automatic retry detection and rich context.\n    61→\n    62→**Key Features**:\n    63→- Error categorization (Retryable, Connection, RateLimit, etc.)\n    64→- Trading context (symbol, order ID, etc.)\n    65→- ~27ns overhead for basic errors\n    66→- Stack traces for fatal errors\n    67→\n    68→#### goroutine\n    69→Production-ready goroutine management for 24/7 trading operations with panic recovery and automatic restart.\n    70→\n    71→**Key Features**:\n    72→- Panic recovery and logging\n    73→- Automatic restart with backoff\n    74→- Monitoring for periodic tasks\n    75→- Group management for related goroutines\n    76→- Global registry for centralized control\n    77→\n    78→#### indicators\n    79→Comprehensive technical analysis library with both standard and proprietary indicators.\n    80→\n    81→**Subpackages**:\n    82→- `common/` - Standard indicators (RSI, ATR, VWAP, etc.)\n    83→- `pinescript/` - Proprietary indicators (ZLTS, MTO, Liquidity Zones)\n    84→- `vol_delta/` - Volume delta for backtesting approximation methods (and accurate live trading methods when implemented)\n    85→\n    86→**Key Features**:\n    87→- Decimal precision throughout\n    88→- Caching for performance\n    89→- Extensible framework for custom indicators\n    90→\n    91→### Code Patterns (.snippets/)\n    92→\n    93→Reference implementations demonstrating solid Go patterns for trading systems. These are learning resources, not drop-in solutions - they need adaptation to your specific use case.\n    94→\n    95→#### Available Patterns:\n    96→- **context_patterns.go** - Context management for cancellation and timeouts\n    97→- **crash_recovery.go** - Robust crash recovery with 3-strikes rule\n    98→- **decimal_cache.go** - Performance optimization with cached decimal constants\n    99→- **event_pipeline.go** - Concurrent event-driven pipeline architecture\n   100→- **fees.go** - Fee calculation for spot and perpetual markets\n   101→- **ledger.go** - Double-entry bookkeeping for P&L tracking\n   102→- **optimized_worker.go** - CPU cache optimization patterns\n   103→- **param_generation.go** - Hash-based parameter generation with deduplication\n   104→- **sliding_window.go** - Efficient streaming calculations\n   105→- **strategy_registry.go** - Dynamic multi-strategy loading pattern\n   106→\n   107→## Quick Start\n   108→\n   109→### Using Packages\n   110→\n   111→```go\n   112→import (\n   113→    \"bigmeanie/pkg/clock\"\n   114→    \"bigmeanie/pkg/errors\"\n   115→    \"bigmeanie/pkg/goroutine\"\n   116→    \"bigmeanie/pkg/indicators/common\"\n   117→)\n   118→\n   119→// Time abstraction for testing\n   120→func NewService(c clock.Clock) *Service {\n   121→    return &Service{clock: c}\n   122→}\n   123→\n   124→// Structured error handling\n   125→if err := api.Call(); err != nil {\n   126→    return errors.Wrap(\"Service.Method\", errors.ErrTypeRetryable, err).\n   127→        WithSymbol(\"BTC-USD\")\n   128→}\n   129→\n   130→// Safe goroutine execution\n   131→goroutine.SafeGoWithRestart(ctx, \"price-feed\", fetchPrices, 5, backoff)\n   132→\n   133→// Technical indicators\n   134→rsi := common.NewRSI(series, 14)\n   135→signal := rsi.Calculate(series.LastIndex())\n   136→```\n   137→\n   138→### Learning from Snippets\n   139→\n   140→```go\n   141→// Study the pattern\n   142→// snippets/fees.go shows decimal-based fee calculation\n   143→\n   144→// Adapt to your needs\n   145→type MyExchangeFees struct {\n   146→    *FeeCalculator\n   147→    VIPTier int\n   148→    // Add exchange-specific fields\n   149→}\n   150→\n   151→// Implement your logic\n   152→func (f *MyExchangeFees) Calculate(order Order) decimal.Decimal {\n   153→    base := f.FeeCalculator.CalculateFee(...)\n   154→    // Apply exchange-specific logic\n   155→    return base.Mul(f.getVIPDiscount())\n   156→}\n   157→```\n   158→\n   159→## Design Principles\n   160→\n   161→### 1. Decimal Precision\n   162→All financial calculations use `shopspring/decimal` to avoid floating-point errors:\n   163→```go\n   164→// Good\n   165→price := decimal.NewFromFloat(100.50)\n   166→fee := price.Mul(decimal.NewFromFloat(0.001))\n   167→\n   168→// Bad - floating point errors\n   169→fee := 100.50 * 0.001\n   170→```\n   171→\n   172→### 2. Error Context\n   173→Rich error information for debugging production issues:\n   174→```go\n   175→return errors.Wrap(\"OrderService.Place\", errors.ErrTypeOrder, err).\n   176→    WithSymbol(order.Symbol).\n   177→    WithContext(\"orderID\", order.ID).\n   178→    WithContext(\"size\", order.Size)\n   179→```\n   180→\n   181→### 3. Testability\n   182→Interfaces and dependency injection for easy testing:\n   183→```go\n   184→type Service struct {\n   185→    clock clock.Clock        // Mockable time\n   186→    db    Database          // Interface, not concrete type\n   187→}\n   188→```\n   189→\n   190→### 4. 24/7 Resilience\n   191→Panic recovery and automatic restart for continuous operation:\n   192→```go\n   193→goroutine.SafeGoWithRestart(\n   194→    ctx,\n   195→    \"critical-service\",\n   196→    serviceFunc,\n   197→    -1, // infinite restarts\n   198→    exponentialBackoff,\n   199→)\n   200→```\n   201→\n   202→## Testing\n   203→\n   204→Each package includes comprehensive tests. Run all tests:\n   205→\n   206→```bash\n   207→go test ./pkg/...\n   208→```\n   209→\n   210→Run tests with coverage:\n   211→\n   212→```bash\n   213→go test -cover ./pkg/...\n   214→```\n   215→\n   216→## Performance Considerations\n   217→\n   218→1. **Caching**: Use `indicators.NewCached()` for expensive calculations\n   219→2. **Goroutines**: Use the goroutine package for panic safety\n   220→3. **Decimals**: Heavier than float64 but necessary for accuracy\n   221→4. **Error Context**: Minimal overhead (~45ns with context)\n   222→\n   223→## Contributing\n   224→\n   225→When adding new packages or patterns:\n   226→\n   227→1. **Document thoroughly** - Include README with examples\n   228→2. **Test comprehensively** - Aim for >80% coverage\n   229→3. **Use decimals** - No float64 for money calculations\n   230→4. **Handle errors** - Use the errors package for consistency\n   231→5. **Consider 24/7** - Design for continuous operation\n   232→\n   233→## Dependencies\n   234→\n   235→Core dependencies used across packages:\n   236→- `github.com/shopspring/decimal` - Arbitrary precision decimals\n   237→- Standard library only for most packages\n   238→\n   239→## License\n   240→\n   241→Part of the Big Meanie trading system. See main project license.\n   242→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"08b5eeda-26e0-42fe-8874-16078314cc64","timestamp":"2025-08-13T10:26:00.858Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/README.md","content":"# Backend Code\n\nCore Go packages and code patterns for the Big Meanie trading system. This directory contains production-ready packages and reference implementations for building high-performance trading applications.\n\n## Structure\n\n```\nback/\n├── .docs/               # Documentation (hidden)\n│   ├── archive/        # Historical docs (DO NOT REFERENCE)\n│   ├── code/           # Developer guidelines\n│   ├── pinescripts/    # TradingView source scripts (in .docs)\n│   └── work-summary/   # Session records\n├── .snippets/          # Code patterns and examples (hidden)\n│   ├── context_patterns.go\n│   ├── crash_recovery.go\n│   ├── decimal_cache.go\n│   ├── event_pipeline.go\n│   ├── fees.go\n│   ├── ledger.go\n│   ├── optimized_worker.go\n│   ├── param_generation.go\n│   ├── sliding_window.go\n│   └── strategy_registry.go\n├── internal/           # Internal packages (currently empty)\n├── pkg/                # Reusable Go packages\n│   ├── clock/          # Time abstraction for testing\n│   ├── decimal_math/   # High-precision math utilities\n│   ├── errors/         # Structured error handling framework\n│   ├── goroutine/      # Safe goroutine management for 24/7 operations\n│   └── indicators/     # Technical analysis indicators\n│       ├── common/     # Standard indicators (RSI, ATR, VWAP)\n│       ├── pinescript/        # Advanced indicators (ZLTS, MTO, AVOP)\n│       └── vol_delta/  # Volume delta calculations\n└── README.md\n```\n\n## Package Overview\n\n### Core Packages (pkg/)\n\n#### clock\nTime abstraction layer enabling deterministic testing and time mocking. Essential for testing time-dependent logic without sleep statements.\n\n**Key Features**:\n- Mockable time for unit tests\n- Deterministic backtesting\n- Simple interface (Now, Since, Until)\n\n#### decimal_math\nMathematical utilities for decimal operations, ensuring financial calculation accuracy without floating-point errors.\n\n**Key Features**:\n- Square root calculation using Newton's method\n- Standard deviation for risk metrics\n- Downside deviation for Sortino ratio\n- Full decimal precision throughout\n\n#### errors\nComprehensive error handling framework designed for trading operations with automatic retry detection and rich context.\n\n**Key Features**:\n- Error categorization (Retryable, Connection, RateLimit, etc.)\n- Trading context (symbol, order ID, etc.)\n- ~27ns overhead for basic errors\n- Stack traces for fatal errors\n\n#### goroutine\nProduction-ready goroutine management for 24/7 trading operations with panic recovery and automatic restart.\n\n**Key Features**:\n- Panic recovery and logging\n- Automatic restart with backoff\n- Monitoring for periodic tasks\n- Group management for related goroutines\n- Global registry for centralized control\n\n#### indicators\nComprehensive technical analysis library with both standard and proprietary indicators.\n\n**Subpackages**:\n- `common/` - Standard indicators (RSI, ATR, VWAP, etc.)\n- `pinescript/` - Proprietary indicators (ZLTS, MTO, Liquidity Zones)\n- `vol_delta/` - Volume delta for backtesting approximation methods (and accurate live trading methods when implemented)\n\n**Key Features**:\n- Decimal precision throughout\n- Caching for performance\n- Extensible framework for custom indicators\n\n### Code Patterns (.snippets/)\n\nReference implementations demonstrating solid Go patterns for trading systems. These are learning resources, not drop-in solutions - they need adaptation to your specific use case.\n\n#### Available Patterns:\n- **context_patterns.go** - Context management for cancellation and timeouts\n- **crash_recovery.go** - Robust crash recovery with 3-strikes rule\n- **decimal_cache.go** - Performance optimization with cached decimal constants\n- **event_pipeline.go** - Concurrent event-driven pipeline architecture\n- **fees.go** - Fee calculation for spot and perpetual markets\n- **ledger.go** - Double-entry bookkeeping for P&L tracking\n- **optimized_worker.go** - CPU cache optimization patterns\n- **param_generation.go** - Hash-based parameter generation with deduplication\n- **sliding_window.go** - Efficient streaming calculations\n- **strategy_registry.go** - Dynamic multi-strategy loading pattern\n\n## Quick Start\n\n### Using Packages\n\n```go\nimport (\n    \"bigmeanie/pkg/clock\"\n    \"bigmeanie/pkg/errors\"\n    \"bigmeanie/pkg/goroutine\"\n    \"bigmeanie/pkg/indicators/common\"\n)\n\n// Time abstraction for testing\nfunc NewService(c clock.Clock) *Service {\n    return &Service{clock: c}\n}\n\n// Structured error handling\nif err := api.Call(); err != nil {\n    return errors.Wrap(\"Service.Method\", errors.ErrTypeRetryable, err).\n        WithSymbol(\"BTC-USD\")\n}\n\n// Safe goroutine execution\ngoroutine.SafeGoWithRestart(ctx, \"price-feed\", fetchPrices, 5, backoff)\n\n// Technical indicators\nrsi := common.NewRSI(series, 14)\nsignal := rsi.Calculate(series.LastIndex())\n```\n\n### Learning from Snippets\n\n```go\n// Study the pattern\n// snippets/fees.go shows decimal-based fee calculation\n\n// Adapt to your needs\ntype MyExchangeFees struct {\n    *FeeCalculator\n    VIPTier int\n    // Add exchange-specific fields\n}\n\n// Implement your logic\nfunc (f *MyExchangeFees) Calculate(order Order) decimal.Decimal {\n    base := f.FeeCalculator.CalculateFee(...)\n    // Apply exchange-specific logic\n    return base.Mul(f.getVIPDiscount())\n}\n```\n\n## Design Principles\n\n### 1. Decimal Precision\nAll financial calculations use `shopspring/decimal` to avoid floating-point errors:\n```go\n// Good\nprice := decimal.NewFromFloat(100.50)\nfee := price.Mul(decimal.NewFromFloat(0.001))\n\n// Bad - floating point errors\nfee := 100.50 * 0.001\n```\n\n### 2. Error Context\nRich error information for debugging production issues:\n```go\nreturn errors.Wrap(\"OrderService.Place\", errors.ErrTypeOrder, err).\n    WithSymbol(order.Symbol).\n    WithContext(\"orderID\", order.ID).\n    WithContext(\"size\", order.Size)\n```\n\n### 3. Testability\nInterfaces and dependency injection for easy testing:\n```go\ntype Service struct {\n    clock clock.Clock        // Mockable time\n    db    Database          // Interface, not concrete type\n}\n```\n\n### 4. 24/7 Resilience\nPanic recovery and automatic restart for continuous operation:\n```go\ngoroutine.SafeGoWithRestart(\n    ctx,\n    \"critical-service\",\n    serviceFunc,\n    -1, // infinite restarts\n    exponentialBackoff,\n)\n```\n\n## Testing\n\nEach package includes comprehensive tests. Run all tests:\n\n```bash\ngo test ./pkg/...\n```\n\nRun tests with coverage:\n\n```bash\ngo test -cover ./pkg/...\n```\n\n## Performance Considerations\n\n1. **Caching**: Use `indicators.NewCached()` for expensive calculations\n2. **Goroutines**: Use the goroutine package for panic safety\n3. **Decimals**: Heavier than float64 but necessary for accuracy\n4. **Error Context**: Minimal overhead (~45ns with context)\n\n## Contributing\n\nWhen adding new packages or patterns:\n\n1. **Document thoroughly** - Include README with examples\n2. **Test comprehensively** - Aim for >80% coverage\n3. **Use decimals** - No float64 for money calculations\n4. **Handle errors** - Use the errors package for consistency\n5. **Consider 24/7** - Design for continuous operation\n\n## Dependencies\n\nCore dependencies used across packages:\n- `github.com/shopspring/decimal` - Arbitrary precision decimals\n- Standard library only for most packages\n\n## License\n\nPart of the Big Meanie trading system. See main project license.\n","numLines":242,"startLine":1,"totalLines":242}}}
{"parentUuid":"08b5eeda-26e0-42fe-8874-16078314cc64","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01MSQ91enMMyMo4LSM2yB2tM","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"**Big Meanie Trading System** - 24/7 cryptocurrency trading bot built in Go\n\n## Project Overview\n\n**Architecture**: Go-based trading bot leveraging Go's concurrency for maximum performance\n- **Multi-exchange support**: Spot, futures, and perpetual trading\n- **Feature parity**: Backtesting and live trading environments  \n- **Technical indicators**: Custom strategies with decimal precision\n- **24/7 operations**: Graceful shutdown, panic recovery, automatic restart\n\n## Key Structure\n\n- **`/back`**: Core Go packages and trading system backend\n- **`/front`**: Frontend (currently empty - backend focus)  \n- **`/backend-code`**: Legacy codebase (marked for deletion in git status)\n- **`/backend-docs`**: Documentation build artifacts\n\n## Core Packages (`back/pkg/`)\n\n- **`clock`**: Time abstraction for deterministic testing/backtesting\n- **`decimal_math`**: High-precision financial calculations  \n- **`errors`**: Structured error handling with trading context (~27ns overhead)\n- **`goroutine`**: 24/7 panic recovery and restart management\n- **`indicators`**: Technical analysis library\n  - `common/`: Standard indicators (RSI, ATR, VWAP)\n  - `pinescript/`: Proprietary indicators (ZLTS, MTO, Liquidity Zones) \n  - `vol_delta/`: Volume delta approximations for backtesting\n\n## Agent Delegation\n\n- **gad** → Architecture/design decisions  \n- **god** → Go code implementation\n- **Main Claude** → Project management, docs, git ops\n\n## Current Status\n\nRestructuring in progress - cleaning up legacy `backend-code` directory and consolidating into `back/` structure. Focus on decimal precision, 24/7 resilience, and comprehensive testing."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":3087,"cache_read_input_tokens":51836,"output_tokens":423,"service_tier":"standard"}},"requestId":"req_011CS5YjpJtoYynXRGJpgTG2","type":"assistant","uuid":"dbacabd5-c06e-492f-aedb-1ad0d58e1b23","timestamp":"2025-08-13T10:26:11.953Z"}
{"parentUuid":"dbacabd5-c06e-492f-aedb-1ad0d58e1b23","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"system","content":"\u001b[1mStop\u001b[22m [paplay /run/current-system/sw/share/sounds/freedesktop/stereo/bell.oga] completed successfully","isMeta":false,"timestamp":"2025-08-13T10:26:12.289Z","uuid":"20cb0948-ac5d-4115-99f9-bf8dd2bbf322","toolUseID":"7ee2e9d4-a111-4d97-a4cd-328909fae346","level":"info"}
{"parentUuid":"20cb0948-ac5d-4115-99f9-bf8dd2bbf322","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":"/god review /back/.docs/code files for acurracy and gaps"},"uuid":"d61ff890-6e1b-45b1-a45a-e3d811dac2a0","timestamp":"2025-08-13T10:27:36.887Z"}
{"parentUuid":"d61ff890-6e1b-45b1-a45a-e3d811dac2a0","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01DSUjPqqAoop3PUUq2aJyK7","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_017192VtHanSr51KikLzgA53","name":"Task","input":{"subagent_type":"god","description":"Review code documentation files","prompt":"Review all files in /home/aural/Code/bigmeanie/back/.docs/code/ for accuracy and identify any gaps in the documentation. \n\nSpecifically:\n1. Check if the documented practices align with actual code patterns in the /back/pkg/ directory\n2. Identify any outdated information or inconsistencies\n3. Look for missing documentation that would help developers understand the codebase\n4. Verify that examples and code snippets are correct and follow the project's conventions\n5. Note any areas where additional documentation would be beneficial\n\nPlease provide a comprehensive review with specific recommendations for improvements or additions needed."}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":446,"cache_read_input_tokens":54923,"output_tokens":223,"service_tier":"standard"}},"requestId":"req_011CS5YrufoaV2B1L9Q5Bx9C","type":"assistant","uuid":"7f6025f4-573d-4aa6-8b58-bce7f23c1ca1","timestamp":"2025-08-13T10:27:43.563Z"}
{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":"Review all files in /home/aural/Code/bigmeanie/back/.docs/code/ for accuracy and identify any gaps in the documentation. \n\nSpecifically:\n1. Check if the documented practices align with actual code patterns in the /back/pkg/ directory\n2. Identify any outdated information or inconsistencies\n3. Look for missing documentation that would help developers understand the codebase\n4. Verify that examples and code snippets are correct and follow the project's conventions\n5. Note any areas where additional documentation would be beneficial\n\nPlease provide a comprehensive review with specific recommendations for improvements or additions needed."},"uuid":"e132e954-232f-42c2-8475-746129ff7a51","timestamp":"2025-08-13T10:27:43.617Z"}
{"parentUuid":"e132e954-232f-42c2-8475-746129ff7a51","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01Mnxw8X1g2JFBhd5oKMADTD","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"text","text":"I'll review the documentation files in `/home/aural/Code/bigmeanie/back/.docs/code/` and compare them against the actual codebase to identify gaps and inconsistencies. Let me start by examining what documentation exists and then validate it against the actual code."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":1558,"cache_read_input_tokens":30920,"output_tokens":166,"service_tier":"standard"}},"requestId":"req_011CS5YsQ1su14bigZnWi2cU","type":"assistant","uuid":"7eb4a832-2ec7-4ba1-b1d6-d7b3d88b2fa0","timestamp":"2025-08-13T10:27:48.099Z"}
{"parentUuid":"7eb4a832-2ec7-4ba1-b1d6-d7b3d88b2fa0","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01Mnxw8X1g2JFBhd5oKMADTD","type":"message","role":"assistant","model":"claude-opus-4-1-20250805","content":[{"type":"tool_use","id":"toolu_018iSBrTr896Xk9K8qX5Pzxf","name":"Bash","input":{"command":"find /home/aural/Code/bigmeanie/back/.docs/code/ -type f -name \"*.md\" | head -20","description":"List documentation files in code directory"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":1558,"cache_read_input_tokens":30920,"output_tokens":166,"service_tier":"standard"}},"requestId":"req_011CS5YsQ1su14bigZnWi2cU","type":"assistant","uuid":"bdffad06-9e16-4138-913e-c0ddcb833452","timestamp":"2025-08-13T10:27:49.356Z"}
{"parentUuid":"bdffad06-9e16-4138-913e-c0ddcb833452","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018iSBrTr896Xk9K8qX5Pzxf","type":"tool_result","content":"/home/aural/Code/bigmeanie/back/.docs/code/errors.md\n/home/aural/Code/bigmeanie/back/.docs/code/fundamentals.md\n/home/aural/Code/bigmeanie/back/.docs/code/decimal-patterns.md\n/home/aural/Code/bigmeanie/back/.docs/code/design-patterns.md\n/home/aural/Code/bigmeanie/back/.docs/code/api-patterns.md\n/home/aural/Code/bigmeanie/back/.docs/code/packages.md\n/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md\n/home/aural/Code/bigmeanie/back/.docs/code/concurrency.md\n/home/aural/Code/bigmeanie/back/.docs/code/database-patterns.md\n/home/aural/Code/bigmeanie/back/.docs/code/testing.md\n/home/aural/Code/bigmeanie/back/.docs/code/performance.md","is_error":false}]},"uuid":"47ddbb2f-4e5d-4d81-8681-45dc866010bd","timestamp":"2025-08-13T10:27:49.401Z","toolUseResult":{"stdout":"/home/aural/Code/bigmeanie/back/.docs/code/errors.md\n/home/aural/Code/bigmeanie/back/.docs/code/fundamentals.md\n/home/aural/Code/bigmeanie/back/.docs/code/decimal-patterns.md\n/home/aural/Code/bigmeanie/back/.docs/code/design-patterns.md\n/home/aural/Code/bigmeanie/back/.docs/code/api-patterns.md\n/home/aural/Code/bigmeanie/back/.docs/code/packages.md\n/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md\n/home/aural/Code/bigmeanie/back/.docs/code/concurrency.md\n/home/aural/Code/bigmeanie/back/.docs/code/database-patterns.md\n/home/aural/Code/bigmeanie/back/.docs/code/testing.md\n/home/aural/Code/bigmeanie/back/.docs/code/performance.md","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"47ddbb2f-4e5d-4d81-8681-45dc866010bd","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01RZQogiUY3WyUSgBM5b6LAz","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_018jwzvnemyyyQD5nMs1xAS4","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/fundamentals.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":32905,"cache_read_input_tokens":0,"output_tokens":302,"service_tier":"standard"}},"requestId":"req_011CS5YsqfyJffgNNLyWwzCk","type":"assistant","uuid":"076705f2-d943-47dc-9d32-eaadf6c36ef6","timestamp":"2025-08-13T10:27:52.837Z"}
{"parentUuid":"076705f2-d943-47dc-9d32-eaadf6c36ef6","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01RZQogiUY3WyUSgBM5b6LAz","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01CSZcK9k2oC2owHCp4kMZL7","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/decimal-patterns.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":32905,"cache_read_input_tokens":0,"output_tokens":302,"service_tier":"standard"}},"requestId":"req_011CS5YsqfyJffgNNLyWwzCk","type":"assistant","uuid":"e9e9b52c-7ac7-4d10-bb13-ee8fcb320f5b","timestamp":"2025-08-13T10:27:53.443Z"}
{"parentUuid":"e9e9b52c-7ac7-4d10-bb13-ee8fcb320f5b","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01RZQogiUY3WyUSgBM5b6LAz","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_0197EZKCMLbD7EMx5AAB2miP","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":32905,"cache_read_input_tokens":0,"output_tokens":302,"service_tier":"standard"}},"requestId":"req_011CS5YsqfyJffgNNLyWwzCk","type":"assistant","uuid":"be81859a-df03-4992-9a72-1489be55698c","timestamp":"2025-08-13T10:27:53.940Z"}
{"parentUuid":"be81859a-df03-4992-9a72-1489be55698c","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01RZQogiUY3WyUSgBM5b6LAz","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01RKCVzPdMdNNUKy2SxjFy2P","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/packages.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":32905,"cache_read_input_tokens":0,"output_tokens":302,"service_tier":"standard"}},"requestId":"req_011CS5YsqfyJffgNNLyWwzCk","type":"assistant","uuid":"84b1aa70-e98c-4d06-ba61-038467013b65","timestamp":"2025-08-13T10:27:54.915Z"}
{"parentUuid":"84b1aa70-e98c-4d06-ba61-038467013b65","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01RZQogiUY3WyUSgBM5b6LAz","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01DkrAkqu3Zf3uoD4HP3bSSe","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/testing.md"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":32905,"cache_read_input_tokens":0,"output_tokens":302,"service_tier":"standard"}},"requestId":"req_011CS5YsqfyJffgNNLyWwzCk","type":"assistant","uuid":"8b76fd01-c600-4ec6-b971-b1d778fc664d","timestamp":"2025-08-13T10:27:54.920Z"}
{"parentUuid":"8b76fd01-c600-4ec6-b971-b1d778fc664d","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CSZcK9k2oC2owHCp4kMZL7","type":"tool_result","content":"     1→# Decimal Patterns - shopspring/decimal for Financial Calculations\n     2→\n     3→## Overview\n     4→\n     5→Big Meanie uses shopspring/decimal for ALL numeric operations involving money, prices, quantities, and percentages. This ensures exact decimal arithmetic without floating-point rounding errors that could cost real money in trading operations.\n     6→\n     7→## Table of Contents\n     8→1. [Core Principles](#core-principles)\n     9→2. [Basic Operations](#basic-operations)\n    10→3. [Trading-Specific Patterns](#trading-specific-patterns)\n    11→4. [Common Gotchas](#common-gotchas)\n    12→5. [Performance Considerations](#performance-considerations)\n    13→6. [Best Practices](#best-practices)\n    14→\n    15→## Core Principles\n    16→\n    17→```go\n    18→import \"github.com/shopspring/decimal\"\n    19→\n    20→// NEVER use float64 for financial calculations\n    21→// BAD\n    22→price := 100.123  // float64 - NEVER DO THIS\n    23→total := price * 1.5\n    24→\n    25→// GOOD\n    26→price := decimal.NewFromFloat(100.123)\n    27→total := price.Mul(decimal.NewFromFloat(1.5))\n    28→\n    29→// BETTER - avoid float entirely\n    30→price := decimal.RequireFromString(\"100.123\")\n    31→multiplier := decimal.RequireFromString(\"1.5\")\n    32→total := price.Mul(multiplier)\n    33→```\n    34→\n    35→## Basic Operations\n    36→\n    37→### Creation and Initialization\n    38→\n    39→```go\n    40→// From string (PREFERRED for literals)\n    41→price := decimal.RequireFromString(\"123.456789\")\n    42→\n    43→// From int\n    44→quantity := decimal.NewFromInt(100)\n    45→\n    46→// From float (ONLY when interfacing with external APIs)\n    47→// Always validate precision after conversion\n    48→apiPrice := decimal.NewFromFloat(apiResponse.Price)\n    49→if apiPrice.Exponent() < -8 {\n    50→    // Handle precision loss\n    51→}\n    52→\n    53→// Zero and common values\n    54→zero := decimal.Zero\n    55→one := decimal.NewFromInt(1)\n    56→hundred := decimal.NewFromInt(100)\n    57→```\n    58→\n    59→### Arithmetic Operations\n    60→\n    61→```go\n    62→// All operations return new decimals (immutable)\n    63→a := decimal.RequireFromString(\"100.50\")\n    64→b := decimal.RequireFromString(\"25.25\")\n    65→\n    66→sum := a.Add(b)           // 125.75\n    67→diff := a.Sub(b)          // 75.25\n    68→product := a.Mul(b)       // 2537.625\n    69→quotient := a.Div(b)      // 3.98...\n    70→\n    71→// Chaining operations\n    72→total := price.Mul(quantity).Add(fee).Sub(discount)\n    73→\n    74→// Percentage calculations\n    75→price := decimal.RequireFromString(\"100\")\n    76→taxRate := decimal.RequireFromString(\"0.08\") // 8%\n    77→tax := price.Mul(taxRate)\n    78→totalWithTax := price.Add(tax)\n    79→\n    80→// Or as percentage\n    81→pct := decimal.RequireFromString(\"8\")\n    82→tax = price.Mul(pct).Div(decimal.NewFromInt(100))\n    83→```\n    84→\n    85→### Comparisons\n    86→\n    87→```go\n    88→a := decimal.RequireFromString(\"100.01\")\n    89→b := decimal.RequireFromString(\"100.02\")\n    90→\n    91→if a.Equal(b) {\n    92→    // Exact equality\n    93→}\n    94→\n    95→if a.LessThan(b) {\n    96→    // a < b\n    97→}\n    98→\n    99→if a.LessThanOrEqual(b) {\n   100→    // a <= b\n   101→}\n   102→\n   103→if a.GreaterThan(b) {\n   104→    // a > b\n   105→}\n   106→\n   107→if a.GreaterThanOrEqual(b) {\n   108→    // a >= b\n   109→}\n   110→\n   111→// Compare with zero\n   112→if balance.IsPositive() {\n   113→    // balance > 0\n   114→}\n   115→\n   116→if balance.IsNegative() {\n   117→    // balance < 0\n   118→}\n   119→\n   120→if balance.IsZero() {\n   121→    // balance == 0\n   122→}\n   123→\n   124→// Sign check\n   125→sign := amount.Sign() // Returns -1, 0, or 1\n   126→```\n   127→\n   128→## Trading-Specific Patterns\n   129→\n   130→### Price and Quantity Handling\n   131→\n   132→```go\n   133→type Order struct {\n   134→    Price    decimal.Decimal\n   135→    Quantity decimal.Decimal\n   136→    Side     string\n   137→}\n   138→\n   139→// Calculate order value\n   140→func (o Order) Value() decimal.Decimal {\n   141→    return o.Price.Mul(o.Quantity)\n   142→}\n   143→\n   144→// Apply trading fees\n   145→func (o Order) TotalWithFee(feeRate decimal.Decimal) decimal.Decimal {\n   146→    value := o.Value()\n   147→    fee := value.Mul(feeRate)\n   148→    \n   149→    if o.Side == \"BUY\" {\n   150→        return value.Add(fee)\n   151→    }\n   152→    return value.Sub(fee)\n   153→}\n   154→\n   155→// Price tick rounding\n   156→func RoundToTick(price, tickSize decimal.Decimal) decimal.Decimal {\n   157→    if tickSize.IsZero() {\n   158→        return price\n   159→    }\n   160→    return price.Div(tickSize).Round(0).Mul(tickSize)\n   161→}\n   162→```\n   163→\n   164→### Portfolio Calculations\n   165→\n   166→```go\n   167→type Position struct {\n   168→    Symbol   string\n   169→    Quantity decimal.Decimal\n   170→    AvgPrice decimal.Decimal\n   171→}\n   172→\n   173→// Calculate position value\n   174→func (p Position) Value(currentPrice decimal.Decimal) decimal.Decimal {\n   175→    return p.Quantity.Mul(currentPrice)\n   176→}\n   177→\n   178→// Calculate P&L\n   179→func (p Position) PnL(currentPrice decimal.Decimal) decimal.Decimal {\n   180→    currentValue := p.Value(currentPrice)\n   181→    costBasis := p.Quantity.Mul(p.AvgPrice)\n   182→    return currentValue.Sub(costBasis)\n   183→}\n   184→\n   185→// Calculate P&L percentage\n   186→func (p Position) PnLPercent(currentPrice decimal.Decimal) decimal.Decimal {\n   187→    if p.AvgPrice.IsZero() {\n   188→        return decimal.Zero\n   189→    }\n   190→    \n   191→    pnl := currentPrice.Sub(p.AvgPrice)\n   192→    return pnl.Div(p.AvgPrice).Mul(decimal.NewFromInt(100))\n   193→}\n   194→\n   195→// Portfolio totals\n   196→func CalculatePortfolioValue(positions []Position, prices map[string]decimal.Decimal) decimal.Decimal {\n   197→    total := decimal.Zero\n   198→    \n   199→    for _, pos := range positions {\n   200→        if price, ok := prices[pos.Symbol]; ok {\n   201→            total = total.Add(pos.Value(price))\n   202→        }\n   203→    }\n   204→    \n   205→    return total\n   206→}\n   207→```\n   208→\n   209→### Technical Indicators\n   210→\n   211→```go\n   212→// Moving average with decimal precision\n   213→func SMA(prices []decimal.Decimal, period int) decimal.Decimal {\n   214→    if len(prices) < period {\n   215→        return decimal.Zero\n   216→    }\n   217→    \n   218→    sum := decimal.Zero\n   219→    for i := len(prices) - period; i < len(prices); i++ {\n   220→        sum = sum.Add(prices[i])\n   221→    }\n   222→    \n   223→    return sum.Div(decimal.NewFromInt(int64(period)))\n   224→}\n   225→\n   226→// RSI calculation\n   227→func RSI(prices []decimal.Decimal, period int) decimal.Decimal {\n   228→    if len(prices) < period+1 {\n   229→        return decimal.Zero\n   230→    }\n   231→    \n   232→    gains := decimal.Zero\n   233→    losses := decimal.Zero\n   234→    \n   235→    for i := len(prices) - period; i < len(prices); i++ {\n   236→        diff := prices[i].Sub(prices[i-1])\n   237→        if diff.IsPositive() {\n   238→            gains = gains.Add(diff)\n   239→        } else {\n   240→            losses = losses.Add(diff.Abs())\n   241→        }\n   242→    }\n   243→    \n   244→    avgGain := gains.Div(decimal.NewFromInt(int64(period)))\n   245→    avgLoss := losses.Div(decimal.NewFromInt(int64(period)))\n   246→    \n   247→    if avgLoss.IsZero() {\n   248→        return decimal.NewFromInt(100)\n   249→    }\n   250→    \n   251→    rs := avgGain.Div(avgLoss)\n   252→    rsi := decimal.NewFromInt(100).Sub(\n   253→        decimal.NewFromInt(100).Div(\n   254→            decimal.NewFromInt(1).Add(rs),\n   255→        ),\n   256→    )\n   257→    \n   258→    return rsi\n   259→}\n   260→```\n   261→\n   262→### Risk Management\n   263→\n   264→```go\n   265→// Position sizing with Kelly Criterion\n   266→func KellySize(winProb, winSize, lossSize decimal.Decimal) decimal.Decimal {\n   267→    if lossSize.IsZero() {\n   268→        return decimal.Zero\n   269→    }\n   270→    \n   271→    // f = (p * b - q) / b\n   272→    // where p = win probability, q = loss probability, b = win/loss ratio\n   273→    q := decimal.NewFromInt(1).Sub(winProb)\n   274→    b := winSize.Div(lossSize)\n   275→    \n   276→    numerator := winProb.Mul(b).Sub(q)\n   277→    kelly := numerator.Div(b)\n   278→    \n   279→    // Never risk more than 25% (Kelly can suggest aggressive sizes)\n   280→    maxSize := decimal.RequireFromString(\"0.25\")\n   281→    if kelly.GreaterThan(maxSize) {\n   282→        return maxSize\n   283→    }\n   284→    \n   285→    if kelly.IsNegative() {\n   286→        return decimal.Zero\n   287→    }\n   288→    \n   289→    return kelly\n   290→}\n   291→\n   292→// Stop loss calculation\n   293→func CalculateStopLoss(entry, riskPercent decimal.Decimal, side string) decimal.Decimal {\n   294→    risk := entry.Mul(riskPercent).Div(decimal.NewFromInt(100))\n   295→    \n   296→    if side == \"LONG\" {\n   297→        return entry.Sub(risk)\n   298→    }\n   299→    return entry.Add(risk) // SHORT position\n   300→}\n   301→\n   302→// Position size from risk amount\n   303→func PositionSizeFromRisk(riskAmount, entry, stopLoss decimal.Decimal) decimal.Decimal {\n   304→    riskPerUnit := entry.Sub(stopLoss).Abs()\n   305→    if riskPerUnit.IsZero() {\n   306→        return decimal.Zero\n   307→    }\n   308→    \n   309→    return riskAmount.Div(riskPerUnit)\n   310→}\n   311→```\n   312→\n   313→## Common Gotchas\n   314→\n   315→### 1. Division by Zero\n   316→\n   317→```go\n   318→// ALWAYS check for zero before division\n   319→func SafeDivide(a, b decimal.Decimal) decimal.Decimal {\n   320→    if b.IsZero() {\n   321→        return decimal.Zero // or handle error appropriately\n   322→    }\n   323→    return a.Div(b)\n   324→}\n   325→\n   326→// In ratio calculations\n   327→func PriceToEarnings(price, earnings decimal.Decimal) decimal.Decimal {\n   328→    if earnings.IsZero() || earnings.IsNegative() {\n   329→        return decimal.NewFromInt(-1) // Indicate N/A\n   330→    }\n   331→    return price.Div(earnings)\n   332→}\n   333→```\n   334→\n   335→### 2. Precision and Rounding\n   336→\n   337→```go\n   338→// Round to specific decimal places\n   339→price := decimal.RequireFromString(\"123.456789\")\n   340→rounded := price.Round(2) // 123.46\n   341→\n   342→// Round for display vs calculation\n   343→type Price struct {\n   344→    value decimal.Decimal\n   345→}\n   346→\n   347→func (p Price) Display() string {\n   348→    // Round to 2 places for display\n   349→    return p.value.Round(2).String()\n   350→}\n   351→\n   352→func (p Price) Calculate() decimal.Decimal {\n   353→    // Keep full precision for calculations\n   354→    return p.value\n   355→}\n   356→\n   357→// Exchange-specific precision\n   358→func FormatForExchange(price decimal.Decimal, exchange string) string {\n   359→    precisions := map[string]int32{\n   360→        \"binance\":  8,\n   361→        \"coinbase\": 2,\n   362→        \"kraken\":   5,\n   363→    }\n   364→    \n   365→    precision := precisions[exchange]\n   366→    return price.Round(precision).String()\n   367→}\n   368→```\n   369→\n   370→### 3. String Conversion Errors\n   371→\n   372→```go\n   373→// Always handle string parsing errors\n   374→func ParsePrice(s string) (decimal.Decimal, error) {\n   375→    price, err := decimal.NewFromString(s)\n   376→    if err != nil {\n   377→        return decimal.Zero, fmt.Errorf(\"invalid price format: %w\", err)\n   378→    }\n   379→    \n   380→    // Validate reasonable bounds\n   381→    maxPrice := decimal.NewFromInt(1000000)\n   382→    if price.IsNegative() || price.GreaterThan(maxPrice) {\n   383→        return decimal.Zero, fmt.Errorf(\"price out of bounds: %s\", s)\n   384→    }\n   385→    \n   386→    return price, nil\n   387→}\n   388→\n   389→// Use RequireFromString only with hardcoded values\n   390→const FeeRate = \"0.001\" // 0.1%\n   391→var TradingFee = decimal.RequireFromString(FeeRate)\n   392→```\n   393→\n   394→### 4. JSON Marshaling\n   395→\n   396→```go\n   397→// Decimal fields in JSON\n   398→type Trade struct {\n   399→    ID       string          `json:\"id\"`\n   400→    Price    decimal.Decimal `json:\"price\"`\n   401→    Quantity decimal.Decimal `json:\"quantity\"`\n   402→    Total    decimal.Decimal `json:\"total\"`\n   403→}\n   404→\n   405→// Custom JSON handling if needed\n   406→func (t Trade) MarshalJSON() ([]byte, error) {\n   407→    type Alias Trade\n   408→    return json.Marshal(&struct {\n   409→        Price    string `json:\"price\"`\n   410→        Quantity string `json:\"quantity\"`\n   411→        Total    string `json:\"total\"`\n   412→        *Alias\n   413→    }{\n   414→        Price:    t.Price.String(),\n   415→        Quantity: t.Quantity.String(),\n   416→        Total:    t.Total.String(),\n   417→        Alias:    (*Alias)(&t),\n   418→    })\n   419→}\n   420→```\n   421→\n   422→### 5. Database Storage\n   423→\n   424→```go\n   425→// Store as DECIMAL or NUMERIC in PostgreSQL\n   426→CREATE TABLE trades (\n   427→    id         SERIAL PRIMARY KEY,\n   428→    price      DECIMAL(20, 8) NOT NULL,\n   429→    quantity   DECIMAL(20, 8) NOT NULL,\n   430→    total      DECIMAL(20, 8) NOT NULL,\n   431→    fee        DECIMAL(20, 8) DEFAULT 0\n   432→);\n   433→\n   434→// In Go with sqlx/pgx\n   435→func SaveTrade(db *sql.DB, trade Trade) error {\n   436→    query := `\n   437→        INSERT INTO trades (price, quantity, total)\n   438→        VALUES ($1, $2, $3)\n   439→    `\n   440→    _, err := db.Exec(query, \n   441→        trade.Price.String(),\n   442→        trade.Quantity.String(),\n   443→        trade.Total.String(),\n   444→    )\n   445→    return err\n   446→}\n   447→```\n   448→\n   449→## Performance Considerations\n   450→\n   451→### Memory Allocation\n   452→\n   453→```go\n   454→// Reuse decimal values when possible\n   455→var (\n   456→    // Common constants\n   457→    Zero     = decimal.Zero\n   458→    One      = decimal.NewFromInt(1)\n   459→    Hundred  = decimal.NewFromInt(100)\n   460→    Thousand = decimal.NewFromInt(1000)\n   461→)\n   462→\n   463→// Avoid creating new decimals in hot paths\n   464→type Calculator struct {\n   465→    // Pre-allocated decimals\n   466→    hundred  decimal.Decimal\n   467→    feeRate  decimal.Decimal\n   468→    tickSize decimal.Decimal\n   469→}\n   470→\n   471→func NewCalculator() *Calculator {\n   472→    return &Calculator{\n   473→        hundred:  decimal.NewFromInt(100),\n   474→        feeRate:  decimal.RequireFromString(\"0.001\"),\n   475→        tickSize: decimal.RequireFromString(\"0.01\"),\n   476→    }\n   477→}\n   478→```\n   479→\n   480→### Batch Operations\n   481→\n   482→```go\n   483→// Process multiple calculations efficiently\n   484→func CalculateTotals(trades []Trade) decimal.Decimal {\n   485→    total := decimal.Zero\n   486→    \n   487→    // Single allocation for all iterations\n   488→    for i := range trades {\n   489→        total = total.Add(trades[i].Price.Mul(trades[i].Quantity))\n   490→    }\n   491→    \n   492→    return total\n   493→}\n   494→\n   495→// Parallel processing for large datasets\n   496→func ParallelSum(values []decimal.Decimal) decimal.Decimal {\n   497→    if len(values) < 1000 {\n   498→        // Serial for small datasets\n   499→        sum := decimal.Zero\n   500→        for _, v := range values {\n   501→            sum = sum.Add(v)\n   502→        }\n   503→        return sum\n   504→    }\n   505→    \n   506→    // Parallel for large datasets\n   507→    numWorkers := runtime.NumCPU()\n   508→    chunkSize := len(values) / numWorkers\n   509→    results := make(chan decimal.Decimal, numWorkers)\n   510→    \n   511→    for i := 0; i < numWorkers; i++ {\n   512→        start := i * chunkSize\n   513→        end := start + chunkSize\n   514→        if i == numWorkers-1 {\n   515→            end = len(values)\n   516→        }\n   517→        \n   518→        go func(chunk []decimal.Decimal) {\n   519→            sum := decimal.Zero\n   520→            for _, v := range chunk {\n   521→                sum = sum.Add(v)\n   522→            }\n   523→            results <- sum\n   524→        }(values[start:end])\n   525→    }\n   526→    \n   527→    total := decimal.Zero\n   528→    for i := 0; i < numWorkers; i++ {\n   529→        total = total.Add(<-results)\n   530→    }\n   531→    \n   532→    return total\n   533→}\n   534→```\n   535→\n   536→## Best Practices\n   537→\n   538→### 1. Type Safety\n   539→\n   540→```go\n   541→// Create domain types for different decimal uses\n   542→type Price decimal.Decimal\n   543→type Quantity decimal.Decimal\n   544→type Percentage decimal.Decimal\n   545→\n   546→func (p Price) Mul(q Quantity) decimal.Decimal {\n   547→    return decimal.Decimal(p).Mul(decimal.Decimal(q))\n   548→}\n   549→\n   550→// This prevents mixing incompatible types\n   551→// price.Mul(percentage) // Compile error!\n   552→```\n   553→\n   554→### 2. Validation\n   555→\n   556→```go\n   557→func ValidateOrderParams(price, quantity decimal.Decimal) error {\n   558→    if price.IsNegative() || price.IsZero() {\n   559→        return fmt.Errorf(\"invalid price: %s\", price)\n   560→    }\n   561→    \n   562→    if quantity.IsNegative() || quantity.IsZero() {\n   563→        return fmt.Errorf(\"invalid quantity: %s\", quantity)\n   564→    }\n   565→    \n   566→    minNotional := decimal.NewFromInt(10)\n   567→    if price.Mul(quantity).LessThan(minNotional) {\n   568→        return fmt.Errorf(\"order value below minimum: %s\", price.Mul(quantity))\n   569→    }\n   570→    \n   571→    return nil\n   572→}\n   573→```\n   574→\n   575→### 3. Constants\n   576→\n   577→```go\n   578→// Define reusable constants\n   579→var (\n   580→    BasisPoint = decimal.RequireFromString(\"0.0001\")  // 0.01%\n   581→    Percentage = decimal.RequireFromString(\"0.01\")    // 1%\n   582→    \n   583→    MaxLeverage = decimal.NewFromInt(10)\n   584→    MinOrderSize = decimal.RequireFromString(\"0.001\")\n   585→    \n   586→    MakerFee = decimal.RequireFromString(\"0.001\")     // 0.1%\n   587→    TakerFee = decimal.RequireFromString(\"0.0015\")    // 0.15%\n   588→)\n   589→```\n   590→\n   591→### 4. Error Handling\n   592→\n   593→```go\n   594→// Always validate external inputs\n   595→func ProcessTradeRequest(req TradeRequest) error {\n   596→    price, err := decimal.NewFromString(req.Price)\n   597→    if err != nil {\n   598→        return fmt.Errorf(\"invalid price: %w\", err)\n   599→    }\n   600→    \n   601→    quantity, err := decimal.NewFromString(req.Quantity)\n   602→    if err != nil {\n   603→        return fmt.Errorf(\"invalid quantity: %w\", err)\n   604→    }\n   605→    \n   606→    // Validate business rules\n   607→    if err := ValidateOrderParams(price, quantity); err != nil {\n   608→        return err\n   609→    }\n   610→    \n   611→    // Process trade...\n   612→    return nil\n   613→}\n   614→```\n   615→\n   616→### 5. Testing\n   617→\n   618→```go\n   619→func TestPriceCalculation(t *testing.T) {\n   620→    tests := []struct {\n   621→        name     string\n   622→        price    string\n   623→        quantity string\n   624→        expected string\n   625→    }{\n   626→        {\n   627→            name:     \"simple multiplication\",\n   628→            price:    \"100.50\",\n   629→            quantity: \"2.5\",\n   630→            expected: \"251.25\",\n   631→        },\n   632→        {\n   633→            name:     \"precision handling\",\n   634→            price:    \"0.00000001\",\n   635→            quantity: \"100000000\",\n   636→            expected: \"1\",\n   637→        },\n   638→    }\n   639→    \n   640→    for _, tt := range tests {\n   641→        t.Run(tt.name, func(t *testing.T) {\n   642→            price := decimal.RequireFromString(tt.price)\n   643→            quantity := decimal.RequireFromString(tt.quantity)\n   644→            expected := decimal.RequireFromString(tt.expected)\n   645→            \n   646→            result := price.Mul(quantity)\n   647→            \n   648→            if !result.Equal(expected) {\n   649→                t.Errorf(\"got %s, want %s\", result, expected)\n   650→            }\n   651→        })\n   652→    }\n   653→}\n   654→```\n   655→\n   656→## Summary\n   657→\n   658→1. **Always use decimal for money** - Never float64\n   659→2. **Parse from strings** - Avoid NewFromFloat when possible\n   660→3. **Check for zero** - Before division operations\n   661→4. **Validate inputs** - Especially from external sources\n   662→5. **Define constants** - For commonly used values\n   663→6. **Round appropriately** - Different precision for display vs calculation\n   664→7. **Handle errors** - String parsing can fail\n   665→8. **Test thoroughly** - Include edge cases and precision tests\n   666→9. **Use domain types** - Price, Quantity, Percentage for type safety\n   667→10. **Profile if needed** - Decimal ops are slower than float, optimize hot paths\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"ddca2a71-4082-4435-a503-6fbcd135b860","timestamp":"2025-08-13T10:27:54.989Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/decimal-patterns.md","content":"# Decimal Patterns - shopspring/decimal for Financial Calculations\n\n## Overview\n\nBig Meanie uses shopspring/decimal for ALL numeric operations involving money, prices, quantities, and percentages. This ensures exact decimal arithmetic without floating-point rounding errors that could cost real money in trading operations.\n\n## Table of Contents\n1. [Core Principles](#core-principles)\n2. [Basic Operations](#basic-operations)\n3. [Trading-Specific Patterns](#trading-specific-patterns)\n4. [Common Gotchas](#common-gotchas)\n5. [Performance Considerations](#performance-considerations)\n6. [Best Practices](#best-practices)\n\n## Core Principles\n\n```go\nimport \"github.com/shopspring/decimal\"\n\n// NEVER use float64 for financial calculations\n// BAD\nprice := 100.123  // float64 - NEVER DO THIS\ntotal := price * 1.5\n\n// GOOD\nprice := decimal.NewFromFloat(100.123)\ntotal := price.Mul(decimal.NewFromFloat(1.5))\n\n// BETTER - avoid float entirely\nprice := decimal.RequireFromString(\"100.123\")\nmultiplier := decimal.RequireFromString(\"1.5\")\ntotal := price.Mul(multiplier)\n```\n\n## Basic Operations\n\n### Creation and Initialization\n\n```go\n// From string (PREFERRED for literals)\nprice := decimal.RequireFromString(\"123.456789\")\n\n// From int\nquantity := decimal.NewFromInt(100)\n\n// From float (ONLY when interfacing with external APIs)\n// Always validate precision after conversion\napiPrice := decimal.NewFromFloat(apiResponse.Price)\nif apiPrice.Exponent() < -8 {\n    // Handle precision loss\n}\n\n// Zero and common values\nzero := decimal.Zero\none := decimal.NewFromInt(1)\nhundred := decimal.NewFromInt(100)\n```\n\n### Arithmetic Operations\n\n```go\n// All operations return new decimals (immutable)\na := decimal.RequireFromString(\"100.50\")\nb := decimal.RequireFromString(\"25.25\")\n\nsum := a.Add(b)           // 125.75\ndiff := a.Sub(b)          // 75.25\nproduct := a.Mul(b)       // 2537.625\nquotient := a.Div(b)      // 3.98...\n\n// Chaining operations\ntotal := price.Mul(quantity).Add(fee).Sub(discount)\n\n// Percentage calculations\nprice := decimal.RequireFromString(\"100\")\ntaxRate := decimal.RequireFromString(\"0.08\") // 8%\ntax := price.Mul(taxRate)\ntotalWithTax := price.Add(tax)\n\n// Or as percentage\npct := decimal.RequireFromString(\"8\")\ntax = price.Mul(pct).Div(decimal.NewFromInt(100))\n```\n\n### Comparisons\n\n```go\na := decimal.RequireFromString(\"100.01\")\nb := decimal.RequireFromString(\"100.02\")\n\nif a.Equal(b) {\n    // Exact equality\n}\n\nif a.LessThan(b) {\n    // a < b\n}\n\nif a.LessThanOrEqual(b) {\n    // a <= b\n}\n\nif a.GreaterThan(b) {\n    // a > b\n}\n\nif a.GreaterThanOrEqual(b) {\n    // a >= b\n}\n\n// Compare with zero\nif balance.IsPositive() {\n    // balance > 0\n}\n\nif balance.IsNegative() {\n    // balance < 0\n}\n\nif balance.IsZero() {\n    // balance == 0\n}\n\n// Sign check\nsign := amount.Sign() // Returns -1, 0, or 1\n```\n\n## Trading-Specific Patterns\n\n### Price and Quantity Handling\n\n```go\ntype Order struct {\n    Price    decimal.Decimal\n    Quantity decimal.Decimal\n    Side     string\n}\n\n// Calculate order value\nfunc (o Order) Value() decimal.Decimal {\n    return o.Price.Mul(o.Quantity)\n}\n\n// Apply trading fees\nfunc (o Order) TotalWithFee(feeRate decimal.Decimal) decimal.Decimal {\n    value := o.Value()\n    fee := value.Mul(feeRate)\n    \n    if o.Side == \"BUY\" {\n        return value.Add(fee)\n    }\n    return value.Sub(fee)\n}\n\n// Price tick rounding\nfunc RoundToTick(price, tickSize decimal.Decimal) decimal.Decimal {\n    if tickSize.IsZero() {\n        return price\n    }\n    return price.Div(tickSize).Round(0).Mul(tickSize)\n}\n```\n\n### Portfolio Calculations\n\n```go\ntype Position struct {\n    Symbol   string\n    Quantity decimal.Decimal\n    AvgPrice decimal.Decimal\n}\n\n// Calculate position value\nfunc (p Position) Value(currentPrice decimal.Decimal) decimal.Decimal {\n    return p.Quantity.Mul(currentPrice)\n}\n\n// Calculate P&L\nfunc (p Position) PnL(currentPrice decimal.Decimal) decimal.Decimal {\n    currentValue := p.Value(currentPrice)\n    costBasis := p.Quantity.Mul(p.AvgPrice)\n    return currentValue.Sub(costBasis)\n}\n\n// Calculate P&L percentage\nfunc (p Position) PnLPercent(currentPrice decimal.Decimal) decimal.Decimal {\n    if p.AvgPrice.IsZero() {\n        return decimal.Zero\n    }\n    \n    pnl := currentPrice.Sub(p.AvgPrice)\n    return pnl.Div(p.AvgPrice).Mul(decimal.NewFromInt(100))\n}\n\n// Portfolio totals\nfunc CalculatePortfolioValue(positions []Position, prices map[string]decimal.Decimal) decimal.Decimal {\n    total := decimal.Zero\n    \n    for _, pos := range positions {\n        if price, ok := prices[pos.Symbol]; ok {\n            total = total.Add(pos.Value(price))\n        }\n    }\n    \n    return total\n}\n```\n\n### Technical Indicators\n\n```go\n// Moving average with decimal precision\nfunc SMA(prices []decimal.Decimal, period int) decimal.Decimal {\n    if len(prices) < period {\n        return decimal.Zero\n    }\n    \n    sum := decimal.Zero\n    for i := len(prices) - period; i < len(prices); i++ {\n        sum = sum.Add(prices[i])\n    }\n    \n    return sum.Div(decimal.NewFromInt(int64(period)))\n}\n\n// RSI calculation\nfunc RSI(prices []decimal.Decimal, period int) decimal.Decimal {\n    if len(prices) < period+1 {\n        return decimal.Zero\n    }\n    \n    gains := decimal.Zero\n    losses := decimal.Zero\n    \n    for i := len(prices) - period; i < len(prices); i++ {\n        diff := prices[i].Sub(prices[i-1])\n        if diff.IsPositive() {\n            gains = gains.Add(diff)\n        } else {\n            losses = losses.Add(diff.Abs())\n        }\n    }\n    \n    avgGain := gains.Div(decimal.NewFromInt(int64(period)))\n    avgLoss := losses.Div(decimal.NewFromInt(int64(period)))\n    \n    if avgLoss.IsZero() {\n        return decimal.NewFromInt(100)\n    }\n    \n    rs := avgGain.Div(avgLoss)\n    rsi := decimal.NewFromInt(100).Sub(\n        decimal.NewFromInt(100).Div(\n            decimal.NewFromInt(1).Add(rs),\n        ),\n    )\n    \n    return rsi\n}\n```\n\n### Risk Management\n\n```go\n// Position sizing with Kelly Criterion\nfunc KellySize(winProb, winSize, lossSize decimal.Decimal) decimal.Decimal {\n    if lossSize.IsZero() {\n        return decimal.Zero\n    }\n    \n    // f = (p * b - q) / b\n    // where p = win probability, q = loss probability, b = win/loss ratio\n    q := decimal.NewFromInt(1).Sub(winProb)\n    b := winSize.Div(lossSize)\n    \n    numerator := winProb.Mul(b).Sub(q)\n    kelly := numerator.Div(b)\n    \n    // Never risk more than 25% (Kelly can suggest aggressive sizes)\n    maxSize := decimal.RequireFromString(\"0.25\")\n    if kelly.GreaterThan(maxSize) {\n        return maxSize\n    }\n    \n    if kelly.IsNegative() {\n        return decimal.Zero\n    }\n    \n    return kelly\n}\n\n// Stop loss calculation\nfunc CalculateStopLoss(entry, riskPercent decimal.Decimal, side string) decimal.Decimal {\n    risk := entry.Mul(riskPercent).Div(decimal.NewFromInt(100))\n    \n    if side == \"LONG\" {\n        return entry.Sub(risk)\n    }\n    return entry.Add(risk) // SHORT position\n}\n\n// Position size from risk amount\nfunc PositionSizeFromRisk(riskAmount, entry, stopLoss decimal.Decimal) decimal.Decimal {\n    riskPerUnit := entry.Sub(stopLoss).Abs()\n    if riskPerUnit.IsZero() {\n        return decimal.Zero\n    }\n    \n    return riskAmount.Div(riskPerUnit)\n}\n```\n\n## Common Gotchas\n\n### 1. Division by Zero\n\n```go\n// ALWAYS check for zero before division\nfunc SafeDivide(a, b decimal.Decimal) decimal.Decimal {\n    if b.IsZero() {\n        return decimal.Zero // or handle error appropriately\n    }\n    return a.Div(b)\n}\n\n// In ratio calculations\nfunc PriceToEarnings(price, earnings decimal.Decimal) decimal.Decimal {\n    if earnings.IsZero() || earnings.IsNegative() {\n        return decimal.NewFromInt(-1) // Indicate N/A\n    }\n    return price.Div(earnings)\n}\n```\n\n### 2. Precision and Rounding\n\n```go\n// Round to specific decimal places\nprice := decimal.RequireFromString(\"123.456789\")\nrounded := price.Round(2) // 123.46\n\n// Round for display vs calculation\ntype Price struct {\n    value decimal.Decimal\n}\n\nfunc (p Price) Display() string {\n    // Round to 2 places for display\n    return p.value.Round(2).String()\n}\n\nfunc (p Price) Calculate() decimal.Decimal {\n    // Keep full precision for calculations\n    return p.value\n}\n\n// Exchange-specific precision\nfunc FormatForExchange(price decimal.Decimal, exchange string) string {\n    precisions := map[string]int32{\n        \"binance\":  8,\n        \"coinbase\": 2,\n        \"kraken\":   5,\n    }\n    \n    precision := precisions[exchange]\n    return price.Round(precision).String()\n}\n```\n\n### 3. String Conversion Errors\n\n```go\n// Always handle string parsing errors\nfunc ParsePrice(s string) (decimal.Decimal, error) {\n    price, err := decimal.NewFromString(s)\n    if err != nil {\n        return decimal.Zero, fmt.Errorf(\"invalid price format: %w\", err)\n    }\n    \n    // Validate reasonable bounds\n    maxPrice := decimal.NewFromInt(1000000)\n    if price.IsNegative() || price.GreaterThan(maxPrice) {\n        return decimal.Zero, fmt.Errorf(\"price out of bounds: %s\", s)\n    }\n    \n    return price, nil\n}\n\n// Use RequireFromString only with hardcoded values\nconst FeeRate = \"0.001\" // 0.1%\nvar TradingFee = decimal.RequireFromString(FeeRate)\n```\n\n### 4. JSON Marshaling\n\n```go\n// Decimal fields in JSON\ntype Trade struct {\n    ID       string          `json:\"id\"`\n    Price    decimal.Decimal `json:\"price\"`\n    Quantity decimal.Decimal `json:\"quantity\"`\n    Total    decimal.Decimal `json:\"total\"`\n}\n\n// Custom JSON handling if needed\nfunc (t Trade) MarshalJSON() ([]byte, error) {\n    type Alias Trade\n    return json.Marshal(&struct {\n        Price    string `json:\"price\"`\n        Quantity string `json:\"quantity\"`\n        Total    string `json:\"total\"`\n        *Alias\n    }{\n        Price:    t.Price.String(),\n        Quantity: t.Quantity.String(),\n        Total:    t.Total.String(),\n        Alias:    (*Alias)(&t),\n    })\n}\n```\n\n### 5. Database Storage\n\n```go\n// Store as DECIMAL or NUMERIC in PostgreSQL\nCREATE TABLE trades (\n    id         SERIAL PRIMARY KEY,\n    price      DECIMAL(20, 8) NOT NULL,\n    quantity   DECIMAL(20, 8) NOT NULL,\n    total      DECIMAL(20, 8) NOT NULL,\n    fee        DECIMAL(20, 8) DEFAULT 0\n);\n\n// In Go with sqlx/pgx\nfunc SaveTrade(db *sql.DB, trade Trade) error {\n    query := `\n        INSERT INTO trades (price, quantity, total)\n        VALUES ($1, $2, $3)\n    `\n    _, err := db.Exec(query, \n        trade.Price.String(),\n        trade.Quantity.String(),\n        trade.Total.String(),\n    )\n    return err\n}\n```\n\n## Performance Considerations\n\n### Memory Allocation\n\n```go\n// Reuse decimal values when possible\nvar (\n    // Common constants\n    Zero     = decimal.Zero\n    One      = decimal.NewFromInt(1)\n    Hundred  = decimal.NewFromInt(100)\n    Thousand = decimal.NewFromInt(1000)\n)\n\n// Avoid creating new decimals in hot paths\ntype Calculator struct {\n    // Pre-allocated decimals\n    hundred  decimal.Decimal\n    feeRate  decimal.Decimal\n    tickSize decimal.Decimal\n}\n\nfunc NewCalculator() *Calculator {\n    return &Calculator{\n        hundred:  decimal.NewFromInt(100),\n        feeRate:  decimal.RequireFromString(\"0.001\"),\n        tickSize: decimal.RequireFromString(\"0.01\"),\n    }\n}\n```\n\n### Batch Operations\n\n```go\n// Process multiple calculations efficiently\nfunc CalculateTotals(trades []Trade) decimal.Decimal {\n    total := decimal.Zero\n    \n    // Single allocation for all iterations\n    for i := range trades {\n        total = total.Add(trades[i].Price.Mul(trades[i].Quantity))\n    }\n    \n    return total\n}\n\n// Parallel processing for large datasets\nfunc ParallelSum(values []decimal.Decimal) decimal.Decimal {\n    if len(values) < 1000 {\n        // Serial for small datasets\n        sum := decimal.Zero\n        for _, v := range values {\n            sum = sum.Add(v)\n        }\n        return sum\n    }\n    \n    // Parallel for large datasets\n    numWorkers := runtime.NumCPU()\n    chunkSize := len(values) / numWorkers\n    results := make(chan decimal.Decimal, numWorkers)\n    \n    for i := 0; i < numWorkers; i++ {\n        start := i * chunkSize\n        end := start + chunkSize\n        if i == numWorkers-1 {\n            end = len(values)\n        }\n        \n        go func(chunk []decimal.Decimal) {\n            sum := decimal.Zero\n            for _, v := range chunk {\n                sum = sum.Add(v)\n            }\n            results <- sum\n        }(values[start:end])\n    }\n    \n    total := decimal.Zero\n    for i := 0; i < numWorkers; i++ {\n        total = total.Add(<-results)\n    }\n    \n    return total\n}\n```\n\n## Best Practices\n\n### 1. Type Safety\n\n```go\n// Create domain types for different decimal uses\ntype Price decimal.Decimal\ntype Quantity decimal.Decimal\ntype Percentage decimal.Decimal\n\nfunc (p Price) Mul(q Quantity) decimal.Decimal {\n    return decimal.Decimal(p).Mul(decimal.Decimal(q))\n}\n\n// This prevents mixing incompatible types\n// price.Mul(percentage) // Compile error!\n```\n\n### 2. Validation\n\n```go\nfunc ValidateOrderParams(price, quantity decimal.Decimal) error {\n    if price.IsNegative() || price.IsZero() {\n        return fmt.Errorf(\"invalid price: %s\", price)\n    }\n    \n    if quantity.IsNegative() || quantity.IsZero() {\n        return fmt.Errorf(\"invalid quantity: %s\", quantity)\n    }\n    \n    minNotional := decimal.NewFromInt(10)\n    if price.Mul(quantity).LessThan(minNotional) {\n        return fmt.Errorf(\"order value below minimum: %s\", price.Mul(quantity))\n    }\n    \n    return nil\n}\n```\n\n### 3. Constants\n\n```go\n// Define reusable constants\nvar (\n    BasisPoint = decimal.RequireFromString(\"0.0001\")  // 0.01%\n    Percentage = decimal.RequireFromString(\"0.01\")    // 1%\n    \n    MaxLeverage = decimal.NewFromInt(10)\n    MinOrderSize = decimal.RequireFromString(\"0.001\")\n    \n    MakerFee = decimal.RequireFromString(\"0.001\")     // 0.1%\n    TakerFee = decimal.RequireFromString(\"0.0015\")    // 0.15%\n)\n```\n\n### 4. Error Handling\n\n```go\n// Always validate external inputs\nfunc ProcessTradeRequest(req TradeRequest) error {\n    price, err := decimal.NewFromString(req.Price)\n    if err != nil {\n        return fmt.Errorf(\"invalid price: %w\", err)\n    }\n    \n    quantity, err := decimal.NewFromString(req.Quantity)\n    if err != nil {\n        return fmt.Errorf(\"invalid quantity: %w\", err)\n    }\n    \n    // Validate business rules\n    if err := ValidateOrderParams(price, quantity); err != nil {\n        return err\n    }\n    \n    // Process trade...\n    return nil\n}\n```\n\n### 5. Testing\n\n```go\nfunc TestPriceCalculation(t *testing.T) {\n    tests := []struct {\n        name     string\n        price    string\n        quantity string\n        expected string\n    }{\n        {\n            name:     \"simple multiplication\",\n            price:    \"100.50\",\n            quantity: \"2.5\",\n            expected: \"251.25\",\n        },\n        {\n            name:     \"precision handling\",\n            price:    \"0.00000001\",\n            quantity: \"100000000\",\n            expected: \"1\",\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            price := decimal.RequireFromString(tt.price)\n            quantity := decimal.RequireFromString(tt.quantity)\n            expected := decimal.RequireFromString(tt.expected)\n            \n            result := price.Mul(quantity)\n            \n            if !result.Equal(expected) {\n                t.Errorf(\"got %s, want %s\", result, expected)\n            }\n        })\n    }\n}\n```\n\n## Summary\n\n1. **Always use decimal for money** - Never float64\n2. **Parse from strings** - Avoid NewFromFloat when possible\n3. **Check for zero** - Before division operations\n4. **Validate inputs** - Especially from external sources\n5. **Define constants** - For commonly used values\n6. **Round appropriately** - Different precision for display vs calculation\n7. **Handle errors** - String parsing can fail\n8. **Test thoroughly** - Include edge cases and precision tests\n9. **Use domain types** - Price, Quantity, Percentage for type safety\n10. **Profile if needed** - Decimal ops are slower than float, optimize hot paths","numLines":667,"startLine":1,"totalLines":667}}}
{"parentUuid":"ddca2a71-4082-4435-a503-6fbcd135b860","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0197EZKCMLbD7EMx5AAB2miP","type":"tool_result","content":"     1→# Big Meanie Project Conventions\n     2→\n     3→## Philosophy\n     4→\n     5→Big Meanie follows a radical simplicity approach: **break fast, fix immediately**. We prioritize clean breaks over compatibility layers because hidden issues compound exponentially. A breaking change that forces immediate fixes is better than subtle bugs that surface months later in production.\n     6→\n     7→## Table of Contents\n     8→1. [Core Philosophy](#core-philosophy)\n     9→2. [Naming Conventions](#naming-conventions)\n    10→3. [No Backwards Compatibility](#no-backwards-compatibility)\n    11→4. [Project Structure](#project-structure)\n    12→5. [File Management](#file-management)\n    13→6. [Code Organization](#code-organization)\n    14→7. [Testing Standards](#testing-standards)\n    15→8. [Documentation Rules](#documentation-rules)\n    16→\n    17→## Core Philosophy\n    18→\n    19→### The Big Meanie Way\n    20→\n    21→```go\n    22→// We value:\n    23→// 1. Clarity over cleverness\n    24→// 2. Breaking changes over hidden complexity\n    25→// 3. Direct solutions over abstractions\n    26→// 4. Fast failures over graceful degradation\n    27→// 5. Today's correctness over tomorrow's flexibility\n    28→```\n    29→\n    30→### Design Principles\n    31→\n    32→```go\n    33→// BAD: Maintaining compatibility\n    34→type OrderService interface {\n    35→    PlaceOrder(order Order) error\n    36→    PlaceOrderV2(order OrderV2) error  // NEVER DO THIS\n    37→}\n    38→\n    39→// GOOD: Clean break\n    40→type OrderService interface {\n    41→    PlaceOrder(order Order) error  // Just change it\n    42→}\n    43→\n    44→// BAD: Migration code\n    45→func MigrateData() {\n    46→    if isOldFormat() {\n    47→        convertToNew()  // NEVER DO THIS\n    48→    }\n    49→}\n    50→\n    51→// GOOD: Direct cutover\n    52→func LoadData() {\n    53→    // Assume new format only\n    54→    // Old format fails fast\n    55→}\n    56→```\n    57→\n    58→## Naming Conventions\n    59→\n    60→### Ultra-Concise Names\n    61→\n    62→Big Meanie uses ultra-concise naming. We prefer short, clear names over verbose descriptions.\n    63→\n    64→```go\n    65→// BAD: Verbose naming\n    66→type SupportResistanceCalculator struct {\n    67→    maximumLookbackPeriod int\n    68→    minimumVolumeThreshold decimal.Decimal\n    69→}\n    70→\n    71→func CalculateSupportAndResistanceLevels() {}\n    72→func GetMovingAverageConvergenceDivergence() {}\n    73→\n    74→// GOOD: Ultra-concise\n    75→type SR struct {  // Support/Resistance\n    76→    maxLookback int\n    77→    minVol decimal.Decimal\n    78→}\n    79→\n    80→func CalcSR() {}\n    81→func MACD() {}\n    82→```\n    83→\n    84→### Standard Abbreviations\n    85→\n    86→```go\n    87→// Common trading abbreviations\n    88→SR   // Support/Resistance\n    89→MA   // Moving Average\n    90→EMA  // Exponential Moving Average\n    91→RSI  // Relative Strength Index\n    92→MACD // Moving Average Convergence Divergence\n    93→BB   // Bollinger Bands\n    94→ATR  // Average True Range\n    95→OBV  // On-Balance Volume\n    96→MFI  // Money Flow Index\n    97→\n    98→// System abbreviations\n    99→cfg  // config\n   100→ctx  // context\n   101→conn // connection\n   102→db   // database\n   103→err  // error\n   104→msg  // message\n   105→req  // request\n   106→res  // response/result\n   107→tx   // transaction\n   108→\n   109→// Trading specific\n   110→qty  // quantity\n   111→vol  // volume\n   112→pos  // position\n   113→pnl  // profit and loss\n   114→nav  // net asset value\n   115→liq  // liquidation/liquidity\n   116→```\n   117→\n   118→### Method Names\n   119→\n   120→```go\n   121→// Prefer short verbs\n   122→Calc()  not  Calculate()\n   123→Exec()  not  Execute()\n   124→Init()  not  Initialize()\n   125→Proc()  not  Process()\n   126→Gen()   not  Generate()\n   127→\n   128→// Getters don't use Get\n   129→Price()     not  GetPrice()\n   130→Quantity()  not  GetQuantity()\n   131→\n   132→// Setters use Set\n   133→SetPrice()\n   134→SetQuantity()\n   135→\n   136→// Boolean methods\n   137→IsValid()   not  CheckIfValid()\n   138→HasData()   not  CheckHasData()\n   139→CanTrade()  not  CheckCanTrade()\n   140→```\n   141→\n   142→## No Backwards Compatibility\n   143→\n   144→### Breaking Changes Are Good\n   145→\n   146→```go\n   147→// BAD: Versioned APIs\n   148→func (api *API) RegisterHandlers() {\n   149→    api.HandleFunc(\"/v1/orders\", ordersV1Handler)\n   150→    api.HandleFunc(\"/v2/orders\", ordersV2Handler)  // NEVER\n   151→}\n   152→\n   153→// GOOD: One version only\n   154→func (api *API) RegisterHandlers() {\n   155→    api.HandleFunc(\"/orders\", ordersHandler)  // Break it, fix it\n   156→}\n   157→\n   158→// BAD: Compatibility fields\n   159→type Order struct {\n   160→    ID       string\n   161→    Price    decimal.Decimal\n   162→    \n   163→    // Deprecated: Use Price instead\n   164→    PriceStr string  // NEVER KEEP THIS\n   165→}\n   166→\n   167→// GOOD: Clean structure\n   168→type Order struct {\n   169→    ID    string\n   170→    Price decimal.Decimal  // Changed? Fix all usages\n   171→}\n   172→```\n   173→\n   174→### Migration Anti-Patterns to Avoid\n   175→\n   176→```go\n   177→// NEVER: Gradual migration\n   178→func LoadConfig() Config {\n   179→    if FileExists(\"config.yaml\") {\n   180→        return LoadYAML()\n   181→    }\n   182→    // Fallback to old format\n   183→    return LoadJSON()  // NEVER DO THIS\n   184→}\n   185→\n   186→// ALWAYS: Direct cutover\n   187→func LoadConfig() Config {\n   188→    return LoadYAML()  // Old format fails immediately\n   189→}\n   190→\n   191→// NEVER: Adapter patterns\n   192→type LegacyAdapter struct {\n   193→    newService *Service\n   194→}\n   195→\n   196→func (a *LegacyAdapter) OldMethod() {\n   197→    a.newService.NewMethod()  // NEVER BUILD ADAPTERS\n   198→}\n   199→\n   200→// ALWAYS: Direct replacement\n   201→// Just change OldMethod to NewMethod everywhere\n   202→```\n   203→\n   204→### Database Migration Rules\n   205→\n   206→```sql\n   207→-- BAD: Maintaining old columns\n   208→ALTER TABLE orders ADD COLUMN price_decimal DECIMAL(20,8);\n   209→UPDATE orders SET price_decimal = CAST(price_string AS DECIMAL);\n   210→-- Keep both columns during \"transition\" - NEVER\n   211→\n   212→-- GOOD: Direct replacement\n   213→ALTER TABLE orders DROP COLUMN price_string;\n   214→ALTER TABLE orders ADD COLUMN price DECIMAL(20,8) NOT NULL;\n   215→-- Breaks immediately, forces data migration\n   216→```\n   217→\n   218→## Project Structure\n   219→\n   220→### Directory Layout\n   221→\n   222→```\n   223→bigmeanie/\n   224→├── back/                 # Backend code\n   225→│   ├── cmd/             # Entry points\n   226→│   │   ├── trade/       # Trading bot\n   227→│   │   ├── backtest/    # Backtesting engine\n   228→│   │   └── api/         # REST API server\n   229→│   ├── internal/        # Private packages\n   230→│   │   ├── engine/      # Trading engine\n   231→│   │   ├── strategy/    # Trading strategies\n   232→│   │   ├── exchange/    # Exchange integrations\n   233→│   │   ├── portfolio/   # Portfolio management\n   234→│   │   └── risk/        # Risk management\n   235→│   ├── pkg/             # Public packages\n   236→│   │   ├── indicators/  # Technical indicators\n   237→│   │   ├── decimal/     # Decimal utilities\n   238→│   │   └── errors/      # Error handling\n   239→│   └── .docs/           # Documentation\n   240→│       ├── code/        # Code patterns\n   241→│       ├── plan.md      # Current planning\n   242→│       └── todo.md      # Task tracking\n   243→└── front/               # Frontend code\n   244→    └── [React/Next.js structure]\n   245→```\n   246→\n   247→### Package Organization\n   248→\n   249→```go\n   250→// Each package has single responsibility\n   251→// internal/engine/engine.go\n   252→package engine\n   253→\n   254→type Engine struct {\n   255→    // Only engine-related fields\n   256→}\n   257→\n   258→// internal/strategy/strategy.go\n   259→package strategy\n   260→\n   261→type Strategy interface {\n   262→    // Only strategy methods\n   263→}\n   264→\n   265→// Never mix concerns in one package\n   266→// BAD: internal/trading/everything.go\n   267→// GOOD: Separate packages for separate concerns\n   268→```\n   269→\n   270→## File Management\n   271→\n   272→### No Variant Files\n   273→\n   274→```go\n   275→// NEVER create these files:\n   276→order.go\n   277→order_v2.go      // NEVER\n   278→order_new.go     // NEVER\n   279→order_enhanced.go // NEVER\n   280→order_refactored.go // NEVER\n   281→\n   282→// ALWAYS update the original:\n   283→order.go  // Just change this file\n   284→```\n   285→\n   286→### File Naming\n   287→\n   288→```go\n   289→// Standard Go conventions\n   290→order.go        // Types and methods\n   291→order_test.go   // Tests\n   292→doc.go         // Package documentation\n   293→\n   294→// Group by feature, not by type\n   295→// BAD structure:\n   296→types.go       // All types\n   297→methods.go     // All methods\n   298→interfaces.go  // All interfaces\n   299→\n   300→// GOOD structure:\n   301→order.go       // Order type and methods\n   302→trade.go       // Trade type and methods\n   303→portfolio.go   // Portfolio type and methods\n   304→```\n   305→\n   306→### Import Organization\n   307→\n   308→```go\n   309→import (\n   310→    // Standard library\n   311→    \"context\"\n   312→    \"fmt\"\n   313→    \n   314→    // External dependencies\n   315→    \"github.com/shopspring/decimal\"\n   316→    \n   317→    // Internal packages\n   318→    \"bigmeanie/internal/engine\"\n   319→    \"bigmeanie/pkg/indicators\"\n   320→)\n   321→\n   322→// Never use relative imports\n   323→// BAD:  import \"../engine\"\n   324→// GOOD: import \"bigmeanie/internal/engine\"\n   325→```\n   326→\n   327→## Code Organization\n   328→\n   329→### Interface Design\n   330→\n   331→```go\n   332→// Small, focused interfaces\n   333→type Trader interface {\n   334→    Trade(ctx context.Context, signal Signal) error\n   335→}\n   336→\n   337→// Not large, kitchen-sink interfaces\n   338→type BadTrader interface {\n   339→    Trade() error\n   340→    GetBalance() decimal.Decimal\n   341→    GetHistory() []Trade\n   342→    Configure(Config) error\n   343→    // ... 20 more methods - NO!\n   344→}\n   345→\n   346→// Compose interfaces when needed\n   347→type FullTrader interface {\n   348→    Trader\n   349→    Backtester\n   350→    Reporter\n   351→}\n   352→```\n   353→\n   354→### Error Handling\n   355→\n   356→```go\n   357→// Always wrap errors with context\n   358→if err != nil {\n   359→    return fmt.Errorf(\"engine.Start: %w\", err)\n   360→}\n   361→\n   362→// Define sentinel errors\n   363→var (\n   364→    ErrInsufficientFunds = errors.New(\"insufficient funds\")\n   365→    ErrOrderTooSmall     = errors.New(\"order below minimum\")\n   366→    ErrExchangeDown      = errors.New(\"exchange unavailable\")\n   367→)\n   368→\n   369→// Use errors.Is for checking\n   370→if errors.Is(err, ErrInsufficientFunds) {\n   371→    // Handle specific error\n   372→}\n   373→```\n   374→\n   375→### Concurrency Patterns\n   376→\n   377→```go\n   378→// Always use context for cancellation\n   379→func (e *Engine) Run(ctx context.Context) error {\n   380→    for {\n   381→        select {\n   382→        case <-ctx.Done():\n   383→            return ctx.Err()\n   384→        case signal := <-e.signals:\n   385→            e.process(signal)\n   386→        }\n   387→    }\n   388→}\n   389→\n   390→// Protect shared state\n   391→type Portfolio struct {\n   392→    mu       sync.RWMutex\n   393→    balances map[string]decimal.Decimal\n   394→}\n   395→\n   396→func (p *Portfolio) Balance(asset string) decimal.Decimal {\n   397→    p.mu.RLock()\n   398→    defer p.mu.RUnlock()\n   399→    return p.balances[asset]\n   400→}\n   401→```\n   402→\n   403→## Testing Standards\n   404→\n   405→### Test Organization\n   406→\n   407→```go\n   408→// Table-driven tests always\n   409→func TestCalcSR(t *testing.T) {\n   410→    tests := []struct {\n   411→        name string\n   412→        data []decimal.Decimal\n   413→        want []Level\n   414→    }{\n   415→        {\n   416→            name: \"basic support\",\n   417→            data: []decimal.Decimal{...},\n   418→            want: []Level{...},\n   419→        },\n   420→    }\n   421→    \n   422→    for _, tt := range tests {\n   423→        t.Run(tt.name, func(t *testing.T) {\n   424→            got := CalcSR(tt.data)\n   425→            require.Equal(t, tt.want, got)\n   426→        })\n   427→    }\n   428→}\n   429→\n   430→// NEVER use t.Skip()\n   431→// BAD:\n   432→func TestBrokenFeature(t *testing.T) {\n   433→    t.Skip(\"Fix later\")  // NEVER\n   434→}\n   435→\n   436→// GOOD: Fix it or delete it\n   437→```\n   438→\n   439→### Test Coverage\n   440→\n   441→```go\n   442→// Test edge cases\n   443→func TestDivision(t *testing.T) {\n   444→    // Test zero division\n   445→    _, err := Divide(decimal.NewFromInt(1), decimal.Zero)\n   446→    require.Error(t, err)\n   447→    \n   448→    // Test negative values\n   449→    result := Divide(decimal.NewFromInt(-10), decimal.NewFromInt(2))\n   450→    require.Equal(t, decimal.NewFromInt(-5), result)\n   451→}\n   452→\n   453→// Benchmark hot paths\n   454→func BenchmarkCalcSR(b *testing.B) {\n   455→    data := generatePriceData(1000)\n   456→    b.ResetTimer()\n   457→    \n   458→    for i := 0; i < b.N; i++ {\n   459→        CalcSR(data)\n   460→    }\n   461→}\n   462→```\n   463→\n   464→## Documentation Rules\n   465→\n   466→### Code Comments\n   467→\n   468→```go\n   469→// Document WHY, not WHAT\n   470→// BAD:\n   471→// Increment counter by 1\n   472→counter++\n   473→\n   474→// GOOD:\n   475→// Retry count for exchange rate limiting\n   476→counter++\n   477→\n   478→// Document edge cases\n   479→// Returns -1 if no valid price found\n   480→func FindPrice(prices []decimal.Decimal) decimal.Decimal {\n   481→    // ...\n   482→}\n   483→\n   484→// Document assumptions\n   485→// Assumes prices are sorted in ascending order\n   486→func BinarySearch(prices []decimal.Decimal, target decimal.Decimal) int {\n   487→    // ...\n   488→}\n   489→```\n   490→\n   491→### Package Documentation\n   492→\n   493→```go\n   494→// Package engine implements the core trading engine for Big Meanie.\n   495→//\n   496→// The engine coordinates between strategy signals, risk management,\n   497→// and exchange execution. It runs continuously, processing signals\n   498→// and managing positions according to configured strategies.\n   499→//\n   500→// Basic usage:\n   501→//\n   502→//\tcfg := engine.DefaultConfig()\n   503→//\teng := engine.New(cfg)\n   504→//\terr := eng.Run(ctx)\n   505→//\n   506→package engine\n   507→```\n   508→\n   509→### README Files\n   510→\n   511→```markdown\n   512→# Component Name\n   513→\n   514→## Purpose\n   515→One paragraph explaining what this does and why it exists.\n   516→\n   517→## Usage\n   518→Code examples showing common usage patterns.\n   519→\n   520→## Configuration\n   521→Environment variables or config files needed.\n   522→\n   523→## Testing\n   524→How to run tests for this component.\n   525→\n   526→Never create documentation unless explicitly requested.\n   527→Document in code, not in separate files.\n   528→```\n   529→\n   530→## Anti-Patterns to Avoid\n   531→\n   532→### Never Do These\n   533→\n   534→```go\n   535→// 1. Backwards compatibility layers\n   536→type Service struct {\n   537→    v1Client *ClientV1\n   538→    v2Client *ClientV2  // NEVER\n   539→}\n   540→\n   541→// 2. Gradual migrations\n   542→if useNewSystem {\n   543→    processNew()\n   544→} else {\n   545→    processOld()  // NEVER\n   546→}\n   547→\n   548→// 3. Deprecation warnings\n   549→// Deprecated: Use NewMethod instead\n   550→func OldMethod() {  // Just delete it\n   551→}\n   552→\n   553→// 4. Feature flags for old behavior\n   554→if featureFlag(\"use-old-algorithm\") {  // NEVER\n   555→    oldAlgorithm()\n   556→}\n   557→\n   558→// 5. Compatibility shims\n   559→func shimOldToNew(old Old) New {  // NEVER\n   560→    // Convert old format to new\n   561→}\n   562→\n   563→// 6. Variant files\n   564→order_v2.go      // NEVER\n   565→order_new.go     // NEVER\n   566→order_temp.go    // NEVER\n   567→\n   568→// 7. TODO comments for compatibility\n   569→// TODO: Remove after all clients updated  // NEVER\n   570→```\n   571→\n   572→## Summary of Conventions\n   573→\n   574→1. **Ultra-concise naming** - SR not SupportResistance\n   575→2. **No backwards compatibility** - Break it cleanly\n   576→3. **No migration code** - Direct cutover only\n   577→4. **No variant files** - Update the original\n   578→5. **Fast failures** - Errors surface immediately\n   579→6. **Single version** - No v1, v2 APIs\n   580→7. **Clean breaks** - Force immediate fixes\n   581→8. **Direct solutions** - No adapter patterns\n   582→9. **Test everything** - Never skip tests\n   583→10. **Document WHY** - Code explains what, comments explain why\n   584→\n   585→Remember: **Every line of compatibility code is technical debt.** Break fast, fix immediately, move forward.\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"56ffaaa0-b9b8-48b1-bd90-7f23d476d31a","timestamp":"2025-08-13T10:27:54.989Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md","content":"# Big Meanie Project Conventions\n\n## Philosophy\n\nBig Meanie follows a radical simplicity approach: **break fast, fix immediately**. We prioritize clean breaks over compatibility layers because hidden issues compound exponentially. A breaking change that forces immediate fixes is better than subtle bugs that surface months later in production.\n\n## Table of Contents\n1. [Core Philosophy](#core-philosophy)\n2. [Naming Conventions](#naming-conventions)\n3. [No Backwards Compatibility](#no-backwards-compatibility)\n4. [Project Structure](#project-structure)\n5. [File Management](#file-management)\n6. [Code Organization](#code-organization)\n7. [Testing Standards](#testing-standards)\n8. [Documentation Rules](#documentation-rules)\n\n## Core Philosophy\n\n### The Big Meanie Way\n\n```go\n// We value:\n// 1. Clarity over cleverness\n// 2. Breaking changes over hidden complexity\n// 3. Direct solutions over abstractions\n// 4. Fast failures over graceful degradation\n// 5. Today's correctness over tomorrow's flexibility\n```\n\n### Design Principles\n\n```go\n// BAD: Maintaining compatibility\ntype OrderService interface {\n    PlaceOrder(order Order) error\n    PlaceOrderV2(order OrderV2) error  // NEVER DO THIS\n}\n\n// GOOD: Clean break\ntype OrderService interface {\n    PlaceOrder(order Order) error  // Just change it\n}\n\n// BAD: Migration code\nfunc MigrateData() {\n    if isOldFormat() {\n        convertToNew()  // NEVER DO THIS\n    }\n}\n\n// GOOD: Direct cutover\nfunc LoadData() {\n    // Assume new format only\n    // Old format fails fast\n}\n```\n\n## Naming Conventions\n\n### Ultra-Concise Names\n\nBig Meanie uses ultra-concise naming. We prefer short, clear names over verbose descriptions.\n\n```go\n// BAD: Verbose naming\ntype SupportResistanceCalculator struct {\n    maximumLookbackPeriod int\n    minimumVolumeThreshold decimal.Decimal\n}\n\nfunc CalculateSupportAndResistanceLevels() {}\nfunc GetMovingAverageConvergenceDivergence() {}\n\n// GOOD: Ultra-concise\ntype SR struct {  // Support/Resistance\n    maxLookback int\n    minVol decimal.Decimal\n}\n\nfunc CalcSR() {}\nfunc MACD() {}\n```\n\n### Standard Abbreviations\n\n```go\n// Common trading abbreviations\nSR   // Support/Resistance\nMA   // Moving Average\nEMA  // Exponential Moving Average\nRSI  // Relative Strength Index\nMACD // Moving Average Convergence Divergence\nBB   // Bollinger Bands\nATR  // Average True Range\nOBV  // On-Balance Volume\nMFI  // Money Flow Index\n\n// System abbreviations\ncfg  // config\nctx  // context\nconn // connection\ndb   // database\nerr  // error\nmsg  // message\nreq  // request\nres  // response/result\ntx   // transaction\n\n// Trading specific\nqty  // quantity\nvol  // volume\npos  // position\npnl  // profit and loss\nnav  // net asset value\nliq  // liquidation/liquidity\n```\n\n### Method Names\n\n```go\n// Prefer short verbs\nCalc()  not  Calculate()\nExec()  not  Execute()\nInit()  not  Initialize()\nProc()  not  Process()\nGen()   not  Generate()\n\n// Getters don't use Get\nPrice()     not  GetPrice()\nQuantity()  not  GetQuantity()\n\n// Setters use Set\nSetPrice()\nSetQuantity()\n\n// Boolean methods\nIsValid()   not  CheckIfValid()\nHasData()   not  CheckHasData()\nCanTrade()  not  CheckCanTrade()\n```\n\n## No Backwards Compatibility\n\n### Breaking Changes Are Good\n\n```go\n// BAD: Versioned APIs\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/v1/orders\", ordersV1Handler)\n    api.HandleFunc(\"/v2/orders\", ordersV2Handler)  // NEVER\n}\n\n// GOOD: One version only\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/orders\", ordersHandler)  // Break it, fix it\n}\n\n// BAD: Compatibility fields\ntype Order struct {\n    ID       string\n    Price    decimal.Decimal\n    \n    // Deprecated: Use Price instead\n    PriceStr string  // NEVER KEEP THIS\n}\n\n// GOOD: Clean structure\ntype Order struct {\n    ID    string\n    Price decimal.Decimal  // Changed? Fix all usages\n}\n```\n\n### Migration Anti-Patterns to Avoid\n\n```go\n// NEVER: Gradual migration\nfunc LoadConfig() Config {\n    if FileExists(\"config.yaml\") {\n        return LoadYAML()\n    }\n    // Fallback to old format\n    return LoadJSON()  // NEVER DO THIS\n}\n\n// ALWAYS: Direct cutover\nfunc LoadConfig() Config {\n    return LoadYAML()  // Old format fails immediately\n}\n\n// NEVER: Adapter patterns\ntype LegacyAdapter struct {\n    newService *Service\n}\n\nfunc (a *LegacyAdapter) OldMethod() {\n    a.newService.NewMethod()  // NEVER BUILD ADAPTERS\n}\n\n// ALWAYS: Direct replacement\n// Just change OldMethod to NewMethod everywhere\n```\n\n### Database Migration Rules\n\n```sql\n-- BAD: Maintaining old columns\nALTER TABLE orders ADD COLUMN price_decimal DECIMAL(20,8);\nUPDATE orders SET price_decimal = CAST(price_string AS DECIMAL);\n-- Keep both columns during \"transition\" - NEVER\n\n-- GOOD: Direct replacement\nALTER TABLE orders DROP COLUMN price_string;\nALTER TABLE orders ADD COLUMN price DECIMAL(20,8) NOT NULL;\n-- Breaks immediately, forces data migration\n```\n\n## Project Structure\n\n### Directory Layout\n\n```\nbigmeanie/\n├── back/                 # Backend code\n│   ├── cmd/             # Entry points\n│   │   ├── trade/       # Trading bot\n│   │   ├── backtest/    # Backtesting engine\n│   │   └── api/         # REST API server\n│   ├── internal/        # Private packages\n│   │   ├── engine/      # Trading engine\n│   │   ├── strategy/    # Trading strategies\n│   │   ├── exchange/    # Exchange integrations\n│   │   ├── portfolio/   # Portfolio management\n│   │   └── risk/        # Risk management\n│   ├── pkg/             # Public packages\n│   │   ├── indicators/  # Technical indicators\n│   │   ├── decimal/     # Decimal utilities\n│   │   └── errors/      # Error handling\n│   └── .docs/           # Documentation\n│       ├── code/        # Code patterns\n│       ├── plan.md      # Current planning\n│       └── todo.md      # Task tracking\n└── front/               # Frontend code\n    └── [React/Next.js structure]\n```\n\n### Package Organization\n\n```go\n// Each package has single responsibility\n// internal/engine/engine.go\npackage engine\n\ntype Engine struct {\n    // Only engine-related fields\n}\n\n// internal/strategy/strategy.go\npackage strategy\n\ntype Strategy interface {\n    // Only strategy methods\n}\n\n// Never mix concerns in one package\n// BAD: internal/trading/everything.go\n// GOOD: Separate packages for separate concerns\n```\n\n## File Management\n\n### No Variant Files\n\n```go\n// NEVER create these files:\norder.go\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_enhanced.go // NEVER\norder_refactored.go // NEVER\n\n// ALWAYS update the original:\norder.go  // Just change this file\n```\n\n### File Naming\n\n```go\n// Standard Go conventions\norder.go        // Types and methods\norder_test.go   // Tests\ndoc.go         // Package documentation\n\n// Group by feature, not by type\n// BAD structure:\ntypes.go       // All types\nmethods.go     // All methods\ninterfaces.go  // All interfaces\n\n// GOOD structure:\norder.go       // Order type and methods\ntrade.go       // Trade type and methods\nportfolio.go   // Portfolio type and methods\n```\n\n### Import Organization\n\n```go\nimport (\n    // Standard library\n    \"context\"\n    \"fmt\"\n    \n    // External dependencies\n    \"github.com/shopspring/decimal\"\n    \n    // Internal packages\n    \"bigmeanie/internal/engine\"\n    \"bigmeanie/pkg/indicators\"\n)\n\n// Never use relative imports\n// BAD:  import \"../engine\"\n// GOOD: import \"bigmeanie/internal/engine\"\n```\n\n## Code Organization\n\n### Interface Design\n\n```go\n// Small, focused interfaces\ntype Trader interface {\n    Trade(ctx context.Context, signal Signal) error\n}\n\n// Not large, kitchen-sink interfaces\ntype BadTrader interface {\n    Trade() error\n    GetBalance() decimal.Decimal\n    GetHistory() []Trade\n    Configure(Config) error\n    // ... 20 more methods - NO!\n}\n\n// Compose interfaces when needed\ntype FullTrader interface {\n    Trader\n    Backtester\n    Reporter\n}\n```\n\n### Error Handling\n\n```go\n// Always wrap errors with context\nif err != nil {\n    return fmt.Errorf(\"engine.Start: %w\", err)\n}\n\n// Define sentinel errors\nvar (\n    ErrInsufficientFunds = errors.New(\"insufficient funds\")\n    ErrOrderTooSmall     = errors.New(\"order below minimum\")\n    ErrExchangeDown      = errors.New(\"exchange unavailable\")\n)\n\n// Use errors.Is for checking\nif errors.Is(err, ErrInsufficientFunds) {\n    // Handle specific error\n}\n```\n\n### Concurrency Patterns\n\n```go\n// Always use context for cancellation\nfunc (e *Engine) Run(ctx context.Context) error {\n    for {\n        select {\n        case <-ctx.Done():\n            return ctx.Err()\n        case signal := <-e.signals:\n            e.process(signal)\n        }\n    }\n}\n\n// Protect shared state\ntype Portfolio struct {\n    mu       sync.RWMutex\n    balances map[string]decimal.Decimal\n}\n\nfunc (p *Portfolio) Balance(asset string) decimal.Decimal {\n    p.mu.RLock()\n    defer p.mu.RUnlock()\n    return p.balances[asset]\n}\n```\n\n## Testing Standards\n\n### Test Organization\n\n```go\n// Table-driven tests always\nfunc TestCalcSR(t *testing.T) {\n    tests := []struct {\n        name string\n        data []decimal.Decimal\n        want []Level\n    }{\n        {\n            name: \"basic support\",\n            data: []decimal.Decimal{...},\n            want: []Level{...},\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := CalcSR(tt.data)\n            require.Equal(t, tt.want, got)\n        })\n    }\n}\n\n// NEVER use t.Skip()\n// BAD:\nfunc TestBrokenFeature(t *testing.T) {\n    t.Skip(\"Fix later\")  // NEVER\n}\n\n// GOOD: Fix it or delete it\n```\n\n### Test Coverage\n\n```go\n// Test edge cases\nfunc TestDivision(t *testing.T) {\n    // Test zero division\n    _, err := Divide(decimal.NewFromInt(1), decimal.Zero)\n    require.Error(t, err)\n    \n    // Test negative values\n    result := Divide(decimal.NewFromInt(-10), decimal.NewFromInt(2))\n    require.Equal(t, decimal.NewFromInt(-5), result)\n}\n\n// Benchmark hot paths\nfunc BenchmarkCalcSR(b *testing.B) {\n    data := generatePriceData(1000)\n    b.ResetTimer()\n    \n    for i := 0; i < b.N; i++ {\n        CalcSR(data)\n    }\n}\n```\n\n## Documentation Rules\n\n### Code Comments\n\n```go\n// Document WHY, not WHAT\n// BAD:\n// Increment counter by 1\ncounter++\n\n// GOOD:\n// Retry count for exchange rate limiting\ncounter++\n\n// Document edge cases\n// Returns -1 if no valid price found\nfunc FindPrice(prices []decimal.Decimal) decimal.Decimal {\n    // ...\n}\n\n// Document assumptions\n// Assumes prices are sorted in ascending order\nfunc BinarySearch(prices []decimal.Decimal, target decimal.Decimal) int {\n    // ...\n}\n```\n\n### Package Documentation\n\n```go\n// Package engine implements the core trading engine for Big Meanie.\n//\n// The engine coordinates between strategy signals, risk management,\n// and exchange execution. It runs continuously, processing signals\n// and managing positions according to configured strategies.\n//\n// Basic usage:\n//\n//\tcfg := engine.DefaultConfig()\n//\teng := engine.New(cfg)\n//\terr := eng.Run(ctx)\n//\npackage engine\n```\n\n### README Files\n\n```markdown\n# Component Name\n\n## Purpose\nOne paragraph explaining what this does and why it exists.\n\n## Usage\nCode examples showing common usage patterns.\n\n## Configuration\nEnvironment variables or config files needed.\n\n## Testing\nHow to run tests for this component.\n\nNever create documentation unless explicitly requested.\nDocument in code, not in separate files.\n```\n\n## Anti-Patterns to Avoid\n\n### Never Do These\n\n```go\n// 1. Backwards compatibility layers\ntype Service struct {\n    v1Client *ClientV1\n    v2Client *ClientV2  // NEVER\n}\n\n// 2. Gradual migrations\nif useNewSystem {\n    processNew()\n} else {\n    processOld()  // NEVER\n}\n\n// 3. Deprecation warnings\n// Deprecated: Use NewMethod instead\nfunc OldMethod() {  // Just delete it\n}\n\n// 4. Feature flags for old behavior\nif featureFlag(\"use-old-algorithm\") {  // NEVER\n    oldAlgorithm()\n}\n\n// 5. Compatibility shims\nfunc shimOldToNew(old Old) New {  // NEVER\n    // Convert old format to new\n}\n\n// 6. Variant files\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_temp.go    // NEVER\n\n// 7. TODO comments for compatibility\n// TODO: Remove after all clients updated  // NEVER\n```\n\n## Summary of Conventions\n\n1. **Ultra-concise naming** - SR not SupportResistance\n2. **No backwards compatibility** - Break it cleanly\n3. **No migration code** - Direct cutover only\n4. **No variant files** - Update the original\n5. **Fast failures** - Errors surface immediately\n6. **Single version** - No v1, v2 APIs\n7. **Clean breaks** - Force immediate fixes\n8. **Direct solutions** - No adapter patterns\n9. **Test everything** - Never skip tests\n10. **Document WHY** - Code explains what, comments explain why\n\nRemember: **Every line of compatibility code is technical debt.** Break fast, fix immediately, move forward.","numLines":585,"startLine":1,"totalLines":585}}}
{"parentUuid":"56ffaaa0-b9b8-48b1-bd90-7f23d476d31a","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018jwzvnemyyyQD5nMs1xAS4","type":"tool_result","content":"     1→# Go Language Fundamentals - Complete Reference\n     2→\n     3→## Table of Contents\n     4→1. [Introduction](#introduction)\n     5→2. [Basic Syntax](#basic-syntax)\n     6→3. [Variables and Constants](#variables-and-constants)\n     7→4. [Data Types](#data-types)\n     8→5. [Control Flow](#control-flow)\n     9→6. [Functions](#functions)\n    10→7. [Methods](#methods)\n    11→8. [Structs](#structs)\n    12→9. [Interfaces](#interfaces)\n    13→10. [Pointers](#pointers)\n    14→11. [Arrays and Slices](#arrays-and-slices)\n    15→12. [Maps](#maps)\n    16→13. [Error Handling](#error-handling)\n    17→14. [Packages and Modules](#packages-and-modules)\n    18→15. [Type Assertions and Type Switches](#type-assertions-and-type-switches)\n    19→16. [Embedding and Composition](#embedding-and-composition)\n    20→17. [Generics](#generics)\n    21→\n    22→## Introduction\n    23→\n    24→Go is a statically typed, compiled language designed for simplicity, efficiency, and reliable software. Created at Google in 2007 by Robert Griesemer, Rob Pike, and Ken Thompson, Go combines the performance of compiled languages with the ease of programming of dynamic languages.\n    25→\n    26→### Core Philosophy\n    27→- **Simplicity**: Less is exponentially more\n    28→- **Readability**: Code is read more often than written\n    29→- **Efficiency**: Fast compilation, fast execution\n    30→- **Concurrency**: Built-in primitives for concurrent programming\n    31→- **Pragmatism**: Solve real problems with practical solutions\n    32→\n    33→## Basic Syntax\n    34→\n    35→### Program Structure\n    36→\n    37→Every Go program starts with a package declaration and imports:\n    38→\n    39→```go\n    40→package main\n    41→\n    42→import (\n    43→    \"fmt\"\n    44→    \"strings\"\n    45→    \"time\"\n    46→)\n    47→\n    48→func main() {\n    49→    fmt.Println(\"Hello, Go!\")\n    50→}\n    51→```\n    52→\n    53→### Comments\n    54→\n    55→```go\n    56→// Single-line comment\n    57→\n    58→/*\n    59→   Multi-line comment\n    60→   Can span multiple lines\n    61→*/\n    62→\n    63→// Package documentation comment (must precede package declaration)\n    64→// Package math provides basic mathematical functions.\n    65→package math\n    66→\n    67→// Function documentation (must precede function declaration)\n    68→// Add returns the sum of two integers.\n    69→func Add(a, b int) int {\n    70→    return a + b\n    71→}\n    72→```\n    73→\n    74→### Naming Conventions\n    75→\n    76→```go\n    77→// Exported (public) - starts with uppercase\n    78→type Strategy struct{}\n    79→func CalculateProfit() {}\n    80→const MaxRetries = 3\n    81→var DefaultTimeout = 5 * time.Second\n    82→\n    83→// Unexported (private) - starts with lowercase\n    84→type position struct{}\n    85→func calculateLoss() {}\n    86→const maxAttempts = 5\n    87→var defaultBuffer = 1024\n    88→\n    89→// Package names - lowercase, single word\n    90→package trading  // Good\n    91→package tradingEngine  // Bad - use trading or engine\n    92→\n    93→// Interface names - typically end with -er\n    94→type Reader interface{}\n    95→type Writer interface{}\n    96→type Closer interface{}\n    97→type ReadWriteCloser interface{}  // Composition\n    98→\n    99→// Acronyms - keep consistent case\n   100→var httpClient HTTP  // Bad\n   101→var HTTPClient HTTP  // Good\n   102→var xmlParser XML    // Bad\n   103→var XMLParser XML    // Good\n   104→```\n   105→\n   106→## Variables and Constants\n   107→\n   108→### Variable Declaration\n   109→\n   110→```go\n   111→// var declaration with type\n   112→var name string\n   113→var age int\n   114→var balance float64\n   115→\n   116→// var declaration with initialization\n   117→var name string = \"John\"\n   118→var age int = 30\n   119→var balance = 1000.50  // Type inferred\n   120→\n   121→// Short variable declaration (only inside functions)\n   122→name := \"John\"\n   123→age := 30\n   124→balance := 1000.50\n   125→\n   126→// Multiple variable declaration\n   127→var (\n   128→    firstName string = \"John\"\n   129→    lastName  string = \"Doe\"\n   130→    age       int    = 30\n   131→)\n   132→\n   133→// Multiple assignment\n   134→x, y := 10, 20\n   135→a, b = b, a  // Swap values\n   136→\n   137→// Blank identifier for unused values\n   138→_, err := someFunction()  // Ignore first return value\n   139→```\n   140→\n   141→### Constants\n   142→\n   143→```go\n   144→// Single constant\n   145→const Pi = 3.14159\n   146→const MaxRetries = 3\n   147→const Message = \"Hello\"\n   148→\n   149→// Typed constants\n   150→const MaxInt int = 1000\n   151→const Timeout time.Duration = 5 * time.Second\n   152→\n   153→// Multiple constants\n   154→const (\n   155→    StatusOK       = 200\n   156→    StatusNotFound = 404\n   157→    StatusError    = 500\n   158→)\n   159→\n   160→// iota - constant generator\n   161→const (\n   162→    Sunday = iota  // 0\n   163→    Monday         // 1\n   164→    Tuesday        // 2\n   165→    Wednesday      // 3\n   166→    Thursday       // 4\n   167→    Friday         // 5\n   168→    Saturday       // 6\n   169→)\n   170→\n   171→// iota with expressions\n   172→const (\n   173→    _  = iota             // 0 (ignored)\n   174→    KB = 1 << (10 * iota) // 1024\n   175→    MB                    // 1048576\n   176→    GB                    // 1073741824\n   177→    TB                    // 1099511627776\n   178→)\n   179→\n   180→// Bit flags with iota\n   181→const (\n   182→    ReadPermission = 1 << iota  // 1\n   183→    WritePermission              // 2\n   184→    ExecutePermission            // 4\n   185→)\n   186→```\n   187→\n   188→## Data Types\n   189→\n   190→### Basic Types\n   191→\n   192→```go\n   193→// Boolean\n   194→var isActive bool = true\n   195→var isComplete bool  // Zero value: false\n   196→\n   197→// Integers\n   198→var i8 int8 = 127                    // -128 to 127\n   199→var i16 int16 = 32767                // -32768 to 32767\n   200→var i32 int32 = 2147483647           // -2147483648 to 2147483647\n   201→var i64 int64 = 9223372036854775807  // -9223372036854775808 to 9223372036854775807\n   202→var i int = 42                       // Platform dependent (32 or 64 bit)\n   203→\n   204→// Unsigned integers\n   205→var ui8 uint8 = 255                  // 0 to 255 (byte is alias)\n   206→var ui16 uint16 = 65535              // 0 to 65535\n   207→var ui32 uint32 = 4294967295         // 0 to 4294967295\n   208→var ui64 uint64 = 18446744073709551615  // 0 to 18446744073709551615\n   209→var ui uint = 42                     // Platform dependent\n   210→\n   211→// Floating point\n   212→var f32 float32 = 3.14               // IEEE-754 32-bit\n   213→var f64 float64 = 3.141592653589793  // IEEE-754 64-bit\n   214→\n   215→// Complex numbers\n   216→var c64 complex64 = 1 + 2i           // float32 real and imaginary\n   217→var c128 complex128 = 1 + 2i         // float64 real and imaginary\n   218→\n   219→// Strings\n   220→var str string = \"Hello, Go!\"        // UTF-8 encoded\n   221→var multiline = `This is\n   222→a multiline\n   223→string`                               // Raw string literal\n   224→\n   225→// Rune (Unicode code point)\n   226→var r rune = 'A'                     // int32 alias\n   227→var emoji rune = '😀'\n   228→\n   229→// Byte\n   230→var b byte = 65                      // uint8 alias\n   231→```\n   232→\n   233→### Type Conversions\n   234→\n   235→```go\n   236→// Explicit type conversion required\n   237→var i int = 42\n   238→var f float64 = float64(i)\n   239→var u uint = uint(i)\n   240→\n   241→// String conversions\n   242→import \"strconv\"\n   243→\n   244→// Int to string\n   245→s := strconv.Itoa(42)\n   246→s := strconv.FormatInt(42, 10)  // base 10\n   247→\n   248→// String to int\n   249→i, err := strconv.Atoi(\"42\")\n   250→i64, err := strconv.ParseInt(\"42\", 10, 64)\n   251→\n   252→// Float to string\n   253→s := strconv.FormatFloat(3.14, 'f', 2, 64)  // 2 decimal places\n   254→\n   255→// String to float\n   256→f, err := strconv.ParseFloat(\"3.14\", 64)\n   257→\n   258→// Type assertions (for interfaces)\n   259→var x interface{} = \"hello\"\n   260→s := x.(string)  // Panics if x is not string\n   261→s, ok := x.(string)  // Safe assertion with ok check\n   262→```\n   263→\n   264→### Zero Values\n   265→\n   266→```go\n   267→// All types have zero values\n   268→var b bool        // false\n   269→var i int         // 0\n   270→var f float64     // 0.0\n   271→var s string      // \"\"\n   272→var p *int        // nil\n   273→var a []int       // nil\n   274→var m map[string]int  // nil\n   275→var c chan int    // nil\n   276→var fn func()     // nil\n   277→var iface error   // nil\n   278→```\n   279→\n   280→## Control Flow\n   281→\n   282→### If Statements\n   283→\n   284→```go\n   285→// Basic if\n   286→if x > 0 {\n   287→    fmt.Println(\"Positive\")\n   288→}\n   289→\n   290→// If-else\n   291→if x > 0 {\n   292→    fmt.Println(\"Positive\")\n   293→} else {\n   294→    fmt.Println(\"Non-positive\")\n   295→}\n   296→\n   297→// If-else if-else\n   298→if x > 0 {\n   299→    fmt.Println(\"Positive\")\n   300→} else if x < 0 {\n   301→    fmt.Println(\"Negative\")\n   302→} else {\n   303→    fmt.Println(\"Zero\")\n   304→}\n   305→\n   306→// If with initialization\n   307→if err := doSomething(); err != nil {\n   308→    return err  // err is scoped to if block\n   309→}\n   310→\n   311→// Common patterns\n   312→// Check error immediately\n   313→if err != nil {\n   314→    return fmt.Errorf(\"failed to process: %w\", err)\n   315→}\n   316→\n   317→// Check boolean\n   318→if !isValid {\n   319→    return errors.New(\"invalid input\")\n   320→}\n   321→\n   322→// Check nil\n   323→if data == nil {\n   324→    return errors.New(\"data is nil\")\n   325→}\n   326→```\n   327→\n   328→### Switch Statements\n   329→\n   330→```go\n   331→// Basic switch\n   332→switch day {\n   333→case \"Monday\":\n   334→    fmt.Println(\"Start of work week\")\n   335→case \"Friday\":\n   336→    fmt.Println(\"TGIF!\")\n   337→case \"Saturday\", \"Sunday\":\n   338→    fmt.Println(\"Weekend!\")\n   339→default:\n   340→    fmt.Println(\"Midweek\")\n   341→}\n   342→\n   343→// Switch with no expression (like if-else chain)\n   344→switch {\n   345→case x < 0:\n   346→    fmt.Println(\"Negative\")\n   347→case x == 0:\n   348→    fmt.Println(\"Zero\")\n   349→case x > 0:\n   350→    fmt.Println(\"Positive\")\n   351→}\n   352→\n   353→// Switch with initialization\n   354→switch os := runtime.GOOS; os {\n   355→case \"darwin\":\n   356→    fmt.Println(\"macOS\")\n   357→case \"linux\":\n   358→    fmt.Println(\"Linux\")\n   359→default:\n   360→    fmt.Printf(\"Unknown OS: %s\\n\", os)\n   361→}\n   362→\n   363→// Type switch\n   364→func describe(i interface{}) {\n   365→    switch v := i.(type) {\n   366→    case int:\n   367→        fmt.Printf(\"Integer: %d\\n\", v)\n   368→    case string:\n   369→        fmt.Printf(\"String: %s\\n\", v)\n   370→    case bool:\n   371→        fmt.Printf(\"Boolean: %t\\n\", v)\n   372→    case nil:\n   373→        fmt.Println(\"nil value\")\n   374→    default:\n   375→        fmt.Printf(\"Unknown type: %T\\n\", v)\n   376→    }\n   377→}\n   378→\n   379→// Fallthrough (rarely used)\n   380→switch num {\n   381→case 1:\n   382→    fmt.Println(\"One\")\n   383→    fallthrough  // Continue to next case\n   384→case 2:\n   385→    fmt.Println(\"One or Two\")\n   386→}\n   387→```\n   388→\n   389→### Loops\n   390→\n   391→```go\n   392→// For loop - traditional\n   393→for i := 0; i < 10; i++ {\n   394→    fmt.Println(i)\n   395→}\n   396→\n   397→// For loop - while style\n   398→count := 0\n   399→for count < 10 {\n   400→    fmt.Println(count)\n   401→    count++\n   402→}\n   403→\n   404→// Infinite loop\n   405→for {\n   406→    // Break or return to exit\n   407→    if condition {\n   408→        break\n   409→    }\n   410→}\n   411→\n   412→// Range over slice\n   413→numbers := []int{1, 2, 3, 4, 5}\n   414→for index, value := range numbers {\n   415→    fmt.Printf(\"%d: %d\\n\", index, value)\n   416→}\n   417→\n   418→// Range over slice - values only\n   419→for _, value := range numbers {\n   420→    fmt.Println(value)\n   421→}\n   422→\n   423→// Range over slice - indices only\n   424→for index := range numbers {\n   425→    fmt.Println(index)\n   426→}\n   427→\n   428→// Range over map\n   429→ages := map[string]int{\"Alice\": 30, \"Bob\": 25}\n   430→for name, age := range ages {\n   431→    fmt.Printf(\"%s is %d years old\\n\", name, age)\n   432→}\n   433→\n   434→// Range over string (gives runes)\n   435→for index, runeValue := range \"Hello, 世界\" {\n   436→    fmt.Printf(\"%d: %c\\n\", index, runeValue)\n   437→}\n   438→\n   439→// Range over channel\n   440→ch := make(chan int)\n   441→go func() {\n   442→    for i := 0; i < 5; i++ {\n   443→        ch <- i\n   444→    }\n   445→    close(ch)\n   446→}()\n   447→for value := range ch {\n   448→    fmt.Println(value)\n   449→}\n   450→\n   451→// Continue and break with labels\n   452→outer:\n   453→for i := 0; i < 3; i++ {\n   454→    for j := 0; j < 3; j++ {\n   455→        if i == 1 && j == 1 {\n   456→            break outer  // Break outer loop\n   457→        }\n   458→        fmt.Printf(\"(%d, %d) \", i, j)\n   459→    }\n   460→}\n   461→```\n   462→\n   463→### Defer, Panic, and Recover\n   464→\n   465→```go\n   466→// Defer - executes when function returns\n   467→func readFile(filename string) error {\n   468→    file, err := os.Open(filename)\n   469→    if err != nil {\n   470→        return err\n   471→    }\n   472→    defer file.Close()  // Executed when function returns\n   473→    \n   474→    // Read file...\n   475→    return nil\n   476→}\n   477→\n   478→// Multiple defers - LIFO order\n   479→func example() {\n   480→    defer fmt.Println(\"Third\")\n   481→    defer fmt.Println(\"Second\")\n   482→    defer fmt.Println(\"First\")\n   483→    // Prints: First, Second, Third\n   484→}\n   485→\n   486→// Defer with arguments - evaluated immediately\n   487→func deferArgs() {\n   488→    i := 0\n   489→    defer fmt.Println(i)  // Prints 0, not 1\n   490→    i++\n   491→}\n   492→\n   493→// Defer with closure - captures variables\n   494→func deferClosure() {\n   495→    i := 0\n   496→    defer func() {\n   497→        fmt.Println(i)  // Prints 1\n   498→    }()\n   499→    i++\n   500→}\n   501→\n   502→// Panic - runtime error\n   503→func divide(a, b int) int {\n   504→    if b == 0 {\n   505→        panic(\"division by zero\")\n   506→    }\n   507→    return a / b\n   508→}\n   509→\n   510→// Recover - catch panic\n   511→func safeFunction() {\n   512→    defer func() {\n   513→        if r := recover(); r != nil {\n   514→            fmt.Printf(\"Recovered from panic: %v\\n\", r)\n   515→        }\n   516→    }()\n   517→    \n   518→    // Code that might panic\n   519→    panic(\"something went wrong\")\n   520→}\n   521→\n   522→// Practical error recovery pattern\n   523→func robustFunction() (err error) {\n   524→    defer func() {\n   525→        if r := recover(); r != nil {\n   526→            err = fmt.Errorf(\"panic recovered: %v\", r)\n   527→        }\n   528→    }()\n   529→    \n   530→    // Potentially panicking code\n   531→    return nil\n   532→}\n   533→```\n   534→\n   535→## Functions\n   536→\n   537→### Function Declaration\n   538→\n   539→```go\n   540→// Basic function\n   541→func greet() {\n   542→    fmt.Println(\"Hello!\")\n   543→}\n   544→\n   545→// Function with parameters\n   546→func add(a int, b int) int {\n   547→    return a + b\n   548→}\n   549→\n   550→// Shorthand for same type parameters\n   551→func add(a, b int) int {\n   552→    return a + b\n   553→}\n   554→\n   555→// Multiple return values\n   556→func divide(a, b float64) (float64, error) {\n   557→    if b == 0 {\n   558→        return 0, errors.New(\"division by zero\")\n   559→    }\n   560→    return a / b, nil\n   561→}\n   562→\n   563→// Named return values\n   564→func getCoordinates() (x, y int) {\n   565→    x = 10\n   566→    y = 20\n   567→    return  // Naked return\n   568→}\n   569→\n   570→// Named returns with explicit values\n   571→func calculate(a, b int) (sum, product int) {\n   572→    sum = a + b\n   573→    product = a * b\n   574→    return sum, product  // Can be explicit\n   575→}\n   576→\n   577→// Variadic functions\n   578→func sum(numbers ...int) int {\n   579→    total := 0\n   580→    for _, n := range numbers {\n   581→        total += n\n   582→    }\n   583→    return total\n   584→}\n   585→\n   586→// Calling variadic functions\n   587→result := sum(1, 2, 3, 4, 5)\n   588→nums := []int{1, 2, 3}\n   589→result := sum(nums...)  // Spread slice\n   590→```\n   591→\n   592→### Function Types and Values\n   593→\n   594→```go\n   595→// Function as type\n   596→type Operation func(int, int) int\n   597→\n   598→func add(a, b int) int { return a + b }\n   599→func multiply(a, b int) int { return a * b }\n   600→\n   601→var op Operation = add\n   602→result := op(5, 3)  // 8\n   603→\n   604→// Function as parameter\n   605→func apply(op Operation, a, b int) int {\n   606→    return op(a, b)\n   607→}\n   608→\n   609→result := apply(add, 5, 3)\n   610→result = apply(multiply, 5, 3)\n   611→\n   612→// Function returning function\n   613→func makeAdder(x int) func(int) int {\n   614→    return func(y int) int {\n   615→        return x + y\n   616→    }\n   617→}\n   618→\n   619→add5 := makeAdder(5)\n   620→result := add5(3)  // 8\n   621→\n   622→// Anonymous functions\n   623→func() {\n   624→    fmt.Println(\"Anonymous function\")\n   625→}()  // Immediately invoked\n   626→\n   627→// Assign to variable\n   628→greet := func(name string) {\n   629→    fmt.Printf(\"Hello, %s!\\n\", name)\n   630→}\n   631→greet(\"World\")\n   632→```\n   633→\n   634→### Closures\n   635→\n   636→```go\n   637→// Closure captures variables\n   638→func counter() func() int {\n   639→    count := 0\n   640→    return func() int {\n   641→        count++\n   642→        return count\n   643→    }\n   644→}\n   645→\n   646→c := counter()\n   647→fmt.Println(c())  // 1\n   648→fmt.Println(c())  // 2\n   649→fmt.Println(c())  // 3\n   650→\n   651→// Closure in loop (common pitfall)\n   652→// Wrong way\n   653→funcs := []func(){}\n   654→for i := 0; i < 3; i++ {\n   655→    funcs = append(funcs, func() {\n   656→        fmt.Println(i)  // All print 3\n   657→    })\n   658→}\n   659→\n   660→// Correct way\n   661→for i := 0; i < 3; i++ {\n   662→    i := i  // Shadow variable\n   663→    funcs = append(funcs, func() {\n   664→        fmt.Println(i)  // Prints 0, 1, 2\n   665→    })\n   666→}\n   667→\n   668→// Alternative correct way\n   669→for i := 0; i < 3; i++ {\n   670→    func(n int) {\n   671→        funcs = append(funcs, func() {\n   672→            fmt.Println(n)\n   673→        })\n   674→    }(i)\n   675→}\n   676→```\n   677→\n   678→## Methods\n   679→\n   680→### Method Declaration\n   681→\n   682→```go\n   683→// Method on struct\n   684→type Rectangle struct {\n   685→    Width, Height float64\n   686→}\n   687→\n   688→// Value receiver\n   689→func (r Rectangle) Area() float64 {\n   690→    return r.Width * r.Height\n   691→}\n   692→\n   693→// Pointer receiver\n   694→func (r *Rectangle) Scale(factor float64) {\n   695→    r.Width *= factor\n   696→    r.Height *= factor\n   697→}\n   698→\n   699→// Using methods\n   700→rect := Rectangle{Width: 10, Height: 5}\n   701→area := rect.Area()        // 50\n   702→rect.Scale(2)              // Width=20, Height=10\n   703→\n   704→// Method on non-struct types\n   705→type MyInt int\n   706→\n   707→func (m MyInt) IsEven() bool {\n   708→    return m%2 == 0\n   709→}\n   710→\n   711→var num MyInt = 42\n   712→if num.IsEven() {\n   713→    fmt.Println(\"Even number\")\n   714→}\n   715→\n   716→// Method on pointer vs value\n   717→type Counter struct {\n   718→    value int\n   719→}\n   720→\n   721→// Value receiver - cannot modify\n   722→func (c Counter) GetValue() int {\n   723→    return c.value\n   724→}\n   725→\n   726→// Pointer receiver - can modify\n   727→func (c *Counter) Increment() {\n   728→    c.value++\n   729→}\n   730→\n   731→// Pointer receiver - can handle nil\n   732→func (c *Counter) SafeIncrement() {\n   733→    if c == nil {\n   734→        return\n   735→    }\n   736→    c.value++\n   737→}\n   738→```\n   739→\n   740→### Method Sets\n   741→\n   742→```go\n   743→// Method set rules:\n   744→// - Type T has method set of all methods with receiver T\n   745→// - Type *T has method set of all methods with receiver T or *T\n   746→\n   747→type Shape struct {\n   748→    Name string\n   749→}\n   750→\n   751→func (s Shape) GetName() string {\n   752→    return s.Name\n   753→}\n   754→\n   755→func (s *Shape) SetName(name string) {\n   756→    s.Name = name\n   757→}\n   758→\n   759→// Value type can call value receiver methods\n   760→shape := Shape{Name: \"Circle\"}\n   761→name := shape.GetName()  // OK\n   762→\n   763→// Value type automatically gets address for pointer receiver\n   764→shape.SetName(\"Square\")  // OK (Go converts to (&shape).SetName())\n   765→\n   766→// Pointer type can call both\n   767→shapePtr := &Shape{Name: \"Triangle\"}\n   768→name = shapePtr.GetName()  // OK\n   769→shapePtr.SetName(\"Pentagon\")  // OK\n   770→```\n   771→\n   772→## Structs\n   773→\n   774→### Struct Declaration and Usage\n   775→\n   776→```go\n   777→// Basic struct\n   778→type Person struct {\n   779→    FirstName string\n   780→    LastName  string\n   781→    Age       int\n   782→}\n   783→\n   784→// Creating structs\n   785→p1 := Person{\n   786→    FirstName: \"John\",\n   787→    LastName:  \"Doe\",\n   788→    Age:       30,\n   789→}\n   790→\n   791→// Positional initialization (not recommended)\n   792→p2 := Person{\"Jane\", \"Doe\", 25}\n   793→\n   794→// Zero value struct\n   795→var p3 Person  // All fields have zero values\n   796→\n   797→// Accessing fields\n   798→fmt.Println(p1.FirstName)\n   799→p1.Age = 31\n   800→\n   801→// Struct pointer\n   802→ptr := &Person{FirstName: \"Bob\"}\n   803→ptr.Age = 40  // Automatic dereferencing\n   804→\n   805→// Anonymous struct\n   806→point := struct {\n   807→    X, Y int\n   808→}{X: 10, Y: 20}\n   809→\n   810→// Struct tags\n   811→type User struct {\n   812→    ID        int    `json:\"id\" db:\"user_id\"`\n   813→    Email     string `json:\"email\" validate:\"required,email\"`\n   814→    Password  string `json:\"-\"`  // Omit from JSON\n   815→    CreatedAt time.Time `json:\"created_at,omitempty\"`\n   816→}\n   817→\n   818→// Accessing tags via reflection\n   819→import \"reflect\"\n   820→\n   821→t := reflect.TypeOf(User{})\n   822→field, _ := t.FieldByName(\"Email\")\n   823→fmt.Println(field.Tag.Get(\"json\"))     // \"email\"\n   824→fmt.Println(field.Tag.Get(\"validate\")) // \"required,email\"\n   825→```\n   826→\n   827→### Struct Embedding\n   828→\n   829→```go\n   830→// Embedding for composition\n   831→type Address struct {\n   832→    Street  string\n   833→    City    string\n   834→    Country string\n   835→}\n   836→\n   837→type Employee struct {\n   838→    Person  // Embedded struct\n   839→    Address // Another embedded struct\n   840→    Salary  float64\n   841→}\n   842→\n   843→emp := Employee{\n   844→    Person: Person{\n   845→        FirstName: \"Alice\",\n   846→        LastName:  \"Smith\",\n   847→        Age:       28,\n   848→    },\n   849→    Address: Address{\n   850→        City:    \"New York\",\n   851→        Country: \"USA\",\n   852→    },\n   853→    Salary: 75000,\n   854→}\n   855→\n   856→// Promoted fields\n   857→fmt.Println(emp.FirstName)  // Promoted from Person\n   858→fmt.Println(emp.City)       // Promoted from Address\n   859→\n   860→// Explicit access\n   861→fmt.Println(emp.Person.FirstName)\n   862→\n   863→// Method promotion\n   864→type Writer struct{}\n   865→\n   866→func (w Writer) Write(data []byte) (int, error) {\n   867→    return len(data), nil\n   868→}\n   869→\n   870→type Logger struct {\n   871→    Writer  // Embedded\n   872→    prefix string\n   873→}\n   874→\n   875→log := Logger{prefix: \"[INFO]\"}\n   876→log.Write([]byte(\"message\"))  // Promoted method\n   877→```\n   878→\n   879→### Struct Comparison\n   880→\n   881→```go\n   882→// Structs are comparable if all fields are comparable\n   883→type Point struct {\n   884→    X, Y int\n   885→}\n   886→\n   887→p1 := Point{1, 2}\n   888→p2 := Point{1, 2}\n   889→p3 := Point{2, 3}\n   890→\n   891→fmt.Println(p1 == p2)  // true\n   892→fmt.Println(p1 == p3)  // false\n   893→\n   894→// Non-comparable structs (contain slices, maps, functions)\n   895→type Data struct {\n   896→    Values []int  // Slices are not comparable\n   897→}\n   898→\n   899→// This won't compile:\n   900→// d1 := Data{Values: []int{1, 2}}\n   901→// d2 := Data{Values: []int{1, 2}}\n   902→// fmt.Println(d1 == d2)  // Compile error\n   903→```\n   904→\n   905→## Interfaces\n   906→\n   907→### Interface Declaration and Implementation\n   908→\n   909→```go\n   910→// Interface declaration\n   911→type Writer interface {\n   912→    Write([]byte) (int, error)\n   913→}\n   914→\n   915→// Interface with multiple methods\n   916→type ReadWriter interface {\n   917→    Read([]byte) (int, error)\n   918→    Write([]byte) (int, error)\n   919→}\n   920→\n   921→// Empty interface (any type)\n   922→type Any interface{}  // Pre Go 1.18\n   923→type Any = any        // Go 1.18+\n   924→\n   925→// Implicit implementation\n   926→type FileWriter struct {\n   927→    filename string\n   928→}\n   929→\n   930→func (f FileWriter) Write(data []byte) (int, error) {\n   931→    // Implementation\n   932→    return len(data), nil\n   933→}\n   934→\n   935→// FileWriter implements Writer implicitly\n   936→var w Writer = FileWriter{filename: \"test.txt\"}\n   937→```\n   938→\n   939→### Interface Composition\n   940→\n   941→```go\n   942→// Composing interfaces\n   943→type Reader interface {\n   944→    Read([]byte) (int, error)\n   945→}\n   946→\n   947→type Writer interface {\n   948→    Write([]byte) (int, error)\n   949→}\n   950→\n   951→type Closer interface {\n   952→    Close() error\n   953→}\n   954→\n   955→// Composed interface\n   956→type ReadWriteCloser interface {\n   957→    Reader\n   958→    Writer\n   959→    Closer\n   960→}\n   961→\n   962→// Alternative inline composition\n   963→type ReadWriter interface {\n   964→    Read([]byte) (int, error)\n   965→    Write([]byte) (int, error)\n   966→}\n   967→```\n   968→\n   969→### Interface Values and nil\n   970→\n   971→```go\n   972→// Interface values have two components: type and value\n   973→var w Writer\n   974→fmt.Printf(\"Type: %T, Value: %v\\n\", w, w)  // Type: <nil>, Value: <nil>\n   975→\n   976→// nil interface vs interface with nil value\n   977→type MyWriter struct{}\n   978→\n   979→func (m *MyWriter) Write(data []byte) (int, error) {\n   980→    if m == nil {\n   981→        return 0, errors.New(\"nil writer\")\n   982→    }\n   983→    return len(data), nil\n   984→}\n   985→\n   986→var mw *MyWriter = nil\n   987→var w Writer = mw\n   988→// w is not nil (has type *MyWriter), but its value is nil\n   989→\n   990→if w == nil {\n   991→    fmt.Println(\"w is nil\")  // Won't print\n   992→}\n   993→\n   994→// Check for nil value\n   995→if mw == nil {\n   996→    fmt.Println(\"mw is nil\")  // Will print\n   997→}\n   998→```\n   999→\n  1000→### Type Assertions and Type Switches\n  1001→\n  1002→```go\n  1003→// Type assertion\n  1004→var i interface{} = \"hello\"\n  1005→\n  1006→// Direct assertion (panics if wrong type)\n  1007→s := i.(string)\n  1008→fmt.Println(s)\n  1009→\n  1010→// Safe assertion with comma-ok\n  1011→s, ok := i.(string)\n  1012→if ok {\n  1013→    fmt.Println(\"String:\", s)\n  1014→}\n  1015→\n  1016→// Check interface implementation\n  1017→var w io.Writer = &bytes.Buffer{}\n  1018→if buf, ok := w.(*bytes.Buffer); ok {\n  1019→    fmt.Println(\"It's a buffer:\", buf)\n  1020→}\n  1021→\n  1022→// Type switch\n  1023→func describe(i interface{}) {\n  1024→    switch v := i.(type) {\n  1025→    case int:\n  1026→        fmt.Printf(\"Integer: %d\\n\", v)\n  1027→    case string:\n  1028→        fmt.Printf(\"String: %s\\n\", v)\n  1029→    case io.Reader:\n  1030→        fmt.Println(\"It's a reader\")\n  1031→    case nil:\n  1032→        fmt.Println(\"It's nil\")\n  1033→    default:\n  1034→        fmt.Printf(\"Unknown type: %T\\n\", v)\n  1035→    }\n  1036→}\n  1037→```\n  1038→\n  1039→### Common Interface Patterns\n  1040→\n  1041→```go\n  1042→// Stringer interface\n  1043→type Stringer interface {\n  1044→    String() string\n  1045→}\n  1046→\n  1047→type Point struct {\n  1048→    X, Y int\n  1049→}\n  1050→\n  1051→func (p Point) String() string {\n  1052→    return fmt.Sprintf(\"(%d, %d)\", p.X, p.Y)\n  1053→}\n  1054→\n  1055→// Error interface\n  1056→type error interface {\n  1057→    Error() string\n  1058→}\n  1059→\n  1060→type ValidationError struct {\n  1061→    Field string\n  1062→    Value string\n  1063→}\n  1064→\n  1065→func (e ValidationError) Error() string {\n  1066→    return fmt.Sprintf(\"validation failed for field %s: %s\", e.Field, e.Value)\n  1067→}\n  1068→\n  1069→// Sort interface\n  1070→type Interface interface {\n  1071→    Len() int\n  1072→    Less(i, j int) bool\n  1073→    Swap(i, j int)\n  1074→}\n  1075→\n  1076→// Custom sort implementation\n  1077→type ByAge []Person\n  1078→\n  1079→func (a ByAge) Len() int           { return len(a) }\n  1080→func (a ByAge) Less(i, j int) bool { return a[i].Age < a[j].Age }\n  1081→func (a ByAge) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }\n  1082→\n  1083→// Usage\n  1084→people := []Person{{Name: \"Alice\", Age: 30}, {Name: \"Bob\", Age: 25}}\n  1085→sort.Sort(ByAge(people))\n  1086→```\n  1087→\n  1088→## Pointers\n  1089→\n  1090→### Pointer Basics\n  1091→\n  1092→```go\n  1093→// Declare pointer\n  1094→var p *int\n  1095→\n  1096→// Get address of variable\n  1097→x := 42\n  1098→p = &x\n  1099→\n  1100→// Dereference pointer\n  1101→fmt.Println(*p)  // 42\n  1102→*p = 100\n  1103→fmt.Println(x)   // 100\n  1104→\n  1105→// Pointer zero value is nil\n  1106→var ptr *string\n  1107→if ptr == nil {\n  1108→    fmt.Println(\"ptr is nil\")\n  1109→}\n  1110→\n  1111→// New function allocates memory\n  1112→ptr = new(string)\n  1113→*ptr = \"Hello\"\n  1114→\n  1115→// Pointer to struct\n  1116→type Person struct {\n  1117→    Name string\n  1118→    Age  int\n  1119→}\n  1120→\n  1121→person := &Person{Name: \"Alice\", Age: 30}\n  1122→person.Age = 31  // Automatic dereferencing\n  1123→\n  1124→// Pointer arithmetic is NOT allowed in Go\n  1125→// p++  // This won't compile\n  1126→```\n  1127→\n  1128→### Pointers vs Values\n  1129→\n  1130→```go\n  1131→// Pass by value\n  1132→func modifyValue(x int) {\n  1133→    x = 100  // Doesn't affect original\n  1134→}\n  1135→\n  1136→// Pass by pointer\n  1137→func modifyPointer(x *int) {\n  1138→    *x = 100  // Modifies original\n  1139→}\n  1140→\n  1141→value := 42\n  1142→modifyValue(value)\n  1143→fmt.Println(value)  // Still 42\n  1144→\n  1145→modifyPointer(&value)\n  1146→fmt.Println(value)  // Now 100\n  1147→\n  1148→// Slices, maps, channels are reference types\n  1149→func modifySlice(s []int) {\n  1150→    s[0] = 100  // Modifies original\n  1151→}\n  1152→\n  1153→slice := []int{1, 2, 3}\n  1154→modifySlice(slice)\n  1155→fmt.Println(slice)  // [100, 2, 3]\n  1156→\n  1157→// But reassigning doesn't affect original\n  1158→func reassignSlice(s []int) {\n  1159→    s = []int{4, 5, 6}  // Doesn't affect original\n  1160→}\n  1161→\n  1162→// To modify slice itself, use pointer\n  1163→func replaceSlice(s *[]int) {\n  1164→    *s = []int{4, 5, 6}\n  1165→}\n  1166→```\n  1167→\n  1168→## Arrays and Slices\n  1169→\n  1170→### Arrays\n  1171→\n  1172→```go\n  1173→// Array declaration\n  1174→var arr [5]int              // [0 0 0 0 0]\n  1175→arr[0] = 10\n  1176→arr[4] = 50\n  1177→\n  1178→// Array initialization\n  1179→arr := [5]int{1, 2, 3, 4, 5}\n  1180→arr := [...]int{1, 2, 3}    // Compiler counts elements\n  1181→arr := [5]int{0: 10, 4: 50} // Index:value pairs\n  1182→\n  1183→// Arrays are values (copied on assignment)\n  1184→arr1 := [3]int{1, 2, 3}\n  1185→arr2 := arr1\n  1186→arr2[0] = 100\n  1187→fmt.Println(arr1)  // [1 2 3] - unchanged\n  1188→fmt.Println(arr2)  // [100 2 3]\n  1189→\n  1190→// Array size is part of type\n  1191→var a [5]int\n  1192→var b [10]int\n  1193→// a = b  // Won't compile - different types\n  1194→\n  1195→// Multidimensional arrays\n  1196→var matrix [3][3]int\n  1197→matrix[1][1] = 5\n  1198→\n  1199→// Array iteration\n  1200→for i := 0; i < len(arr); i++ {\n  1201→    fmt.Println(arr[i])\n  1202→}\n  1203→\n  1204→for index, value := range arr {\n  1205→    fmt.Printf(\"%d: %d\\n\", index, value)\n  1206→}\n  1207→```\n  1208→\n  1209→### Slices\n  1210→\n  1211→```go\n  1212→// Slice declaration\n  1213→var slice []int            // nil slice\n  1214→slice = []int{}           // Empty slice\n  1215→slice = []int{1, 2, 3}    // Initialized slice\n  1216→\n  1217→// Make function\n  1218→slice = make([]int, 5)    // Length 5, capacity 5\n  1219→slice = make([]int, 5, 10) // Length 5, capacity 10\n  1220→\n  1221→// Slice from array\n  1222→arr := [5]int{1, 2, 3, 4, 5}\n  1223→slice = arr[1:4]  // [2 3 4]\n  1224→slice = arr[:3]   // [1 2 3]\n  1225→slice = arr[2:]   // [3 4 5]\n  1226→slice = arr[:]    // [1 2 3 4 5]\n  1227→\n  1228→// Slice properties\n  1229→fmt.Println(len(slice))  // Length\n  1230→fmt.Println(cap(slice))  // Capacity\n  1231→\n  1232→// Append\n  1233→slice = []int{1, 2, 3}\n  1234→slice = append(slice, 4)\n  1235→slice = append(slice, 5, 6, 7)\n  1236→slice = append(slice, []int{8, 9}...)\n  1237→\n  1238→// Copy\n  1239→src := []int{1, 2, 3}\n  1240→dst := make([]int, len(src))\n  1241→n := copy(dst, src)  // Returns number copied\n  1242→\n  1243→// Slice tricks\n  1244→// Remove element at index i\n  1245→slice = append(slice[:i], slice[i+1:]...)\n  1246→\n  1247→// Insert element at index i\n  1248→slice = append(slice[:i], append([]int{x}, slice[i:]...)...)\n  1249→\n  1250→// Pop from end\n  1251→x := slice[len(slice)-1]\n  1252→slice = slice[:len(slice)-1]\n  1253→\n  1254→// Push to front\n  1255→slice = append([]int{x}, slice...)\n  1256→\n  1257→// Filter in place\n  1258→n := 0\n  1259→for _, x := range slice {\n  1260→    if keepElement(x) {\n  1261→        slice[n] = x\n  1262→        n++\n  1263→    }\n  1264→}\n  1265→slice = slice[:n]\n  1266→```\n  1267→\n  1268→### Slice Internals\n  1269→\n  1270→```go\n  1271→// Slice header (conceptual)\n  1272→type SliceHeader struct {\n  1273→    Data uintptr  // Pointer to underlying array\n  1274→    Len  int      // Current length\n  1275→    Cap  int      // Capacity\n  1276→}\n  1277→\n  1278→// Slices share underlying array\n  1279→original := []int{1, 2, 3, 4, 5}\n  1280→slice1 := original[1:4]  // [2 3 4]\n  1281→slice2 := original[2:5]  // [3 4 5]\n  1282→\n  1283→slice1[1] = 100  // Modifies shared array\n  1284→fmt.Println(slice2)  // [100 4 5]\n  1285→\n  1286→// Full slice expression controls capacity\n  1287→slice := original[1:3:4]  // [low:high:max]\n  1288→// len = high - low = 2\n  1289→// cap = max - low = 3\n  1290→\n  1291→// nil vs empty slice\n  1292→var nilSlice []int        // nil\n  1293→emptySlice := []int{}     // Not nil, but empty\n  1294→madeSlice := make([]int, 0) // Not nil, but empty\n  1295→\n  1296→fmt.Println(nilSlice == nil)    // true\n  1297→fmt.Println(emptySlice == nil)  // false\n  1298→fmt.Println(len(nilSlice))      // 0\n  1299→fmt.Println(len(emptySlice))    // 0\n  1300→\n  1301→// Both work with append\n  1302→nilSlice = append(nilSlice, 1)\n  1303→emptySlice = append(emptySlice, 1)\n  1304→```\n  1305→\n  1306→## Maps\n  1307→\n  1308→### Map Basics\n  1309→\n  1310→```go\n  1311→// Map declaration\n  1312→var m map[string]int      // nil map\n  1313→m = make(map[string]int)  // Initialize\n  1314→\n  1315→// Map literal\n  1316→m = map[string]int{\n  1317→    \"Alice\": 30,\n  1318→    \"Bob\":   25,\n  1319→}\n  1320→\n  1321→// Operations\n  1322→m[\"Charlie\"] = 35         // Insert/Update\n  1323→age := m[\"Alice\"]         // Retrieve\n  1324→delete(m, \"Bob\")          // Delete\n  1325→\n  1326→// Check if key exists\n  1327→age, exists := m[\"David\"]\n  1328→if exists {\n  1329→    fmt.Printf(\"David is %d years old\\n\", age)\n  1330→}\n  1331→\n  1332→// Zero value for missing key\n  1333→fmt.Println(m[\"Unknown\"])  // 0 (zero value for int)\n  1334→\n  1335→// Iteration (order is random)\n  1336→for key, value := range m {\n  1337→    fmt.Printf(\"%s: %d\\n\", key, value)\n  1338→}\n  1339→\n  1340→// Keys only\n  1341→for key := range m {\n  1342→    fmt.Println(key)\n  1343→}\n  1344→\n  1345→// Values only\n  1346→for _, value := range m {\n  1347→    fmt.Println(value)\n  1348→}\n  1349→```\n  1350→\n  1351→### Map Patterns\n  1352→\n  1353→```go\n  1354→// Map as set\n  1355→set := make(map[string]bool)\n  1356→set[\"apple\"] = true\n  1357→set[\"banana\"] = true\n  1358→\n  1359→if set[\"apple\"] {\n  1360→    fmt.Println(\"apple is in the set\")\n  1361→}\n  1362→\n  1363→// Alternative set using empty struct (memory efficient)\n  1364→type void struct{}\n  1365→var member void\n  1366→\n  1367→set := make(map[string]void)\n  1368→set[\"apple\"] = member\n  1369→set[\"banana\"] = member\n  1370→\n  1371→if _, exists := set[\"apple\"]; exists {\n  1372→    fmt.Println(\"apple is in the set\")\n  1373→}\n  1374→\n  1375→// Counting with maps\n  1376→counts := make(map[string]int)\n  1377→words := []string{\"apple\", \"banana\", \"apple\", \"orange\", \"banana\", \"apple\"}\n  1378→\n  1379→for _, word := range words {\n  1380→    counts[word]++  // Works even if key doesn't exist\n  1381→}\n  1382→\n  1383→// Grouping with maps\n  1384→type Person struct {\n  1385→    Name string\n  1386→    Age  int\n  1387→}\n  1388→\n  1389→people := []Person{\n  1390→    {\"Alice\", 30},\n  1391→    {\"Bob\", 25},\n  1392→    {\"Charlie\", 30},\n  1393→    {\"David\", 25},\n  1394→}\n  1395→\n  1396→ageGroups := make(map[int][]Person)\n  1397→for _, person := range people {\n  1398→    ageGroups[person.Age] = append(ageGroups[person.Age], person)\n  1399→}\n  1400→\n  1401→// Map of maps\n  1402→nested := make(map[string]map[string]int)\n  1403→nested[\"scores\"] = make(map[string]int)\n  1404→nested[\"scores\"][\"Alice\"] = 95\n  1405→nested[\"scores\"][\"Bob\"] = 87\n  1406→\n  1407→// Safe nested access\n  1408→if scores, ok := nested[\"scores\"]; ok {\n  1409→    if score, ok := scores[\"Alice\"]; ok {\n  1410→        fmt.Printf(\"Alice's score: %d\\n\", score)\n  1411→    }\n  1412→}\n  1413→```\n  1414→\n  1415→### Maps and Concurrency\n  1416→\n  1417→```go\n  1418→// Maps are not safe for concurrent access\n  1419→// Use sync.Map or mutex\n  1420→\n  1421→import \"sync\"\n  1422→\n  1423→// With mutex\n  1424→type SafeMap struct {\n  1425→    mu sync.RWMutex\n  1426→    m  map[string]int\n  1427→}\n  1428→\n  1429→func (sm *SafeMap) Set(key string, value int) {\n  1430→    sm.mu.Lock()\n  1431→    defer sm.mu.Unlock()\n  1432→    sm.m[key] = value\n  1433→}\n  1434→\n  1435→func (sm *SafeMap) Get(key string) (int, bool) {\n  1436→    sm.mu.RLock()\n  1437→    defer sm.mu.RUnlock()\n  1438→    value, exists := sm.m[key]\n  1439→    return value, exists\n  1440→}\n  1441→\n  1442→// Using sync.Map (for specific use cases)\n  1443→var m sync.Map\n  1444→\n  1445→// Store\n  1446→m.Store(\"key\", \"value\")\n  1447→\n  1448→// Load\n  1449→value, ok := m.Load(\"key\")\n  1450→\n  1451→// LoadOrStore\n  1452→actual, loaded := m.LoadOrStore(\"key\", \"new-value\")\n  1453→\n  1454→// Delete\n  1455→m.Delete(\"key\")\n  1456→\n  1457→// Range\n  1458→m.Range(func(key, value interface{}) bool {\n  1459→    fmt.Printf(\"%v: %v\\n\", key, value)\n  1460→    return true  // Continue iteration\n  1461→})\n  1462→```\n  1463→\n  1464→## Error Handling\n  1465→\n  1466→### Error Interface\n  1467→\n  1468→```go\n  1469→// Error interface\n  1470→type error interface {\n  1471→    Error() string\n  1472→}\n  1473→\n  1474→// Creating errors\n  1475→import \"errors\"\n  1476→\n  1477→err := errors.New(\"something went wrong\")\n  1478→err := fmt.Errorf(\"failed to process %s: %v\", filename, originalErr)\n  1479→\n  1480→// Custom error types\n  1481→type ValidationError struct {\n  1482→    Field string\n  1483→    Value interface{}\n  1484→    Msg   string\n  1485→}\n  1486→\n  1487→func (e ValidationError) Error() string {\n  1488→    return fmt.Sprintf(\"validation error: field=%s value=%v msg=%s\", \n  1489→        e.Field, e.Value, e.Msg)\n  1490→}\n  1491→\n  1492→// Sentinel errors\n  1493→var (\n  1494→    ErrNotFound   = errors.New(\"not found\")\n  1495→    ErrPermission = errors.New(\"permission denied\")\n  1496→    ErrTimeout    = errors.New(\"operation timed out\")\n  1497→)\n  1498→\n  1499→// Error wrapping (Go 1.13+)\n  1500→originalErr := errors.New(\"original error\")\n  1501→wrappedErr := fmt.Errorf(\"wrapped: %w\", originalErr)\n  1502→\n  1503→// Unwrap errors\n  1504→if errors.Is(wrappedErr, originalErr) {\n  1505→    fmt.Println(\"Error is originalErr\")\n  1506→}\n  1507→\n  1508→var validationErr ValidationError\n  1509→if errors.As(wrappedErr, &validationErr) {\n  1510→    fmt.Printf(\"Validation error: %s\\n\", validationErr.Field)\n  1511→}\n  1512→```\n  1513→\n  1514→### Error Handling Patterns\n  1515→\n  1516→```go\n  1517→// Immediate error checking\n  1518→result, err := doSomething()\n  1519→if err != nil {\n  1520→    return fmt.Errorf(\"doSomething failed: %w\", err)\n  1521→}\n  1522→\n  1523→// Multiple error sources\n  1524→func processFile(filename string) error {\n  1525→    file, err := os.Open(filename)\n  1526→    if err != nil {\n  1527→        return fmt.Errorf(\"open file: %w\", err)\n  1528→    }\n  1529→    defer file.Close()\n  1530→    \n  1531→    data, err := io.ReadAll(file)\n  1532→    if err != nil {\n  1533→        return fmt.Errorf(\"read file: %w\", err)\n  1534→    }\n  1535→    \n  1536→    if err := processData(data); err != nil {\n  1537→        return fmt.Errorf(\"process data: %w\", err)\n  1538→    }\n  1539→    \n  1540→    return nil\n  1541→}\n  1542→\n  1543→// Error accumulation\n  1544→var errs []error\n  1545→\n  1546→for _, item := range items {\n  1547→    if err := process(item); err != nil {\n  1548→        errs = append(errs, err)\n  1549→    }\n  1550→}\n  1551→\n  1552→if len(errs) > 0 {\n  1553→    return fmt.Errorf(\"processing failed with %d errors\", len(errs))\n  1554→}\n  1555→\n  1556→// Retry pattern\n  1557→func retryOperation(maxAttempts int) error {\n  1558→    var lastErr error\n  1559→    \n  1560→    for i := 0; i < maxAttempts; i++ {\n  1561→        if err := attemptOperation(); err != nil {\n  1562→            lastErr = err\n  1563→            time.Sleep(time.Second * time.Duration(i+1))\n  1564→            continue\n  1565→        }\n  1566→        return nil  // Success\n  1567→    }\n  1568→    \n  1569→    return fmt.Errorf(\"failed after %d attempts: %w\", maxAttempts, lastErr)\n  1570→}\n  1571→\n  1572→// Cleanup on error\n  1573→func createResources() (err error) {\n  1574→    resource1, err := createResource1()\n  1575→    if err != nil {\n  1576→        return err\n  1577→    }\n  1578→    defer func() {\n  1579→        if err != nil {\n  1580→            resource1.Cleanup()\n  1581→        }\n  1582→    }()\n  1583→    \n  1584→    resource2, err := createResource2()\n  1585→    if err != nil {\n  1586→        return err  // resource1 cleaned up by defer\n  1587→    }\n  1588→    \n  1589→    return nil\n  1590→}\n  1591→```\n  1592→\n  1593→## Packages and Modules\n  1594→\n  1595→### Package Organization\n  1596→\n  1597→```go\n  1598→// Package declaration (first non-comment line)\n  1599→package mypackage\n  1600→\n  1601→// Package documentation\n  1602→// Package mypackage provides utilities for data processing.\n  1603→// It includes functions for parsing, validation, and transformation.\n  1604→package mypackage\n  1605→\n  1606→// Import statements\n  1607→import (\n  1608→    \"fmt\"           // Standard library\n  1609→    \"time\"\n  1610→    \n  1611→    \"github.com/pkg/errors\"  // External packages\n  1612→    \n  1613→    \"myproject/internal/utils\"  // Internal packages\n  1614→)\n  1615→\n  1616→// Import aliasing\n  1617→import (\n  1618→    \"context\"\n  1619→    stdlog \"log\"  // Alias to avoid conflicts\n  1620→    . \"math\"      // Dot import (use sparingly)\n  1621→    _ \"image/png\" // Import for side effects only\n  1622→)\n  1623→\n  1624→// Package initialization\n  1625→func init() {\n  1626→    // Runs when package is imported\n  1627→    // Can have multiple init functions\n  1628→    fmt.Println(\"Package initialized\")\n  1629→}\n  1630→\n  1631→// Exported (public) - uppercase\n  1632→func PublicFunction() {}\n  1633→type PublicType struct{}\n  1634→const PublicConst = 42\n  1635→var PublicVar = \"hello\"\n  1636→\n  1637→// Unexported (private) - lowercase\n  1638→func privateFunction() {}\n  1639→type privateType struct{}\n  1640→const privateConst = 42\n  1641→var privateVar = \"hello\"\n  1642→```\n  1643→\n  1644→### Module Management\n  1645→\n  1646→```bash\n  1647→# Initialize module\n  1648→go mod init github.com/username/projectname\n  1649→\n  1650→# Add dependencies\n  1651→go get github.com/pkg/errors\n  1652→go get github.com/stretchr/testify@v1.8.0\n  1653→\n  1654→# Update dependencies\n  1655→go get -u ./...              # Update all\n  1656→go get -u github.com/pkg/errors  # Update specific\n  1657→\n  1658→# Clean up\n  1659→go mod tidy  # Remove unused dependencies\n  1660→\n  1661→# Vendor dependencies\n  1662→go mod vendor  # Copy dependencies to vendor/\n  1663→\n  1664→# Module directives in go.mod\n  1665→module github.com/username/project\n  1666→\n  1667→go 1.21\n  1668→\n  1669→require (\n  1670→    github.com/pkg/errors v0.9.1\n  1671→    github.com/stretchr/testify v1.8.0\n  1672→)\n  1673→\n  1674→replace github.com/old/package => github.com/new/package v1.0.0\n  1675→\n  1676→exclude github.com/bad/package v1.0.0\n  1677→```\n  1678→\n  1679→### Internal Packages\n  1680→\n  1681→```go\n  1682→// Internal packages can only be imported by nearby code\n  1683→myproject/\n  1684→├── cmd/\n  1685→│   └── app/\n  1686→│       └── main.go  // Can import internal/\n  1687→├── internal/\n  1688→│   ├── database/    // Only accessible within myproject\n  1689→│   └── utils/\n  1690→├── pkg/             // Public packages\n  1691→│   └── api/\n  1692→└── go.mod\n  1693→\n  1694→// This import works in myproject\n  1695→import \"myproject/internal/database\"\n  1696→\n  1697→// This import fails outside myproject\n  1698→import \"github.com/other/project/internal/database\"  // Error\n  1699→```\n  1700→\n  1701→## Type Assertions and Type Switches\n  1702→\n  1703→### Type Assertions\n  1704→\n  1705→```go\n  1706→// Basic type assertion\n  1707→var i interface{} = \"hello\"\n  1708→s := i.(string)  // Panics if not string\n  1709→fmt.Println(s)\n  1710→\n  1711→// Safe type assertion\n  1712→s, ok := i.(string)\n  1713→if !ok {\n  1714→    fmt.Println(\"Not a string\")\n  1715→}\n  1716→\n  1717→// Common patterns\n  1718→func processValue(v interface{}) {\n  1719→    // Try multiple types\n  1720→    switch value := v.(type) {\n  1721→    case string:\n  1722→        fmt.Printf(\"String: %s\\n\", value)\n  1723→    case int:\n  1724→        fmt.Printf(\"Integer: %d\\n\", value)\n  1725→    case []byte:\n  1726→        fmt.Printf(\"Bytes: %s\\n\", string(value))\n  1727→    default:\n  1728→        fmt.Printf(\"Unknown: %T\\n\", value)\n  1729→    }\n  1730→}\n  1731→\n  1732→// Check for interface implementation\n  1733→type Stringer interface {\n  1734→    String() string\n  1735→}\n  1736→\n  1737→func toString(v interface{}) string {\n  1738→    if s, ok := v.(Stringer); ok {\n  1739→        return s.String()\n  1740→    }\n  1741→    return fmt.Sprintf(\"%v\", v)\n  1742→}\n  1743→\n  1744→// Nil interface gotcha\n  1745→var p *Person  // nil pointer\n  1746→var i interface{} = p\n  1747→\n  1748→if i == nil {\n  1749→    fmt.Println(\"i is nil\")  // Won't print!\n  1750→}\n  1751→\n  1752→if p == nil {\n  1753→    fmt.Println(\"p is nil\")  // Will print\n  1754→}\n  1755→```\n  1756→\n  1757→## Embedding and Composition\n  1758→\n  1759→### Struct Embedding\n  1760→\n  1761→```go\n  1762→// Base types\n  1763→type Person struct {\n  1764→    Name string\n  1765→    Age  int\n  1766→}\n  1767→\n  1768→type Address struct {\n  1769→    Street string\n  1770→    City   string\n  1771→}\n  1772→\n  1773→// Embedding\n  1774→type Employee struct {\n  1775→    Person      // Anonymous field\n  1776→    Address     // Another anonymous field\n  1777→    Department string\n  1778→    Salary     float64\n  1779→}\n  1780→\n  1781→emp := Employee{\n  1782→    Person:     Person{Name: \"Alice\", Age: 30},\n  1783→    Address:    Address{City: \"New York\"},\n  1784→    Department: \"Engineering\",\n  1785→}\n  1786→\n  1787→// Field promotion\n  1788→fmt.Println(emp.Name)  // Accessed directly\n  1789→fmt.Println(emp.City)\n  1790→\n  1791→// Method promotion\n  1792→func (p Person) Introduce() {\n  1793→    fmt.Printf(\"Hi, I'm %s\\n\", p.Name)\n  1794→}\n  1795→\n  1796→emp.Introduce()  // Method promoted from Person\n  1797→\n  1798→// Shadowing\n  1799→type Manager struct {\n  1800→    Employee\n  1801→    Name string  // Shadows Person.Name\n  1802→}\n  1803→\n  1804→mgr := Manager{\n  1805→    Employee: emp,\n  1806→    Name:     \"Manager Name\",  // This shadows Employee.Person.Name\n  1807→}\n  1808→\n  1809→fmt.Println(mgr.Name)              // \"Manager Name\"\n  1810→fmt.Println(mgr.Employee.Name)     // \"Alice\"\n  1811→fmt.Println(mgr.Employee.Person.Name)  // \"Alice\"\n  1812→```\n  1813→\n  1814→### Interface Embedding\n  1815→\n  1816→```go\n  1817→// Base interfaces\n  1818→type Reader interface {\n  1819→    Read([]byte) (int, error)\n  1820→}\n  1821→\n  1822→type Writer interface {\n  1823→    Write([]byte) (int, error)\n  1824→}\n  1825→\n  1826→type Closer interface {\n  1827→    Close() error\n  1828→}\n  1829→\n  1830→// Embedded interfaces\n  1831→type ReadWriter interface {\n  1832→    Reader\n  1833→    Writer\n  1834→}\n  1835→\n  1836→type ReadWriteCloser interface {\n  1837→    Reader\n  1838→    Writer\n  1839→    Closer\n  1840→}\n  1841→\n  1842→// Alternative syntax\n  1843→type ReadWriteCloser interface {\n  1844→    Read([]byte) (int, error)\n  1845→    Write([]byte) (int, error)\n  1846→    Close() error\n  1847→}\n  1848→\n  1849→// Implementation\n  1850→type File struct {\n  1851→    // fields\n  1852→}\n  1853→\n  1854→func (f *File) Read(p []byte) (int, error) {\n  1855→    // implementation\n  1856→}\n  1857→\n  1858→func (f *File) Write(p []byte) (int, error) {\n  1859→    // implementation\n  1860→}\n  1861→\n  1862→func (f *File) Close() error {\n  1863→    // implementation\n  1864→}\n  1865→\n  1866→// File now implements ReadWriteCloser\n  1867→var rwc ReadWriteCloser = &File{}\n  1868→```\n  1869→\n  1870→## Generics\n  1871→\n  1872→### Generic Functions\n  1873→\n  1874→```go\n  1875→// Generic function with type parameter\n  1876→func Max[T comparable](a, b T) T {\n  1877→    if a > b {\n  1878→        return a\n  1879→    }\n  1880→    return b\n  1881→}\n  1882→\n  1883→// Usage\n  1884→maxInt := Max(10, 20)           // Type inferred\n  1885→maxFloat := Max[float64](3.14, 2.71)  // Explicit type\n  1886→\n  1887→// Multiple type parameters\n  1888→func Swap[T, U any](a T, b U) (U, T) {\n  1889→    return b, a\n  1890→}\n  1891→\n  1892→// Type constraints\n  1893→type Number interface {\n  1894→    int | int32 | int64 | float32 | float64\n  1895→}\n  1896→\n  1897→func Sum[T Number](numbers []T) T {\n  1898→    var sum T\n  1899→    for _, n := range numbers {\n  1900→        sum += n\n  1901→    }\n  1902→    return sum\n  1903→}\n  1904→\n  1905→// Using standard constraints\n  1906→import \"golang.org/x/exp/constraints\"\n  1907→\n  1908→func Min[T constraints.Ordered](a, b T) T {\n  1909→    if a < b {\n  1910→        return a\n  1911→    }\n  1912→    return b\n  1913→}\n  1914→```\n  1915→\n  1916→### Generic Types\n  1917→\n  1918→```go\n  1919→// Generic struct\n  1920→type Stack[T any] struct {\n  1921→    items []T\n  1922→}\n  1923→\n  1924→func (s *Stack[T]) Push(item T) {\n  1925→    s.items = append(s.items, item)\n  1926→}\n  1927→\n  1928→func (s *Stack[T]) Pop() (T, bool) {\n  1929→    var zero T\n  1930→    if len(s.items) == 0 {\n  1931→        return zero, false\n  1932→    }\n  1933→    item := s.items[len(s.items)-1]\n  1934→    s.items = s.items[:len(s.items)-1]\n  1935→    return item, true\n  1936→}\n  1937→\n  1938→// Usage\n  1939→intStack := Stack[int]{}\n  1940→intStack.Push(42)\n  1941→value, ok := intStack.Pop()\n  1942→\n  1943→// Generic interface\n  1944→type Container[T any] interface {\n  1945→    Add(T)\n  1946→    Get(int) T\n  1947→    Size() int\n  1948→}\n  1949→\n  1950→// Type inference with generics\n  1951→type Pair[T, U any] struct {\n  1952→    First  T\n  1953→    Second U\n  1954→}\n  1955→\n  1956→// Constructor function\n  1957→func NewPair[T, U any](first T, second U) Pair[T, U] {\n  1958→    return Pair[T, U]{First: first, Second: second}\n  1959→}\n  1960→\n  1961→// Type inference in use\n  1962→p := NewPair(1, \"hello\")  // Pair[int, string] inferred\n  1963→```\n  1964→\n  1965→### Type Constraints\n  1966→\n  1967→```go\n  1968→// Custom constraints\n  1969→type Signed interface {\n  1970→    ~int | ~int8 | ~int16 | ~int32 | ~int64\n  1971→}\n  1972→\n  1973→type Unsigned interface {\n  1974→    ~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64\n  1975→}\n  1976→\n  1977→type Integer interface {\n  1978→    Signed | Unsigned\n  1979→}\n  1980→\n  1981→// Tilde (~) allows underlying types\n  1982→type MyInt int\n  1983→\n  1984→func Double[T ~int](x T) T {\n  1985→    return x * 2\n  1986→}\n  1987→\n  1988→var mi MyInt = 5\n  1989→result := Double(mi)  // Works because MyInt's underlying type is int\n  1990→\n  1991→// Constraint with methods\n  1992→type Stringer interface {\n  1993→    String() string\n  1994→}\n  1995→\n  1996→func PrintAll[T Stringer](items []T) {\n  1997→    for _, item := range items {\n  1998→        fmt.Println(item.String())\n  1999→    }\n  2000→}\n  2001→\n  2002→// Complex constraints\n  2003→type Number interface {\n  2004→    ~int | ~int8 | ~int16 | ~int32 | ~int64 |\n  2005→    ~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64 |\n  2006→    ~float32 | ~float64\n  2007→}\n  2008→\n  2009→type Addable[T any] interface {\n  2010→    Add(T) T\n  2011→}\n  2012→\n  2013→type AddableNumber[T Number] interface {\n  2014→    Number\n  2015→    Addable[T]\n  2016→}\n  2017→```\n  2018→\n  2019→## Best Practices Summary\n  2020→\n  2021→### Code Organization\n  2022→- Keep packages small and focused\n  2023→- Use clear, descriptive names\n  2024→- Group related functionality\n  2025→- Minimize package dependencies\n  2026→- Use internal packages for private code\n  2027→\n  2028→### Error Handling\n  2029→- Always check errors\n  2030→- Wrap errors with context\n  2031→- Use sentinel errors for known conditions\n  2032→- Create custom error types when needed\n  2033→- Handle errors at the appropriate level\n  2034→\n  2035→### Concurrency\n  2036→- Don't communicate by sharing memory; share memory by communicating\n  2037→- Use channels for coordination\n  2038→- Keep goroutines simple\n  2039→- Always handle goroutine cleanup\n  2040→- Use context for cancellation\n  2041→\n  2042→### Performance\n  2043→- Measure before optimizing\n  2044→- Preallocate slices when size is known\n  2045→- Use string.Builder for string concatenation\n  2046→- Be aware of memory allocations\n  2047→- Profile your code\n  2048→\n  2049→### Testing\n  2050→- Write table-driven tests\n  2051→- Test edge cases\n  2052→- Use subtests for better organization\n  2053→- Mock external dependencies\n  2054→- Aim for high test coverage\n  2055→\n  2056→### Documentation\n  2057→- Document all exported items\n  2058→- Write clear package documentation\n  2059→- Include examples in documentation\n  2060→- Keep comments up to date\n  2061→- Use godoc format\n  2062→\n  2063→This comprehensive guide covers the fundamental aspects of Go programming. Each topic includes practical examples and best practices to help write idiomatic, efficient Go code.\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"e05025ce-a09a-4063-81d6-e83741f875cc","timestamp":"2025-08-13T10:27:55.186Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/fundamentals.md","content":"# Go Language Fundamentals - Complete Reference\n\n## Table of Contents\n1. [Introduction](#introduction)\n2. [Basic Syntax](#basic-syntax)\n3. [Variables and Constants](#variables-and-constants)\n4. [Data Types](#data-types)\n5. [Control Flow](#control-flow)\n6. [Functions](#functions)\n7. [Methods](#methods)\n8. [Structs](#structs)\n9. [Interfaces](#interfaces)\n10. [Pointers](#pointers)\n11. [Arrays and Slices](#arrays-and-slices)\n12. [Maps](#maps)\n13. [Error Handling](#error-handling)\n14. [Packages and Modules](#packages-and-modules)\n15. [Type Assertions and Type Switches](#type-assertions-and-type-switches)\n16. [Embedding and Composition](#embedding-and-composition)\n17. [Generics](#generics)\n\n## Introduction\n\nGo is a statically typed, compiled language designed for simplicity, efficiency, and reliable software. Created at Google in 2007 by Robert Griesemer, Rob Pike, and Ken Thompson, Go combines the performance of compiled languages with the ease of programming of dynamic languages.\n\n### Core Philosophy\n- **Simplicity**: Less is exponentially more\n- **Readability**: Code is read more often than written\n- **Efficiency**: Fast compilation, fast execution\n- **Concurrency**: Built-in primitives for concurrent programming\n- **Pragmatism**: Solve real problems with practical solutions\n\n## Basic Syntax\n\n### Program Structure\n\nEvery Go program starts with a package declaration and imports:\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"strings\"\n    \"time\"\n)\n\nfunc main() {\n    fmt.Println(\"Hello, Go!\")\n}\n```\n\n### Comments\n\n```go\n// Single-line comment\n\n/*\n   Multi-line comment\n   Can span multiple lines\n*/\n\n// Package documentation comment (must precede package declaration)\n// Package math provides basic mathematical functions.\npackage math\n\n// Function documentation (must precede function declaration)\n// Add returns the sum of two integers.\nfunc Add(a, b int) int {\n    return a + b\n}\n```\n\n### Naming Conventions\n\n```go\n// Exported (public) - starts with uppercase\ntype Strategy struct{}\nfunc CalculateProfit() {}\nconst MaxRetries = 3\nvar DefaultTimeout = 5 * time.Second\n\n// Unexported (private) - starts with lowercase\ntype position struct{}\nfunc calculateLoss() {}\nconst maxAttempts = 5\nvar defaultBuffer = 1024\n\n// Package names - lowercase, single word\npackage trading  // Good\npackage tradingEngine  // Bad - use trading or engine\n\n// Interface names - typically end with -er\ntype Reader interface{}\ntype Writer interface{}\ntype Closer interface{}\ntype ReadWriteCloser interface{}  // Composition\n\n// Acronyms - keep consistent case\nvar httpClient HTTP  // Bad\nvar HTTPClient HTTP  // Good\nvar xmlParser XML    // Bad\nvar XMLParser XML    // Good\n```\n\n## Variables and Constants\n\n### Variable Declaration\n\n```go\n// var declaration with type\nvar name string\nvar age int\nvar balance float64\n\n// var declaration with initialization\nvar name string = \"John\"\nvar age int = 30\nvar balance = 1000.50  // Type inferred\n\n// Short variable declaration (only inside functions)\nname := \"John\"\nage := 30\nbalance := 1000.50\n\n// Multiple variable declaration\nvar (\n    firstName string = \"John\"\n    lastName  string = \"Doe\"\n    age       int    = 30\n)\n\n// Multiple assignment\nx, y := 10, 20\na, b = b, a  // Swap values\n\n// Blank identifier for unused values\n_, err := someFunction()  // Ignore first return value\n```\n\n### Constants\n\n```go\n// Single constant\nconst Pi = 3.14159\nconst MaxRetries = 3\nconst Message = \"Hello\"\n\n// Typed constants\nconst MaxInt int = 1000\nconst Timeout time.Duration = 5 * time.Second\n\n// Multiple constants\nconst (\n    StatusOK       = 200\n    StatusNotFound = 404\n    StatusError    = 500\n)\n\n// iota - constant generator\nconst (\n    Sunday = iota  // 0\n    Monday         // 1\n    Tuesday        // 2\n    Wednesday      // 3\n    Thursday       // 4\n    Friday         // 5\n    Saturday       // 6\n)\n\n// iota with expressions\nconst (\n    _  = iota             // 0 (ignored)\n    KB = 1 << (10 * iota) // 1024\n    MB                    // 1048576\n    GB                    // 1073741824\n    TB                    // 1099511627776\n)\n\n// Bit flags with iota\nconst (\n    ReadPermission = 1 << iota  // 1\n    WritePermission              // 2\n    ExecutePermission            // 4\n)\n```\n\n## Data Types\n\n### Basic Types\n\n```go\n// Boolean\nvar isActive bool = true\nvar isComplete bool  // Zero value: false\n\n// Integers\nvar i8 int8 = 127                    // -128 to 127\nvar i16 int16 = 32767                // -32768 to 32767\nvar i32 int32 = 2147483647           // -2147483648 to 2147483647\nvar i64 int64 = 9223372036854775807  // -9223372036854775808 to 9223372036854775807\nvar i int = 42                       // Platform dependent (32 or 64 bit)\n\n// Unsigned integers\nvar ui8 uint8 = 255                  // 0 to 255 (byte is alias)\nvar ui16 uint16 = 65535              // 0 to 65535\nvar ui32 uint32 = 4294967295         // 0 to 4294967295\nvar ui64 uint64 = 18446744073709551615  // 0 to 18446744073709551615\nvar ui uint = 42                     // Platform dependent\n\n// Floating point\nvar f32 float32 = 3.14               // IEEE-754 32-bit\nvar f64 float64 = 3.141592653589793  // IEEE-754 64-bit\n\n// Complex numbers\nvar c64 complex64 = 1 + 2i           // float32 real and imaginary\nvar c128 complex128 = 1 + 2i         // float64 real and imaginary\n\n// Strings\nvar str string = \"Hello, Go!\"        // UTF-8 encoded\nvar multiline = `This is\na multiline\nstring`                               // Raw string literal\n\n// Rune (Unicode code point)\nvar r rune = 'A'                     // int32 alias\nvar emoji rune = '😀'\n\n// Byte\nvar b byte = 65                      // uint8 alias\n```\n\n### Type Conversions\n\n```go\n// Explicit type conversion required\nvar i int = 42\nvar f float64 = float64(i)\nvar u uint = uint(i)\n\n// String conversions\nimport \"strconv\"\n\n// Int to string\ns := strconv.Itoa(42)\ns := strconv.FormatInt(42, 10)  // base 10\n\n// String to int\ni, err := strconv.Atoi(\"42\")\ni64, err := strconv.ParseInt(\"42\", 10, 64)\n\n// Float to string\ns := strconv.FormatFloat(3.14, 'f', 2, 64)  // 2 decimal places\n\n// String to float\nf, err := strconv.ParseFloat(\"3.14\", 64)\n\n// Type assertions (for interfaces)\nvar x interface{} = \"hello\"\ns := x.(string)  // Panics if x is not string\ns, ok := x.(string)  // Safe assertion with ok check\n```\n\n### Zero Values\n\n```go\n// All types have zero values\nvar b bool        // false\nvar i int         // 0\nvar f float64     // 0.0\nvar s string      // \"\"\nvar p *int        // nil\nvar a []int       // nil\nvar m map[string]int  // nil\nvar c chan int    // nil\nvar fn func()     // nil\nvar iface error   // nil\n```\n\n## Control Flow\n\n### If Statements\n\n```go\n// Basic if\nif x > 0 {\n    fmt.Println(\"Positive\")\n}\n\n// If-else\nif x > 0 {\n    fmt.Println(\"Positive\")\n} else {\n    fmt.Println(\"Non-positive\")\n}\n\n// If-else if-else\nif x > 0 {\n    fmt.Println(\"Positive\")\n} else if x < 0 {\n    fmt.Println(\"Negative\")\n} else {\n    fmt.Println(\"Zero\")\n}\n\n// If with initialization\nif err := doSomething(); err != nil {\n    return err  // err is scoped to if block\n}\n\n// Common patterns\n// Check error immediately\nif err != nil {\n    return fmt.Errorf(\"failed to process: %w\", err)\n}\n\n// Check boolean\nif !isValid {\n    return errors.New(\"invalid input\")\n}\n\n// Check nil\nif data == nil {\n    return errors.New(\"data is nil\")\n}\n```\n\n### Switch Statements\n\n```go\n// Basic switch\nswitch day {\ncase \"Monday\":\n    fmt.Println(\"Start of work week\")\ncase \"Friday\":\n    fmt.Println(\"TGIF!\")\ncase \"Saturday\", \"Sunday\":\n    fmt.Println(\"Weekend!\")\ndefault:\n    fmt.Println(\"Midweek\")\n}\n\n// Switch with no expression (like if-else chain)\nswitch {\ncase x < 0:\n    fmt.Println(\"Negative\")\ncase x == 0:\n    fmt.Println(\"Zero\")\ncase x > 0:\n    fmt.Println(\"Positive\")\n}\n\n// Switch with initialization\nswitch os := runtime.GOOS; os {\ncase \"darwin\":\n    fmt.Println(\"macOS\")\ncase \"linux\":\n    fmt.Println(\"Linux\")\ndefault:\n    fmt.Printf(\"Unknown OS: %s\\n\", os)\n}\n\n// Type switch\nfunc describe(i interface{}) {\n    switch v := i.(type) {\n    case int:\n        fmt.Printf(\"Integer: %d\\n\", v)\n    case string:\n        fmt.Printf(\"String: %s\\n\", v)\n    case bool:\n        fmt.Printf(\"Boolean: %t\\n\", v)\n    case nil:\n        fmt.Println(\"nil value\")\n    default:\n        fmt.Printf(\"Unknown type: %T\\n\", v)\n    }\n}\n\n// Fallthrough (rarely used)\nswitch num {\ncase 1:\n    fmt.Println(\"One\")\n    fallthrough  // Continue to next case\ncase 2:\n    fmt.Println(\"One or Two\")\n}\n```\n\n### Loops\n\n```go\n// For loop - traditional\nfor i := 0; i < 10; i++ {\n    fmt.Println(i)\n}\n\n// For loop - while style\ncount := 0\nfor count < 10 {\n    fmt.Println(count)\n    count++\n}\n\n// Infinite loop\nfor {\n    // Break or return to exit\n    if condition {\n        break\n    }\n}\n\n// Range over slice\nnumbers := []int{1, 2, 3, 4, 5}\nfor index, value := range numbers {\n    fmt.Printf(\"%d: %d\\n\", index, value)\n}\n\n// Range over slice - values only\nfor _, value := range numbers {\n    fmt.Println(value)\n}\n\n// Range over slice - indices only\nfor index := range numbers {\n    fmt.Println(index)\n}\n\n// Range over map\nages := map[string]int{\"Alice\": 30, \"Bob\": 25}\nfor name, age := range ages {\n    fmt.Printf(\"%s is %d years old\\n\", name, age)\n}\n\n// Range over string (gives runes)\nfor index, runeValue := range \"Hello, 世界\" {\n    fmt.Printf(\"%d: %c\\n\", index, runeValue)\n}\n\n// Range over channel\nch := make(chan int)\ngo func() {\n    for i := 0; i < 5; i++ {\n        ch <- i\n    }\n    close(ch)\n}()\nfor value := range ch {\n    fmt.Println(value)\n}\n\n// Continue and break with labels\nouter:\nfor i := 0; i < 3; i++ {\n    for j := 0; j < 3; j++ {\n        if i == 1 && j == 1 {\n            break outer  // Break outer loop\n        }\n        fmt.Printf(\"(%d, %d) \", i, j)\n    }\n}\n```\n\n### Defer, Panic, and Recover\n\n```go\n// Defer - executes when function returns\nfunc readFile(filename string) error {\n    file, err := os.Open(filename)\n    if err != nil {\n        return err\n    }\n    defer file.Close()  // Executed when function returns\n    \n    // Read file...\n    return nil\n}\n\n// Multiple defers - LIFO order\nfunc example() {\n    defer fmt.Println(\"Third\")\n    defer fmt.Println(\"Second\")\n    defer fmt.Println(\"First\")\n    // Prints: First, Second, Third\n}\n\n// Defer with arguments - evaluated immediately\nfunc deferArgs() {\n    i := 0\n    defer fmt.Println(i)  // Prints 0, not 1\n    i++\n}\n\n// Defer with closure - captures variables\nfunc deferClosure() {\n    i := 0\n    defer func() {\n        fmt.Println(i)  // Prints 1\n    }()\n    i++\n}\n\n// Panic - runtime error\nfunc divide(a, b int) int {\n    if b == 0 {\n        panic(\"division by zero\")\n    }\n    return a / b\n}\n\n// Recover - catch panic\nfunc safeFunction() {\n    defer func() {\n        if r := recover(); r != nil {\n            fmt.Printf(\"Recovered from panic: %v\\n\", r)\n        }\n    }()\n    \n    // Code that might panic\n    panic(\"something went wrong\")\n}\n\n// Practical error recovery pattern\nfunc robustFunction() (err error) {\n    defer func() {\n        if r := recover(); r != nil {\n            err = fmt.Errorf(\"panic recovered: %v\", r)\n        }\n    }()\n    \n    // Potentially panicking code\n    return nil\n}\n```\n\n## Functions\n\n### Function Declaration\n\n```go\n// Basic function\nfunc greet() {\n    fmt.Println(\"Hello!\")\n}\n\n// Function with parameters\nfunc add(a int, b int) int {\n    return a + b\n}\n\n// Shorthand for same type parameters\nfunc add(a, b int) int {\n    return a + b\n}\n\n// Multiple return values\nfunc divide(a, b float64) (float64, error) {\n    if b == 0 {\n        return 0, errors.New(\"division by zero\")\n    }\n    return a / b, nil\n}\n\n// Named return values\nfunc getCoordinates() (x, y int) {\n    x = 10\n    y = 20\n    return  // Naked return\n}\n\n// Named returns with explicit values\nfunc calculate(a, b int) (sum, product int) {\n    sum = a + b\n    product = a * b\n    return sum, product  // Can be explicit\n}\n\n// Variadic functions\nfunc sum(numbers ...int) int {\n    total := 0\n    for _, n := range numbers {\n        total += n\n    }\n    return total\n}\n\n// Calling variadic functions\nresult := sum(1, 2, 3, 4, 5)\nnums := []int{1, 2, 3}\nresult := sum(nums...)  // Spread slice\n```\n\n### Function Types and Values\n\n```go\n// Function as type\ntype Operation func(int, int) int\n\nfunc add(a, b int) int { return a + b }\nfunc multiply(a, b int) int { return a * b }\n\nvar op Operation = add\nresult := op(5, 3)  // 8\n\n// Function as parameter\nfunc apply(op Operation, a, b int) int {\n    return op(a, b)\n}\n\nresult := apply(add, 5, 3)\nresult = apply(multiply, 5, 3)\n\n// Function returning function\nfunc makeAdder(x int) func(int) int {\n    return func(y int) int {\n        return x + y\n    }\n}\n\nadd5 := makeAdder(5)\nresult := add5(3)  // 8\n\n// Anonymous functions\nfunc() {\n    fmt.Println(\"Anonymous function\")\n}()  // Immediately invoked\n\n// Assign to variable\ngreet := func(name string) {\n    fmt.Printf(\"Hello, %s!\\n\", name)\n}\ngreet(\"World\")\n```\n\n### Closures\n\n```go\n// Closure captures variables\nfunc counter() func() int {\n    count := 0\n    return func() int {\n        count++\n        return count\n    }\n}\n\nc := counter()\nfmt.Println(c())  // 1\nfmt.Println(c())  // 2\nfmt.Println(c())  // 3\n\n// Closure in loop (common pitfall)\n// Wrong way\nfuncs := []func(){}\nfor i := 0; i < 3; i++ {\n    funcs = append(funcs, func() {\n        fmt.Println(i)  // All print 3\n    })\n}\n\n// Correct way\nfor i := 0; i < 3; i++ {\n    i := i  // Shadow variable\n    funcs = append(funcs, func() {\n        fmt.Println(i)  // Prints 0, 1, 2\n    })\n}\n\n// Alternative correct way\nfor i := 0; i < 3; i++ {\n    func(n int) {\n        funcs = append(funcs, func() {\n            fmt.Println(n)\n        })\n    }(i)\n}\n```\n\n## Methods\n\n### Method Declaration\n\n```go\n// Method on struct\ntype Rectangle struct {\n    Width, Height float64\n}\n\n// Value receiver\nfunc (r Rectangle) Area() float64 {\n    return r.Width * r.Height\n}\n\n// Pointer receiver\nfunc (r *Rectangle) Scale(factor float64) {\n    r.Width *= factor\n    r.Height *= factor\n}\n\n// Using methods\nrect := Rectangle{Width: 10, Height: 5}\narea := rect.Area()        // 50\nrect.Scale(2)              // Width=20, Height=10\n\n// Method on non-struct types\ntype MyInt int\n\nfunc (m MyInt) IsEven() bool {\n    return m%2 == 0\n}\n\nvar num MyInt = 42\nif num.IsEven() {\n    fmt.Println(\"Even number\")\n}\n\n// Method on pointer vs value\ntype Counter struct {\n    value int\n}\n\n// Value receiver - cannot modify\nfunc (c Counter) GetValue() int {\n    return c.value\n}\n\n// Pointer receiver - can modify\nfunc (c *Counter) Increment() {\n    c.value++\n}\n\n// Pointer receiver - can handle nil\nfunc (c *Counter) SafeIncrement() {\n    if c == nil {\n        return\n    }\n    c.value++\n}\n```\n\n### Method Sets\n\n```go\n// Method set rules:\n// - Type T has method set of all methods with receiver T\n// - Type *T has method set of all methods with receiver T or *T\n\ntype Shape struct {\n    Name string\n}\n\nfunc (s Shape) GetName() string {\n    return s.Name\n}\n\nfunc (s *Shape) SetName(name string) {\n    s.Name = name\n}\n\n// Value type can call value receiver methods\nshape := Shape{Name: \"Circle\"}\nname := shape.GetName()  // OK\n\n// Value type automatically gets address for pointer receiver\nshape.SetName(\"Square\")  // OK (Go converts to (&shape).SetName())\n\n// Pointer type can call both\nshapePtr := &Shape{Name: \"Triangle\"}\nname = shapePtr.GetName()  // OK\nshapePtr.SetName(\"Pentagon\")  // OK\n```\n\n## Structs\n\n### Struct Declaration and Usage\n\n```go\n// Basic struct\ntype Person struct {\n    FirstName string\n    LastName  string\n    Age       int\n}\n\n// Creating structs\np1 := Person{\n    FirstName: \"John\",\n    LastName:  \"Doe\",\n    Age:       30,\n}\n\n// Positional initialization (not recommended)\np2 := Person{\"Jane\", \"Doe\", 25}\n\n// Zero value struct\nvar p3 Person  // All fields have zero values\n\n// Accessing fields\nfmt.Println(p1.FirstName)\np1.Age = 31\n\n// Struct pointer\nptr := &Person{FirstName: \"Bob\"}\nptr.Age = 40  // Automatic dereferencing\n\n// Anonymous struct\npoint := struct {\n    X, Y int\n}{X: 10, Y: 20}\n\n// Struct tags\ntype User struct {\n    ID        int    `json:\"id\" db:\"user_id\"`\n    Email     string `json:\"email\" validate:\"required,email\"`\n    Password  string `json:\"-\"`  // Omit from JSON\n    CreatedAt time.Time `json:\"created_at,omitempty\"`\n}\n\n// Accessing tags via reflection\nimport \"reflect\"\n\nt := reflect.TypeOf(User{})\nfield, _ := t.FieldByName(\"Email\")\nfmt.Println(field.Tag.Get(\"json\"))     // \"email\"\nfmt.Println(field.Tag.Get(\"validate\")) // \"required,email\"\n```\n\n### Struct Embedding\n\n```go\n// Embedding for composition\ntype Address struct {\n    Street  string\n    City    string\n    Country string\n}\n\ntype Employee struct {\n    Person  // Embedded struct\n    Address // Another embedded struct\n    Salary  float64\n}\n\nemp := Employee{\n    Person: Person{\n        FirstName: \"Alice\",\n        LastName:  \"Smith\",\n        Age:       28,\n    },\n    Address: Address{\n        City:    \"New York\",\n        Country: \"USA\",\n    },\n    Salary: 75000,\n}\n\n// Promoted fields\nfmt.Println(emp.FirstName)  // Promoted from Person\nfmt.Println(emp.City)       // Promoted from Address\n\n// Explicit access\nfmt.Println(emp.Person.FirstName)\n\n// Method promotion\ntype Writer struct{}\n\nfunc (w Writer) Write(data []byte) (int, error) {\n    return len(data), nil\n}\n\ntype Logger struct {\n    Writer  // Embedded\n    prefix string\n}\n\nlog := Logger{prefix: \"[INFO]\"}\nlog.Write([]byte(\"message\"))  // Promoted method\n```\n\n### Struct Comparison\n\n```go\n// Structs are comparable if all fields are comparable\ntype Point struct {\n    X, Y int\n}\n\np1 := Point{1, 2}\np2 := Point{1, 2}\np3 := Point{2, 3}\n\nfmt.Println(p1 == p2)  // true\nfmt.Println(p1 == p3)  // false\n\n// Non-comparable structs (contain slices, maps, functions)\ntype Data struct {\n    Values []int  // Slices are not comparable\n}\n\n// This won't compile:\n// d1 := Data{Values: []int{1, 2}}\n// d2 := Data{Values: []int{1, 2}}\n// fmt.Println(d1 == d2)  // Compile error\n```\n\n## Interfaces\n\n### Interface Declaration and Implementation\n\n```go\n// Interface declaration\ntype Writer interface {\n    Write([]byte) (int, error)\n}\n\n// Interface with multiple methods\ntype ReadWriter interface {\n    Read([]byte) (int, error)\n    Write([]byte) (int, error)\n}\n\n// Empty interface (any type)\ntype Any interface{}  // Pre Go 1.18\ntype Any = any        // Go 1.18+\n\n// Implicit implementation\ntype FileWriter struct {\n    filename string\n}\n\nfunc (f FileWriter) Write(data []byte) (int, error) {\n    // Implementation\n    return len(data), nil\n}\n\n// FileWriter implements Writer implicitly\nvar w Writer = FileWriter{filename: \"test.txt\"}\n```\n\n### Interface Composition\n\n```go\n// Composing interfaces\ntype Reader interface {\n    Read([]byte) (int, error)\n}\n\ntype Writer interface {\n    Write([]byte) (int, error)\n}\n\ntype Closer interface {\n    Close() error\n}\n\n// Composed interface\ntype ReadWriteCloser interface {\n    Reader\n    Writer\n    Closer\n}\n\n// Alternative inline composition\ntype ReadWriter interface {\n    Read([]byte) (int, error)\n    Write([]byte) (int, error)\n}\n```\n\n### Interface Values and nil\n\n```go\n// Interface values have two components: type and value\nvar w Writer\nfmt.Printf(\"Type: %T, Value: %v\\n\", w, w)  // Type: <nil>, Value: <nil>\n\n// nil interface vs interface with nil value\ntype MyWriter struct{}\n\nfunc (m *MyWriter) Write(data []byte) (int, error) {\n    if m == nil {\n        return 0, errors.New(\"nil writer\")\n    }\n    return len(data), nil\n}\n\nvar mw *MyWriter = nil\nvar w Writer = mw\n// w is not nil (has type *MyWriter), but its value is nil\n\nif w == nil {\n    fmt.Println(\"w is nil\")  // Won't print\n}\n\n// Check for nil value\nif mw == nil {\n    fmt.Println(\"mw is nil\")  // Will print\n}\n```\n\n### Type Assertions and Type Switches\n\n```go\n// Type assertion\nvar i interface{} = \"hello\"\n\n// Direct assertion (panics if wrong type)\ns := i.(string)\nfmt.Println(s)\n\n// Safe assertion with comma-ok\ns, ok := i.(string)\nif ok {\n    fmt.Println(\"String:\", s)\n}\n\n// Check interface implementation\nvar w io.Writer = &bytes.Buffer{}\nif buf, ok := w.(*bytes.Buffer); ok {\n    fmt.Println(\"It's a buffer:\", buf)\n}\n\n// Type switch\nfunc describe(i interface{}) {\n    switch v := i.(type) {\n    case int:\n        fmt.Printf(\"Integer: %d\\n\", v)\n    case string:\n        fmt.Printf(\"String: %s\\n\", v)\n    case io.Reader:\n        fmt.Println(\"It's a reader\")\n    case nil:\n        fmt.Println(\"It's nil\")\n    default:\n        fmt.Printf(\"Unknown type: %T\\n\", v)\n    }\n}\n```\n\n### Common Interface Patterns\n\n```go\n// Stringer interface\ntype Stringer interface {\n    String() string\n}\n\ntype Point struct {\n    X, Y int\n}\n\nfunc (p Point) String() string {\n    return fmt.Sprintf(\"(%d, %d)\", p.X, p.Y)\n}\n\n// Error interface\ntype error interface {\n    Error() string\n}\n\ntype ValidationError struct {\n    Field string\n    Value string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"validation failed for field %s: %s\", e.Field, e.Value)\n}\n\n// Sort interface\ntype Interface interface {\n    Len() int\n    Less(i, j int) bool\n    Swap(i, j int)\n}\n\n// Custom sort implementation\ntype ByAge []Person\n\nfunc (a ByAge) Len() int           { return len(a) }\nfunc (a ByAge) Less(i, j int) bool { return a[i].Age < a[j].Age }\nfunc (a ByAge) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }\n\n// Usage\npeople := []Person{{Name: \"Alice\", Age: 30}, {Name: \"Bob\", Age: 25}}\nsort.Sort(ByAge(people))\n```\n\n## Pointers\n\n### Pointer Basics\n\n```go\n// Declare pointer\nvar p *int\n\n// Get address of variable\nx := 42\np = &x\n\n// Dereference pointer\nfmt.Println(*p)  // 42\n*p = 100\nfmt.Println(x)   // 100\n\n// Pointer zero value is nil\nvar ptr *string\nif ptr == nil {\n    fmt.Println(\"ptr is nil\")\n}\n\n// New function allocates memory\nptr = new(string)\n*ptr = \"Hello\"\n\n// Pointer to struct\ntype Person struct {\n    Name string\n    Age  int\n}\n\nperson := &Person{Name: \"Alice\", Age: 30}\nperson.Age = 31  // Automatic dereferencing\n\n// Pointer arithmetic is NOT allowed in Go\n// p++  // This won't compile\n```\n\n### Pointers vs Values\n\n```go\n// Pass by value\nfunc modifyValue(x int) {\n    x = 100  // Doesn't affect original\n}\n\n// Pass by pointer\nfunc modifyPointer(x *int) {\n    *x = 100  // Modifies original\n}\n\nvalue := 42\nmodifyValue(value)\nfmt.Println(value)  // Still 42\n\nmodifyPointer(&value)\nfmt.Println(value)  // Now 100\n\n// Slices, maps, channels are reference types\nfunc modifySlice(s []int) {\n    s[0] = 100  // Modifies original\n}\n\nslice := []int{1, 2, 3}\nmodifySlice(slice)\nfmt.Println(slice)  // [100, 2, 3]\n\n// But reassigning doesn't affect original\nfunc reassignSlice(s []int) {\n    s = []int{4, 5, 6}  // Doesn't affect original\n}\n\n// To modify slice itself, use pointer\nfunc replaceSlice(s *[]int) {\n    *s = []int{4, 5, 6}\n}\n```\n\n## Arrays and Slices\n\n### Arrays\n\n```go\n// Array declaration\nvar arr [5]int              // [0 0 0 0 0]\narr[0] = 10\narr[4] = 50\n\n// Array initialization\narr := [5]int{1, 2, 3, 4, 5}\narr := [...]int{1, 2, 3}    // Compiler counts elements\narr := [5]int{0: 10, 4: 50} // Index:value pairs\n\n// Arrays are values (copied on assignment)\narr1 := [3]int{1, 2, 3}\narr2 := arr1\narr2[0] = 100\nfmt.Println(arr1)  // [1 2 3] - unchanged\nfmt.Println(arr2)  // [100 2 3]\n\n// Array size is part of type\nvar a [5]int\nvar b [10]int\n// a = b  // Won't compile - different types\n\n// Multidimensional arrays\nvar matrix [3][3]int\nmatrix[1][1] = 5\n\n// Array iteration\nfor i := 0; i < len(arr); i++ {\n    fmt.Println(arr[i])\n}\n\nfor index, value := range arr {\n    fmt.Printf(\"%d: %d\\n\", index, value)\n}\n```\n\n### Slices\n\n```go\n// Slice declaration\nvar slice []int            // nil slice\nslice = []int{}           // Empty slice\nslice = []int{1, 2, 3}    // Initialized slice\n\n// Make function\nslice = make([]int, 5)    // Length 5, capacity 5\nslice = make([]int, 5, 10) // Length 5, capacity 10\n\n// Slice from array\narr := [5]int{1, 2, 3, 4, 5}\nslice = arr[1:4]  // [2 3 4]\nslice = arr[:3]   // [1 2 3]\nslice = arr[2:]   // [3 4 5]\nslice = arr[:]    // [1 2 3 4 5]\n\n// Slice properties\nfmt.Println(len(slice))  // Length\nfmt.Println(cap(slice))  // Capacity\n\n// Append\nslice = []int{1, 2, 3}\nslice = append(slice, 4)\nslice = append(slice, 5, 6, 7)\nslice = append(slice, []int{8, 9}...)\n\n// Copy\nsrc := []int{1, 2, 3}\ndst := make([]int, len(src))\nn := copy(dst, src)  // Returns number copied\n\n// Slice tricks\n// Remove element at index i\nslice = append(slice[:i], slice[i+1:]...)\n\n// Insert element at index i\nslice = append(slice[:i], append([]int{x}, slice[i:]...)...)\n\n// Pop from end\nx := slice[len(slice)-1]\nslice = slice[:len(slice)-1]\n\n// Push to front\nslice = append([]int{x}, slice...)\n\n// Filter in place\nn := 0\nfor _, x := range slice {\n    if keepElement(x) {\n        slice[n] = x\n        n++\n    }\n}\nslice = slice[:n]\n```\n\n### Slice Internals\n\n```go\n// Slice header (conceptual)\ntype SliceHeader struct {\n    Data uintptr  // Pointer to underlying array\n    Len  int      // Current length\n    Cap  int      // Capacity\n}\n\n// Slices share underlying array\noriginal := []int{1, 2, 3, 4, 5}\nslice1 := original[1:4]  // [2 3 4]\nslice2 := original[2:5]  // [3 4 5]\n\nslice1[1] = 100  // Modifies shared array\nfmt.Println(slice2)  // [100 4 5]\n\n// Full slice expression controls capacity\nslice := original[1:3:4]  // [low:high:max]\n// len = high - low = 2\n// cap = max - low = 3\n\n// nil vs empty slice\nvar nilSlice []int        // nil\nemptySlice := []int{}     // Not nil, but empty\nmadeSlice := make([]int, 0) // Not nil, but empty\n\nfmt.Println(nilSlice == nil)    // true\nfmt.Println(emptySlice == nil)  // false\nfmt.Println(len(nilSlice))      // 0\nfmt.Println(len(emptySlice))    // 0\n\n// Both work with append\nnilSlice = append(nilSlice, 1)\nemptySlice = append(emptySlice, 1)\n```\n\n## Maps\n\n### Map Basics\n\n```go\n// Map declaration\nvar m map[string]int      // nil map\nm = make(map[string]int)  // Initialize\n\n// Map literal\nm = map[string]int{\n    \"Alice\": 30,\n    \"Bob\":   25,\n}\n\n// Operations\nm[\"Charlie\"] = 35         // Insert/Update\nage := m[\"Alice\"]         // Retrieve\ndelete(m, \"Bob\")          // Delete\n\n// Check if key exists\nage, exists := m[\"David\"]\nif exists {\n    fmt.Printf(\"David is %d years old\\n\", age)\n}\n\n// Zero value for missing key\nfmt.Println(m[\"Unknown\"])  // 0 (zero value for int)\n\n// Iteration (order is random)\nfor key, value := range m {\n    fmt.Printf(\"%s: %d\\n\", key, value)\n}\n\n// Keys only\nfor key := range m {\n    fmt.Println(key)\n}\n\n// Values only\nfor _, value := range m {\n    fmt.Println(value)\n}\n```\n\n### Map Patterns\n\n```go\n// Map as set\nset := make(map[string]bool)\nset[\"apple\"] = true\nset[\"banana\"] = true\n\nif set[\"apple\"] {\n    fmt.Println(\"apple is in the set\")\n}\n\n// Alternative set using empty struct (memory efficient)\ntype void struct{}\nvar member void\n\nset := make(map[string]void)\nset[\"apple\"] = member\nset[\"banana\"] = member\n\nif _, exists := set[\"apple\"]; exists {\n    fmt.Println(\"apple is in the set\")\n}\n\n// Counting with maps\ncounts := make(map[string]int)\nwords := []string{\"apple\", \"banana\", \"apple\", \"orange\", \"banana\", \"apple\"}\n\nfor _, word := range words {\n    counts[word]++  // Works even if key doesn't exist\n}\n\n// Grouping with maps\ntype Person struct {\n    Name string\n    Age  int\n}\n\npeople := []Person{\n    {\"Alice\", 30},\n    {\"Bob\", 25},\n    {\"Charlie\", 30},\n    {\"David\", 25},\n}\n\nageGroups := make(map[int][]Person)\nfor _, person := range people {\n    ageGroups[person.Age] = append(ageGroups[person.Age], person)\n}\n\n// Map of maps\nnested := make(map[string]map[string]int)\nnested[\"scores\"] = make(map[string]int)\nnested[\"scores\"][\"Alice\"] = 95\nnested[\"scores\"][\"Bob\"] = 87\n\n// Safe nested access\nif scores, ok := nested[\"scores\"]; ok {\n    if score, ok := scores[\"Alice\"]; ok {\n        fmt.Printf(\"Alice's score: %d\\n\", score)\n    }\n}\n```\n\n### Maps and Concurrency\n\n```go\n// Maps are not safe for concurrent access\n// Use sync.Map or mutex\n\nimport \"sync\"\n\n// With mutex\ntype SafeMap struct {\n    mu sync.RWMutex\n    m  map[string]int\n}\n\nfunc (sm *SafeMap) Set(key string, value int) {\n    sm.mu.Lock()\n    defer sm.mu.Unlock()\n    sm.m[key] = value\n}\n\nfunc (sm *SafeMap) Get(key string) (int, bool) {\n    sm.mu.RLock()\n    defer sm.mu.RUnlock()\n    value, exists := sm.m[key]\n    return value, exists\n}\n\n// Using sync.Map (for specific use cases)\nvar m sync.Map\n\n// Store\nm.Store(\"key\", \"value\")\n\n// Load\nvalue, ok := m.Load(\"key\")\n\n// LoadOrStore\nactual, loaded := m.LoadOrStore(\"key\", \"new-value\")\n\n// Delete\nm.Delete(\"key\")\n\n// Range\nm.Range(func(key, value interface{}) bool {\n    fmt.Printf(\"%v: %v\\n\", key, value)\n    return true  // Continue iteration\n})\n```\n\n## Error Handling\n\n### Error Interface\n\n```go\n// Error interface\ntype error interface {\n    Error() string\n}\n\n// Creating errors\nimport \"errors\"\n\nerr := errors.New(\"something went wrong\")\nerr := fmt.Errorf(\"failed to process %s: %v\", filename, originalErr)\n\n// Custom error types\ntype ValidationError struct {\n    Field string\n    Value interface{}\n    Msg   string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"validation error: field=%s value=%v msg=%s\", \n        e.Field, e.Value, e.Msg)\n}\n\n// Sentinel errors\nvar (\n    ErrNotFound   = errors.New(\"not found\")\n    ErrPermission = errors.New(\"permission denied\")\n    ErrTimeout    = errors.New(\"operation timed out\")\n)\n\n// Error wrapping (Go 1.13+)\noriginalErr := errors.New(\"original error\")\nwrappedErr := fmt.Errorf(\"wrapped: %w\", originalErr)\n\n// Unwrap errors\nif errors.Is(wrappedErr, originalErr) {\n    fmt.Println(\"Error is originalErr\")\n}\n\nvar validationErr ValidationError\nif errors.As(wrappedErr, &validationErr) {\n    fmt.Printf(\"Validation error: %s\\n\", validationErr.Field)\n}\n```\n\n### Error Handling Patterns\n\n```go\n// Immediate error checking\nresult, err := doSomething()\nif err != nil {\n    return fmt.Errorf(\"doSomething failed: %w\", err)\n}\n\n// Multiple error sources\nfunc processFile(filename string) error {\n    file, err := os.Open(filename)\n    if err != nil {\n        return fmt.Errorf(\"open file: %w\", err)\n    }\n    defer file.Close()\n    \n    data, err := io.ReadAll(file)\n    if err != nil {\n        return fmt.Errorf(\"read file: %w\", err)\n    }\n    \n    if err := processData(data); err != nil {\n        return fmt.Errorf(\"process data: %w\", err)\n    }\n    \n    return nil\n}\n\n// Error accumulation\nvar errs []error\n\nfor _, item := range items {\n    if err := process(item); err != nil {\n        errs = append(errs, err)\n    }\n}\n\nif len(errs) > 0 {\n    return fmt.Errorf(\"processing failed with %d errors\", len(errs))\n}\n\n// Retry pattern\nfunc retryOperation(maxAttempts int) error {\n    var lastErr error\n    \n    for i := 0; i < maxAttempts; i++ {\n        if err := attemptOperation(); err != nil {\n            lastErr = err\n            time.Sleep(time.Second * time.Duration(i+1))\n            continue\n        }\n        return nil  // Success\n    }\n    \n    return fmt.Errorf(\"failed after %d attempts: %w\", maxAttempts, lastErr)\n}\n\n// Cleanup on error\nfunc createResources() (err error) {\n    resource1, err := createResource1()\n    if err != nil {\n        return err\n    }\n    defer func() {\n        if err != nil {\n            resource1.Cleanup()\n        }\n    }()\n    \n    resource2, err := createResource2()\n    if err != nil {\n        return err  // resource1 cleaned up by defer\n    }\n    \n    return nil\n}\n```\n\n## Packages and Modules\n\n### Package Organization\n\n```go\n// Package declaration (first non-comment line)\npackage mypackage\n\n// Package documentation\n// Package mypackage provides utilities for data processing.\n// It includes functions for parsing, validation, and transformation.\npackage mypackage\n\n// Import statements\nimport (\n    \"fmt\"           // Standard library\n    \"time\"\n    \n    \"github.com/pkg/errors\"  // External packages\n    \n    \"myproject/internal/utils\"  // Internal packages\n)\n\n// Import aliasing\nimport (\n    \"context\"\n    stdlog \"log\"  // Alias to avoid conflicts\n    . \"math\"      // Dot import (use sparingly)\n    _ \"image/png\" // Import for side effects only\n)\n\n// Package initialization\nfunc init() {\n    // Runs when package is imported\n    // Can have multiple init functions\n    fmt.Println(\"Package initialized\")\n}\n\n// Exported (public) - uppercase\nfunc PublicFunction() {}\ntype PublicType struct{}\nconst PublicConst = 42\nvar PublicVar = \"hello\"\n\n// Unexported (private) - lowercase\nfunc privateFunction() {}\ntype privateType struct{}\nconst privateConst = 42\nvar privateVar = \"hello\"\n```\n\n### Module Management\n\n```bash\n# Initialize module\ngo mod init github.com/username/projectname\n\n# Add dependencies\ngo get github.com/pkg/errors\ngo get github.com/stretchr/testify@v1.8.0\n\n# Update dependencies\ngo get -u ./...              # Update all\ngo get -u github.com/pkg/errors  # Update specific\n\n# Clean up\ngo mod tidy  # Remove unused dependencies\n\n# Vendor dependencies\ngo mod vendor  # Copy dependencies to vendor/\n\n# Module directives in go.mod\nmodule github.com/username/project\n\ngo 1.21\n\nrequire (\n    github.com/pkg/errors v0.9.1\n    github.com/stretchr/testify v1.8.0\n)\n\nreplace github.com/old/package => github.com/new/package v1.0.0\n\nexclude github.com/bad/package v1.0.0\n```\n\n### Internal Packages\n\n```go\n// Internal packages can only be imported by nearby code\nmyproject/\n├── cmd/\n│   └── app/\n│       └── main.go  // Can import internal/\n├── internal/\n│   ├── database/    // Only accessible within myproject\n│   └── utils/\n├── pkg/             // Public packages\n│   └── api/\n└── go.mod\n\n// This import works in myproject\nimport \"myproject/internal/database\"\n\n// This import fails outside myproject\nimport \"github.com/other/project/internal/database\"  // Error\n```\n\n## Type Assertions and Type Switches\n\n### Type Assertions\n\n```go\n// Basic type assertion\nvar i interface{} = \"hello\"\ns := i.(string)  // Panics if not string\nfmt.Println(s)\n\n// Safe type assertion\ns, ok := i.(string)\nif !ok {\n    fmt.Println(\"Not a string\")\n}\n\n// Common patterns\nfunc processValue(v interface{}) {\n    // Try multiple types\n    switch value := v.(type) {\n    case string:\n        fmt.Printf(\"String: %s\\n\", value)\n    case int:\n        fmt.Printf(\"Integer: %d\\n\", value)\n    case []byte:\n        fmt.Printf(\"Bytes: %s\\n\", string(value))\n    default:\n        fmt.Printf(\"Unknown: %T\\n\", value)\n    }\n}\n\n// Check for interface implementation\ntype Stringer interface {\n    String() string\n}\n\nfunc toString(v interface{}) string {\n    if s, ok := v.(Stringer); ok {\n        return s.String()\n    }\n    return fmt.Sprintf(\"%v\", v)\n}\n\n// Nil interface gotcha\nvar p *Person  // nil pointer\nvar i interface{} = p\n\nif i == nil {\n    fmt.Println(\"i is nil\")  // Won't print!\n}\n\nif p == nil {\n    fmt.Println(\"p is nil\")  // Will print\n}\n```\n\n## Embedding and Composition\n\n### Struct Embedding\n\n```go\n// Base types\ntype Person struct {\n    Name string\n    Age  int\n}\n\ntype Address struct {\n    Street string\n    City   string\n}\n\n// Embedding\ntype Employee struct {\n    Person      // Anonymous field\n    Address     // Another anonymous field\n    Department string\n    Salary     float64\n}\n\nemp := Employee{\n    Person:     Person{Name: \"Alice\", Age: 30},\n    Address:    Address{City: \"New York\"},\n    Department: \"Engineering\",\n}\n\n// Field promotion\nfmt.Println(emp.Name)  // Accessed directly\nfmt.Println(emp.City)\n\n// Method promotion\nfunc (p Person) Introduce() {\n    fmt.Printf(\"Hi, I'm %s\\n\", p.Name)\n}\n\nemp.Introduce()  // Method promoted from Person\n\n// Shadowing\ntype Manager struct {\n    Employee\n    Name string  // Shadows Person.Name\n}\n\nmgr := Manager{\n    Employee: emp,\n    Name:     \"Manager Name\",  // This shadows Employee.Person.Name\n}\n\nfmt.Println(mgr.Name)              // \"Manager Name\"\nfmt.Println(mgr.Employee.Name)     // \"Alice\"\nfmt.Println(mgr.Employee.Person.Name)  // \"Alice\"\n```\n\n### Interface Embedding\n\n```go\n// Base interfaces\ntype Reader interface {\n    Read([]byte) (int, error)\n}\n\ntype Writer interface {\n    Write([]byte) (int, error)\n}\n\ntype Closer interface {\n    Close() error\n}\n\n// Embedded interfaces\ntype ReadWriter interface {\n    Reader\n    Writer\n}\n\ntype ReadWriteCloser interface {\n    Reader\n    Writer\n    Closer\n}\n\n// Alternative syntax\ntype ReadWriteCloser interface {\n    Read([]byte) (int, error)\n    Write([]byte) (int, error)\n    Close() error\n}\n\n// Implementation\ntype File struct {\n    // fields\n}\n\nfunc (f *File) Read(p []byte) (int, error) {\n    // implementation\n}\n\nfunc (f *File) Write(p []byte) (int, error) {\n    // implementation\n}\n\nfunc (f *File) Close() error {\n    // implementation\n}\n\n// File now implements ReadWriteCloser\nvar rwc ReadWriteCloser = &File{}\n```\n\n## Generics\n\n### Generic Functions\n\n```go\n// Generic function with type parameter\nfunc Max[T comparable](a, b T) T {\n    if a > b {\n        return a\n    }\n    return b\n}\n\n// Usage\nmaxInt := Max(10, 20)           // Type inferred\nmaxFloat := Max[float64](3.14, 2.71)  // Explicit type\n\n// Multiple type parameters\nfunc Swap[T, U any](a T, b U) (U, T) {\n    return b, a\n}\n\n// Type constraints\ntype Number interface {\n    int | int32 | int64 | float32 | float64\n}\n\nfunc Sum[T Number](numbers []T) T {\n    var sum T\n    for _, n := range numbers {\n        sum += n\n    }\n    return sum\n}\n\n// Using standard constraints\nimport \"golang.org/x/exp/constraints\"\n\nfunc Min[T constraints.Ordered](a, b T) T {\n    if a < b {\n        return a\n    }\n    return b\n}\n```\n\n### Generic Types\n\n```go\n// Generic struct\ntype Stack[T any] struct {\n    items []T\n}\n\nfunc (s *Stack[T]) Push(item T) {\n    s.items = append(s.items, item)\n}\n\nfunc (s *Stack[T]) Pop() (T, bool) {\n    var zero T\n    if len(s.items) == 0 {\n        return zero, false\n    }\n    item := s.items[len(s.items)-1]\n    s.items = s.items[:len(s.items)-1]\n    return item, true\n}\n\n// Usage\nintStack := Stack[int]{}\nintStack.Push(42)\nvalue, ok := intStack.Pop()\n\n// Generic interface\ntype Container[T any] interface {\n    Add(T)\n    Get(int) T\n    Size() int\n}\n\n// Type inference with generics\ntype Pair[T, U any] struct {\n    First  T\n    Second U\n}\n\n// Constructor function\nfunc NewPair[T, U any](first T, second U) Pair[T, U] {\n    return Pair[T, U]{First: first, Second: second}\n}\n\n// Type inference in use\np := NewPair(1, \"hello\")  // Pair[int, string] inferred\n```\n\n### Type Constraints\n\n```go\n// Custom constraints\ntype Signed interface {\n    ~int | ~int8 | ~int16 | ~int32 | ~int64\n}\n\ntype Unsigned interface {\n    ~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64\n}\n\ntype Integer interface {\n    Signed | Unsigned\n}\n\n// Tilde (~) allows underlying types\ntype MyInt int\n\nfunc Double[T ~int](x T) T {\n    return x * 2\n}\n\nvar mi MyInt = 5\nresult := Double(mi)  // Works because MyInt's underlying type is int\n\n// Constraint with methods\ntype Stringer interface {\n    String() string\n}\n\nfunc PrintAll[T Stringer](items []T) {\n    for _, item := range items {\n        fmt.Println(item.String())\n    }\n}\n\n// Complex constraints\ntype Number interface {\n    ~int | ~int8 | ~int16 | ~int32 | ~int64 |\n    ~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64 |\n    ~float32 | ~float64\n}\n\ntype Addable[T any] interface {\n    Add(T) T\n}\n\ntype AddableNumber[T Number] interface {\n    Number\n    Addable[T]\n}\n```\n\n## Best Practices Summary\n\n### Code Organization\n- Keep packages small and focused\n- Use clear, descriptive names\n- Group related functionality\n- Minimize package dependencies\n- Use internal packages for private code\n\n### Error Handling\n- Always check errors\n- Wrap errors with context\n- Use sentinel errors for known conditions\n- Create custom error types when needed\n- Handle errors at the appropriate level\n\n### Concurrency\n- Don't communicate by sharing memory; share memory by communicating\n- Use channels for coordination\n- Keep goroutines simple\n- Always handle goroutine cleanup\n- Use context for cancellation\n\n### Performance\n- Measure before optimizing\n- Preallocate slices when size is known\n- Use string.Builder for string concatenation\n- Be aware of memory allocations\n- Profile your code\n\n### Testing\n- Write table-driven tests\n- Test edge cases\n- Use subtests for better organization\n- Mock external dependencies\n- Aim for high test coverage\n\n### Documentation\n- Document all exported items\n- Write clear package documentation\n- Include examples in documentation\n- Keep comments up to date\n- Use godoc format\n\nThis comprehensive guide covers the fundamental aspects of Go programming. Each topic includes practical examples and best practices to help write idiomatic, efficient Go code.","numLines":2063,"startLine":1,"totalLines":2063}}}
{"parentUuid":"e05025ce-a09a-4063-81d6-e83741f875cc","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DkrAkqu3Zf3uoD4HP3bSSe","type":"tool_result","content":"     1→# Go Testing - Complete Testing Guide\n     2→\n     3→## Table of Contents\n     4→1. [Unit Tests](#unit-tests)\n     5→2. [Table-Driven Tests](#table-driven-tests)\n     6→3. [Subtests](#subtests)\n     7→4. [Mocks and Stubs](#mocks-and-stubs)\n     8→5. [Fuzz Testing](#fuzz-testing)\n     9→6. [Benchmarks](#benchmarks)\n    10→7. [Coverage](#coverage)\n    11→8. [Integration Tests](#integration-tests)\n    12→9. [Test Fixtures and Helpers](#test-fixtures-and-helpers)\n    13→10. [Advanced Testing Techniques](#advanced-testing-techniques)\n    14→\n    15→## Unit Tests\n    16→\n    17→### Basic Test Structure\n    18→```go\n    19→// File: math.go\n    20→package math\n    21→\n    22→func Add(a, b int) int {\n    23→    return a + b\n    24→}\n    25→\n    26→// File: math_test.go\n    27→package math\n    28→\n    29→import \"testing\"\n    30→\n    31→func TestAdd(t *testing.T) {\n    32→    result := Add(2, 3)\n    33→    expected := 5\n    34→    \n    35→    if result != expected {\n    36→        t.Errorf(\"Add(2, 3) = %d; want %d\", result, expected)\n    37→    }\n    38→}\n    39→\n    40→// Test with multiple assertions\n    41→func TestMultipleAssertions(t *testing.T) {\n    42→    // Arrange\n    43→    input := \"test\"\n    44→    \n    45→    // Act\n    46→    result := Process(input)\n    47→    \n    48→    // Assert\n    49→    if result.Status != \"success\" {\n    50→        t.Errorf(\"expected status 'success', got %q\", result.Status)\n    51→    }\n    52→    \n    53→    if len(result.Data) == 0 {\n    54→        t.Error(\"expected non-empty data\")\n    55→    }\n    56→    \n    57→    if result.Timestamp.IsZero() {\n    58→        t.Error(\"expected non-zero timestamp\")\n    59→    }\n    60→}\n    61→\n    62→// Using t.Fatal for critical failures\n    63→func TestCriticalFailure(t *testing.T) {\n    64→    db, err := connectDB()\n    65→    if err != nil {\n    66→        t.Fatalf(\"failed to connect to database: %v\", err)\n    67→    }\n    68→    defer db.Close()\n    69→    \n    70→    // Continue with test...\n    71→}\n    72→\n    73→// Using t.Skip for conditional tests\n    74→func TestRequiresDocker(t *testing.T) {\n    75→    if !dockerAvailable() {\n    76→        t.Skip(\"skipping test; Docker not available\")\n    77→    }\n    78→    \n    79→    // Docker-dependent test...\n    80→}\n    81→\n    82→// Parallel tests\n    83→func TestParallel1(t *testing.T) {\n    84→    t.Parallel() // Run in parallel with other parallel tests\n    85→    // Test implementation...\n    86→}\n    87→\n    88→func TestParallel2(t *testing.T) {\n    89→    t.Parallel()\n    90→    // Test implementation...\n    91→}\n    92→```\n    93→\n    94→### Test Organization\n    95→```go\n    96→// Testing exported functions\n    97→func TestPublicFunction(t *testing.T) {\n    98→    result := PublicFunction(\"input\")\n    99→    if result != \"expected\" {\n   100→        t.Errorf(\"got %q, want %q\", result, \"expected\")\n   101→    }\n   102→}\n   103→\n   104→// Testing unexported functions (same package)\n   105→func TestPrivateFunction(t *testing.T) {\n   106→    result := privateFunction(\"input\")\n   107→    if result != \"expected\" {\n   108→        t.Errorf(\"got %q, want %q\", result, \"expected\")\n   109→    }\n   110→}\n   111→\n   112→// Testing with external package (black-box testing)\n   113→package math_test\n   114→\n   115→import (\n   116→    \"testing\"\n   117→    \"myproject/math\"\n   118→)\n   119→\n   120→func TestAddExternal(t *testing.T) {\n   121→    result := math.Add(2, 3)\n   122→    if result != 5 {\n   123→        t.Errorf(\"math.Add(2, 3) = %d; want 5\", result)\n   124→    }\n   125→}\n   126→\n   127→// Example tests (show up in documentation)\n   128→func ExampleAdd() {\n   129→    result := Add(2, 3)\n   130→    fmt.Println(result)\n   131→    // Output: 5\n   132→}\n   133→\n   134→func ExampleAdd_negative() {\n   135→    result := Add(-2, -3)\n   136→    fmt.Println(result)\n   137→    // Output: -5\n   138→}\n   139→\n   140→// Testing main function\n   141→func TestMain(m *testing.M) {\n   142→    // Setup before tests\n   143→    setup()\n   144→    \n   145→    // Run tests\n   146→    code := m.Run()\n   147→    \n   148→    // Cleanup after tests\n   149→    teardown()\n   150→    \n   151→    os.Exit(code)\n   152→}\n   153→```\n   154→\n   155→## Table-Driven Tests\n   156→\n   157→### Basic Table-Driven Tests\n   158→```go\n   159→func TestAdd(t *testing.T) {\n   160→    tests := []struct {\n   161→        name     string\n   162→        a, b     int\n   163→        expected int\n   164→    }{\n   165→        {\"positive numbers\", 2, 3, 5},\n   166→        {\"negative numbers\", -2, -3, -5},\n   167→        {\"mixed\", -5, 10, 5},\n   168→        {\"with zero\", 0, 5, 5},\n   169→        {\"both zero\", 0, 0, 0},\n   170→    }\n   171→    \n   172→    for _, tt := range tests {\n   173→        t.Run(tt.name, func(t *testing.T) {\n   174→            result := Add(tt.a, tt.b)\n   175→            if result != tt.expected {\n   176→                t.Errorf(\"Add(%d, %d) = %d; want %d\", \n   177→                    tt.a, tt.b, result, tt.expected)\n   178→            }\n   179→        })\n   180→    }\n   181→}\n   182→\n   183→// Table-driven tests with errors\n   184→func TestDivide(t *testing.T) {\n   185→    tests := []struct {\n   186→        name      string\n   187→        dividend  float64\n   188→        divisor   float64\n   189→        want      float64\n   190→        wantErr   bool\n   191→        errString string\n   192→    }{\n   193→        {\n   194→            name:     \"normal division\",\n   195→            dividend: 10,\n   196→            divisor:  2,\n   197→            want:     5,\n   198→            wantErr:  false,\n   199→        },\n   200→        {\n   201→            name:      \"divide by zero\",\n   202→            dividend:  10,\n   203→            divisor:   0,\n   204→            want:      0,\n   205→            wantErr:   true,\n   206→            errString: \"division by zero\",\n   207→        },\n   208→        {\n   209→            name:     \"negative division\",\n   210→            dividend: -10,\n   211→            divisor:  2,\n   212→            want:     -5,\n   213→            wantErr:  false,\n   214→        },\n   215→    }\n   216→    \n   217→    for _, tt := range tests {\n   218→        t.Run(tt.name, func(t *testing.T) {\n   219→            got, err := Divide(tt.dividend, tt.divisor)\n   220→            \n   221→            if (err != nil) != tt.wantErr {\n   222→                t.Errorf(\"Divide() error = %v, wantErr %v\", err, tt.wantErr)\n   223→                return\n   224→            }\n   225→            \n   226→            if tt.wantErr && err.Error() != tt.errString {\n   227→                t.Errorf(\"Divide() error = %q, want %q\", err.Error(), tt.errString)\n   228→                return\n   229→            }\n   230→            \n   231→            if got != tt.want {\n   232→                t.Errorf(\"Divide() = %v, want %v\", got, tt.want)\n   233→            }\n   234→        })\n   235→    }\n   236→}\n   237→\n   238→// Complex table-driven tests\n   239→func TestParser(t *testing.T) {\n   240→    tests := []struct {\n   241→        name    string\n   242→        input   string\n   243→        setup   func()\n   244→        cleanup func()\n   245→        want    *Result\n   246→        wantErr bool\n   247→        check   func(t *testing.T, got *Result)\n   248→    }{\n   249→        {\n   250→            name:  \"valid JSON\",\n   251→            input: `{\"key\": \"value\"}`,\n   252→            want: &Result{\n   253→                Type: \"object\",\n   254→                Data: map[string]interface{}{\"key\": \"value\"},\n   255→            },\n   256→        },\n   257→        {\n   258→            name:  \"complex validation\",\n   259→            input: `{\"items\": [1, 2, 3]}`,\n   260→            check: func(t *testing.T, got *Result) {\n   261→                if got.Type != \"object\" {\n   262→                    t.Errorf(\"wrong type: %s\", got.Type)\n   263→                }\n   264→                items, ok := got.Data.(map[string]interface{})[\"items\"].([]interface{})\n   265→                if !ok || len(items) != 3 {\n   266→                    t.Error(\"expected 3 items\")\n   267→                }\n   268→            },\n   269→        },\n   270→        {\n   271→            name: \"with setup\",\n   272→            input: \"special\",\n   273→            setup: func() {\n   274→                // Prepare test environment\n   275→                os.Setenv(\"TEST_MODE\", \"special\")\n   276→            },\n   277→            cleanup: func() {\n   278→                os.Unsetenv(\"TEST_MODE\")\n   279→            },\n   280→            want: &Result{Type: \"special\"},\n   281→        },\n   282→    }\n   283→    \n   284→    for _, tt := range tests {\n   285→        t.Run(tt.name, func(t *testing.T) {\n   286→            if tt.setup != nil {\n   287→                tt.setup()\n   288→            }\n   289→            if tt.cleanup != nil {\n   290→                defer tt.cleanup()\n   291→            }\n   292→            \n   293→            got, err := Parse(tt.input)\n   294→            \n   295→            if (err != nil) != tt.wantErr {\n   296→                t.Errorf(\"Parse() error = %v, wantErr %v\", err, tt.wantErr)\n   297→                return\n   298→            }\n   299→            \n   300→            if tt.check != nil {\n   301→                tt.check(t, got)\n   302→            } else if !reflect.DeepEqual(got, tt.want) {\n   303→                t.Errorf(\"Parse() = %v, want %v\", got, tt.want)\n   304→            }\n   305→        })\n   306→    }\n   307→}\n   308→```\n   309→\n   310→## Subtests\n   311→\n   312→### Using Subtests\n   313→```go\n   314→func TestFeature(t *testing.T) {\n   315→    // Setup shared by all subtests\n   316→    db := setupTestDB(t)\n   317→    defer db.Close()\n   318→    \n   319→    t.Run(\"Create\", func(t *testing.T) {\n   320→        // Can run in parallel with other subtests\n   321→        t.Parallel()\n   322→        \n   323→        err := db.Create(&User{Name: \"Alice\"})\n   324→        if err != nil {\n   325→            t.Errorf(\"failed to create user: %v\", err)\n   326→        }\n   327→    })\n   328→    \n   329→    t.Run(\"Read\", func(t *testing.T) {\n   330→        t.Parallel()\n   331→        \n   332→        user, err := db.Read(1)\n   333→        if err != nil {\n   334→            t.Errorf(\"failed to read user: %v\", err)\n   335→        }\n   336→        if user.Name != \"Alice\" {\n   337→            t.Errorf(\"wrong name: got %q, want %q\", user.Name, \"Alice\")\n   338→        }\n   339→    })\n   340→    \n   341→    t.Run(\"Update\", func(t *testing.T) {\n   342→        t.Parallel()\n   343→        \n   344→        err := db.Update(1, &User{Name: \"Bob\"})\n   345→        if err != nil {\n   346→            t.Errorf(\"failed to update user: %v\", err)\n   347→        }\n   348→    })\n   349→    \n   350→    t.Run(\"Delete\", func(t *testing.T) {\n   351→        t.Parallel()\n   352→        \n   353→        err := db.Delete(1)\n   354→        if err != nil {\n   355→            t.Errorf(\"failed to delete user: %v\", err)\n   356→        }\n   357→    })\n   358→}\n   359→\n   360→// Nested subtests\n   361→func TestComplexFeature(t *testing.T) {\n   362→    t.Run(\"Component1\", func(t *testing.T) {\n   363→        t.Run(\"Subcomponent1\", func(t *testing.T) {\n   364→            // Test specific functionality\n   365→        })\n   366→        \n   367→        t.Run(\"Subcomponent2\", func(t *testing.T) {\n   368→            // Test specific functionality\n   369→        })\n   370→    })\n   371→    \n   372→    t.Run(\"Component2\", func(t *testing.T) {\n   373→        t.Run(\"Subcomponent1\", func(t *testing.T) {\n   374→            // Test specific functionality\n   375→        })\n   376→    })\n   377→}\n   378→\n   379→// Dynamic subtests\n   380→func TestDynamicSubtests(t *testing.T) {\n   381→    scenarios := loadTestScenarios()\n   382→    \n   383→    for _, scenario := range scenarios {\n   384→        scenario := scenario // Capture range variable\n   385→        t.Run(scenario.Name, func(t *testing.T) {\n   386→            t.Parallel()\n   387→            \n   388→            result := ProcessScenario(scenario)\n   389→            if !result.Success {\n   390→                t.Errorf(\"scenario %q failed: %v\", scenario.Name, result.Error)\n   391→            }\n   392→        })\n   393→    }\n   394→}\n   395→```\n   396→\n   397→## Mocks and Stubs\n   398→\n   399→### Manual Mocks\n   400→```go\n   401→// Interface to mock\n   402→type DataStore interface {\n   403→    Get(key string) (string, error)\n   404→    Set(key, value string) error\n   405→}\n   406→\n   407→// Mock implementation\n   408→type MockDataStore struct {\n   409→    data      map[string]string\n   410→    getCalls  []string\n   411→    setCalls  []struct{ key, value string }\n   412→    getError  error\n   413→    setError  error\n   414→}\n   415→\n   416→func NewMockDataStore() *MockDataStore {\n   417→    return &MockDataStore{\n   418→        data: make(map[string]string),\n   419→    }\n   420→}\n   421→\n   422→func (m *MockDataStore) Get(key string) (string, error) {\n   423→    m.getCalls = append(m.getCalls, key)\n   424→    if m.getError != nil {\n   425→        return \"\", m.getError\n   426→    }\n   427→    return m.data[key], nil\n   428→}\n   429→\n   430→func (m *MockDataStore) Set(key, value string) error {\n   431→    m.setCalls = append(m.setCalls, struct{ key, value string }{key, value})\n   432→    if m.setError != nil {\n   433→        return m.setError\n   434→    }\n   435→    m.data[key] = value\n   436→    return nil\n   437→}\n   438→\n   439→// Using the mock in tests\n   440→func TestService(t *testing.T) {\n   441→    mock := NewMockDataStore()\n   442→    mock.data[\"key1\"] = \"value1\"\n   443→    \n   444→    service := NewService(mock)\n   445→    \n   446→    result, err := service.Process(\"key1\")\n   447→    if err != nil {\n   448→        t.Fatalf(\"unexpected error: %v\", err)\n   449→    }\n   450→    \n   451→    if result != \"processed: value1\" {\n   452→        t.Errorf(\"got %q, want %q\", result, \"processed: value1\")\n   453→    }\n   454→    \n   455→    // Verify mock was called correctly\n   456→    if len(mock.getCalls) != 1 || mock.getCalls[0] != \"key1\" {\n   457→        t.Errorf(\"unexpected Get calls: %v\", mock.getCalls)\n   458→    }\n   459→}\n   460→\n   461→// Stub with configurable behavior\n   462→type StubHTTPClient struct {\n   463→    responses map[string]*http.Response\n   464→    errors    map[string]error\n   465→}\n   466→\n   467→func (s *StubHTTPClient) Do(req *http.Request) (*http.Response, error) {\n   468→    key := req.Method + \" \" + req.URL.String()\n   469→    \n   470→    if err, ok := s.errors[key]; ok {\n   471→        return nil, err\n   472→    }\n   473→    \n   474→    if resp, ok := s.responses[key]; ok {\n   475→        return resp, nil\n   476→    }\n   477→    \n   478→    return &http.Response{\n   479→        StatusCode: 404,\n   480→        Body:       io.NopCloser(strings.NewReader(\"Not Found\")),\n   481→    }, nil\n   482→}\n   483→```\n   484→\n   485→### Using testify/mock\n   486→```go\n   487→import (\n   488→    \"github.com/stretchr/testify/mock\"\n   489→    \"github.com/stretchr/testify/assert\"\n   490→)\n   491→\n   492→// Mock using testify\n   493→type MockRepository struct {\n   494→    mock.Mock\n   495→}\n   496→\n   497→func (m *MockRepository) GetUser(id int) (*User, error) {\n   498→    args := m.Called(id)\n   499→    if args.Get(0) == nil {\n   500→        return nil, args.Error(1)\n   501→    }\n   502→    return args.Get(0).(*User), args.Error(1)\n   503→}\n   504→\n   505→func (m *MockRepository) SaveUser(user *User) error {\n   506→    args := m.Called(user)\n   507→    return args.Error(0)\n   508→}\n   509→\n   510→func TestUserService(t *testing.T) {\n   511→    // Create mock\n   512→    mockRepo := new(MockRepository)\n   513→    \n   514→    // Set expectations\n   515→    mockRepo.On(\"GetUser\", 1).Return(&User{ID: 1, Name: \"Alice\"}, nil)\n   516→    mockRepo.On(\"SaveUser\", mock.Anything).Return(nil)\n   517→    \n   518→    // Create service with mock\n   519→    service := NewUserService(mockRepo)\n   520→    \n   521→    // Test\n   522→    user, err := service.GetUser(1)\n   523→    assert.NoError(t, err)\n   524→    assert.Equal(t, \"Alice\", user.Name)\n   525→    \n   526→    // Verify expectations were met\n   527→    mockRepo.AssertExpectations(t)\n   528→}\n   529→\n   530→// Advanced mocking\n   531→func TestComplexInteraction(t *testing.T) {\n   532→    mockRepo := new(MockRepository)\n   533→    \n   534→    // Match specific arguments\n   535→    mockRepo.On(\"GetUser\", mock.MatchedBy(func(id int) bool {\n   536→        return id > 0\n   537→    })).Return(&User{}, nil)\n   538→    \n   539→    // Return different values on successive calls\n   540→    mockRepo.On(\"SaveUser\", mock.Anything).\n   541→        Return(errors.New(\"first error\")).Once()\n   542→    mockRepo.On(\"SaveUser\", mock.Anything).\n   543→        Return(nil).Once()\n   544→    \n   545→    // Run function when called\n   546→    mockRepo.On(\"GetUser\", 2).\n   547→        Run(func(args mock.Arguments) {\n   548→            id := args.Get(0).(int)\n   549→            t.Logf(\"GetUser called with id: %d\", id)\n   550→        }).\n   551→        Return(&User{ID: 2}, nil)\n   552→}\n   553→```\n   554→\n   555→### Using gomock\n   556→```go\n   557→//go:generate mockgen -source=interface.go -destination=mocks/mock_interface.go\n   558→\n   559→import (\n   560→    \"github.com/golang/mock/gomock\"\n   561→    \"myproject/mocks\"\n   562→)\n   563→\n   564→func TestWithGoMock(t *testing.T) {\n   565→    ctrl := gomock.NewController(t)\n   566→    defer ctrl.Finish()\n   567→    \n   568→    mockStore := mocks.NewMockDataStore(ctrl)\n   569→    \n   570→    // Set expectations\n   571→    mockStore.EXPECT().\n   572→        Get(\"key1\").\n   573→        Return(\"value1\", nil).\n   574→        Times(1)\n   575→    \n   576→    mockStore.EXPECT().\n   577→        Set(\"key2\", \"value2\").\n   578→        Return(nil).\n   579→        AnyTimes()\n   580→    \n   581→    // Ordered expectations\n   582→    gomock.InOrder(\n   583→        mockStore.EXPECT().Get(\"first\"),\n   584→        mockStore.EXPECT().Get(\"second\"),\n   585→        mockStore.EXPECT().Get(\"third\"),\n   586→    )\n   587→    \n   588→    // Use mock in test\n   589→    service := NewService(mockStore)\n   590→    result := service.Process()\n   591→    \n   592→    assert.Equal(t, \"expected\", result)\n   593→}\n   594→```\n   595→\n   596→## Fuzz Testing\n   597→\n   598→### Basic Fuzzing\n   599→```go\n   600→// Fuzz test (Go 1.18+)\n   601→func FuzzReverse(f *testing.F) {\n   602→    // Add seed corpus\n   603→    f.Add(\"hello\")\n   604→    f.Add(\"world\")\n   605→    f.Add(\"12345\")\n   606→    f.Add(\"\")\n   607→    f.Add(\"a\")\n   608→    \n   609→    // Fuzz target\n   610→    f.Fuzz(func(t *testing.T, input string) {\n   611→        reversed := Reverse(input)\n   612→        doubleReversed := Reverse(reversed)\n   613→        \n   614→        // Property: reversing twice should give original\n   615→        if input != doubleReversed {\n   616→            t.Errorf(\"double reverse failed: input=%q, got=%q\", \n   617→                input, doubleReversed)\n   618→        }\n   619→        \n   620→        // Property: length should be same\n   621→        if len(input) != len(reversed) {\n   622→            t.Errorf(\"length mismatch: input=%d, reversed=%d\", \n   623→                len(input), len(reversed))\n   624→        }\n   625→    })\n   626→}\n   627→\n   628→// Fuzz with multiple inputs\n   629→func FuzzAdd(f *testing.F) {\n   630→    // Seed corpus\n   631→    f.Add(int8(1), int8(2))\n   632→    f.Add(int8(127), int8(1))\n   633→    f.Add(int8(-128), int8(-1))\n   634→    \n   635→    f.Fuzz(func(t *testing.T, a, b int8) {\n   636→        result := Add(a, b)\n   637→        \n   638→        // Check for overflow\n   639→        if a > 0 && b > 0 && result < 0 {\n   640→            t.Skip(\"overflow detected\")\n   641→        }\n   642→        if a < 0 && b < 0 && result > 0 {\n   643→            t.Skip(\"underflow detected\")\n   644→        }\n   645→        \n   646→        // Property: addition is commutative\n   647→        if Add(a, b) != Add(b, a) {\n   648→            t.Errorf(\"not commutative: Add(%d,%d) != Add(%d,%d)\", \n   649→                a, b, b, a)\n   650→        }\n   651→    })\n   652→}\n   653→\n   654→// Complex fuzzing\n   655→func FuzzJSONParser(f *testing.F) {\n   656→    // Add valid JSON seeds\n   657→    f.Add(`{\"key\": \"value\"}`)\n   658→    f.Add(`[1, 2, 3]`)\n   659→    f.Add(`null`)\n   660→    f.Add(`true`)\n   661→    f.Add(`123.45`)\n   662→    f.Add(`\"string\"`)\n   663→    \n   664→    f.Fuzz(func(t *testing.T, input string) {\n   665→        parsed, err := ParseJSON(input)\n   666→        if err != nil {\n   667→            // Invalid JSON is expected sometimes\n   668→            return\n   669→        }\n   670→        \n   671→        // If parsing succeeded, marshaling should work\n   672→        marshaled, err := json.Marshal(parsed)\n   673→        if err != nil {\n   674→            t.Fatalf(\"failed to marshal parsed JSON: %v\", err)\n   675→        }\n   676→        \n   677→        // Parse again and compare\n   678→        var reparsed interface{}\n   679→        if err := json.Unmarshal(marshaled, &reparsed); err != nil {\n   680→            t.Fatalf(\"failed to unmarshal: %v\", err)\n   681→        }\n   682→        \n   683→        if !reflect.DeepEqual(parsed, reparsed) {\n   684→            t.Errorf(\"roundtrip failed: %v != %v\", parsed, reparsed)\n   685→        }\n   686→    })\n   687→}\n   688→```\n   689→\n   690→## Benchmarks\n   691→\n   692→### Basic Benchmarks\n   693→```go\n   694→func BenchmarkAdd(b *testing.B) {\n   695→    for i := 0; i < b.N; i++ {\n   696→        Add(2, 3)\n   697→    }\n   698→}\n   699→\n   700→// Benchmark with setup\n   701→func BenchmarkComplexOperation(b *testing.B) {\n   702→    // Setup is not counted in benchmark time\n   703→    data := generateTestData()\n   704→    \n   705→    b.ResetTimer() // Reset timer after setup\n   706→    \n   707→    for i := 0; i < b.N; i++ {\n   708→        ProcessData(data)\n   709→    }\n   710→}\n   711→\n   712→// Benchmark with cleanup\n   713→func BenchmarkWithCleanup(b *testing.B) {\n   714→    for i := 0; i < b.N; i++ {\n   715→        b.StopTimer() // Pause timer for cleanup\n   716→        cleanup()\n   717→        b.StartTimer() // Resume timer\n   718→        \n   719→        ExpensiveOperation()\n   720→    }\n   721→}\n   722→\n   723→// Parallel benchmarks\n   724→func BenchmarkParallel(b *testing.B) {\n   725→    b.RunParallel(func(pb *testing.PB) {\n   726→        for pb.Next() {\n   727→            ConcurrentOperation()\n   728→        }\n   729→    })\n   730→}\n   731→\n   732→// Sub-benchmarks\n   733→func BenchmarkSort(b *testing.B) {\n   734→    sizes := []int{10, 100, 1000, 10000}\n   735→    \n   736→    for _, size := range sizes {\n   737→        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n   738→            data := generateData(size)\n   739→            b.ResetTimer()\n   740→            \n   741→            for i := 0; i < b.N; i++ {\n   742→                b.StopTimer()\n   743→                unsorted := make([]int, len(data))\n   744→                copy(unsorted, data)\n   745→                b.StartTimer()\n   746→                \n   747→                Sort(unsorted)\n   748→            }\n   749→        })\n   750→    }\n   751→}\n   752→\n   753→// Memory allocation benchmarks\n   754→func BenchmarkMemory(b *testing.B) {\n   755→    b.ReportAllocs() // Report memory allocations\n   756→    \n   757→    for i := 0; i < b.N; i++ {\n   758→        result := AllocatingFunction()\n   759→        _ = result\n   760→    }\n   761→}\n   762→\n   763→// Custom metrics\n   764→func BenchmarkCustomMetric(b *testing.B) {\n   765→    var totalBytes int64\n   766→    \n   767→    for i := 0; i < b.N; i++ {\n   768→        bytes := ProcessFile(\"test.txt\")\n   769→        totalBytes += bytes\n   770→    }\n   771→    \n   772→    b.SetBytes(totalBytes / int64(b.N)) // Bytes processed per operation\n   773→    b.ReportMetric(float64(totalBytes)/float64(b.N), \"bytes/op\")\n   774→}\n   775→\n   776→// Comparative benchmarks\n   777→func BenchmarkImplementations(b *testing.B) {\n   778→    b.Run(\"Implementation1\", func(b *testing.B) {\n   779→        for i := 0; i < b.N; i++ {\n   780→            Implementation1()\n   781→        }\n   782→    })\n   783→    \n   784→    b.Run(\"Implementation2\", func(b *testing.B) {\n   785→        for i := 0; i < b.N; i++ {\n   786→            Implementation2()\n   787→        }\n   788→    })\n   789→    \n   790→    b.Run(\"Implementation3\", func(b *testing.B) {\n   791→        for i := 0; i < b.N; i++ {\n   792→            Implementation3()\n   793→        }\n   794→    })\n   795→}\n   796→```\n   797→\n   798→## Coverage\n   799→\n   800→### Running Coverage\n   801→```bash\n   802→# Run tests with coverage\n   803→go test -cover\n   804→\n   805→# Generate coverage profile\n   806→go test -coverprofile=coverage.out\n   807→\n   808→# View coverage in browser\n   809→go tool cover -html=coverage.out\n   810→\n   811→# Coverage for specific functions\n   812→go tool cover -func=coverage.out\n   813→\n   814→# Coverage with multiple packages\n   815→go test -coverprofile=coverage.out ./...\n   816→\n   817→# Coverage mode\n   818→go test -covermode=count -coverprofile=coverage.out\n   819→# Modes: set (default), count, atomic\n   820→\n   821→# Exclude files from coverage\n   822→# Use build tags\n   823→//go:build !test\n   824→```\n   825→\n   826→### Coverage in Code\n   827→```go\n   828→// Ensuring coverage\n   829→func TestFullCoverage(t *testing.T) {\n   830→    tests := []struct {\n   831→        name  string\n   832→        input int\n   833→        want  string\n   834→    }{\n   835→        {\"positive\", 1, \"positive\"},\n   836→        {\"negative\", -1, \"negative\"},\n   837→        {\"zero\", 0, \"zero\"}, // Cover all branches\n   838→    }\n   839→    \n   840→    for _, tt := range tests {\n   841→        t.Run(tt.name, func(t *testing.T) {\n   842→            got := Classify(tt.input)\n   843→            if got != tt.want {\n   844→                t.Errorf(\"Classify(%d) = %q, want %q\", \n   845→                    tt.input, got, tt.want)\n   846→            }\n   847→        })\n   848→    }\n   849→}\n   850→\n   851→// Testing error paths for coverage\n   852→func TestErrorPaths(t *testing.T) {\n   853→    // Test success path\n   854→    result, err := RiskyOperation(validInput)\n   855→    if err != nil {\n   856→        t.Fatalf(\"unexpected error: %v\", err)\n   857→    }\n   858→    \n   859→    // Test error path 1\n   860→    _, err = RiskyOperation(invalidInput1)\n   861→    if err == nil {\n   862→        t.Error(\"expected error for invalid input 1\")\n   863→    }\n   864→    \n   865→    // Test error path 2\n   866→    _, err = RiskyOperation(invalidInput2)\n   867→    if err == nil {\n   868→        t.Error(\"expected error for invalid input 2\")\n   869→    }\n   870→}\n   871→```\n   872→\n   873→## Integration Tests\n   874→\n   875→### Database Integration Tests\n   876→```go\n   877→//go:build integration\n   878→\n   879→package db_test\n   880→\n   881→import (\n   882→    \"database/sql\"\n   883→    \"testing\"\n   884→    _ \"github.com/lib/pq\"\n   885→)\n   886→\n   887→func TestDatabaseIntegration(t *testing.T) {\n   888→    if testing.Short() {\n   889→        t.Skip(\"skipping integration test in short mode\")\n   890→    }\n   891→    \n   892→    // Connect to test database\n   893→    db, err := sql.Open(\"postgres\", getTestDatabaseURL())\n   894→    if err != nil {\n   895→        t.Fatalf(\"failed to connect: %v\", err)\n   896→    }\n   897→    defer db.Close()\n   898→    \n   899→    // Run migrations\n   900→    if err := runMigrations(db); err != nil {\n   901→        t.Fatalf(\"failed to run migrations: %v\", err)\n   902→    }\n   903→    \n   904→    // Test repository\n   905→    repo := NewUserRepository(db)\n   906→    \n   907→    t.Run(\"Create\", func(t *testing.T) {\n   908→        user := &User{Name: \"Alice\", Email: \"alice@example.com\"}\n   909→        err := repo.Create(user)\n   910→        if err != nil {\n   911→            t.Fatalf(\"failed to create user: %v\", err)\n   912→        }\n   913→        if user.ID == 0 {\n   914→            t.Error(\"expected user ID to be set\")\n   915→        }\n   916→    })\n   917→    \n   918→    t.Run(\"Transaction\", func(t *testing.T) {\n   919→        tx, err := db.Begin()\n   920→        if err != nil {\n   921→            t.Fatal(err)\n   922→        }\n   923→        defer tx.Rollback()\n   924→        \n   925→        // Operations in transaction\n   926→        repoTx := NewUserRepositoryTx(tx)\n   927→        // ... test operations\n   928→        \n   929→        if err := tx.Commit(); err != nil {\n   930→            t.Fatal(err)\n   931→        }\n   932→    })\n   933→}\n   934→\n   935→// HTTP Integration Tests\n   936→func TestHTTPIntegration(t *testing.T) {\n   937→    // Start test server\n   938→    server := httptest.NewServer(NewRouter())\n   939→    defer server.Close()\n   940→    \n   941→    client := server.Client()\n   942→    \n   943→    t.Run(\"GET /users\", func(t *testing.T) {\n   944→        resp, err := client.Get(server.URL + \"/users\")\n   945→        if err != nil {\n   946→            t.Fatal(err)\n   947→        }\n   948→        defer resp.Body.Close()\n   949→        \n   950→        if resp.StatusCode != http.StatusOK {\n   951→            t.Errorf(\"expected status 200, got %d\", resp.StatusCode)\n   952→        }\n   953→        \n   954→        var users []User\n   955→        if err := json.NewDecoder(resp.Body).Decode(&users); err != nil {\n   956→            t.Fatal(err)\n   957→        }\n   958→    })\n   959→    \n   960→    t.Run(\"POST /users\", func(t *testing.T) {\n   961→        user := User{Name: \"Bob\", Email: \"bob@example.com\"}\n   962→        body, _ := json.Marshal(user)\n   963→        \n   964→        resp, err := client.Post(\n   965→            server.URL+\"/users\",\n   966→            \"application/json\",\n   967→            bytes.NewReader(body),\n   968→        )\n   969→        if err != nil {\n   970→            t.Fatal(err)\n   971→        }\n   972→        defer resp.Body.Close()\n   973→        \n   974→        if resp.StatusCode != http.StatusCreated {\n   975→            t.Errorf(\"expected status 201, got %d\", resp.StatusCode)\n   976→        }\n   977→    })\n   978→}\n   979→```\n   980→\n   981→### Container Integration Tests\n   982→```go\n   983→import (\n   984→    \"github.com/testcontainers/testcontainers-go\"\n   985→    \"github.com/testcontainers/testcontainers-go/wait\"\n   986→)\n   987→\n   988→func TestWithRedis(t *testing.T) {\n   989→    ctx := context.Background()\n   990→    \n   991→    // Start Redis container\n   992→    req := testcontainers.ContainerRequest{\n   993→        Image:        \"redis:latest\",\n   994→        ExposedPorts: []string{\"6379/tcp\"},\n   995→        WaitingFor:   wait.ForLog(\"Ready to accept connections\"),\n   996→    }\n   997→    \n   998→    redis, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n   999→        ContainerRequest: req,\n  1000→        Started:          true,\n  1001→    })\n  1002→    if err != nil {\n  1003→        t.Fatal(err)\n  1004→    }\n  1005→    defer redis.Terminate(ctx)\n  1006→    \n  1007→    // Get connection details\n  1008→    host, err := redis.Host(ctx)\n  1009→    if err != nil {\n  1010→        t.Fatal(err)\n  1011→    }\n  1012→    \n  1013→    port, err := redis.MappedPort(ctx, \"6379\")\n  1014→    if err != nil {\n  1015→        t.Fatal(err)\n  1016→    }\n  1017→    \n  1018→    // Connect to Redis\n  1019→    client := NewRedisClient(host, port.Port())\n  1020→    \n  1021→    // Run tests\n  1022→    t.Run(\"Set and Get\", func(t *testing.T) {\n  1023→        err := client.Set(\"key\", \"value\")\n  1024→        if err != nil {\n  1025→            t.Fatal(err)\n  1026→        }\n  1027→        \n  1028→        val, err := client.Get(\"key\")\n  1029→        if err != nil {\n  1030→            t.Fatal(err)\n  1031→        }\n  1032→        \n  1033→        if val != \"value\" {\n  1034→            t.Errorf(\"got %q, want %q\", val, \"value\")\n  1035→        }\n  1036→    })\n  1037→}\n  1038→```\n  1039→\n  1040→## Test Fixtures and Helpers\n  1041→\n  1042→### Test Fixtures\n  1043→```go\n  1044→// fixtures.go\n  1045→package testutil\n  1046→\n  1047→type Fixtures struct {\n  1048→    Users    []*User\n  1049→    Products []*Product\n  1050→    Orders   []*Order\n  1051→}\n  1052→\n  1053→func LoadFixtures() *Fixtures {\n  1054→    return &Fixtures{\n  1055→        Users: []*User{\n  1056→            {ID: 1, Name: \"Alice\", Email: \"alice@example.com\"},\n  1057→            {ID: 2, Name: \"Bob\", Email: \"bob@example.com\"},\n  1058→        },\n  1059→        Products: []*Product{\n  1060→            {ID: 1, Name: \"Widget\", Price: 9.99},\n  1061→            {ID: 2, Name: \"Gadget\", Price: 19.99},\n  1062→        },\n  1063→        Orders: []*Order{\n  1064→            {ID: 1, UserID: 1, Total: 29.98},\n  1065→        },\n  1066→    }\n  1067→}\n  1068→\n  1069→// Test data builders\n  1070→type UserBuilder struct {\n  1071→    user User\n  1072→}\n  1073→\n  1074→func NewUserBuilder() *UserBuilder {\n  1075→    return &UserBuilder{\n  1076→        user: User{\n  1077→            ID:    1,\n  1078→            Name:  \"Test User\",\n  1079→            Email: \"test@example.com\",\n  1080→        },\n  1081→    }\n  1082→}\n  1083→\n  1084→func (b *UserBuilder) WithName(name string) *UserBuilder {\n  1085→    b.user.Name = name\n  1086→    return b\n  1087→}\n  1088→\n  1089→func (b *UserBuilder) WithEmail(email string) *UserBuilder {\n  1090→    b.user.Email = email\n  1091→    return b\n  1092→}\n  1093→\n  1094→func (b *UserBuilder) Build() *User {\n  1095→    return &b.user\n  1096→}\n  1097→\n  1098→// Usage\n  1099→func TestWithBuilder(t *testing.T) {\n  1100→    user := NewUserBuilder().\n  1101→        WithName(\"Alice\").\n  1102→        WithEmail(\"alice@test.com\").\n  1103→        Build()\n  1104→    \n  1105→    // Test with user...\n  1106→}\n  1107→```\n  1108→\n  1109→### Test Helpers\n  1110→```go\n  1111→// helpers.go\n  1112→package testutil\n  1113→\n  1114→// Test database helper\n  1115→func SetupTestDB(t testing.TB) *sql.DB {\n  1116→    t.Helper()\n  1117→    \n  1118→    db, err := sql.Open(\"sqlite3\", \":memory:\")\n  1119→    if err != nil {\n  1120→        t.Fatal(err)\n  1121→    }\n  1122→    \n  1123→    if err := runMigrations(db); err != nil {\n  1124→        t.Fatal(err)\n  1125→    }\n  1126→    \n  1127→    t.Cleanup(func() {\n  1128→        db.Close()\n  1129→    })\n  1130→    \n  1131→    return db\n  1132→}\n  1133→\n  1134→// Temporary directory helper\n  1135→func TempDir(t testing.TB) string {\n  1136→    t.Helper()\n  1137→    \n  1138→    dir, err := os.MkdirTemp(\"\", \"test\")\n  1139→    if err != nil {\n  1140→        t.Fatal(err)\n  1141→    }\n  1142→    \n  1143→    t.Cleanup(func() {\n  1144→        os.RemoveAll(dir)\n  1145→    })\n  1146→    \n  1147→    return dir\n  1148→}\n  1149→\n  1150→// Assert helpers\n  1151→func AssertEqual(t testing.TB, got, want interface{}) {\n  1152→    t.Helper()\n  1153→    \n  1154→    if !reflect.DeepEqual(got, want) {\n  1155→        t.Errorf(\"got %v, want %v\", got, want)\n  1156→    }\n  1157→}\n  1158→\n  1159→func AssertNoError(t testing.TB, err error) {\n  1160→    t.Helper()\n  1161→    \n  1162→    if err != nil {\n  1163→        t.Fatalf(\"unexpected error: %v\", err)\n  1164→    }\n  1165→}\n  1166→\n  1167→func AssertError(t testing.TB, err error) {\n  1168→    t.Helper()\n  1169→    \n  1170→    if err == nil {\n  1171→        t.Fatal(\"expected error, got nil\")\n  1172→    }\n  1173→}\n  1174→\n  1175→// Golden file helper\n  1176→func GoldenFile(t testing.TB, name string, got []byte) {\n  1177→    t.Helper()\n  1178→    \n  1179→    golden := filepath.Join(\"testdata\", name+\".golden\")\n  1180→    \n  1181→    if *update {\n  1182→        os.WriteFile(golden, got, 0644)\n  1183→        return\n  1184→    }\n  1185→    \n  1186→    want, err := os.ReadFile(golden)\n  1187→    if err != nil {\n  1188→        t.Fatal(err)\n  1189→    }\n  1190→    \n  1191→    if !bytes.Equal(got, want) {\n  1192→        t.Errorf(\"output mismatch for %s\", name)\n  1193→    }\n  1194→}\n  1195→```\n  1196→\n  1197→## Advanced Testing Techniques\n  1198→\n  1199→### Property-Based Testing\n  1200→```go\n  1201→import \"github.com/leanovate/gopter\"\n  1202→\n  1203→func TestPropertyBased(t *testing.T) {\n  1204→    properties := gopter.NewProperties(nil)\n  1205→    \n  1206→    properties.Property(\"reverse twice is identity\", prop.ForAll(\n  1207→        func(s string) bool {\n  1208→            return s == Reverse(Reverse(s))\n  1209→        },\n  1210→        gopter.Gen.String(),\n  1211→    ))\n  1212→    \n  1213→    properties.Property(\"list append preserves length\", prop.ForAll(\n  1214→        func(list []int, item int) bool {\n  1215→            original := len(list)\n  1216→            result := append(list, item)\n  1217→            return len(result) == original+1\n  1218→        },\n  1219→        gopter.Gen.SliceOf(gopter.Gen.Int()),\n  1220→        gopter.Gen.Int(),\n  1221→    ))\n  1222→    \n  1223→    properties.TestingRun(t)\n  1224→}\n  1225→```\n  1226→\n  1227→### Snapshot Testing\n  1228→```go\n  1229→func TestSnapshot(t *testing.T) {\n  1230→    data := generateComplexData()\n  1231→    output := RenderHTML(data)\n  1232→    \n  1233→    snapshot := filepath.Join(\"testdata\", t.Name()+\".snapshot\")\n  1234→    \n  1235→    if *updateSnapshots {\n  1236→        if err := os.WriteFile(snapshot, []byte(output), 0644); err != nil {\n  1237→            t.Fatal(err)\n  1238→        }\n  1239→        return\n  1240→    }\n  1241→    \n  1242→    expected, err := os.ReadFile(snapshot)\n  1243→    if err != nil {\n  1244→        t.Fatal(err)\n  1245→    }\n  1246→    \n  1247→    if output != string(expected) {\n  1248→        t.Error(\"snapshot mismatch\")\n  1249→        // Could use diff library to show differences\n  1250→    }\n  1251→}\n  1252→```\n  1253→\n  1254→### Contract Testing\n  1255→```go\n  1256→// Define contract that implementations must satisfy\n  1257→type StorageContract struct {\n  1258→    t       testing.TB\n  1259→    storage Storage\n  1260→}\n  1261→\n  1262→func (c *StorageContract) TestStore() {\n  1263→    c.t.Helper()\n  1264→    \n  1265→    err := c.storage.Store(\"key\", \"value\")\n  1266→    if err != nil {\n  1267→        c.t.Errorf(\"Store failed: %v\", err)\n  1268→    }\n  1269→    \n  1270→    val, err := c.storage.Retrieve(\"key\")\n  1271→    if err != nil {\n  1272→        c.t.Errorf(\"Retrieve failed: %v\", err)\n  1273→    }\n  1274→    \n  1275→    if val != \"value\" {\n  1276→        c.t.Errorf(\"got %q, want %q\", val, \"value\")\n  1277→    }\n  1278→}\n  1279→\n  1280→func (c *StorageContract) TestDelete() {\n  1281→    c.t.Helper()\n  1282→    \n  1283→    c.storage.Store(\"key\", \"value\")\n  1284→    err := c.storage.Delete(\"key\")\n  1285→    if err != nil {\n  1286→        c.t.Errorf(\"Delete failed: %v\", err)\n  1287→    }\n  1288→    \n  1289→    _, err = c.storage.Retrieve(\"key\")\n  1290→    if err == nil {\n  1291→        c.t.Error(\"expected error after delete\")\n  1292→    }\n  1293→}\n  1294→\n  1295→// Test different implementations\n  1296→func TestMemoryStorage(t *testing.T) {\n  1297→    storage := NewMemoryStorage()\n  1298→    contract := &StorageContract{t: t, storage: storage}\n  1299→    contract.TestStore()\n  1300→    contract.TestDelete()\n  1301→}\n  1302→\n  1303→func TestDiskStorage(t *testing.T) {\n  1304→    storage := NewDiskStorage(t.TempDir())\n  1305→    contract := &StorageContract{t: t, storage: storage}\n  1306→    contract.TestStore()\n  1307→    contract.TestDelete()\n  1308→}\n  1309→```\n  1310→\n  1311→## Best Practices Summary\n  1312→\n  1313→1. **Write table-driven tests** - Comprehensive and maintainable\n  1314→2. **Use subtests** - Better organization and parallel execution\n  1315→3. **Mock external dependencies** - Fast and reliable tests\n  1316→4. **Test edge cases** - Empty inputs, nil values, errors\n  1317→5. **Benchmark critical paths** - Measure performance\n  1318→6. **Aim for high coverage** - But focus on meaningful tests\n  1319→7. **Use t.Helper()** - Better error reporting in test helpers\n  1320→8. **Cleanup with t.Cleanup()** - Guaranteed cleanup\n  1321→9. **Use build tags for integration tests** - Separate slow tests\n  1322→10. **Keep tests deterministic** - No random failures\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"222151ab-2ef1-4401-9f5e-47f957a82586","timestamp":"2025-08-13T10:27:55.233Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/testing.md","content":"# Go Testing - Complete Testing Guide\n\n## Table of Contents\n1. [Unit Tests](#unit-tests)\n2. [Table-Driven Tests](#table-driven-tests)\n3. [Subtests](#subtests)\n4. [Mocks and Stubs](#mocks-and-stubs)\n5. [Fuzz Testing](#fuzz-testing)\n6. [Benchmarks](#benchmarks)\n7. [Coverage](#coverage)\n8. [Integration Tests](#integration-tests)\n9. [Test Fixtures and Helpers](#test-fixtures-and-helpers)\n10. [Advanced Testing Techniques](#advanced-testing-techniques)\n\n## Unit Tests\n\n### Basic Test Structure\n```go\n// File: math.go\npackage math\n\nfunc Add(a, b int) int {\n    return a + b\n}\n\n// File: math_test.go\npackage math\n\nimport \"testing\"\n\nfunc TestAdd(t *testing.T) {\n    result := Add(2, 3)\n    expected := 5\n    \n    if result != expected {\n        t.Errorf(\"Add(2, 3) = %d; want %d\", result, expected)\n    }\n}\n\n// Test with multiple assertions\nfunc TestMultipleAssertions(t *testing.T) {\n    // Arrange\n    input := \"test\"\n    \n    // Act\n    result := Process(input)\n    \n    // Assert\n    if result.Status != \"success\" {\n        t.Errorf(\"expected status 'success', got %q\", result.Status)\n    }\n    \n    if len(result.Data) == 0 {\n        t.Error(\"expected non-empty data\")\n    }\n    \n    if result.Timestamp.IsZero() {\n        t.Error(\"expected non-zero timestamp\")\n    }\n}\n\n// Using t.Fatal for critical failures\nfunc TestCriticalFailure(t *testing.T) {\n    db, err := connectDB()\n    if err != nil {\n        t.Fatalf(\"failed to connect to database: %v\", err)\n    }\n    defer db.Close()\n    \n    // Continue with test...\n}\n\n// Using t.Skip for conditional tests\nfunc TestRequiresDocker(t *testing.T) {\n    if !dockerAvailable() {\n        t.Skip(\"skipping test; Docker not available\")\n    }\n    \n    // Docker-dependent test...\n}\n\n// Parallel tests\nfunc TestParallel1(t *testing.T) {\n    t.Parallel() // Run in parallel with other parallel tests\n    // Test implementation...\n}\n\nfunc TestParallel2(t *testing.T) {\n    t.Parallel()\n    // Test implementation...\n}\n```\n\n### Test Organization\n```go\n// Testing exported functions\nfunc TestPublicFunction(t *testing.T) {\n    result := PublicFunction(\"input\")\n    if result != \"expected\" {\n        t.Errorf(\"got %q, want %q\", result, \"expected\")\n    }\n}\n\n// Testing unexported functions (same package)\nfunc TestPrivateFunction(t *testing.T) {\n    result := privateFunction(\"input\")\n    if result != \"expected\" {\n        t.Errorf(\"got %q, want %q\", result, \"expected\")\n    }\n}\n\n// Testing with external package (black-box testing)\npackage math_test\n\nimport (\n    \"testing\"\n    \"myproject/math\"\n)\n\nfunc TestAddExternal(t *testing.T) {\n    result := math.Add(2, 3)\n    if result != 5 {\n        t.Errorf(\"math.Add(2, 3) = %d; want 5\", result)\n    }\n}\n\n// Example tests (show up in documentation)\nfunc ExampleAdd() {\n    result := Add(2, 3)\n    fmt.Println(result)\n    // Output: 5\n}\n\nfunc ExampleAdd_negative() {\n    result := Add(-2, -3)\n    fmt.Println(result)\n    // Output: -5\n}\n\n// Testing main function\nfunc TestMain(m *testing.M) {\n    // Setup before tests\n    setup()\n    \n    // Run tests\n    code := m.Run()\n    \n    // Cleanup after tests\n    teardown()\n    \n    os.Exit(code)\n}\n```\n\n## Table-Driven Tests\n\n### Basic Table-Driven Tests\n```go\nfunc TestAdd(t *testing.T) {\n    tests := []struct {\n        name     string\n        a, b     int\n        expected int\n    }{\n        {\"positive numbers\", 2, 3, 5},\n        {\"negative numbers\", -2, -3, -5},\n        {\"mixed\", -5, 10, 5},\n        {\"with zero\", 0, 5, 5},\n        {\"both zero\", 0, 0, 0},\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            result := Add(tt.a, tt.b)\n            if result != tt.expected {\n                t.Errorf(\"Add(%d, %d) = %d; want %d\", \n                    tt.a, tt.b, result, tt.expected)\n            }\n        })\n    }\n}\n\n// Table-driven tests with errors\nfunc TestDivide(t *testing.T) {\n    tests := []struct {\n        name      string\n        dividend  float64\n        divisor   float64\n        want      float64\n        wantErr   bool\n        errString string\n    }{\n        {\n            name:     \"normal division\",\n            dividend: 10,\n            divisor:  2,\n            want:     5,\n            wantErr:  false,\n        },\n        {\n            name:      \"divide by zero\",\n            dividend:  10,\n            divisor:   0,\n            want:      0,\n            wantErr:   true,\n            errString: \"division by zero\",\n        },\n        {\n            name:     \"negative division\",\n            dividend: -10,\n            divisor:  2,\n            want:     -5,\n            wantErr:  false,\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got, err := Divide(tt.dividend, tt.divisor)\n            \n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Divide() error = %v, wantErr %v\", err, tt.wantErr)\n                return\n            }\n            \n            if tt.wantErr && err.Error() != tt.errString {\n                t.Errorf(\"Divide() error = %q, want %q\", err.Error(), tt.errString)\n                return\n            }\n            \n            if got != tt.want {\n                t.Errorf(\"Divide() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n\n// Complex table-driven tests\nfunc TestParser(t *testing.T) {\n    tests := []struct {\n        name    string\n        input   string\n        setup   func()\n        cleanup func()\n        want    *Result\n        wantErr bool\n        check   func(t *testing.T, got *Result)\n    }{\n        {\n            name:  \"valid JSON\",\n            input: `{\"key\": \"value\"}`,\n            want: &Result{\n                Type: \"object\",\n                Data: map[string]interface{}{\"key\": \"value\"},\n            },\n        },\n        {\n            name:  \"complex validation\",\n            input: `{\"items\": [1, 2, 3]}`,\n            check: func(t *testing.T, got *Result) {\n                if got.Type != \"object\" {\n                    t.Errorf(\"wrong type: %s\", got.Type)\n                }\n                items, ok := got.Data.(map[string]interface{})[\"items\"].([]interface{})\n                if !ok || len(items) != 3 {\n                    t.Error(\"expected 3 items\")\n                }\n            },\n        },\n        {\n            name: \"with setup\",\n            input: \"special\",\n            setup: func() {\n                // Prepare test environment\n                os.Setenv(\"TEST_MODE\", \"special\")\n            },\n            cleanup: func() {\n                os.Unsetenv(\"TEST_MODE\")\n            },\n            want: &Result{Type: \"special\"},\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            if tt.setup != nil {\n                tt.setup()\n            }\n            if tt.cleanup != nil {\n                defer tt.cleanup()\n            }\n            \n            got, err := Parse(tt.input)\n            \n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Parse() error = %v, wantErr %v\", err, tt.wantErr)\n                return\n            }\n            \n            if tt.check != nil {\n                tt.check(t, got)\n            } else if !reflect.DeepEqual(got, tt.want) {\n                t.Errorf(\"Parse() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n```\n\n## Subtests\n\n### Using Subtests\n```go\nfunc TestFeature(t *testing.T) {\n    // Setup shared by all subtests\n    db := setupTestDB(t)\n    defer db.Close()\n    \n    t.Run(\"Create\", func(t *testing.T) {\n        // Can run in parallel with other subtests\n        t.Parallel()\n        \n        err := db.Create(&User{Name: \"Alice\"})\n        if err != nil {\n            t.Errorf(\"failed to create user: %v\", err)\n        }\n    })\n    \n    t.Run(\"Read\", func(t *testing.T) {\n        t.Parallel()\n        \n        user, err := db.Read(1)\n        if err != nil {\n            t.Errorf(\"failed to read user: %v\", err)\n        }\n        if user.Name != \"Alice\" {\n            t.Errorf(\"wrong name: got %q, want %q\", user.Name, \"Alice\")\n        }\n    })\n    \n    t.Run(\"Update\", func(t *testing.T) {\n        t.Parallel()\n        \n        err := db.Update(1, &User{Name: \"Bob\"})\n        if err != nil {\n            t.Errorf(\"failed to update user: %v\", err)\n        }\n    })\n    \n    t.Run(\"Delete\", func(t *testing.T) {\n        t.Parallel()\n        \n        err := db.Delete(1)\n        if err != nil {\n            t.Errorf(\"failed to delete user: %v\", err)\n        }\n    })\n}\n\n// Nested subtests\nfunc TestComplexFeature(t *testing.T) {\n    t.Run(\"Component1\", func(t *testing.T) {\n        t.Run(\"Subcomponent1\", func(t *testing.T) {\n            // Test specific functionality\n        })\n        \n        t.Run(\"Subcomponent2\", func(t *testing.T) {\n            // Test specific functionality\n        })\n    })\n    \n    t.Run(\"Component2\", func(t *testing.T) {\n        t.Run(\"Subcomponent1\", func(t *testing.T) {\n            // Test specific functionality\n        })\n    })\n}\n\n// Dynamic subtests\nfunc TestDynamicSubtests(t *testing.T) {\n    scenarios := loadTestScenarios()\n    \n    for _, scenario := range scenarios {\n        scenario := scenario // Capture range variable\n        t.Run(scenario.Name, func(t *testing.T) {\n            t.Parallel()\n            \n            result := ProcessScenario(scenario)\n            if !result.Success {\n                t.Errorf(\"scenario %q failed: %v\", scenario.Name, result.Error)\n            }\n        })\n    }\n}\n```\n\n## Mocks and Stubs\n\n### Manual Mocks\n```go\n// Interface to mock\ntype DataStore interface {\n    Get(key string) (string, error)\n    Set(key, value string) error\n}\n\n// Mock implementation\ntype MockDataStore struct {\n    data      map[string]string\n    getCalls  []string\n    setCalls  []struct{ key, value string }\n    getError  error\n    setError  error\n}\n\nfunc NewMockDataStore() *MockDataStore {\n    return &MockDataStore{\n        data: make(map[string]string),\n    }\n}\n\nfunc (m *MockDataStore) Get(key string) (string, error) {\n    m.getCalls = append(m.getCalls, key)\n    if m.getError != nil {\n        return \"\", m.getError\n    }\n    return m.data[key], nil\n}\n\nfunc (m *MockDataStore) Set(key, value string) error {\n    m.setCalls = append(m.setCalls, struct{ key, value string }{key, value})\n    if m.setError != nil {\n        return m.setError\n    }\n    m.data[key] = value\n    return nil\n}\n\n// Using the mock in tests\nfunc TestService(t *testing.T) {\n    mock := NewMockDataStore()\n    mock.data[\"key1\"] = \"value1\"\n    \n    service := NewService(mock)\n    \n    result, err := service.Process(\"key1\")\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n    \n    if result != \"processed: value1\" {\n        t.Errorf(\"got %q, want %q\", result, \"processed: value1\")\n    }\n    \n    // Verify mock was called correctly\n    if len(mock.getCalls) != 1 || mock.getCalls[0] != \"key1\" {\n        t.Errorf(\"unexpected Get calls: %v\", mock.getCalls)\n    }\n}\n\n// Stub with configurable behavior\ntype StubHTTPClient struct {\n    responses map[string]*http.Response\n    errors    map[string]error\n}\n\nfunc (s *StubHTTPClient) Do(req *http.Request) (*http.Response, error) {\n    key := req.Method + \" \" + req.URL.String()\n    \n    if err, ok := s.errors[key]; ok {\n        return nil, err\n    }\n    \n    if resp, ok := s.responses[key]; ok {\n        return resp, nil\n    }\n    \n    return &http.Response{\n        StatusCode: 404,\n        Body:       io.NopCloser(strings.NewReader(\"Not Found\")),\n    }, nil\n}\n```\n\n### Using testify/mock\n```go\nimport (\n    \"github.com/stretchr/testify/mock\"\n    \"github.com/stretchr/testify/assert\"\n)\n\n// Mock using testify\ntype MockRepository struct {\n    mock.Mock\n}\n\nfunc (m *MockRepository) GetUser(id int) (*User, error) {\n    args := m.Called(id)\n    if args.Get(0) == nil {\n        return nil, args.Error(1)\n    }\n    return args.Get(0).(*User), args.Error(1)\n}\n\nfunc (m *MockRepository) SaveUser(user *User) error {\n    args := m.Called(user)\n    return args.Error(0)\n}\n\nfunc TestUserService(t *testing.T) {\n    // Create mock\n    mockRepo := new(MockRepository)\n    \n    // Set expectations\n    mockRepo.On(\"GetUser\", 1).Return(&User{ID: 1, Name: \"Alice\"}, nil)\n    mockRepo.On(\"SaveUser\", mock.Anything).Return(nil)\n    \n    // Create service with mock\n    service := NewUserService(mockRepo)\n    \n    // Test\n    user, err := service.GetUser(1)\n    assert.NoError(t, err)\n    assert.Equal(t, \"Alice\", user.Name)\n    \n    // Verify expectations were met\n    mockRepo.AssertExpectations(t)\n}\n\n// Advanced mocking\nfunc TestComplexInteraction(t *testing.T) {\n    mockRepo := new(MockRepository)\n    \n    // Match specific arguments\n    mockRepo.On(\"GetUser\", mock.MatchedBy(func(id int) bool {\n        return id > 0\n    })).Return(&User{}, nil)\n    \n    // Return different values on successive calls\n    mockRepo.On(\"SaveUser\", mock.Anything).\n        Return(errors.New(\"first error\")).Once()\n    mockRepo.On(\"SaveUser\", mock.Anything).\n        Return(nil).Once()\n    \n    // Run function when called\n    mockRepo.On(\"GetUser\", 2).\n        Run(func(args mock.Arguments) {\n            id := args.Get(0).(int)\n            t.Logf(\"GetUser called with id: %d\", id)\n        }).\n        Return(&User{ID: 2}, nil)\n}\n```\n\n### Using gomock\n```go\n//go:generate mockgen -source=interface.go -destination=mocks/mock_interface.go\n\nimport (\n    \"github.com/golang/mock/gomock\"\n    \"myproject/mocks\"\n)\n\nfunc TestWithGoMock(t *testing.T) {\n    ctrl := gomock.NewController(t)\n    defer ctrl.Finish()\n    \n    mockStore := mocks.NewMockDataStore(ctrl)\n    \n    // Set expectations\n    mockStore.EXPECT().\n        Get(\"key1\").\n        Return(\"value1\", nil).\n        Times(1)\n    \n    mockStore.EXPECT().\n        Set(\"key2\", \"value2\").\n        Return(nil).\n        AnyTimes()\n    \n    // Ordered expectations\n    gomock.InOrder(\n        mockStore.EXPECT().Get(\"first\"),\n        mockStore.EXPECT().Get(\"second\"),\n        mockStore.EXPECT().Get(\"third\"),\n    )\n    \n    // Use mock in test\n    service := NewService(mockStore)\n    result := service.Process()\n    \n    assert.Equal(t, \"expected\", result)\n}\n```\n\n## Fuzz Testing\n\n### Basic Fuzzing\n```go\n// Fuzz test (Go 1.18+)\nfunc FuzzReverse(f *testing.F) {\n    // Add seed corpus\n    f.Add(\"hello\")\n    f.Add(\"world\")\n    f.Add(\"12345\")\n    f.Add(\"\")\n    f.Add(\"a\")\n    \n    // Fuzz target\n    f.Fuzz(func(t *testing.T, input string) {\n        reversed := Reverse(input)\n        doubleReversed := Reverse(reversed)\n        \n        // Property: reversing twice should give original\n        if input != doubleReversed {\n            t.Errorf(\"double reverse failed: input=%q, got=%q\", \n                input, doubleReversed)\n        }\n        \n        // Property: length should be same\n        if len(input) != len(reversed) {\n            t.Errorf(\"length mismatch: input=%d, reversed=%d\", \n                len(input), len(reversed))\n        }\n    })\n}\n\n// Fuzz with multiple inputs\nfunc FuzzAdd(f *testing.F) {\n    // Seed corpus\n    f.Add(int8(1), int8(2))\n    f.Add(int8(127), int8(1))\n    f.Add(int8(-128), int8(-1))\n    \n    f.Fuzz(func(t *testing.T, a, b int8) {\n        result := Add(a, b)\n        \n        // Check for overflow\n        if a > 0 && b > 0 && result < 0 {\n            t.Skip(\"overflow detected\")\n        }\n        if a < 0 && b < 0 && result > 0 {\n            t.Skip(\"underflow detected\")\n        }\n        \n        // Property: addition is commutative\n        if Add(a, b) != Add(b, a) {\n            t.Errorf(\"not commutative: Add(%d,%d) != Add(%d,%d)\", \n                a, b, b, a)\n        }\n    })\n}\n\n// Complex fuzzing\nfunc FuzzJSONParser(f *testing.F) {\n    // Add valid JSON seeds\n    f.Add(`{\"key\": \"value\"}`)\n    f.Add(`[1, 2, 3]`)\n    f.Add(`null`)\n    f.Add(`true`)\n    f.Add(`123.45`)\n    f.Add(`\"string\"`)\n    \n    f.Fuzz(func(t *testing.T, input string) {\n        parsed, err := ParseJSON(input)\n        if err != nil {\n            // Invalid JSON is expected sometimes\n            return\n        }\n        \n        // If parsing succeeded, marshaling should work\n        marshaled, err := json.Marshal(parsed)\n        if err != nil {\n            t.Fatalf(\"failed to marshal parsed JSON: %v\", err)\n        }\n        \n        // Parse again and compare\n        var reparsed interface{}\n        if err := json.Unmarshal(marshaled, &reparsed); err != nil {\n            t.Fatalf(\"failed to unmarshal: %v\", err)\n        }\n        \n        if !reflect.DeepEqual(parsed, reparsed) {\n            t.Errorf(\"roundtrip failed: %v != %v\", parsed, reparsed)\n        }\n    })\n}\n```\n\n## Benchmarks\n\n### Basic Benchmarks\n```go\nfunc BenchmarkAdd(b *testing.B) {\n    for i := 0; i < b.N; i++ {\n        Add(2, 3)\n    }\n}\n\n// Benchmark with setup\nfunc BenchmarkComplexOperation(b *testing.B) {\n    // Setup is not counted in benchmark time\n    data := generateTestData()\n    \n    b.ResetTimer() // Reset timer after setup\n    \n    for i := 0; i < b.N; i++ {\n        ProcessData(data)\n    }\n}\n\n// Benchmark with cleanup\nfunc BenchmarkWithCleanup(b *testing.B) {\n    for i := 0; i < b.N; i++ {\n        b.StopTimer() // Pause timer for cleanup\n        cleanup()\n        b.StartTimer() // Resume timer\n        \n        ExpensiveOperation()\n    }\n}\n\n// Parallel benchmarks\nfunc BenchmarkParallel(b *testing.B) {\n    b.RunParallel(func(pb *testing.PB) {\n        for pb.Next() {\n            ConcurrentOperation()\n        }\n    })\n}\n\n// Sub-benchmarks\nfunc BenchmarkSort(b *testing.B) {\n    sizes := []int{10, 100, 1000, 10000}\n    \n    for _, size := range sizes {\n        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n            data := generateData(size)\n            b.ResetTimer()\n            \n            for i := 0; i < b.N; i++ {\n                b.StopTimer()\n                unsorted := make([]int, len(data))\n                copy(unsorted, data)\n                b.StartTimer()\n                \n                Sort(unsorted)\n            }\n        })\n    }\n}\n\n// Memory allocation benchmarks\nfunc BenchmarkMemory(b *testing.B) {\n    b.ReportAllocs() // Report memory allocations\n    \n    for i := 0; i < b.N; i++ {\n        result := AllocatingFunction()\n        _ = result\n    }\n}\n\n// Custom metrics\nfunc BenchmarkCustomMetric(b *testing.B) {\n    var totalBytes int64\n    \n    for i := 0; i < b.N; i++ {\n        bytes := ProcessFile(\"test.txt\")\n        totalBytes += bytes\n    }\n    \n    b.SetBytes(totalBytes / int64(b.N)) // Bytes processed per operation\n    b.ReportMetric(float64(totalBytes)/float64(b.N), \"bytes/op\")\n}\n\n// Comparative benchmarks\nfunc BenchmarkImplementations(b *testing.B) {\n    b.Run(\"Implementation1\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            Implementation1()\n        }\n    })\n    \n    b.Run(\"Implementation2\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            Implementation2()\n        }\n    })\n    \n    b.Run(\"Implementation3\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            Implementation3()\n        }\n    })\n}\n```\n\n## Coverage\n\n### Running Coverage\n```bash\n# Run tests with coverage\ngo test -cover\n\n# Generate coverage profile\ngo test -coverprofile=coverage.out\n\n# View coverage in browser\ngo tool cover -html=coverage.out\n\n# Coverage for specific functions\ngo tool cover -func=coverage.out\n\n# Coverage with multiple packages\ngo test -coverprofile=coverage.out ./...\n\n# Coverage mode\ngo test -covermode=count -coverprofile=coverage.out\n# Modes: set (default), count, atomic\n\n# Exclude files from coverage\n# Use build tags\n//go:build !test\n```\n\n### Coverage in Code\n```go\n// Ensuring coverage\nfunc TestFullCoverage(t *testing.T) {\n    tests := []struct {\n        name  string\n        input int\n        want  string\n    }{\n        {\"positive\", 1, \"positive\"},\n        {\"negative\", -1, \"negative\"},\n        {\"zero\", 0, \"zero\"}, // Cover all branches\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := Classify(tt.input)\n            if got != tt.want {\n                t.Errorf(\"Classify(%d) = %q, want %q\", \n                    tt.input, got, tt.want)\n            }\n        })\n    }\n}\n\n// Testing error paths for coverage\nfunc TestErrorPaths(t *testing.T) {\n    // Test success path\n    result, err := RiskyOperation(validInput)\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n    \n    // Test error path 1\n    _, err = RiskyOperation(invalidInput1)\n    if err == nil {\n        t.Error(\"expected error for invalid input 1\")\n    }\n    \n    // Test error path 2\n    _, err = RiskyOperation(invalidInput2)\n    if err == nil {\n        t.Error(\"expected error for invalid input 2\")\n    }\n}\n```\n\n## Integration Tests\n\n### Database Integration Tests\n```go\n//go:build integration\n\npackage db_test\n\nimport (\n    \"database/sql\"\n    \"testing\"\n    _ \"github.com/lib/pq\"\n)\n\nfunc TestDatabaseIntegration(t *testing.T) {\n    if testing.Short() {\n        t.Skip(\"skipping integration test in short mode\")\n    }\n    \n    // Connect to test database\n    db, err := sql.Open(\"postgres\", getTestDatabaseURL())\n    if err != nil {\n        t.Fatalf(\"failed to connect: %v\", err)\n    }\n    defer db.Close()\n    \n    // Run migrations\n    if err := runMigrations(db); err != nil {\n        t.Fatalf(\"failed to run migrations: %v\", err)\n    }\n    \n    // Test repository\n    repo := NewUserRepository(db)\n    \n    t.Run(\"Create\", func(t *testing.T) {\n        user := &User{Name: \"Alice\", Email: \"alice@example.com\"}\n        err := repo.Create(user)\n        if err != nil {\n            t.Fatalf(\"failed to create user: %v\", err)\n        }\n        if user.ID == 0 {\n            t.Error(\"expected user ID to be set\")\n        }\n    })\n    \n    t.Run(\"Transaction\", func(t *testing.T) {\n        tx, err := db.Begin()\n        if err != nil {\n            t.Fatal(err)\n        }\n        defer tx.Rollback()\n        \n        // Operations in transaction\n        repoTx := NewUserRepositoryTx(tx)\n        // ... test operations\n        \n        if err := tx.Commit(); err != nil {\n            t.Fatal(err)\n        }\n    })\n}\n\n// HTTP Integration Tests\nfunc TestHTTPIntegration(t *testing.T) {\n    // Start test server\n    server := httptest.NewServer(NewRouter())\n    defer server.Close()\n    \n    client := server.Client()\n    \n    t.Run(\"GET /users\", func(t *testing.T) {\n        resp, err := client.Get(server.URL + \"/users\")\n        if err != nil {\n            t.Fatal(err)\n        }\n        defer resp.Body.Close()\n        \n        if resp.StatusCode != http.StatusOK {\n            t.Errorf(\"expected status 200, got %d\", resp.StatusCode)\n        }\n        \n        var users []User\n        if err := json.NewDecoder(resp.Body).Decode(&users); err != nil {\n            t.Fatal(err)\n        }\n    })\n    \n    t.Run(\"POST /users\", func(t *testing.T) {\n        user := User{Name: \"Bob\", Email: \"bob@example.com\"}\n        body, _ := json.Marshal(user)\n        \n        resp, err := client.Post(\n            server.URL+\"/users\",\n            \"application/json\",\n            bytes.NewReader(body),\n        )\n        if err != nil {\n            t.Fatal(err)\n        }\n        defer resp.Body.Close()\n        \n        if resp.StatusCode != http.StatusCreated {\n            t.Errorf(\"expected status 201, got %d\", resp.StatusCode)\n        }\n    })\n}\n```\n\n### Container Integration Tests\n```go\nimport (\n    \"github.com/testcontainers/testcontainers-go\"\n    \"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nfunc TestWithRedis(t *testing.T) {\n    ctx := context.Background()\n    \n    // Start Redis container\n    req := testcontainers.ContainerRequest{\n        Image:        \"redis:latest\",\n        ExposedPorts: []string{\"6379/tcp\"},\n        WaitingFor:   wait.ForLog(\"Ready to accept connections\"),\n    }\n    \n    redis, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n        ContainerRequest: req,\n        Started:          true,\n    })\n    if err != nil {\n        t.Fatal(err)\n    }\n    defer redis.Terminate(ctx)\n    \n    // Get connection details\n    host, err := redis.Host(ctx)\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    port, err := redis.MappedPort(ctx, \"6379\")\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    // Connect to Redis\n    client := NewRedisClient(host, port.Port())\n    \n    // Run tests\n    t.Run(\"Set and Get\", func(t *testing.T) {\n        err := client.Set(\"key\", \"value\")\n        if err != nil {\n            t.Fatal(err)\n        }\n        \n        val, err := client.Get(\"key\")\n        if err != nil {\n            t.Fatal(err)\n        }\n        \n        if val != \"value\" {\n            t.Errorf(\"got %q, want %q\", val, \"value\")\n        }\n    })\n}\n```\n\n## Test Fixtures and Helpers\n\n### Test Fixtures\n```go\n// fixtures.go\npackage testutil\n\ntype Fixtures struct {\n    Users    []*User\n    Products []*Product\n    Orders   []*Order\n}\n\nfunc LoadFixtures() *Fixtures {\n    return &Fixtures{\n        Users: []*User{\n            {ID: 1, Name: \"Alice\", Email: \"alice@example.com\"},\n            {ID: 2, Name: \"Bob\", Email: \"bob@example.com\"},\n        },\n        Products: []*Product{\n            {ID: 1, Name: \"Widget\", Price: 9.99},\n            {ID: 2, Name: \"Gadget\", Price: 19.99},\n        },\n        Orders: []*Order{\n            {ID: 1, UserID: 1, Total: 29.98},\n        },\n    }\n}\n\n// Test data builders\ntype UserBuilder struct {\n    user User\n}\n\nfunc NewUserBuilder() *UserBuilder {\n    return &UserBuilder{\n        user: User{\n            ID:    1,\n            Name:  \"Test User\",\n            Email: \"test@example.com\",\n        },\n    }\n}\n\nfunc (b *UserBuilder) WithName(name string) *UserBuilder {\n    b.user.Name = name\n    return b\n}\n\nfunc (b *UserBuilder) WithEmail(email string) *UserBuilder {\n    b.user.Email = email\n    return b\n}\n\nfunc (b *UserBuilder) Build() *User {\n    return &b.user\n}\n\n// Usage\nfunc TestWithBuilder(t *testing.T) {\n    user := NewUserBuilder().\n        WithName(\"Alice\").\n        WithEmail(\"alice@test.com\").\n        Build()\n    \n    // Test with user...\n}\n```\n\n### Test Helpers\n```go\n// helpers.go\npackage testutil\n\n// Test database helper\nfunc SetupTestDB(t testing.TB) *sql.DB {\n    t.Helper()\n    \n    db, err := sql.Open(\"sqlite3\", \":memory:\")\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    if err := runMigrations(db); err != nil {\n        t.Fatal(err)\n    }\n    \n    t.Cleanup(func() {\n        db.Close()\n    })\n    \n    return db\n}\n\n// Temporary directory helper\nfunc TempDir(t testing.TB) string {\n    t.Helper()\n    \n    dir, err := os.MkdirTemp(\"\", \"test\")\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    t.Cleanup(func() {\n        os.RemoveAll(dir)\n    })\n    \n    return dir\n}\n\n// Assert helpers\nfunc AssertEqual(t testing.TB, got, want interface{}) {\n    t.Helper()\n    \n    if !reflect.DeepEqual(got, want) {\n        t.Errorf(\"got %v, want %v\", got, want)\n    }\n}\n\nfunc AssertNoError(t testing.TB, err error) {\n    t.Helper()\n    \n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n    }\n}\n\nfunc AssertError(t testing.TB, err error) {\n    t.Helper()\n    \n    if err == nil {\n        t.Fatal(\"expected error, got nil\")\n    }\n}\n\n// Golden file helper\nfunc GoldenFile(t testing.TB, name string, got []byte) {\n    t.Helper()\n    \n    golden := filepath.Join(\"testdata\", name+\".golden\")\n    \n    if *update {\n        os.WriteFile(golden, got, 0644)\n        return\n    }\n    \n    want, err := os.ReadFile(golden)\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    if !bytes.Equal(got, want) {\n        t.Errorf(\"output mismatch for %s\", name)\n    }\n}\n```\n\n## Advanced Testing Techniques\n\n### Property-Based Testing\n```go\nimport \"github.com/leanovate/gopter\"\n\nfunc TestPropertyBased(t *testing.T) {\n    properties := gopter.NewProperties(nil)\n    \n    properties.Property(\"reverse twice is identity\", prop.ForAll(\n        func(s string) bool {\n            return s == Reverse(Reverse(s))\n        },\n        gopter.Gen.String(),\n    ))\n    \n    properties.Property(\"list append preserves length\", prop.ForAll(\n        func(list []int, item int) bool {\n            original := len(list)\n            result := append(list, item)\n            return len(result) == original+1\n        },\n        gopter.Gen.SliceOf(gopter.Gen.Int()),\n        gopter.Gen.Int(),\n    ))\n    \n    properties.TestingRun(t)\n}\n```\n\n### Snapshot Testing\n```go\nfunc TestSnapshot(t *testing.T) {\n    data := generateComplexData()\n    output := RenderHTML(data)\n    \n    snapshot := filepath.Join(\"testdata\", t.Name()+\".snapshot\")\n    \n    if *updateSnapshots {\n        if err := os.WriteFile(snapshot, []byte(output), 0644); err != nil {\n            t.Fatal(err)\n        }\n        return\n    }\n    \n    expected, err := os.ReadFile(snapshot)\n    if err != nil {\n        t.Fatal(err)\n    }\n    \n    if output != string(expected) {\n        t.Error(\"snapshot mismatch\")\n        // Could use diff library to show differences\n    }\n}\n```\n\n### Contract Testing\n```go\n// Define contract that implementations must satisfy\ntype StorageContract struct {\n    t       testing.TB\n    storage Storage\n}\n\nfunc (c *StorageContract) TestStore() {\n    c.t.Helper()\n    \n    err := c.storage.Store(\"key\", \"value\")\n    if err != nil {\n        c.t.Errorf(\"Store failed: %v\", err)\n    }\n    \n    val, err := c.storage.Retrieve(\"key\")\n    if err != nil {\n        c.t.Errorf(\"Retrieve failed: %v\", err)\n    }\n    \n    if val != \"value\" {\n        c.t.Errorf(\"got %q, want %q\", val, \"value\")\n    }\n}\n\nfunc (c *StorageContract) TestDelete() {\n    c.t.Helper()\n    \n    c.storage.Store(\"key\", \"value\")\n    err := c.storage.Delete(\"key\")\n    if err != nil {\n        c.t.Errorf(\"Delete failed: %v\", err)\n    }\n    \n    _, err = c.storage.Retrieve(\"key\")\n    if err == nil {\n        c.t.Error(\"expected error after delete\")\n    }\n}\n\n// Test different implementations\nfunc TestMemoryStorage(t *testing.T) {\n    storage := NewMemoryStorage()\n    contract := &StorageContract{t: t, storage: storage}\n    contract.TestStore()\n    contract.TestDelete()\n}\n\nfunc TestDiskStorage(t *testing.T) {\n    storage := NewDiskStorage(t.TempDir())\n    contract := &StorageContract{t: t, storage: storage}\n    contract.TestStore()\n    contract.TestDelete()\n}\n```\n\n## Best Practices Summary\n\n1. **Write table-driven tests** - Comprehensive and maintainable\n2. **Use subtests** - Better organization and parallel execution\n3. **Mock external dependencies** - Fast and reliable tests\n4. **Test edge cases** - Empty inputs, nil values, errors\n5. **Benchmark critical paths** - Measure performance\n6. **Aim for high coverage** - But focus on meaningful tests\n7. **Use t.Helper()** - Better error reporting in test helpers\n8. **Cleanup with t.Cleanup()** - Guaranteed cleanup\n9. **Use build tags for integration tests** - Separate slow tests\n10. **Keep tests deterministic** - No random failures","numLines":1322,"startLine":1,"totalLines":1322}}}
{"parentUuid":"222151ab-2ef1-4401-9f5e-47f957a82586","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RKCVzPdMdNNUKy2SxjFy2P","type":"tool_result","content":"     1→# Go Packages - Package Design and Management\n     2→\n     3→## Table of Contents\n     4→1. [Package Design](#package-design)\n     5→2. [API Design](#api-design)\n     6→3. [Internal Packages](#internal-packages)\n     7→4. [Versioning](#versioning)\n     8→5. [Documentation](#documentation)\n     9→6. [Module Management](#module-management)\n    10→7. [Dependencies](#dependencies)\n    11→8. [Package Patterns](#package-patterns)\n    12→9. [Publishing Packages](#publishing-packages)\n    13→10. [Best Practices](#best-practices)\n    14→\n    15→## Package Design\n    16→\n    17→### Package Structure\n    18→```go\n    19→// Package naming conventions\n    20→package user        // Good: singular, lowercase\n    21→package users       // Bad: plural\n    22→package userMgmt    // Bad: camelCase\n    23→package user_mgmt   // Bad: underscore\n    24→\n    25→// Package organization\n    26→myproject/\n    27→├── cmd/\n    28→│   ├── api/\n    29→│   │   └── main.go\n    30→│   └── worker/\n    31→│       └── main.go\n    32→├── internal/\n    33→│   ├── auth/\n    34→│   ├── database/\n    35→│   └── models/\n    36→├── pkg/\n    37→│   ├── client/\n    38→│   └── utils/\n    39→├── api/\n    40→│   └── v1/\n    41→├── docs/\n    42→├── scripts/\n    43→├── go.mod\n    44→└── go.sum\n    45→\n    46→// Package declaration with documentation\n    47→// Package user provides user management functionality.\n    48→// It includes user creation, authentication, and profile management.\n    49→package user\n    50→\n    51→// Import grouping\n    52→import (\n    53→    // Standard library\n    54→    \"context\"\n    55→    \"fmt\"\n    56→    \"time\"\n    57→    \n    58→    // Third-party packages\n    59→    \"github.com/google/uuid\"\n    60→    \"golang.org/x/crypto/bcrypt\"\n    61→    \n    62→    // Internal packages\n    63→    \"myproject/internal/database\"\n    64→    \"myproject/pkg/errors\"\n    65→)\n    66→```\n    67→\n    68→### Package Cohesion\n    69→```go\n    70→// High cohesion - related functionality\n    71→package auth\n    72→\n    73→type Authenticator interface {\n    74→    Authenticate(credentials Credentials) (*User, error)\n    75→    Refresh(token string) (*Token, error)\n    76→    Revoke(token string) error\n    77→}\n    78→\n    79→type Credentials struct {\n    80→    Username string\n    81→    Password string\n    82→}\n    83→\n    84→type Token struct {\n    85→    AccessToken  string\n    86→    RefreshToken string\n    87→    ExpiresAt    time.Time\n    88→}\n    89→\n    90→type User struct {\n    91→    ID       string\n    92→    Username string\n    93→    Roles    []string\n    94→}\n    95→\n    96→// Low cohesion - avoid generic packages\n    97→package utils  // Bad: too generic\n    98→\n    99→func HashPassword(password string) string { }\n   100→func SendEmail(to, subject, body string) error { }\n   101→func ParseJSON(data []byte) (interface{}, error) { }\n   102→func GenerateID() string { }\n   103→\n   104→// Better: specific packages\n   105→package password\n   106→package email\n   107→package json\n   108→package id\n   109→```\n   110→\n   111→### Package Dependencies\n   112→```go\n   113→// Minimize dependencies\n   114→package user\n   115→\n   116→// Good: depends only on necessary packages\n   117→import (\n   118→    \"context\"\n   119→    \"myproject/internal/database\"\n   120→)\n   121→\n   122→// Bad: too many dependencies\n   123→import (\n   124→    \"myproject/internal/auth\"\n   125→    \"myproject/internal/email\"\n   126→    \"myproject/internal/sms\"\n   127→    \"myproject/internal/push\"\n   128→    \"myproject/internal/analytics\"\n   129→    // ... many more\n   130→)\n   131→\n   132→// Dependency inversion\n   133→package service\n   134→\n   135→// Define interface in the consumer package\n   136→type UserRepository interface {\n   137→    GetUser(ctx context.Context, id string) (*User, error)\n   138→    SaveUser(ctx context.Context, user *User) error\n   139→}\n   140→\n   141→type UserService struct {\n   142→    repo UserRepository  // Depend on interface\n   143→}\n   144→\n   145→// Implementation in another package\n   146→package database\n   147→\n   148→type PostgresUserRepository struct {\n   149→    db *sql.DB\n   150→}\n   151→\n   152→func (r *PostgresUserRepository) GetUser(ctx context.Context, id string) (*User, error) {\n   153→    // Implementation\n   154→}\n   155→\n   156→// Avoid circular dependencies\n   157→package a\n   158→import \"b\"  // a depends on b\n   159→\n   160→package b\n   161→import \"a\"  // b depends on a - CIRCULAR!\n   162→\n   163→// Solution: introduce interface or third package\n   164→package c\n   165→type SharedInterface interface { }\n   166→\n   167→package a\n   168→import \"c\"\n   169→\n   170→package b\n   171→import \"c\"\n   172→```\n   173→\n   174→## API Design\n   175→\n   176→### Exported vs Unexported\n   177→```go\n   178→package mypackage\n   179→\n   180→// Exported (public) - capitalized\n   181→type Client struct {\n   182→    Endpoint string\n   183→    Timeout  time.Duration\n   184→}\n   185→\n   186→func NewClient(endpoint string) *Client {\n   187→    return &Client{\n   188→        Endpoint: endpoint,\n   189→        Timeout:  30 * time.Second,\n   190→    }\n   191→}\n   192→\n   193→func (c *Client) Request(ctx context.Context, data []byte) (*Response, error) {\n   194→    return c.doRequest(ctx, data)\n   195→}\n   196→\n   197→// Unexported (private) - lowercase\n   198→type config struct {\n   199→    retryCount int\n   200→    backoff    time.Duration\n   201→}\n   202→\n   203→func (c *Client) doRequest(ctx context.Context, data []byte) (*Response, error) {\n   204→    // Internal implementation\n   205→}\n   206→\n   207→// Partially exported struct\n   208→type Response struct {\n   209→    Status  int         // Exported\n   210→    Data    []byte      // Exported\n   211→    headers http.Header // Unexported\n   212→}\n   213→```\n   214→\n   215→### API Stability\n   216→```go\n   217→// Stable API design\n   218→package stable\n   219→\n   220→// Use interfaces for flexibility\n   221→type Store interface {\n   222→    Get(key string) ([]byte, error)\n   223→    Set(key string, value []byte) error\n   224→    Delete(key string) error\n   225→}\n   226→\n   227→// Options pattern for extensibility\n   228→type ClientOptions struct {\n   229→    Timeout     time.Duration\n   230→    MaxRetries  int\n   231→    Headers     map[string]string\n   232→    // Can add new fields without breaking\n   233→}\n   234→\n   235→func NewClient(opts ClientOptions) *Client {\n   236→    // Set defaults for zero values\n   237→    if opts.Timeout == 0 {\n   238→        opts.Timeout = 30 * time.Second\n   239→    }\n   240→    if opts.MaxRetries == 0 {\n   241→        opts.MaxRetries = 3\n   242→    }\n   243→    \n   244→    return &Client{opts: opts}\n   245→}\n   246→\n   247→// Functional options for better API\n   248→type Option func(*Client)\n   249→\n   250→func WithTimeout(d time.Duration) Option {\n   251→    return func(c *Client) {\n   252→        c.timeout = d\n   253→    }\n   254→}\n   255→\n   256→func WithRetries(n int) Option {\n   257→    return func(c *Client) {\n   258→        c.maxRetries = n\n   259→    }\n   260→}\n   261→\n   262→func NewClientWithOptions(opts ...Option) *Client {\n   263→    c := &Client{\n   264→        timeout:    30 * time.Second,\n   265→        maxRetries: 3,\n   266→    }\n   267→    \n   268→    for _, opt := range opts {\n   269→        opt(c)\n   270→    }\n   271→    \n   272→    return c\n   273→}\n   274→\n   275→// Deprecation\n   276→// Deprecated: Use NewClientWithOptions instead.\n   277→func NewClientOld(endpoint string) *Client {\n   278→    return NewClientWithOptions(WithEndpoint(endpoint))\n   279→}\n   280→```\n   281→\n   282→### Error Design\n   283→```go\n   284→package mypackage\n   285→\n   286→// Sentinel errors\n   287→var (\n   288→    ErrNotFound      = errors.New(\"not found\")\n   289→    ErrUnauthorized  = errors.New(\"unauthorized\")\n   290→    ErrInvalidInput  = errors.New(\"invalid input\")\n   291→)\n   292→\n   293→// Error types\n   294→type ValidationError struct {\n   295→    Field   string\n   296→    Message string\n   297→}\n   298→\n   299→func (e ValidationError) Error() string {\n   300→    return fmt.Sprintf(\"validation error on field %s: %s\", e.Field, e.Message)\n   301→}\n   302→\n   303→// Error wrapping\n   304→func GetUser(id string) (*User, error) {\n   305→    user, err := db.Query(id)\n   306→    if err != nil {\n   307→        if errors.Is(err, sql.ErrNoRows) {\n   308→            return nil, ErrNotFound\n   309→        }\n   310→        return nil, fmt.Errorf(\"failed to get user %s: %w\", id, err)\n   311→    }\n   312→    return user, nil\n   313→}\n   314→\n   315→// Custom error checking\n   316→func IsNotFound(err error) bool {\n   317→    return errors.Is(err, ErrNotFound)\n   318→}\n   319→\n   320→func IsValidation(err error) bool {\n   321→    var validationErr ValidationError\n   322→    return errors.As(err, &validationErr)\n   323→}\n   324→```\n   325→\n   326→## Internal Packages\n   327→\n   328→### Using Internal\n   329→```go\n   330→// internal/ prevents external imports\n   331→myproject/\n   332→├── internal/\n   333→│   ├── auth/       // Only importable within myproject\n   334→│   ├── database/\n   335→│   └── config/\n   336→├── pkg/\n   337→│   └── public/     // Importable by anyone\n   338→└── cmd/\n   339→\n   340→// In myproject/internal/auth/auth.go\n   341→package auth\n   342→\n   343→type internalAuthenticator struct {\n   344→    // Cannot be imported outside myproject\n   345→}\n   346→\n   347→// In external project - FAILS\n   348→import \"github.com/user/myproject/internal/auth\" // Compile error!\n   349→\n   350→// Internal for sub-packages\n   351→myproject/\n   352→├── feature/\n   353→│   ├── internal/   // Only importable within feature/\n   354→│   ├── api/\n   355→│   └── service/\n   356→\n   357→// Organizing internal packages\n   358→internal/\n   359→├── platform/       // Platform-specific code\n   360→│   ├── database/\n   361→│   ├── cache/\n   362→│   └── queue/\n   363→├── domain/         // Business logic\n   364→│   ├── user/\n   365→│   ├── order/\n   366→│   └── payment/\n   367→└── adapter/        // External adapters\n   368→    ├── http/\n   369→    ├── grpc/\n   370→    └── cli/\n   371→```\n   372→\n   373→### Internal Best Practices\n   374→```go\n   375→// Hide implementation details\n   376→// Public package\n   377→package user\n   378→\n   379→type Service interface {\n   380→    GetUser(id string) (*User, error)\n   381→}\n   382→\n   383→func NewService(db Database) Service {\n   384→    return &service{\n   385→        db: db,\n   386→        validator: internal.NewValidator(),\n   387→    }\n   388→}\n   389→\n   390→// Internal package\n   391→package internal\n   392→\n   393→type Validator struct {\n   394→    rules []Rule\n   395→}\n   396→\n   397→func NewValidator() *Validator {\n   398→    // Hidden from external packages\n   399→}\n   400→\n   401→// Share code between packages\n   402→internal/\n   403→├── shared/\n   404→│   ├── logger/\n   405→│   ├── metrics/\n   406→│   └── errors/\n   407→\n   408→// Use in multiple packages\n   409→package service1\n   410→import \"myproject/internal/shared/logger\"\n   411→\n   412→package service2\n   413→import \"myproject/internal/shared/logger\"\n   414→```\n   415→\n   416→## Versioning\n   417→\n   418→### Semantic Versioning\n   419→```go\n   420→// go.mod versioning\n   421→module github.com/user/myproject\n   422→\n   423→go 1.21\n   424→\n   425→require (\n   426→    github.com/some/dep v1.2.3   // Exact version\n   427→    github.com/other/dep v2.0.0+incompatible\n   428→    github.com/new/dep/v2 v2.1.0 // Major version in path\n   429→)\n   430→\n   431→// Version tags\n   432→// git tag v1.0.0\n   433→// git tag v1.0.1\n   434→// git tag v1.1.0\n   435→// git tag v2.0.0\n   436→\n   437→// Major version changes (v2+)\n   438→// Update module path\n   439→module github.com/user/myproject/v2\n   440→\n   441→// Import with version\n   442→import \"github.com/user/myproject/v2/pkg/client\"\n   443→\n   444→// Maintaining multiple versions\n   445→myproject/\n   446→├── go.mod          // module github.com/user/myproject\n   447→└── v2/\n   448→    └── go.mod      // module github.com/user/myproject/v2\n   449→\n   450→// Version constraints\n   451→require (\n   452→    github.com/some/dep v1.2.3     // Exact\n   453→    github.com/some/dep v1.2.x     // Patch updates\n   454→    github.com/some/dep v1.x.x     // Minor updates\n   455→    github.com/some/dep latest     // Latest\n   456→    github.com/some/dep master     // Branch\n   457→)\n   458→```\n   459→\n   460→### API Versioning\n   461→```go\n   462→// Package versioning\n   463→api/\n   464→├── v1/\n   465→│   └── client.go\n   466→└── v2/\n   467→    └── client.go\n   468→\n   469→// v1/client.go\n   470→package v1\n   471→\n   472→type Client struct {\n   473→    Endpoint string\n   474→}\n   475→\n   476→func (c *Client) Request(data string) (string, error) {\n   477→    // v1 implementation\n   478→}\n   479→\n   480→// v2/client.go\n   481→package v2\n   482→\n   483→type Client struct {\n   484→    Endpoint string\n   485→    Timeout  time.Duration  // New field\n   486→}\n   487→\n   488→func (c *Client) Request(ctx context.Context, data []byte) ([]byte, error) {\n   489→    // v2 implementation with context\n   490→}\n   491→\n   492→// Supporting multiple versions\n   493→package api\n   494→\n   495→import (\n   496→    v1 \"myproject/api/v1\"\n   497→    v2 \"myproject/api/v2\"\n   498→)\n   499→\n   500→func NewClientV1() *v1.Client {\n   501→    return &v1.Client{}\n   502→}\n   503→\n   504→func NewClientV2() *v2.Client {\n   505→    return &v2.Client{}\n   506→}\n   507→```\n   508→\n   509→## Documentation\n   510→\n   511→### Package Documentation\n   512→```go\n   513→// Package documentation (doc.go)\n   514→/*\n   515→Package user provides user management functionality for the application.\n   516→\n   517→The package includes:\n   518→  - User CRUD operations\n   519→  - Authentication and authorization\n   520→  - Profile management\n   521→  - Password reset functionality\n   522→\n   523→Basic usage:\n   524→\n   525→\tservice := user.NewService(db)\n   526→\t\n   527→\t// Create user\n   528→\tu, err := service.Create(ctx, user.CreateRequest{\n   529→\t\tEmail:    \"user@example.com\",\n   530→\t\tPassword: \"secure123\",\n   531→\t})\n   532→\t\n   533→\t// Authenticate\n   534→\ttoken, err := service.Authenticate(ctx, email, password)\n   535→\n   536→For more examples, see the examples directory.\n   537→*/\n   538→package user\n   539→\n   540→// Type documentation\n   541→// User represents a system user.\n   542→// Users can have multiple roles and permissions.\n   543→type User struct {\n   544→    // ID is the unique identifier for the user.\n   545→    ID string\n   546→    \n   547→    // Email is the user's email address.\n   548→    // It must be unique across all users.\n   549→    Email string\n   550→    \n   551→    // CreatedAt is when the user was created.\n   552→    CreatedAt time.Time\n   553→    \n   554→    // Roles contains the user's assigned roles.\n   555→    Roles []Role\n   556→}\n   557→\n   558→// Method documentation\n   559→// Create creates a new user with the given request.\n   560→// It returns an error if the email already exists or validation fails.\n   561→//\n   562→// Example:\n   563→//\n   564→//\tuser, err := service.Create(ctx, CreateRequest{\n   565→//\t    Email:    \"user@example.com\",\n   566→//\t    Password: \"secure123\",\n   567→//\t})\n   568→//\tif err != nil {\n   569→//\t    log.Fatal(err)\n   570→//\t}\n   571→func (s *Service) Create(ctx context.Context, req CreateRequest) (*User, error) {\n   572→    // Implementation\n   573→}\n   574→\n   575→// Deprecated documentation\n   576→// Deprecated: Use CreateWithOptions instead.\n   577→// This function will be removed in v2.0.0.\n   578→func (s *Service) CreateOld(email, password string) (*User, error) {\n   579→    return s.CreateWithOptions(CreateOptions{\n   580→        Email:    email,\n   581→        Password: password,\n   582→    })\n   583→}\n   584→```\n   585→\n   586→### Examples\n   587→```go\n   588→// Example functions (show in documentation)\n   589→func ExampleService_Create() {\n   590→    service := NewService(mockDB)\n   591→    ctx := context.Background()\n   592→    \n   593→    user, err := service.Create(ctx, CreateRequest{\n   594→        Email:    \"user@example.com\",\n   595→        Password: \"secure123\",\n   596→    })\n   597→    if err != nil {\n   598→        log.Fatal(err)\n   599→    }\n   600→    \n   601→    fmt.Println(user.Email)\n   602→    // Output: user@example.com\n   603→}\n   604→\n   605→// Example with suffix\n   606→func ExampleService_Create_withRoles() {\n   607→    service := NewService(mockDB)\n   608→    ctx := context.Background()\n   609→    \n   610→    user, err := service.Create(ctx, CreateRequest{\n   611→        Email:    \"admin@example.com\",\n   612→        Password: \"secure123\",\n   613→        Roles:    []string{\"admin\", \"user\"},\n   614→    })\n   615→    if err != nil {\n   616→        log.Fatal(err)\n   617→    }\n   618→    \n   619→    fmt.Println(user.Roles)\n   620→    // Output: [admin user]\n   621→}\n   622→\n   623→// Package examples\n   624→func Example() {\n   625→    // Initialize service\n   626→    db := setupDatabase()\n   627→    service := NewService(db)\n   628→    \n   629→    // Create user\n   630→    user, _ := service.Create(context.Background(), CreateRequest{\n   631→        Email: \"user@example.com\",\n   632→    })\n   633→    \n   634→    // Authenticate\n   635→    token, _ := service.Authenticate(context.Background(), \n   636→        user.Email, \"password\")\n   637→    \n   638→    fmt.Println(token != \"\")\n   639→    // Output: true\n   640→}\n   641→\n   642→// Testable examples\n   643→func ExampleService_paginate() {\n   644→    users := []User{\n   645→        {Email: \"user1@example.com\"},\n   646→        {Email: \"user2@example.com\"},\n   647→        {Email: \"user3@example.com\"},\n   648→    }\n   649→    \n   650→    page := Paginate(users, 2, 1)\n   651→    for _, u := range page {\n   652→        fmt.Println(u.Email)\n   653→    }\n   654→    // Output:\n   655→    // user1@example.com\n   656→    // user2@example.com\n   657→}\n   658→```\n   659→\n   660→## Module Management\n   661→\n   662→### Go Modules\n   663→```go\n   664→// Initialize module\n   665→// go mod init github.com/user/project\n   666→\n   667→// go.mod structure\n   668→module github.com/user/project\n   669→\n   670→go 1.21\n   671→\n   672→require (\n   673→    github.com/gorilla/mux v1.8.0\n   674→    github.com/stretchr/testify v1.8.0\n   675→)\n   676→\n   677→require (\n   678→    // Indirect dependencies\n   679→    github.com/davecgh/go-spew v1.1.1 // indirect\n   680→    github.com/pmezard/go-difflib v1.0.0 // indirect\n   681→)\n   682→\n   683→// Replace directive\n   684→replace github.com/old/package => github.com/new/package v1.0.0\n   685→\n   686→// Local replace for development\n   687→replace github.com/user/dependency => ../dependency\n   688→\n   689→// Exclude versions\n   690→exclude github.com/bad/package v1.0.0\n   691→\n   692→// Retract versions (go 1.16+)\n   693→retract (\n   694→    v1.0.0 // Critical bug\n   695→    v1.0.1 // Security issue\n   696→)\n   697→\n   698→// Module commands\n   699→// go mod download    - Download dependencies\n   700→// go mod tidy       - Clean up dependencies\n   701→// go mod verify     - Verify dependencies\n   702→// go mod graph      - Show dependency graph\n   703→// go mod vendor     - Create vendor directory\n   704→// go mod why pkg    - Explain why package is needed\n   705→```\n   706→\n   707→### Workspace Mode\n   708→```go\n   709→// go.work (Go 1.18+)\n   710→go 1.21\n   711→\n   712→use (\n   713→    ./project1\n   714→    ./project2\n   715→    ../shared\n   716→)\n   717→\n   718→replace github.com/example/lib => ../lib\n   719→\n   720→// Commands\n   721→// go work init project1 project2\n   722→// go work use ../another-project\n   723→// go work sync\n   724→\n   725→// Development workflow\n   726→workspace/\n   727→├── go.work\n   728→├── project1/\n   729→│   └── go.mod\n   730→├── project2/\n   731→│   └── go.mod\n   732→└── shared/\n   733→    └── go.mod\n   734→\n   735→// Each project has its own module\n   736→// Work on multiple modules simultaneously\n   737→```\n   738→\n   739→## Dependencies\n   740→\n   741→### Managing Dependencies\n   742→```go\n   743→// Adding dependencies\n   744→// go get github.com/pkg/errors\n   745→// go get github.com/pkg/errors@v0.9.1\n   746→// go get github.com/pkg/errors@latest\n   747→// go get github.com/pkg/errors@master\n   748→\n   749→// Updating dependencies\n   750→// go get -u                    - Update all\n   751→// go get -u ./...             - Update all in module\n   752→// go get -u=patch ./...       - Update patch versions\n   753→// go get -u github.com/pkg/...  - Update specific package\n   754→\n   755→// Removing dependencies\n   756→// go mod tidy                  - Remove unused\n   757→\n   758→// Vendoring\n   759→// go mod vendor               - Create vendor/\n   760→// go build -mod=vendor        - Build with vendor/\n   761→\n   762→// Dependency analysis\n   763→import \"golang.org/x/mod/modfile\"\n   764→\n   765→func analyzeDependencies() {\n   766→    data, _ := os.ReadFile(\"go.mod\")\n   767→    file, _ := modfile.Parse(\"go.mod\", data, nil)\n   768→    \n   769→    for _, req := range file.Require {\n   770→        fmt.Printf(\"%s: %s\\n\", req.Mod.Path, req.Mod.Version)\n   771→    }\n   772→}\n   773→\n   774→// Private dependencies\n   775→// Set GOPRIVATE environment variable\n   776→// GOPRIVATE=github.com/company/*\n   777→\n   778→// Use .netrc for authentication\n   779→// machine github.com\n   780→// login username\n   781→// password token\n   782→\n   783→// Or use SSH\n   784→// git config --global url.\"git@github.com:\".insteadOf \"https://github.com/\"\n   785→```\n   786→\n   787→### Dependency Injection\n   788→```go\n   789→// Constructor injection\n   790→type Service struct {\n   791→    db     Database\n   792→    cache  Cache\n   793→    logger Logger\n   794→}\n   795→\n   796→func NewService(db Database, cache Cache, logger Logger) *Service {\n   797→    return &Service{\n   798→        db:     db,\n   799→        cache:  cache,\n   800→        logger: logger,\n   801→    }\n   802→}\n   803→\n   804→// Interface injection\n   805→type Database interface {\n   806→    Query(string) ([]Row, error)\n   807→}\n   808→\n   809→type Cache interface {\n   810→    Get(string) (interface{}, bool)\n   811→    Set(string, interface{})\n   812→}\n   813→\n   814→// Wire for dependency injection\n   815→//go:build wireinject\n   816→\n   817→import \"github.com/google/wire\"\n   818→\n   819→func InitializeService() (*Service, error) {\n   820→    wire.Build(\n   821→        NewDatabase,\n   822→        NewCache,\n   823→        NewLogger,\n   824→        NewService,\n   825→    )\n   826→    return nil, nil\n   827→}\n   828→\n   829→// Provider sets\n   830→var BasicSet = wire.NewSet(\n   831→    NewDatabase,\n   832→    NewCache,\n   833→    NewLogger,\n   834→)\n   835→\n   836→var ServiceSet = wire.NewSet(\n   837→    BasicSet,\n   838→    NewService,\n   839→    NewRepository,\n   840→)\n   841→```\n   842→\n   843→## Package Patterns\n   844→\n   845→### Plugin Pattern\n   846→```go\n   847→// Plugin interface\n   848→package plugin\n   849→\n   850→type Plugin interface {\n   851→    Name() string\n   852→    Initialize(config map[string]interface{}) error\n   853→    Execute(context.Context, interface{}) (interface{}, error)\n   854→    Shutdown() error\n   855→}\n   856→\n   857→// Registry\n   858→type Registry struct {\n   859→    mu      sync.RWMutex\n   860→    plugins map[string]Plugin\n   861→}\n   862→\n   863→func (r *Registry) Register(p Plugin) {\n   864→    r.mu.Lock()\n   865→    defer r.mu.Unlock()\n   866→    r.plugins[p.Name()] = p\n   867→}\n   868→\n   869→func (r *Registry) Get(name string) (Plugin, bool) {\n   870→    r.mu.RLock()\n   871→    defer r.mu.RUnlock()\n   872→    p, ok := r.plugins[name]\n   873→    return p, ok\n   874→}\n   875→\n   876→// Plugin implementation\n   877→package myplugin\n   878→\n   879→type MyPlugin struct {\n   880→    config map[string]interface{}\n   881→}\n   882→\n   883→func (p *MyPlugin) Name() string {\n   884→    return \"my-plugin\"\n   885→}\n   886→\n   887→func (p *MyPlugin) Initialize(config map[string]interface{}) error {\n   888→    p.config = config\n   889→    return nil\n   890→}\n   891→\n   892→// Auto-registration\n   893→func init() {\n   894→    plugin.DefaultRegistry.Register(&MyPlugin{})\n   895→}\n   896→```\n   897→\n   898→### Provider Pattern\n   899→```go\n   900→// Provider interface\n   901→package provider\n   902→\n   903→type StorageProvider interface {\n   904→    Read(key string) ([]byte, error)\n   905→    Write(key string, data []byte) error\n   906→    Delete(key string) error\n   907→}\n   908→\n   909→// Factory\n   910→type ProviderFactory func(config Config) (StorageProvider, error)\n   911→\n   912→var providers = make(map[string]ProviderFactory)\n   913→\n   914→func Register(name string, factory ProviderFactory) {\n   915→    providers[name] = factory\n   916→}\n   917→\n   918→func New(name string, config Config) (StorageProvider, error) {\n   919→    factory, ok := providers[name]\n   920→    if !ok {\n   921→        return nil, fmt.Errorf(\"unknown provider: %s\", name)\n   922→    }\n   923→    return factory(config)\n   924→}\n   925→\n   926→// S3 provider\n   927→package s3\n   928→\n   929→func init() {\n   930→    provider.Register(\"s3\", NewS3Provider)\n   931→}\n   932→\n   933→func NewS3Provider(config provider.Config) (provider.StorageProvider, error) {\n   934→    return &S3Provider{\n   935→        bucket: config.Get(\"bucket\"),\n   936→        region: config.Get(\"region\"),\n   937→    }, nil\n   938→}\n   939→```\n   940→\n   941→### Repository Pattern\n   942→```go\n   943→package repository\n   944→\n   945→// Generic repository interface\n   946→type Repository[T any] interface {\n   947→    Find(ctx context.Context, id string) (*T, error)\n   948→    FindAll(ctx context.Context) ([]*T, error)\n   949→    Create(ctx context.Context, entity *T) error\n   950→    Update(ctx context.Context, entity *T) error\n   951→    Delete(ctx context.Context, id string) error\n   952→}\n   953→\n   954→// Specific implementation\n   955→type UserRepository interface {\n   956→    Repository[User]\n   957→    FindByEmail(ctx context.Context, email string) (*User, error)\n   958→    FindByRole(ctx context.Context, role string) ([]*User, error)\n   959→}\n   960→\n   961→// SQL implementation\n   962→type sqlUserRepository struct {\n   963→    db *sql.DB\n   964→}\n   965→\n   966→func NewSQLUserRepository(db *sql.DB) UserRepository {\n   967→    return &sqlUserRepository{db: db}\n   968→}\n   969→\n   970→func (r *sqlUserRepository) Find(ctx context.Context, id string) (*User, error) {\n   971→    query := `SELECT id, email, created_at FROM users WHERE id = $1`\n   972→    // Implementation\n   973→}\n   974→\n   975→// MongoDB implementation\n   976→type mongoUserRepository struct {\n   977→    collection *mongo.Collection\n   978→}\n   979→\n   980→func NewMongoUserRepository(db *mongo.Database) UserRepository {\n   981→    return &mongoUserRepository{\n   982→        collection: db.Collection(\"users\"),\n   983→    }\n   984→}\n   985→```\n   986→\n   987→## Publishing Packages\n   988→\n   989→### Preparing for Publication\n   990→```go\n   991→// 1. Choose a good name\n   992→// - Descriptive and unique\n   993→// - Avoid generic names (utils, helpers, common)\n   994→// - Check if name is available\n   995→\n   996→// 2. Create comprehensive documentation\n   997→// - README.md with examples\n   998→// - Package documentation\n   999→// - API documentation\n  1000→// - CONTRIBUTING.md\n  1001→// - LICENSE file\n  1002→\n  1003→// 3. Add examples\n  1004→examples/\n  1005→├── basic/\n  1006→│   └── main.go\n  1007→├── advanced/\n  1008→│   └── main.go\n  1009→└── README.md\n  1010→\n  1011→// 4. Write comprehensive tests\n  1012→// - Unit tests\n  1013→// - Integration tests\n  1014→// - Benchmarks\n  1015→// - Examples\n  1016→\n  1017→// 5. Set up CI/CD\n  1018→// .github/workflows/test.yml\n  1019→name: Test\n  1020→on: [push, pull_request]\n  1021→jobs:\n  1022→  test:\n  1023→    runs-on: ubuntu-latest\n  1024→    steps:\n  1025→    - uses: actions/checkout@v2\n  1026→    - uses: actions/setup-go@v2\n  1027→      with:\n  1028→        go-version: 1.21\n  1029→    - run: go test -v ./...\n  1030→    - run: go test -race ./...\n  1031→    - run: go test -cover ./...\n  1032→```\n  1033→\n  1034→### Publishing Process\n  1035→```bash\n  1036→# 1. Tag version\n  1037→git tag v1.0.0\n  1038→git push origin v1.0.0\n  1039→\n  1040→# 2. The package is automatically available\n  1041→# go get github.com/username/package@v1.0.0\n  1042→\n  1043→# 3. Update pkg.go.dev\n  1044→# Visit https://pkg.go.dev/github.com/username/package\n  1045→# Click \"Request\" button\n  1046→\n  1047→# 4. Add badges to README\n  1048→[![Go Reference](https://pkg.go.dev/badge/github.com/username/package.svg)](https://pkg.go.dev/github.com/username/package)\n  1049→[![Go Report Card](https://goreportcard.com/badge/github.com/username/package)](https://goreportcard.com/report/github.com/username/package)\n  1050→[![Coverage Status](https://coveralls.io/repos/github/username/package/badge.svg)](https://coveralls.io/github/username/package)\n  1051→\n  1052→# 5. Create release on GitHub\n  1053→# - Add release notes\n  1054→# - Attach binaries if applicable\n  1055→```\n  1056→\n  1057→### Package Maintenance\n  1058→```go\n  1059→// Deprecation process\n  1060→// 1. Mark as deprecated in documentation\n  1061→// Deprecated: Use NewFunction instead.\n  1062→// This will be removed in v2.0.0.\n  1063→func OldFunction() {}\n  1064→\n  1065→// 2. Log deprecation warnings\n  1066→func OldFunction() {\n  1067→    log.Println(\"Warning: OldFunction is deprecated. Use NewFunction instead.\")\n  1068→    // Existing implementation\n  1069→}\n  1070→\n  1071→// 3. Provide migration guide\n  1072→/*\n  1073→Migration Guide from v1 to v2:\n  1074→\n  1075→1. Replace OldFunction() with NewFunction()\n  1076→2. Update Client struct initialization:\n  1077→   Old: client := &Client{Endpoint: \"url\"}\n  1078→   New: client := NewClient(WithEndpoint(\"url\"))\n  1079→3. Change import path:\n  1080→   Old: import \"github.com/user/package\"\n  1081→   New: import \"github.com/user/package/v2\"\n  1082→*/\n  1083→\n  1084→// Version compatibility\n  1085→// Support multiple versions\n  1086→package compat\n  1087→\n  1088→import (\n  1089→    v1 \"mypackage/v1\"\n  1090→    v2 \"mypackage/v2\"\n  1091→)\n  1092→\n  1093→func MigrateV1ToV2(old *v1.Config) *v2.Config {\n  1094→    return &v2.Config{\n  1095→        // Map old fields to new\n  1096→    }\n  1097→}\n  1098→```\n  1099→\n  1100→## Best Practices\n  1101→\n  1102→### Package Design Principles\n  1103→```go\n  1104→// 1. Single Responsibility\n  1105→// Each package should have one clear purpose\n  1106→\n  1107→// 2. Minimal Public API\n  1108→// Export only what's necessary\n  1109→package mypackage\n  1110→\n  1111→type Client struct{} // Exported\n  1112→\n  1113→type implementation struct{} // Unexported\n  1114→\n  1115→// 3. Accept Interfaces, Return Structs\n  1116→func Process(r io.Reader) *Result {\n  1117→    // Accept interface for flexibility\n  1118→    // Return concrete type for clarity\n  1119→}\n  1120→\n  1121→// 4. Avoid Init Functions\n  1122→// Bad: Side effects on import\n  1123→func init() {\n  1124→    database.Connect() // Side effect!\n  1125→}\n  1126→\n  1127→// Good: Explicit initialization\n  1128→func Initialize() error {\n  1129→    return database.Connect()\n  1130→}\n  1131→\n  1132→// 5. No Circular Dependencies\n  1133→// Use interfaces to break cycles\n  1134→\n  1135→// 6. Consistent Naming\n  1136→// Package name should match directory name\n  1137→// Avoid stuttering: user.User not user.UserUser\n  1138→\n  1139→// 7. Semantic Versioning\n  1140→// Follow semver strictly\n  1141→// Major.Minor.Patch\n  1142→\n  1143→// 8. Comprehensive Testing\n  1144→// Aim for >80% coverage\n  1145→// Include edge cases\n  1146→\n  1147→// 9. Clear Documentation\n  1148→// Document all exports\n  1149→// Provide examples\n  1150→\n  1151→// 10. Minimal Dependencies\n  1152→// Avoid unnecessary dependencies\n  1153→// Vendor or ensure stability\n  1154→```\n  1155→\n  1156→### Common Pitfalls\n  1157→```go\n  1158→// 1. Overusing init()\n  1159→// Avoid side effects on import\n  1160→\n  1161→// 2. God packages\n  1162→// Don't create packages that do everything\n  1163→\n  1164→// 3. Premature abstraction\n  1165→// Start simple, refactor when needed\n  1166→\n  1167→// 4. Ignoring internal/\n  1168→// Use internal/ for non-public code\n  1169→\n  1170→// 5. Poor error messages\n  1171→// Provide context in errors\n  1172→\n  1173→// 6. Breaking changes in minor versions\n  1174→// Use major version for breaking changes\n  1175→\n  1176→// 7. No examples\n  1177→// Always provide usage examples\n  1178→\n  1179→// 8. Inconsistent API\n  1180→// Maintain consistency across package\n  1181→\n  1182→// 9. Global state\n  1183→// Avoid package-level variables\n  1184→\n  1185→// 10. Missing context support\n  1186→// Accept context.Context in long operations\n  1187→```\n  1188→\n  1189→## Best Practices Summary\n  1190→\n  1191→1. **Design cohesive packages** - Single, clear purpose\n  1192→2. **Minimize public API** - Export only what's necessary  \n  1193→3. **Use internal packages** - Hide implementation details\n  1194→4. **Follow semantic versioning** - Major.Minor.Patch\n  1195→5. **Document thoroughly** - Package, types, functions\n  1196→6. **Provide examples** - Show common usage patterns\n  1197→7. **Accept interfaces** - Return concrete types\n  1198→8. **Avoid circular dependencies** - Use interfaces to break cycles\n  1199→9. **Test comprehensively** - Unit, integration, benchmarks\n  1200→10. **Maintain backwards compatibility** - Use versioning for breaking changes\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"895b645e-04ac-4153-bcd0-1c4f17a24ef1","timestamp":"2025-08-13T10:27:55.260Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/packages.md","content":"# Go Packages - Package Design and Management\n\n## Table of Contents\n1. [Package Design](#package-design)\n2. [API Design](#api-design)\n3. [Internal Packages](#internal-packages)\n4. [Versioning](#versioning)\n5. [Documentation](#documentation)\n6. [Module Management](#module-management)\n7. [Dependencies](#dependencies)\n8. [Package Patterns](#package-patterns)\n9. [Publishing Packages](#publishing-packages)\n10. [Best Practices](#best-practices)\n\n## Package Design\n\n### Package Structure\n```go\n// Package naming conventions\npackage user        // Good: singular, lowercase\npackage users       // Bad: plural\npackage userMgmt    // Bad: camelCase\npackage user_mgmt   // Bad: underscore\n\n// Package organization\nmyproject/\n├── cmd/\n│   ├── api/\n│   │   └── main.go\n│   └── worker/\n│       └── main.go\n├── internal/\n│   ├── auth/\n│   ├── database/\n│   └── models/\n├── pkg/\n│   ├── client/\n│   └── utils/\n├── api/\n│   └── v1/\n├── docs/\n├── scripts/\n├── go.mod\n└── go.sum\n\n// Package declaration with documentation\n// Package user provides user management functionality.\n// It includes user creation, authentication, and profile management.\npackage user\n\n// Import grouping\nimport (\n    // Standard library\n    \"context\"\n    \"fmt\"\n    \"time\"\n    \n    // Third-party packages\n    \"github.com/google/uuid\"\n    \"golang.org/x/crypto/bcrypt\"\n    \n    // Internal packages\n    \"myproject/internal/database\"\n    \"myproject/pkg/errors\"\n)\n```\n\n### Package Cohesion\n```go\n// High cohesion - related functionality\npackage auth\n\ntype Authenticator interface {\n    Authenticate(credentials Credentials) (*User, error)\n    Refresh(token string) (*Token, error)\n    Revoke(token string) error\n}\n\ntype Credentials struct {\n    Username string\n    Password string\n}\n\ntype Token struct {\n    AccessToken  string\n    RefreshToken string\n    ExpiresAt    time.Time\n}\n\ntype User struct {\n    ID       string\n    Username string\n    Roles    []string\n}\n\n// Low cohesion - avoid generic packages\npackage utils  // Bad: too generic\n\nfunc HashPassword(password string) string { }\nfunc SendEmail(to, subject, body string) error { }\nfunc ParseJSON(data []byte) (interface{}, error) { }\nfunc GenerateID() string { }\n\n// Better: specific packages\npackage password\npackage email\npackage json\npackage id\n```\n\n### Package Dependencies\n```go\n// Minimize dependencies\npackage user\n\n// Good: depends only on necessary packages\nimport (\n    \"context\"\n    \"myproject/internal/database\"\n)\n\n// Bad: too many dependencies\nimport (\n    \"myproject/internal/auth\"\n    \"myproject/internal/email\"\n    \"myproject/internal/sms\"\n    \"myproject/internal/push\"\n    \"myproject/internal/analytics\"\n    // ... many more\n)\n\n// Dependency inversion\npackage service\n\n// Define interface in the consumer package\ntype UserRepository interface {\n    GetUser(ctx context.Context, id string) (*User, error)\n    SaveUser(ctx context.Context, user *User) error\n}\n\ntype UserService struct {\n    repo UserRepository  // Depend on interface\n}\n\n// Implementation in another package\npackage database\n\ntype PostgresUserRepository struct {\n    db *sql.DB\n}\n\nfunc (r *PostgresUserRepository) GetUser(ctx context.Context, id string) (*User, error) {\n    // Implementation\n}\n\n// Avoid circular dependencies\npackage a\nimport \"b\"  // a depends on b\n\npackage b\nimport \"a\"  // b depends on a - CIRCULAR!\n\n// Solution: introduce interface or third package\npackage c\ntype SharedInterface interface { }\n\npackage a\nimport \"c\"\n\npackage b\nimport \"c\"\n```\n\n## API Design\n\n### Exported vs Unexported\n```go\npackage mypackage\n\n// Exported (public) - capitalized\ntype Client struct {\n    Endpoint string\n    Timeout  time.Duration\n}\n\nfunc NewClient(endpoint string) *Client {\n    return &Client{\n        Endpoint: endpoint,\n        Timeout:  30 * time.Second,\n    }\n}\n\nfunc (c *Client) Request(ctx context.Context, data []byte) (*Response, error) {\n    return c.doRequest(ctx, data)\n}\n\n// Unexported (private) - lowercase\ntype config struct {\n    retryCount int\n    backoff    time.Duration\n}\n\nfunc (c *Client) doRequest(ctx context.Context, data []byte) (*Response, error) {\n    // Internal implementation\n}\n\n// Partially exported struct\ntype Response struct {\n    Status  int         // Exported\n    Data    []byte      // Exported\n    headers http.Header // Unexported\n}\n```\n\n### API Stability\n```go\n// Stable API design\npackage stable\n\n// Use interfaces for flexibility\ntype Store interface {\n    Get(key string) ([]byte, error)\n    Set(key string, value []byte) error\n    Delete(key string) error\n}\n\n// Options pattern for extensibility\ntype ClientOptions struct {\n    Timeout     time.Duration\n    MaxRetries  int\n    Headers     map[string]string\n    // Can add new fields without breaking\n}\n\nfunc NewClient(opts ClientOptions) *Client {\n    // Set defaults for zero values\n    if opts.Timeout == 0 {\n        opts.Timeout = 30 * time.Second\n    }\n    if opts.MaxRetries == 0 {\n        opts.MaxRetries = 3\n    }\n    \n    return &Client{opts: opts}\n}\n\n// Functional options for better API\ntype Option func(*Client)\n\nfunc WithTimeout(d time.Duration) Option {\n    return func(c *Client) {\n        c.timeout = d\n    }\n}\n\nfunc WithRetries(n int) Option {\n    return func(c *Client) {\n        c.maxRetries = n\n    }\n}\n\nfunc NewClientWithOptions(opts ...Option) *Client {\n    c := &Client{\n        timeout:    30 * time.Second,\n        maxRetries: 3,\n    }\n    \n    for _, opt := range opts {\n        opt(c)\n    }\n    \n    return c\n}\n\n// Deprecation\n// Deprecated: Use NewClientWithOptions instead.\nfunc NewClientOld(endpoint string) *Client {\n    return NewClientWithOptions(WithEndpoint(endpoint))\n}\n```\n\n### Error Design\n```go\npackage mypackage\n\n// Sentinel errors\nvar (\n    ErrNotFound      = errors.New(\"not found\")\n    ErrUnauthorized  = errors.New(\"unauthorized\")\n    ErrInvalidInput  = errors.New(\"invalid input\")\n)\n\n// Error types\ntype ValidationError struct {\n    Field   string\n    Message string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"validation error on field %s: %s\", e.Field, e.Message)\n}\n\n// Error wrapping\nfunc GetUser(id string) (*User, error) {\n    user, err := db.Query(id)\n    if err != nil {\n        if errors.Is(err, sql.ErrNoRows) {\n            return nil, ErrNotFound\n        }\n        return nil, fmt.Errorf(\"failed to get user %s: %w\", id, err)\n    }\n    return user, nil\n}\n\n// Custom error checking\nfunc IsNotFound(err error) bool {\n    return errors.Is(err, ErrNotFound)\n}\n\nfunc IsValidation(err error) bool {\n    var validationErr ValidationError\n    return errors.As(err, &validationErr)\n}\n```\n\n## Internal Packages\n\n### Using Internal\n```go\n// internal/ prevents external imports\nmyproject/\n├── internal/\n│   ├── auth/       // Only importable within myproject\n│   ├── database/\n│   └── config/\n├── pkg/\n│   └── public/     // Importable by anyone\n└── cmd/\n\n// In myproject/internal/auth/auth.go\npackage auth\n\ntype internalAuthenticator struct {\n    // Cannot be imported outside myproject\n}\n\n// In external project - FAILS\nimport \"github.com/user/myproject/internal/auth\" // Compile error!\n\n// Internal for sub-packages\nmyproject/\n├── feature/\n│   ├── internal/   // Only importable within feature/\n│   ├── api/\n│   └── service/\n\n// Organizing internal packages\ninternal/\n├── platform/       // Platform-specific code\n│   ├── database/\n│   ├── cache/\n│   └── queue/\n├── domain/         // Business logic\n│   ├── user/\n│   ├── order/\n│   └── payment/\n└── adapter/        // External adapters\n    ├── http/\n    ├── grpc/\n    └── cli/\n```\n\n### Internal Best Practices\n```go\n// Hide implementation details\n// Public package\npackage user\n\ntype Service interface {\n    GetUser(id string) (*User, error)\n}\n\nfunc NewService(db Database) Service {\n    return &service{\n        db: db,\n        validator: internal.NewValidator(),\n    }\n}\n\n// Internal package\npackage internal\n\ntype Validator struct {\n    rules []Rule\n}\n\nfunc NewValidator() *Validator {\n    // Hidden from external packages\n}\n\n// Share code between packages\ninternal/\n├── shared/\n│   ├── logger/\n│   ├── metrics/\n│   └── errors/\n\n// Use in multiple packages\npackage service1\nimport \"myproject/internal/shared/logger\"\n\npackage service2\nimport \"myproject/internal/shared/logger\"\n```\n\n## Versioning\n\n### Semantic Versioning\n```go\n// go.mod versioning\nmodule github.com/user/myproject\n\ngo 1.21\n\nrequire (\n    github.com/some/dep v1.2.3   // Exact version\n    github.com/other/dep v2.0.0+incompatible\n    github.com/new/dep/v2 v2.1.0 // Major version in path\n)\n\n// Version tags\n// git tag v1.0.0\n// git tag v1.0.1\n// git tag v1.1.0\n// git tag v2.0.0\n\n// Major version changes (v2+)\n// Update module path\nmodule github.com/user/myproject/v2\n\n// Import with version\nimport \"github.com/user/myproject/v2/pkg/client\"\n\n// Maintaining multiple versions\nmyproject/\n├── go.mod          // module github.com/user/myproject\n└── v2/\n    └── go.mod      // module github.com/user/myproject/v2\n\n// Version constraints\nrequire (\n    github.com/some/dep v1.2.3     // Exact\n    github.com/some/dep v1.2.x     // Patch updates\n    github.com/some/dep v1.x.x     // Minor updates\n    github.com/some/dep latest     // Latest\n    github.com/some/dep master     // Branch\n)\n```\n\n### API Versioning\n```go\n// Package versioning\napi/\n├── v1/\n│   └── client.go\n└── v2/\n    └── client.go\n\n// v1/client.go\npackage v1\n\ntype Client struct {\n    Endpoint string\n}\n\nfunc (c *Client) Request(data string) (string, error) {\n    // v1 implementation\n}\n\n// v2/client.go\npackage v2\n\ntype Client struct {\n    Endpoint string\n    Timeout  time.Duration  // New field\n}\n\nfunc (c *Client) Request(ctx context.Context, data []byte) ([]byte, error) {\n    // v2 implementation with context\n}\n\n// Supporting multiple versions\npackage api\n\nimport (\n    v1 \"myproject/api/v1\"\n    v2 \"myproject/api/v2\"\n)\n\nfunc NewClientV1() *v1.Client {\n    return &v1.Client{}\n}\n\nfunc NewClientV2() *v2.Client {\n    return &v2.Client{}\n}\n```\n\n## Documentation\n\n### Package Documentation\n```go\n// Package documentation (doc.go)\n/*\nPackage user provides user management functionality for the application.\n\nThe package includes:\n  - User CRUD operations\n  - Authentication and authorization\n  - Profile management\n  - Password reset functionality\n\nBasic usage:\n\n\tservice := user.NewService(db)\n\t\n\t// Create user\n\tu, err := service.Create(ctx, user.CreateRequest{\n\t\tEmail:    \"user@example.com\",\n\t\tPassword: \"secure123\",\n\t})\n\t\n\t// Authenticate\n\ttoken, err := service.Authenticate(ctx, email, password)\n\nFor more examples, see the examples directory.\n*/\npackage user\n\n// Type documentation\n// User represents a system user.\n// Users can have multiple roles and permissions.\ntype User struct {\n    // ID is the unique identifier for the user.\n    ID string\n    \n    // Email is the user's email address.\n    // It must be unique across all users.\n    Email string\n    \n    // CreatedAt is when the user was created.\n    CreatedAt time.Time\n    \n    // Roles contains the user's assigned roles.\n    Roles []Role\n}\n\n// Method documentation\n// Create creates a new user with the given request.\n// It returns an error if the email already exists or validation fails.\n//\n// Example:\n//\n//\tuser, err := service.Create(ctx, CreateRequest{\n//\t    Email:    \"user@example.com\",\n//\t    Password: \"secure123\",\n//\t})\n//\tif err != nil {\n//\t    log.Fatal(err)\n//\t}\nfunc (s *Service) Create(ctx context.Context, req CreateRequest) (*User, error) {\n    // Implementation\n}\n\n// Deprecated documentation\n// Deprecated: Use CreateWithOptions instead.\n// This function will be removed in v2.0.0.\nfunc (s *Service) CreateOld(email, password string) (*User, error) {\n    return s.CreateWithOptions(CreateOptions{\n        Email:    email,\n        Password: password,\n    })\n}\n```\n\n### Examples\n```go\n// Example functions (show in documentation)\nfunc ExampleService_Create() {\n    service := NewService(mockDB)\n    ctx := context.Background()\n    \n    user, err := service.Create(ctx, CreateRequest{\n        Email:    \"user@example.com\",\n        Password: \"secure123\",\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    \n    fmt.Println(user.Email)\n    // Output: user@example.com\n}\n\n// Example with suffix\nfunc ExampleService_Create_withRoles() {\n    service := NewService(mockDB)\n    ctx := context.Background()\n    \n    user, err := service.Create(ctx, CreateRequest{\n        Email:    \"admin@example.com\",\n        Password: \"secure123\",\n        Roles:    []string{\"admin\", \"user\"},\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    \n    fmt.Println(user.Roles)\n    // Output: [admin user]\n}\n\n// Package examples\nfunc Example() {\n    // Initialize service\n    db := setupDatabase()\n    service := NewService(db)\n    \n    // Create user\n    user, _ := service.Create(context.Background(), CreateRequest{\n        Email: \"user@example.com\",\n    })\n    \n    // Authenticate\n    token, _ := service.Authenticate(context.Background(), \n        user.Email, \"password\")\n    \n    fmt.Println(token != \"\")\n    // Output: true\n}\n\n// Testable examples\nfunc ExampleService_paginate() {\n    users := []User{\n        {Email: \"user1@example.com\"},\n        {Email: \"user2@example.com\"},\n        {Email: \"user3@example.com\"},\n    }\n    \n    page := Paginate(users, 2, 1)\n    for _, u := range page {\n        fmt.Println(u.Email)\n    }\n    // Output:\n    // user1@example.com\n    // user2@example.com\n}\n```\n\n## Module Management\n\n### Go Modules\n```go\n// Initialize module\n// go mod init github.com/user/project\n\n// go.mod structure\nmodule github.com/user/project\n\ngo 1.21\n\nrequire (\n    github.com/gorilla/mux v1.8.0\n    github.com/stretchr/testify v1.8.0\n)\n\nrequire (\n    // Indirect dependencies\n    github.com/davecgh/go-spew v1.1.1 // indirect\n    github.com/pmezard/go-difflib v1.0.0 // indirect\n)\n\n// Replace directive\nreplace github.com/old/package => github.com/new/package v1.0.0\n\n// Local replace for development\nreplace github.com/user/dependency => ../dependency\n\n// Exclude versions\nexclude github.com/bad/package v1.0.0\n\n// Retract versions (go 1.16+)\nretract (\n    v1.0.0 // Critical bug\n    v1.0.1 // Security issue\n)\n\n// Module commands\n// go mod download    - Download dependencies\n// go mod tidy       - Clean up dependencies\n// go mod verify     - Verify dependencies\n// go mod graph      - Show dependency graph\n// go mod vendor     - Create vendor directory\n// go mod why pkg    - Explain why package is needed\n```\n\n### Workspace Mode\n```go\n// go.work (Go 1.18+)\ngo 1.21\n\nuse (\n    ./project1\n    ./project2\n    ../shared\n)\n\nreplace github.com/example/lib => ../lib\n\n// Commands\n// go work init project1 project2\n// go work use ../another-project\n// go work sync\n\n// Development workflow\nworkspace/\n├── go.work\n├── project1/\n│   └── go.mod\n├── project2/\n│   └── go.mod\n└── shared/\n    └── go.mod\n\n// Each project has its own module\n// Work on multiple modules simultaneously\n```\n\n## Dependencies\n\n### Managing Dependencies\n```go\n// Adding dependencies\n// go get github.com/pkg/errors\n// go get github.com/pkg/errors@v0.9.1\n// go get github.com/pkg/errors@latest\n// go get github.com/pkg/errors@master\n\n// Updating dependencies\n// go get -u                    - Update all\n// go get -u ./...             - Update all in module\n// go get -u=patch ./...       - Update patch versions\n// go get -u github.com/pkg/...  - Update specific package\n\n// Removing dependencies\n// go mod tidy                  - Remove unused\n\n// Vendoring\n// go mod vendor               - Create vendor/\n// go build -mod=vendor        - Build with vendor/\n\n// Dependency analysis\nimport \"golang.org/x/mod/modfile\"\n\nfunc analyzeDependencies() {\n    data, _ := os.ReadFile(\"go.mod\")\n    file, _ := modfile.Parse(\"go.mod\", data, nil)\n    \n    for _, req := range file.Require {\n        fmt.Printf(\"%s: %s\\n\", req.Mod.Path, req.Mod.Version)\n    }\n}\n\n// Private dependencies\n// Set GOPRIVATE environment variable\n// GOPRIVATE=github.com/company/*\n\n// Use .netrc for authentication\n// machine github.com\n// login username\n// password token\n\n// Or use SSH\n// git config --global url.\"git@github.com:\".insteadOf \"https://github.com/\"\n```\n\n### Dependency Injection\n```go\n// Constructor injection\ntype Service struct {\n    db     Database\n    cache  Cache\n    logger Logger\n}\n\nfunc NewService(db Database, cache Cache, logger Logger) *Service {\n    return &Service{\n        db:     db,\n        cache:  cache,\n        logger: logger,\n    }\n}\n\n// Interface injection\ntype Database interface {\n    Query(string) ([]Row, error)\n}\n\ntype Cache interface {\n    Get(string) (interface{}, bool)\n    Set(string, interface{})\n}\n\n// Wire for dependency injection\n//go:build wireinject\n\nimport \"github.com/google/wire\"\n\nfunc InitializeService() (*Service, error) {\n    wire.Build(\n        NewDatabase,\n        NewCache,\n        NewLogger,\n        NewService,\n    )\n    return nil, nil\n}\n\n// Provider sets\nvar BasicSet = wire.NewSet(\n    NewDatabase,\n    NewCache,\n    NewLogger,\n)\n\nvar ServiceSet = wire.NewSet(\n    BasicSet,\n    NewService,\n    NewRepository,\n)\n```\n\n## Package Patterns\n\n### Plugin Pattern\n```go\n// Plugin interface\npackage plugin\n\ntype Plugin interface {\n    Name() string\n    Initialize(config map[string]interface{}) error\n    Execute(context.Context, interface{}) (interface{}, error)\n    Shutdown() error\n}\n\n// Registry\ntype Registry struct {\n    mu      sync.RWMutex\n    plugins map[string]Plugin\n}\n\nfunc (r *Registry) Register(p Plugin) {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    r.plugins[p.Name()] = p\n}\n\nfunc (r *Registry) Get(name string) (Plugin, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    p, ok := r.plugins[name]\n    return p, ok\n}\n\n// Plugin implementation\npackage myplugin\n\ntype MyPlugin struct {\n    config map[string]interface{}\n}\n\nfunc (p *MyPlugin) Name() string {\n    return \"my-plugin\"\n}\n\nfunc (p *MyPlugin) Initialize(config map[string]interface{}) error {\n    p.config = config\n    return nil\n}\n\n// Auto-registration\nfunc init() {\n    plugin.DefaultRegistry.Register(&MyPlugin{})\n}\n```\n\n### Provider Pattern\n```go\n// Provider interface\npackage provider\n\ntype StorageProvider interface {\n    Read(key string) ([]byte, error)\n    Write(key string, data []byte) error\n    Delete(key string) error\n}\n\n// Factory\ntype ProviderFactory func(config Config) (StorageProvider, error)\n\nvar providers = make(map[string]ProviderFactory)\n\nfunc Register(name string, factory ProviderFactory) {\n    providers[name] = factory\n}\n\nfunc New(name string, config Config) (StorageProvider, error) {\n    factory, ok := providers[name]\n    if !ok {\n        return nil, fmt.Errorf(\"unknown provider: %s\", name)\n    }\n    return factory(config)\n}\n\n// S3 provider\npackage s3\n\nfunc init() {\n    provider.Register(\"s3\", NewS3Provider)\n}\n\nfunc NewS3Provider(config provider.Config) (provider.StorageProvider, error) {\n    return &S3Provider{\n        bucket: config.Get(\"bucket\"),\n        region: config.Get(\"region\"),\n    }, nil\n}\n```\n\n### Repository Pattern\n```go\npackage repository\n\n// Generic repository interface\ntype Repository[T any] interface {\n    Find(ctx context.Context, id string) (*T, error)\n    FindAll(ctx context.Context) ([]*T, error)\n    Create(ctx context.Context, entity *T) error\n    Update(ctx context.Context, entity *T) error\n    Delete(ctx context.Context, id string) error\n}\n\n// Specific implementation\ntype UserRepository interface {\n    Repository[User]\n    FindByEmail(ctx context.Context, email string) (*User, error)\n    FindByRole(ctx context.Context, role string) ([]*User, error)\n}\n\n// SQL implementation\ntype sqlUserRepository struct {\n    db *sql.DB\n}\n\nfunc NewSQLUserRepository(db *sql.DB) UserRepository {\n    return &sqlUserRepository{db: db}\n}\n\nfunc (r *sqlUserRepository) Find(ctx context.Context, id string) (*User, error) {\n    query := `SELECT id, email, created_at FROM users WHERE id = $1`\n    // Implementation\n}\n\n// MongoDB implementation\ntype mongoUserRepository struct {\n    collection *mongo.Collection\n}\n\nfunc NewMongoUserRepository(db *mongo.Database) UserRepository {\n    return &mongoUserRepository{\n        collection: db.Collection(\"users\"),\n    }\n}\n```\n\n## Publishing Packages\n\n### Preparing for Publication\n```go\n// 1. Choose a good name\n// - Descriptive and unique\n// - Avoid generic names (utils, helpers, common)\n// - Check if name is available\n\n// 2. Create comprehensive documentation\n// - README.md with examples\n// - Package documentation\n// - API documentation\n// - CONTRIBUTING.md\n// - LICENSE file\n\n// 3. Add examples\nexamples/\n├── basic/\n│   └── main.go\n├── advanced/\n│   └── main.go\n└── README.md\n\n// 4. Write comprehensive tests\n// - Unit tests\n// - Integration tests\n// - Benchmarks\n// - Examples\n\n// 5. Set up CI/CD\n// .github/workflows/test.yml\nname: Test\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: 1.21\n    - run: go test -v ./...\n    - run: go test -race ./...\n    - run: go test -cover ./...\n```\n\n### Publishing Process\n```bash\n# 1. Tag version\ngit tag v1.0.0\ngit push origin v1.0.0\n\n# 2. The package is automatically available\n# go get github.com/username/package@v1.0.0\n\n# 3. Update pkg.go.dev\n# Visit https://pkg.go.dev/github.com/username/package\n# Click \"Request\" button\n\n# 4. Add badges to README\n[![Go Reference](https://pkg.go.dev/badge/github.com/username/package.svg)](https://pkg.go.dev/github.com/username/package)\n[![Go Report Card](https://goreportcard.com/badge/github.com/username/package)](https://goreportcard.com/report/github.com/username/package)\n[![Coverage Status](https://coveralls.io/repos/github/username/package/badge.svg)](https://coveralls.io/github/username/package)\n\n# 5. Create release on GitHub\n# - Add release notes\n# - Attach binaries if applicable\n```\n\n### Package Maintenance\n```go\n// Deprecation process\n// 1. Mark as deprecated in documentation\n// Deprecated: Use NewFunction instead.\n// This will be removed in v2.0.0.\nfunc OldFunction() {}\n\n// 2. Log deprecation warnings\nfunc OldFunction() {\n    log.Println(\"Warning: OldFunction is deprecated. Use NewFunction instead.\")\n    // Existing implementation\n}\n\n// 3. Provide migration guide\n/*\nMigration Guide from v1 to v2:\n\n1. Replace OldFunction() with NewFunction()\n2. Update Client struct initialization:\n   Old: client := &Client{Endpoint: \"url\"}\n   New: client := NewClient(WithEndpoint(\"url\"))\n3. Change import path:\n   Old: import \"github.com/user/package\"\n   New: import \"github.com/user/package/v2\"\n*/\n\n// Version compatibility\n// Support multiple versions\npackage compat\n\nimport (\n    v1 \"mypackage/v1\"\n    v2 \"mypackage/v2\"\n)\n\nfunc MigrateV1ToV2(old *v1.Config) *v2.Config {\n    return &v2.Config{\n        // Map old fields to new\n    }\n}\n```\n\n## Best Practices\n\n### Package Design Principles\n```go\n// 1. Single Responsibility\n// Each package should have one clear purpose\n\n// 2. Minimal Public API\n// Export only what's necessary\npackage mypackage\n\ntype Client struct{} // Exported\n\ntype implementation struct{} // Unexported\n\n// 3. Accept Interfaces, Return Structs\nfunc Process(r io.Reader) *Result {\n    // Accept interface for flexibility\n    // Return concrete type for clarity\n}\n\n// 4. Avoid Init Functions\n// Bad: Side effects on import\nfunc init() {\n    database.Connect() // Side effect!\n}\n\n// Good: Explicit initialization\nfunc Initialize() error {\n    return database.Connect()\n}\n\n// 5. No Circular Dependencies\n// Use interfaces to break cycles\n\n// 6. Consistent Naming\n// Package name should match directory name\n// Avoid stuttering: user.User not user.UserUser\n\n// 7. Semantic Versioning\n// Follow semver strictly\n// Major.Minor.Patch\n\n// 8. Comprehensive Testing\n// Aim for >80% coverage\n// Include edge cases\n\n// 9. Clear Documentation\n// Document all exports\n// Provide examples\n\n// 10. Minimal Dependencies\n// Avoid unnecessary dependencies\n// Vendor or ensure stability\n```\n\n### Common Pitfalls\n```go\n// 1. Overusing init()\n// Avoid side effects on import\n\n// 2. God packages\n// Don't create packages that do everything\n\n// 3. Premature abstraction\n// Start simple, refactor when needed\n\n// 4. Ignoring internal/\n// Use internal/ for non-public code\n\n// 5. Poor error messages\n// Provide context in errors\n\n// 6. Breaking changes in minor versions\n// Use major version for breaking changes\n\n// 7. No examples\n// Always provide usage examples\n\n// 8. Inconsistent API\n// Maintain consistency across package\n\n// 9. Global state\n// Avoid package-level variables\n\n// 10. Missing context support\n// Accept context.Context in long operations\n```\n\n## Best Practices Summary\n\n1. **Design cohesive packages** - Single, clear purpose\n2. **Minimize public API** - Export only what's necessary  \n3. **Use internal packages** - Hide implementation details\n4. **Follow semantic versioning** - Major.Minor.Patch\n5. **Document thoroughly** - Package, types, functions\n6. **Provide examples** - Show common usage patterns\n7. **Accept interfaces** - Return concrete types\n8. **Avoid circular dependencies** - Use interfaces to break cycles\n9. **Test comprehensively** - Unit, integration, benchmarks\n10. **Maintain backwards compatibility** - Use versioning for breaking changes","numLines":1200,"startLine":1,"totalLines":1200}}}
{"parentUuid":"895b645e-04ac-4153-bcd0-1c4f17a24ef1","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_019uUd6pZQPMzYEF2iy8GsZ7","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Now, let me examine the remaining documentation files and then check the actual codebase to compare against the documented patterns."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":14433,"cache_creation_input_tokens":45835,"cache_read_input_tokens":32905,"output_tokens":269,"service_tier":"standard"}},"requestId":"req_011CS5YtFUwwi4gVR5i7AD9p","type":"assistant","uuid":"f616441b-7550-4e35-bd6b-2c5125ce5038","timestamp":"2025-08-13T10:27:59.612Z"}
{"parentUuid":"f616441b-7550-4e35-bd6b-2c5125ce5038","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_019uUd6pZQPMzYEF2iy8GsZ7","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01UL6hGznRrBWszB1LE1jGJw","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/errors.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":14433,"cache_creation_input_tokens":45835,"cache_read_input_tokens":32905,"output_tokens":269,"service_tier":"standard"}},"requestId":"req_011CS5YtFUwwi4gVR5i7AD9p","type":"assistant","uuid":"029e9c54-92a5-40b7-ab1a-19460690a2ec","timestamp":"2025-08-13T10:28:01.420Z"}
{"parentUuid":"029e9c54-92a5-40b7-ab1a-19460690a2ec","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_019uUd6pZQPMzYEF2iy8GsZ7","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01B1JPnVMjfUiQjM51pd32h9","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/design-patterns.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":14433,"cache_creation_input_tokens":45835,"cache_read_input_tokens":32905,"output_tokens":269,"service_tier":"standard"}},"requestId":"req_011CS5YtFUwwi4gVR5i7AD9p","type":"assistant","uuid":"bfc9a599-4a68-48dc-8247-0359458fe1e7","timestamp":"2025-08-13T10:28:02.190Z"}
{"parentUuid":"bfc9a599-4a68-48dc-8247-0359458fe1e7","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_019uUd6pZQPMzYEF2iy8GsZ7","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_019WsA8iNvJUkfFVSLJwM3dL","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/concurrency.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":14433,"cache_creation_input_tokens":45835,"cache_read_input_tokens":32905,"output_tokens":269,"service_tier":"standard"}},"requestId":"req_011CS5YtFUwwi4gVR5i7AD9p","type":"assistant","uuid":"18820fcf-f3b9-4044-acd9-766027f137dc","timestamp":"2025-08-13T10:28:02.331Z"}
{"parentUuid":"18820fcf-f3b9-4044-acd9-766027f137dc","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_019uUd6pZQPMzYEF2iy8GsZ7","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_012Ld6knAwnn1v9oWFsjkE2C","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/performance.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":14433,"cache_creation_input_tokens":45835,"cache_read_input_tokens":32905,"output_tokens":269,"service_tier":"standard"}},"requestId":"req_011CS5YtFUwwi4gVR5i7AD9p","type":"assistant","uuid":"01e55828-6f77-4beb-8cda-ba52425dcfbf","timestamp":"2025-08-13T10:28:02.342Z"}
{"parentUuid":"01e55828-6f77-4beb-8cda-ba52425dcfbf","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01B1JPnVMjfUiQjM51pd32h9","type":"tool_result","content":"     1→# Design Patterns in Go\n     2→\n     3→## Overview\n     4→This document covers classic design patterns (Gang of Four) and architectural patterns as they apply to Go. For Go-specific idioms and conventions, see `practices-patterns.md`.\n     5→\n     6→## Table of Contents\n     7→1. [Creational Patterns](#creational-patterns)\n     8→2. [Structural Patterns](#structural-patterns)\n     9→3. [Behavioral Patterns](#behavioral-patterns)\n    10→4. [Architectural Patterns](#architectural-patterns)\n    11→5. [Domain-Driven Design Patterns](#domain-driven-design-patterns)\n    12→\n    13→## Creational Patterns\n    14→\n    15→### Singleton\n    16→The singleton pattern ensures only one instance of a type exists. In Go, use `sync.Once` for thread-safe initialization.\n    17→\n    18→```go\n    19→package database\n    20→\n    21→import (\n    22→    \"database/sql\"\n    23→    \"sync\"\n    24→)\n    25→\n    26→type DB struct {\n    27→    conn *sql.DB\n    28→}\n    29→\n    30→var (\n    31→    instance *DB\n    32→    once     sync.Once\n    33→)\n    34→\n    35→// GetInstance returns the singleton database instance\n    36→func GetInstance() *DB {\n    37→    once.Do(func() {\n    38→        conn, _ := sql.Open(\"postgres\", \"connection-string\")\n    39→        instance = &DB{conn: conn}\n    40→    })\n    41→    return instance\n    42→}\n    43→\n    44→// Alternative: Package-level initialization (simpler for most cases)\n    45→var defaultDB = initDB()\n    46→\n    47→func initDB() *DB {\n    48→    conn, _ := sql.Open(\"postgres\", \"connection-string\")\n    49→    return &DB{conn: conn}\n    50→}\n    51→```\n    52→\n    53→### Factory Method\n    54→Factory method defines an interface for creating objects but lets subclasses decide which class to instantiate.\n    55→\n    56→```go\n    57→// Product interface\n    58→type Transport interface {\n    59→    Deliver() string\n    60→    Cost() float64\n    61→}\n    62→\n    63→// Concrete products\n    64→type Truck struct {\n    65→    capacity int\n    66→}\n    67→\n    68→func (t *Truck) Deliver() string {\n    69→    return \"Delivering by land\"\n    70→}\n    71→\n    72→func (t *Truck) Cost() float64 {\n    73→    return 100.0\n    74→}\n    75→\n    76→type Ship struct {\n    77→    tonnage int\n    78→}\n    79→\n    80→func (s *Ship) Deliver() string {\n    81→    return \"Delivering by sea\"\n    82→}\n    83→\n    84→func (s *Ship) Cost() float64 {\n    85→    return 500.0\n    86→}\n    87→\n    88→// Factory\n    89→type LogisticsFactory interface {\n    90→    CreateTransport() Transport\n    91→}\n    92→\n    93→type RoadLogistics struct{}\n    94→\n    95→func (r *RoadLogistics) CreateTransport() Transport {\n    96→    return &Truck{capacity: 1000}\n    97→}\n    98→\n    99→type SeaLogistics struct{}\n   100→\n   101→func (s *SeaLogistics) CreateTransport() Transport {\n   102→    return &Ship{tonnage: 10000}\n   103→}\n   104→\n   105→// Usage\n   106→func planDelivery(factory LogisticsFactory) {\n   107→    transport := factory.CreateTransport()\n   108→    fmt.Println(transport.Deliver())\n   109→    fmt.Printf(\"Cost: $%.2f\\n\", transport.Cost())\n   110→}\n   111→```\n   112→\n   113→### Abstract Factory\n   114→Abstract factory provides an interface for creating families of related objects.\n   115→\n   116→```go\n   117→// Abstract products\n   118→type Button interface {\n   119→    Paint()\n   120→}\n   121→\n   122→type Checkbox interface {\n   123→    Check()\n   124→}\n   125→\n   126→// Concrete products - Windows family\n   127→type WindowsButton struct{}\n   128→\n   129→func (w *WindowsButton) Paint() {\n   130→    fmt.Println(\"Rendering Windows button\")\n   131→}\n   132→\n   133→type WindowsCheckbox struct{}\n   134→\n   135→func (w *WindowsCheckbox) Check() {\n   136→    fmt.Println(\"Checking Windows checkbox\")\n   137→}\n   138→\n   139→// Concrete products - Mac family\n   140→type MacButton struct{}\n   141→\n   142→func (m *MacButton) Paint() {\n   143→    fmt.Println(\"Rendering Mac button\")\n   144→}\n   145→\n   146→type MacCheckbox struct{}\n   147→\n   148→func (m *MacCheckbox) Check() {\n   149→    fmt.Println(\"Checking Mac checkbox\")\n   150→}\n   151→\n   152→// Abstract factory\n   153→type GUIFactory interface {\n   154→    CreateButton() Button\n   155→    CreateCheckbox() Checkbox\n   156→}\n   157→\n   158→// Concrete factories\n   159→type WindowsFactory struct{}\n   160→\n   161→func (w *WindowsFactory) CreateButton() Button {\n   162→    return &WindowsButton{}\n   163→}\n   164→\n   165→func (w *WindowsFactory) CreateCheckbox() Checkbox {\n   166→    return &WindowsCheckbox{}\n   167→}\n   168→\n   169→type MacFactory struct{}\n   170→\n   171→func (m *MacFactory) CreateButton() Button {\n   172→    return &MacButton{}\n   173→}\n   174→\n   175→func (m *MacFactory) CreateCheckbox() Checkbox {\n   176→    return &MacCheckbox{}\n   177→}\n   178→\n   179→// Application\n   180→type Application struct {\n   181→    factory GUIFactory\n   182→    button  Button\n   183→    checkbox Checkbox\n   184→}\n   185→\n   186→func NewApplication(factory GUIFactory) *Application {\n   187→    return &Application{\n   188→        factory:  factory,\n   189→        button:   factory.CreateButton(),\n   190→        checkbox: factory.CreateCheckbox(),\n   191→    }\n   192→}\n   193→\n   194→func (a *Application) Paint() {\n   195→    a.button.Paint()\n   196→    a.checkbox.Check()\n   197→}\n   198→```\n   199→\n   200→### Builder\n   201→Builder pattern separates the construction of complex objects from their representation.\n   202→\n   203→```go\n   204→// Product\n   205→type House struct {\n   206→    Foundation string\n   207→    Structure  string\n   208→    Roof       string\n   209→    Interior   string\n   210→    Garden     bool\n   211→    Pool       bool\n   212→}\n   213→\n   214→// Builder interface\n   215→type HouseBuilder interface {\n   216→    SetFoundation() HouseBuilder\n   217→    SetStructure() HouseBuilder\n   218→    SetRoof() HouseBuilder\n   219→    SetInterior() HouseBuilder\n   220→    SetGarden() HouseBuilder\n   221→    SetPool() HouseBuilder\n   222→    Build() *House\n   223→}\n   224→\n   225→// Concrete builder\n   226→type ModernHouseBuilder struct {\n   227→    house *House\n   228→}\n   229→\n   230→func NewModernHouseBuilder() *ModernHouseBuilder {\n   231→    return &ModernHouseBuilder{\n   232→        house: &House{},\n   233→    }\n   234→}\n   235→\n   236→func (b *ModernHouseBuilder) SetFoundation() HouseBuilder {\n   237→    b.house.Foundation = \"Concrete, brick, and stone\"\n   238→    return b\n   239→}\n   240→\n   241→func (b *ModernHouseBuilder) SetStructure() HouseBuilder {\n   242→    b.house.Structure = \"Steel and glass\"\n   243→    return b\n   244→}\n   245→\n   246→func (b *ModernHouseBuilder) SetRoof() HouseBuilder {\n   247→    b.house.Roof = \"Flat concrete\"\n   248→    return b\n   249→}\n   250→\n   251→func (b *ModernHouseBuilder) SetInterior() HouseBuilder {\n   252→    b.house.Interior = \"Modern minimalist\"\n   253→    return b\n   254→}\n   255→\n   256→func (b *ModernHouseBuilder) SetGarden() HouseBuilder {\n   257→    b.house.Garden = true\n   258→    return b\n   259→}\n   260→\n   261→func (b *ModernHouseBuilder) SetPool() HouseBuilder {\n   262→    b.house.Pool = true\n   263→    return b\n   264→}\n   265→\n   266→func (b *ModernHouseBuilder) Build() *House {\n   267→    return b.house\n   268→}\n   269→\n   270→// Director (optional)\n   271→type ConstructionDirector struct {\n   272→    builder HouseBuilder\n   273→}\n   274→\n   275→func (d *ConstructionDirector) ConstructLuxuryHouse() *House {\n   276→    return d.builder.\n   277→        SetFoundation().\n   278→        SetStructure().\n   279→        SetRoof().\n   280→        SetInterior().\n   281→        SetGarden().\n   282→        SetPool().\n   283→        Build()\n   284→}\n   285→\n   286→// Usage\n   287→func main() {\n   288→    builder := NewModernHouseBuilder()\n   289→    \n   290→    // Direct use\n   291→    house := builder.\n   292→        SetFoundation().\n   293→        SetStructure().\n   294→        SetRoof().\n   295→        Build()\n   296→    \n   297→    // Using director\n   298→    director := &ConstructionDirector{builder: builder}\n   299→    luxuryHouse := director.ConstructLuxuryHouse()\n   300→}\n   301→```\n   302→\n   303→### Prototype\n   304→Prototype pattern creates objects by cloning existing instances.\n   305→\n   306→```go\n   307→// Prototype interface\n   308→type Prototype interface {\n   309→    Clone() Prototype\n   310→}\n   311→\n   312→// Concrete prototype\n   313→type Document struct {\n   314→    Title    string\n   315→    Content  string\n   316→    Images   []string\n   317→    Metadata map[string]string\n   318→}\n   319→\n   320→func (d *Document) Clone() Prototype {\n   321→    // Deep copy\n   322→    newDoc := &Document{\n   323→        Title:   d.Title,\n   324→        Content: d.Content,\n   325→        Images:  make([]string, len(d.Images)),\n   326→        Metadata: make(map[string]string),\n   327→    }\n   328→    \n   329→    copy(newDoc.Images, d.Images)\n   330→    \n   331→    for k, v := range d.Metadata {\n   332→        newDoc.Metadata[k] = v\n   333→    }\n   334→    \n   335→    return newDoc\n   336→}\n   337→\n   338→// Prototype registry\n   339→type DocumentRegistry struct {\n   340→    prototypes map[string]Prototype\n   341→}\n   342→\n   343→func NewDocumentRegistry() *DocumentRegistry {\n   344→    return &DocumentRegistry{\n   345→        prototypes: make(map[string]Prototype),\n   346→    }\n   347→}\n   348→\n   349→func (r *DocumentRegistry) Register(name string, prototype Prototype) {\n   350→    r.prototypes[name] = prototype\n   351→}\n   352→\n   353→func (r *DocumentRegistry) Create(name string) Prototype {\n   354→    if prototype, exists := r.prototypes[name]; exists {\n   355→        return prototype.Clone()\n   356→    }\n   357→    return nil\n   358→}\n   359→\n   360→// Usage\n   361→func main() {\n   362→    registry := NewDocumentRegistry()\n   363→    \n   364→    // Register prototypes\n   365→    registry.Register(\"report\", &Document{\n   366→        Title:    \"Monthly Report Template\",\n   367→        Content:  \"...\",\n   368→        Metadata: map[string]string{\"type\": \"report\"},\n   369→    })\n   370→    \n   371→    registry.Register(\"letter\", &Document{\n   372→        Title:    \"Business Letter Template\",\n   373→        Content:  \"...\",\n   374→        Metadata: map[string]string{\"type\": \"letter\"},\n   375→    })\n   376→    \n   377→    // Create new documents from prototypes\n   378→    report := registry.Create(\"report\").(*Document)\n   379→    report.Title = \"January Report\"\n   380→}\n   381→```\n   382→\n   383→## Structural Patterns\n   384→\n   385→### Adapter\n   386→Adapter allows incompatible interfaces to work together.\n   387→\n   388→```go\n   389→// Target interface (what client expects)\n   390→type PaymentProcessor interface {\n   391→    ProcessPayment(amount float64) error\n   392→}\n   393→\n   394→// Adaptee (incompatible interface)\n   395→type LegacyPaymentSystem struct{}\n   396→\n   397→func (l *LegacyPaymentSystem) MakePayment(sum float64, currency string) string {\n   398→    return fmt.Sprintf(\"Payment of %.2f %s processed\", sum, currency)\n   399→}\n   400→\n   401→// Adapter\n   402→type PaymentAdapter struct {\n   403→    legacy   *LegacyPaymentSystem\n   404→    currency string\n   405→}\n   406→\n   407→func NewPaymentAdapter(legacy *LegacyPaymentSystem, currency string) *PaymentAdapter {\n   408→    return &PaymentAdapter{\n   409→        legacy:   legacy,\n   410→        currency: currency,\n   411→    }\n   412→}\n   413→\n   414→func (a *PaymentAdapter) ProcessPayment(amount float64) error {\n   415→    result := a.legacy.MakePayment(amount, a.currency)\n   416→    if result != \"\" {\n   417→        return nil\n   418→    }\n   419→    return fmt.Errorf(\"payment failed\")\n   420→}\n   421→\n   422→// Client code\n   423→func processOrder(processor PaymentProcessor, amount float64) {\n   424→    if err := processor.ProcessPayment(amount); err != nil {\n   425→        fmt.Printf(\"Payment failed: %v\\n\", err)\n   426→    } else {\n   427→        fmt.Println(\"Payment successful\")\n   428→    }\n   429→}\n   430→\n   431→// Usage\n   432→func main() {\n   433→    legacy := &LegacyPaymentSystem{}\n   434→    adapter := NewPaymentAdapter(legacy, \"USD\")\n   435→    processOrder(adapter, 100.00)\n   436→}\n   437→```\n   438→\n   439→### Bridge\n   440→Bridge decouples abstraction from implementation so both can vary independently.\n   441→\n   442→```go\n   443→// Implementation interface\n   444→type MessageSender interface {\n   445→    Send(title, body string) error\n   446→}\n   447→\n   448→// Concrete implementations\n   449→type EmailSender struct {\n   450→    emailAddress string\n   451→}\n   452→\n   453→func (e *EmailSender) Send(title, body string) error {\n   454→    fmt.Printf(\"Email to %s: %s - %s\\n\", e.emailAddress, title, body)\n   455→    return nil\n   456→}\n   457→\n   458→type SMSSender struct {\n   459→    phoneNumber string\n   460→}\n   461→\n   462→func (s *SMSSender) Send(title, body string) error {\n   463→    fmt.Printf(\"SMS to %s: %s\\n\", s.phoneNumber, body)\n   464→    return nil\n   465→}\n   466→\n   467→// Abstraction\n   468→type Message struct {\n   469→    sender MessageSender\n   470→}\n   471→\n   472→func NewMessage(sender MessageSender) *Message {\n   473→    return &Message{sender: sender}\n   474→}\n   475→\n   476→func (m *Message) Send(title, body string) error {\n   477→    return m.sender.Send(title, body)\n   478→}\n   479→\n   480→// Refined abstraction\n   481→type UrgentMessage struct {\n   482→    Message\n   483→}\n   484→\n   485→func NewUrgentMessage(sender MessageSender) *UrgentMessage {\n   486→    return &UrgentMessage{\n   487→        Message: Message{sender: sender},\n   488→    }\n   489→}\n   490→\n   491→func (u *UrgentMessage) Send(title, body string) error {\n   492→    title = \"URGENT: \" + title\n   493→    return u.sender.Send(title, body)\n   494→}\n   495→\n   496→// Usage\n   497→func main() {\n   498→    // Regular email\n   499→    email := NewMessage(&EmailSender{emailAddress: \"user@example.com\"})\n   500→    email.Send(\"Hello\", \"This is a test message\")\n   501→    \n   502→    // Urgent SMS\n   503→    sms := NewUrgentMessage(&SMSSender{phoneNumber: \"+1234567890\"})\n   504→    sms.Send(\"Alert\", \"Server is down\")\n   505→}\n   506→```\n   507→\n   508→### Composite\n   509→Composite lets you compose objects into tree structures to represent part-whole hierarchies.\n   510→\n   511→```go\n   512→// Component interface\n   513→type FileSystemNode interface {\n   514→    GetName() string\n   515→    GetSize() int64\n   516→    Print(indent string)\n   517→}\n   518→\n   519→// Leaf\n   520→type File struct {\n   521→    name string\n   522→    size int64\n   523→}\n   524→\n   525→func (f *File) GetName() string {\n   526→    return f.name\n   527→}\n   528→\n   529→func (f *File) GetSize() int64 {\n   530→    return f.size\n   531→}\n   532→\n   533→func (f *File) Print(indent string) {\n   534→    fmt.Printf(\"%sFile: %s (%d bytes)\\n\", indent, f.name, f.size)\n   535→}\n   536→\n   537→// Composite\n   538→type Directory struct {\n   539→    name     string\n   540→    children []FileSystemNode\n   541→}\n   542→\n   543→func (d *Directory) GetName() string {\n   544→    return d.name\n   545→}\n   546→\n   547→func (d *Directory) GetSize() int64 {\n   548→    var total int64\n   549→    for _, child := range d.children {\n   550→        total += child.GetSize()\n   551→    }\n   552→    return total\n   553→}\n   554→\n   555→func (d *Directory) Add(node FileSystemNode) {\n   556→    d.children = append(d.children, node)\n   557→}\n   558→\n   559→func (d *Directory) Remove(node FileSystemNode) {\n   560→    for i, child := range d.children {\n   561→        if child == node {\n   562→            d.children = append(d.children[:i], d.children[i+1:]...)\n   563→            break\n   564→        }\n   565→    }\n   566→}\n   567→\n   568→func (d *Directory) Print(indent string) {\n   569→    fmt.Printf(\"%sDirectory: %s (%d bytes)\\n\", indent, d.name, d.GetSize())\n   570→    for _, child := range d.children {\n   571→        child.Print(indent + \"  \")\n   572→    }\n   573→}\n   574→\n   575→// Usage\n   576→func main() {\n   577→    root := &Directory{name: \"root\"}\n   578→    \n   579→    home := &Directory{name: \"home\"}\n   580→    root.Add(home)\n   581→    \n   582→    documents := &Directory{name: \"documents\"}\n   583→    home.Add(documents)\n   584→    \n   585→    documents.Add(&File{name: \"report.pdf\", size: 1024000})\n   586→    documents.Add(&File{name: \"presentation.pptx\", size: 2048000})\n   587→    \n   588→    home.Add(&File{name: \"notes.txt\", size: 1024})\n   589→    \n   590→    root.Print(\"\")\n   591→}\n   592→```\n   593→\n   594→### Decorator\n   595→Decorator adds new functionality to objects without altering their structure.\n   596→\n   597→```go\n   598→// Component interface\n   599→type Coffee interface {\n   600→    GetCost() float64\n   601→    GetDescription() string\n   602→}\n   603→\n   604→// Concrete component\n   605→type SimpleCoffee struct{}\n   606→\n   607→func (c *SimpleCoffee) GetCost() float64 {\n   608→    return 2.0\n   609→}\n   610→\n   611→func (c *SimpleCoffee) GetDescription() string {\n   612→    return \"Simple coffee\"\n   613→}\n   614→\n   615→// Base decorator\n   616→type CoffeeDecorator struct {\n   617→    coffee Coffee\n   618→}\n   619→\n   620→func (d *CoffeeDecorator) GetCost() float64 {\n   621→    return d.coffee.GetCost()\n   622→}\n   623→\n   624→func (d *CoffeeDecorator) GetDescription() string {\n   625→    return d.coffee.GetDescription()\n   626→}\n   627→\n   628→// Concrete decorators\n   629→type MilkDecorator struct {\n   630→    CoffeeDecorator\n   631→}\n   632→\n   633→func NewMilkDecorator(coffee Coffee) *MilkDecorator {\n   634→    return &MilkDecorator{\n   635→        CoffeeDecorator: CoffeeDecorator{coffee: coffee},\n   636→    }\n   637→}\n   638→\n   639→func (m *MilkDecorator) GetCost() float64 {\n   640→    return m.coffee.GetCost() + 0.5\n   641→}\n   642→\n   643→func (m *MilkDecorator) GetDescription() string {\n   644→    return m.coffee.GetDescription() + \", milk\"\n   645→}\n   646→\n   647→type SugarDecorator struct {\n   648→    CoffeeDecorator\n   649→}\n   650→\n   651→func NewSugarDecorator(coffee Coffee) *SugarDecorator {\n   652→    return &SugarDecorator{\n   653→        CoffeeDecorator: CoffeeDecorator{coffee: coffee},\n   654→    }\n   655→}\n   656→\n   657→func (s *SugarDecorator) GetCost() float64 {\n   658→    return s.coffee.GetCost() + 0.2\n   659→}\n   660→\n   661→func (s *SugarDecorator) GetDescription() string {\n   662→    return s.coffee.GetDescription() + \", sugar\"\n   663→}\n   664→\n   665→// Usage\n   666→func main() {\n   667→    coffee := &SimpleCoffee{}\n   668→    fmt.Printf(\"%s: $%.2f\\n\", coffee.GetDescription(), coffee.GetCost())\n   669→    \n   670→    coffeeWithMilk := NewMilkDecorator(coffee)\n   671→    fmt.Printf(\"%s: $%.2f\\n\", coffeeWithMilk.GetDescription(), coffeeWithMilk.GetCost())\n   672→    \n   673→    coffeeWithMilkAndSugar := NewSugarDecorator(coffeeWithMilk)\n   674→    fmt.Printf(\"%s: $%.2f\\n\", coffeeWithMilkAndSugar.GetDescription(), coffeeWithMilkAndSugar.GetCost())\n   675→}\n   676→```\n   677→\n   678→### Facade\n   679→Facade provides a simplified interface to a complex subsystem.\n   680→\n   681→```go\n   682→// Complex subsystem components\n   683→type AccountService struct{}\n   684→\n   685→func (a *AccountService) GetAccount(id string) string {\n   686→    return fmt.Sprintf(\"Account %s\", id)\n   687→}\n   688→\n   689→func (a *AccountService) CheckBalance(id string) float64 {\n   690→    return 1000.00\n   691→}\n   692→\n   693→type SecurityService struct{}\n   694→\n   695→func (s *SecurityService) Authenticate(token string) bool {\n   696→    return token == \"valid-token\"\n   697→}\n   698→\n   699→func (s *SecurityService) Authorize(user, action string) bool {\n   700→    return true\n   701→}\n   702→\n   703→type TransactionService struct{}\n   704→\n   705→func (t *TransactionService) CreateTransaction(from, to string, amount float64) string {\n   706→    return fmt.Sprintf(\"Transaction: %s -> %s: %.2f\", from, to, amount)\n   707→}\n   708→\n   709→func (t *TransactionService) ValidateTransaction(id string) bool {\n   710→    return true\n   711→}\n   712→\n   713→type NotificationService struct{}\n   714→\n   715→func (n *NotificationService) SendEmail(to, message string) {\n   716→    fmt.Printf(\"Email to %s: %s\\n\", to, message)\n   717→}\n   718→\n   719→func (n *NotificationService) SendSMS(to, message string) {\n   720→    fmt.Printf(\"SMS to %s: %s\\n\", to, message)\n   721→}\n   722→\n   723→// Facade\n   724→type BankingFacade struct {\n   725→    account      *AccountService\n   726→    security     *SecurityService\n   727→    transaction  *TransactionService\n   728→    notification *NotificationService\n   729→}\n   730→\n   731→func NewBankingFacade() *BankingFacade {\n   732→    return &BankingFacade{\n   733→        account:      &AccountService{},\n   734→        security:     &SecurityService{},\n   735→        transaction:  &TransactionService{},\n   736→        notification: &NotificationService{},\n   737→    }\n   738→}\n   739→\n   740→func (b *BankingFacade) Transfer(token, from, to string, amount float64) error {\n   741→    // Authenticate\n   742→    if !b.security.Authenticate(token) {\n   743→        return fmt.Errorf(\"authentication failed\")\n   744→    }\n   745→    \n   746→    // Check authorization\n   747→    if !b.security.Authorize(from, \"transfer\") {\n   748→        return fmt.Errorf(\"not authorized\")\n   749→    }\n   750→    \n   751→    // Check balance\n   752→    if b.account.CheckBalance(from) < amount {\n   753→        return fmt.Errorf(\"insufficient funds\")\n   754→    }\n   755→    \n   756→    // Create transaction\n   757→    txID := b.transaction.CreateTransaction(from, to, amount)\n   758→    \n   759→    // Validate\n   760→    if !b.transaction.ValidateTransaction(txID) {\n   761→        return fmt.Errorf(\"transaction validation failed\")\n   762→    }\n   763→    \n   764→    // Notify\n   765→    b.notification.SendEmail(from, fmt.Sprintf(\"Transfer of %.2f completed\", amount))\n   766→    b.notification.SendSMS(to, fmt.Sprintf(\"Received %.2f\", amount))\n   767→    \n   768→    return nil\n   769→}\n   770→\n   771→// Usage\n   772→func main() {\n   773→    banking := NewBankingFacade()\n   774→    \n   775→    err := banking.Transfer(\"valid-token\", \"account1\", \"account2\", 100.00)\n   776→    if err != nil {\n   777→        fmt.Printf(\"Transfer failed: %v\\n\", err)\n   778→    } else {\n   779→        fmt.Println(\"Transfer successful\")\n   780→    }\n   781→}\n   782→```\n   783→\n   784→### Flyweight\n   785→Flyweight minimizes memory usage by sharing efficiently large numbers of fine-grained objects.\n   786→\n   787→```go\n   788→// Flyweight interface\n   789→type Character interface {\n   790→    Display(font string, size int, color string)\n   791→}\n   792→\n   793→// Concrete flyweight\n   794→type ConcreteCharacter struct {\n   795→    symbol rune // Intrinsic state (shared)\n   796→}\n   797→\n   798→func (c *ConcreteCharacter) Display(font string, size int, color string) {\n   799→    // Extrinsic state (passed in)\n   800→    fmt.Printf(\"Character: %c, Font: %s, Size: %d, Color: %s\\n\", \n   801→        c.symbol, font, size, color)\n   802→}\n   803→\n   804→// Flyweight factory\n   805→type CharacterFactory struct {\n   806→    characters map[rune]*ConcreteCharacter\n   807→}\n   808→\n   809→func NewCharacterFactory() *CharacterFactory {\n   810→    return &CharacterFactory{\n   811→        characters: make(map[rune]*ConcreteCharacter),\n   812→    }\n   813→}\n   814→\n   815→func (f *CharacterFactory) GetCharacter(symbol rune) Character {\n   816→    if char, exists := f.characters[symbol]; exists {\n   817→        return char\n   818→    }\n   819→    \n   820→    char := &ConcreteCharacter{symbol: symbol}\n   821→    f.characters[symbol] = char\n   822→    return char\n   823→}\n   824→\n   825→// Context that uses flyweights\n   826→type TextDocument struct {\n   827→    characters []Character\n   828→    fonts      []string\n   829→    sizes      []int\n   830→    colors     []string\n   831→}\n   832→\n   833→func (d *TextDocument) AddCharacter(char Character, font string, size int, color string) {\n   834→    d.characters = append(d.characters, char)\n   835→    d.fonts = append(d.fonts, font)\n   836→    d.sizes = append(d.sizes, size)\n   837→    d.colors = append(d.colors, color)\n   838→}\n   839→\n   840→func (d *TextDocument) Display() {\n   841→    for i, char := range d.characters {\n   842→        char.Display(d.fonts[i], d.sizes[i], d.colors[i])\n   843→    }\n   844→}\n   845→\n   846→// Usage\n   847→func main() {\n   848→    factory := NewCharacterFactory()\n   849→    doc := &TextDocument{}\n   850→    \n   851→    text := \"Hello World\"\n   852→    for _, r := range text {\n   853→        char := factory.GetCharacter(r)\n   854→        doc.AddCharacter(char, \"Arial\", 12, \"black\")\n   855→    }\n   856→    \n   857→    doc.Display()\n   858→    \n   859→    // Characters 'l' and 'o' are reused (shared instances)\n   860→    fmt.Printf(\"Total unique characters created: %d\\n\", len(factory.characters))\n   861→}\n   862→```\n   863→\n   864→### Proxy\n   865→Proxy provides a placeholder or surrogate for another object to control access to it.\n   866→\n   867→```go\n   868→// Subject interface\n   869→type Database interface {\n   870→    Query(sql string) ([]string, error)\n   871→}\n   872→\n   873→// Real subject\n   874→type RealDatabase struct {\n   875→    connectionString string\n   876→}\n   877→\n   878→func (d *RealDatabase) Query(sql string) ([]string, error) {\n   879→    fmt.Printf(\"Executing query: %s\\n\", sql)\n   880→    // Simulate database query\n   881→    return []string{\"result1\", \"result2\"}, nil\n   882→}\n   883→\n   884→// Proxy with caching\n   885→type CachingDatabaseProxy struct {\n   886→    database *RealDatabase\n   887→    cache    map[string][]string\n   888→}\n   889→\n   890→func NewCachingDatabaseProxy(connString string) *CachingDatabaseProxy {\n   891→    return &CachingDatabaseProxy{\n   892→        database: &RealDatabase{connectionString: connString},\n   893→        cache:    make(map[string][]string),\n   894→    }\n   895→}\n   896→\n   897→func (p *CachingDatabaseProxy) Query(sql string) ([]string, error) {\n   898→    // Check cache\n   899→    if results, exists := p.cache[sql]; exists {\n   900→        fmt.Printf(\"Returning cached results for: %s\\n\", sql)\n   901→        return results, nil\n   902→    }\n   903→    \n   904→    // Query real database\n   905→    results, err := p.database.Query(sql)\n   906→    if err != nil {\n   907→        return nil, err\n   908→    }\n   909→    \n   910→    // Cache results\n   911→    p.cache[sql] = results\n   912→    return results, nil\n   913→}\n   914→\n   915→// Security proxy\n   916→type SecureDatabaseProxy struct {\n   917→    database Database\n   918→    userRole string\n   919→}\n   920→\n   921→func NewSecureDatabaseProxy(db Database, role string) *SecureDatabaseProxy {\n   922→    return &SecureDatabaseProxy{\n   923→        database: db,\n   924→        userRole: role,\n   925→    }\n   926→}\n   927→\n   928→func (p *SecureDatabaseProxy) Query(sql string) ([]string, error) {\n   929→    // Check permissions\n   930→    if strings.Contains(strings.ToLower(sql), \"delete\") && p.userRole != \"admin\" {\n   931→        return nil, fmt.Errorf(\"permission denied: only admin can delete\")\n   932→    }\n   933→    \n   934→    return p.database.Query(sql)\n   935→}\n   936→\n   937→// Usage\n   938→func main() {\n   939→    // Caching proxy\n   940→    db := NewCachingDatabaseProxy(\"connection-string\")\n   941→    \n   942→    // First query hits the database\n   943→    results, _ := db.Query(\"SELECT * FROM users\")\n   944→    fmt.Println(\"Results:\", results)\n   945→    \n   946→    // Second identical query uses cache\n   947→    results, _ = db.Query(\"SELECT * FROM users\")\n   948→    fmt.Println(\"Results:\", results)\n   949→    \n   950→    // Security proxy\n   951→    secureDB := NewSecureDatabaseProxy(db, \"user\")\n   952→    _, err := secureDB.Query(\"DELETE FROM users\")\n   953→    if err != nil {\n   954→        fmt.Println(\"Error:\", err)\n   955→    }\n   956→}\n   957→```\n   958→\n   959→## Behavioral Patterns\n   960→\n   961→### Chain of Responsibility\n   962→Chain of Responsibility passes requests along a chain of handlers until one handles it.\n   963→\n   964→```go\n   965→// Handler interface\n   966→type Handler interface {\n   967→    SetNext(Handler) Handler\n   968→    Handle(request string) string\n   969→}\n   970→\n   971→// Base handler\n   972→type BaseHandler struct {\n   973→    next Handler\n   974→}\n   975→\n   976→func (h *BaseHandler) SetNext(next Handler) Handler {\n   977→    h.next = next\n   978→    return next\n   979→}\n   980→\n   981→func (h *BaseHandler) Handle(request string) string {\n   982→    if h.next != nil {\n   983→        return h.next.Handle(request)\n   984→    }\n   985→    return \"\"\n   986→}\n   987→\n   988→// Concrete handlers\n   989→type AuthenticationHandler struct {\n   990→    BaseHandler\n   991→}\n   992→\n   993→func (h *AuthenticationHandler) Handle(request string) string {\n   994→    if request == \"auth\" {\n   995→        return \"Authentication successful\"\n   996→    }\n   997→    return h.BaseHandler.Handle(request)\n   998→}\n   999→\n  1000→type AuthorizationHandler struct {\n  1001→    BaseHandler\n  1002→}\n  1003→\n  1004→func (h *AuthorizationHandler) Handle(request string) string {\n  1005→    if request == \"authz\" {\n  1006→        return \"Authorization granted\"\n  1007→    }\n  1008→    return h.BaseHandler.Handle(request)\n  1009→}\n  1010→\n  1011→type ValidationHandler struct {\n  1012→    BaseHandler\n  1013→}\n  1014→\n  1015→func (h *ValidationHandler) Handle(request string) string {\n  1016→    if request == \"validate\" {\n  1017→        return \"Validation passed\"\n  1018→    }\n  1019→    return h.BaseHandler.Handle(request)\n  1020→}\n  1021→\n  1022→// Usage\n  1023→func main() {\n  1024→    auth := &AuthenticationHandler{}\n  1025→    authz := &AuthorizationHandler{}\n  1026→    valid := &ValidationHandler{}\n  1027→    \n  1028→    // Build chain\n  1029→    auth.SetNext(authz).SetNext(valid)\n  1030→    \n  1031→    // Process requests\n  1032→    fmt.Println(auth.Handle(\"auth\"))     // Handled by auth\n  1033→    fmt.Println(auth.Handle(\"authz\"))    // Handled by authz\n  1034→    fmt.Println(auth.Handle(\"validate\")) // Handled by valid\n  1035→    fmt.Println(auth.Handle(\"unknown\"))  // Not handled\n  1036→}\n  1037→```\n  1038→\n  1039→### Command\n  1040→Command encapsulates a request as an object, letting you parameterize clients with different requests.\n  1041→\n  1042→```go\n  1043→// Command interface\n  1044→type Command interface {\n  1045→    Execute() error\n  1046→    Undo() error\n  1047→}\n  1048→\n  1049→// Receiver\n  1050→type Light struct {\n  1051→    isOn bool\n  1052→}\n  1053→\n  1054→func (l *Light) TurnOn() {\n  1055→    l.isOn = true\n  1056→    fmt.Println(\"Light is on\")\n  1057→}\n  1058→\n  1059→func (l *Light) TurnOff() {\n  1060→    l.isOn = false\n  1061→    fmt.Println(\"Light is off\")\n  1062→}\n  1063→\n  1064→// Concrete commands\n  1065→type TurnOnCommand struct {\n  1066→    light *Light\n  1067→}\n  1068→\n  1069→func (c *TurnOnCommand) Execute() error {\n  1070→    c.light.TurnOn()\n  1071→    return nil\n  1072→}\n  1073→\n  1074→func (c *TurnOnCommand) Undo() error {\n  1075→    c.light.TurnOff()\n  1076→    return nil\n  1077→}\n  1078→\n  1079→type TurnOffCommand struct {\n  1080→    light *Light\n  1081→}\n  1082→\n  1083→func (c *TurnOffCommand) Execute() error {\n  1084→    c.light.TurnOff()\n  1085→    return nil\n  1086→}\n  1087→\n  1088→func (c *TurnOffCommand) Undo() error {\n  1089→    c.light.TurnOn()\n  1090→    return nil\n  1091→}\n  1092→\n  1093→// Invoker\n  1094→type RemoteControl struct {\n  1095→    commands []Command\n  1096→    history  []Command\n  1097→}\n  1098→\n  1099→func (r *RemoteControl) SetCommand(slot int, cmd Command) {\n  1100→    if slot >= len(r.commands) {\n  1101→        r.commands = append(r.commands, make([]Command, slot-len(r.commands)+1)...)\n  1102→    }\n  1103→    r.commands[slot] = cmd\n  1104→}\n  1105→\n  1106→func (r *RemoteControl) PressButton(slot int) {\n  1107→    if slot < len(r.commands) && r.commands[slot] != nil {\n  1108→        r.commands[slot].Execute()\n  1109→        r.history = append(r.history, r.commands[slot])\n  1110→    }\n  1111→}\n  1112→\n  1113→func (r *RemoteControl) PressUndo() {\n  1114→    if len(r.history) > 0 {\n  1115→        lastCommand := r.history[len(r.history)-1]\n  1116→        lastCommand.Undo()\n  1117→        r.history = r.history[:len(r.history)-1]\n  1118→    }\n  1119→}\n  1120→\n  1121→// Macro command\n  1122→type MacroCommand struct {\n  1123→    commands []Command\n  1124→}\n  1125→\n  1126→func (m *MacroCommand) Execute() error {\n  1127→    for _, cmd := range m.commands {\n  1128→        if err := cmd.Execute(); err != nil {\n  1129→            return err\n  1130→        }\n  1131→    }\n  1132→    return nil\n  1133→}\n  1134→\n  1135→func (m *MacroCommand) Undo() error {\n  1136→    // Undo in reverse order\n  1137→    for i := len(m.commands) - 1; i >= 0; i-- {\n  1138→        if err := m.commands[i].Undo(); err != nil {\n  1139→            return err\n  1140→        }\n  1141→    }\n  1142→    return nil\n  1143→}\n  1144→\n  1145→// Usage\n  1146→func main() {\n  1147→    light := &Light{}\n  1148→    remote := &RemoteControl{}\n  1149→    \n  1150→    turnOn := &TurnOnCommand{light: light}\n  1151→    turnOff := &TurnOffCommand{light: light}\n  1152→    \n  1153→    remote.SetCommand(0, turnOn)\n  1154→    remote.SetCommand(1, turnOff)\n  1155→    \n  1156→    remote.PressButton(0) // Turn on\n  1157→    remote.PressButton(1) // Turn off\n  1158→    remote.PressUndo()    // Turn on again\n  1159→}\n  1160→```\n  1161→\n  1162→### Iterator\n  1163→Iterator provides a way to access elements of a collection sequentially without exposing its underlying representation.\n  1164→\n  1165→```go\n  1166→// Iterator interface\n  1167→type Iterator[T any] interface {\n  1168→    HasNext() bool\n  1169→    Next() T\n  1170→}\n  1171→\n  1172→// Collection interface\n  1173→type Collection[T any] interface {\n  1174→    CreateIterator() Iterator[T]\n  1175→}\n  1176→\n  1177→// Concrete collection\n  1178→type BookCollection struct {\n  1179→    books []string\n  1180→}\n  1181→\n  1182→func (c *BookCollection) Add(book string) {\n  1183→    c.books = append(c.books, book)\n  1184→}\n  1185→\n  1186→func (c *BookCollection) CreateIterator() Iterator[string] {\n  1187→    return &BookIterator{\n  1188→        collection: c,\n  1189→        index:      0,\n  1190→    }\n  1191→}\n  1192→\n  1193→// Concrete iterator\n  1194→type BookIterator struct {\n  1195→    collection *BookCollection\n  1196→    index      int\n  1197→}\n  1198→\n  1199→func (i *BookIterator) HasNext() bool {\n  1200→    return i.index < len(i.collection.books)\n  1201→}\n  1202→\n  1203→func (i *BookIterator) Next() string {\n  1204→    if i.HasNext() {\n  1205→        book := i.collection.books[i.index]\n  1206→        i.index++\n  1207→        return book\n  1208→    }\n  1209→    return \"\"\n  1210→}\n  1211→\n  1212→// Usage with channels (Go idiomatic)\n  1213→type ChannelIterator[T any] struct {\n  1214→    ch <-chan T\n  1215→    current T\n  1216→    hasNext bool\n  1217→}\n  1218→\n  1219→func NewChannelIterator[T any](items []T) *ChannelIterator[T] {\n  1220→    ch := make(chan T)\n  1221→    go func() {\n  1222→        for _, item := range items {\n  1223→            ch <- item\n  1224→        }\n  1225→        close(ch)\n  1226→    }()\n  1227→    \n  1228→    iter := &ChannelIterator[T]{ch: ch}\n  1229→    iter.advance()\n  1230→    return iter\n  1231→}\n  1232→\n  1233→func (i *ChannelIterator[T]) advance() {\n  1234→    i.current, i.hasNext = <-i.ch\n  1235→}\n  1236→\n  1237→func (i *ChannelIterator[T]) HasNext() bool {\n  1238→    return i.hasNext\n  1239→}\n  1240→\n  1241→func (i *ChannelIterator[T]) Next() T {\n  1242→    current := i.current\n  1243→    i.advance()\n  1244→    return current\n  1245→}\n  1246→\n  1247→// Usage\n  1248→func main() {\n  1249→    // Traditional iterator\n  1250→    collection := &BookCollection{}\n  1251→    collection.Add(\"Design Patterns\")\n  1252→    collection.Add(\"Clean Code\")\n  1253→    collection.Add(\"The Pragmatic Programmer\")\n  1254→    \n  1255→    iterator := collection.CreateIterator()\n  1256→    for iterator.HasNext() {\n  1257→        fmt.Println(iterator.Next())\n  1258→    }\n  1259→    \n  1260→    // Channel-based iterator\n  1261→    numbers := []int{1, 2, 3, 4, 5}\n  1262→    numIter := NewChannelIterator(numbers)\n  1263→    for numIter.HasNext() {\n  1264→        fmt.Println(numIter.Next())\n  1265→    }\n  1266→}\n  1267→```\n  1268→\n  1269→### Mediator\n  1270→Mediator defines how a set of objects interact, promoting loose coupling.\n  1271→\n  1272→```go\n  1273→// Mediator interface\n  1274→type ChatRoomMediator interface {\n  1275→    SendMessage(msg string, user User)\n  1276→    AddUser(user User)\n  1277→}\n  1278→\n  1279→// Colleague interface\n  1280→type User interface {\n  1281→    Send(msg string)\n  1282→    Receive(msg string)\n  1283→    SetMediator(mediator ChatRoomMediator)\n  1284→}\n  1285→\n  1286→// Concrete mediator\n  1287→type ChatRoom struct {\n  1288→    users []User\n  1289→}\n  1290→\n  1291→func (c *ChatRoom) SendMessage(msg string, sender User) {\n  1292→    for _, user := range c.users {\n  1293→        // Don't send message back to sender\n  1294→        if user != sender {\n  1295→            user.Receive(msg)\n  1296→        }\n  1297→    }\n  1298→}\n  1299→\n  1300→func (c *ChatRoom) AddUser(user User) {\n  1301→    c.users = append(c.users, user)\n  1302→    user.SetMediator(c)\n  1303→}\n  1304→\n  1305→// Concrete colleague\n  1306→type ChatUser struct {\n  1307→    name     string\n  1308→    mediator ChatRoomMediator\n  1309→}\n  1310→\n  1311→func NewChatUser(name string) *ChatUser {\n  1312→    return &ChatUser{name: name}\n  1313→}\n  1314→\n  1315→func (u *ChatUser) Send(msg string) {\n  1316→    fmt.Printf(\"%s sends: %s\\n\", u.name, msg)\n  1317→    if u.mediator != nil {\n  1318→        u.mediator.SendMessage(msg, u)\n  1319→    }\n  1320→}\n  1321→\n  1322→func (u *ChatUser) Receive(msg string) {\n  1323→    fmt.Printf(\"%s receives: %s\\n\", u.name, msg)\n  1324→}\n  1325→\n  1326→func (u *ChatUser) SetMediator(mediator ChatRoomMediator) {\n  1327→    u.mediator = mediator\n  1328→}\n  1329→\n  1330→// Usage\n  1331→func main() {\n  1332→    chatRoom := &ChatRoom{}\n  1333→    \n  1334→    alice := NewChatUser(\"Alice\")\n  1335→    bob := NewChatUser(\"Bob\")\n  1336→    charlie := NewChatUser(\"Charlie\")\n  1337→    \n  1338→    chatRoom.AddUser(alice)\n  1339→    chatRoom.AddUser(bob)\n  1340→    chatRoom.AddUser(charlie)\n  1341→    \n  1342→    alice.Send(\"Hello everyone!\")\n  1343→    bob.Send(\"Hey Alice!\")\n  1344→}\n  1345→```\n  1346→\n  1347→### Memento\n  1348→Memento captures and externalizes an object's internal state for later restoration.\n  1349→\n  1350→```go\n  1351→// Memento\n  1352→type EditorMemento struct {\n  1353→    content string\n  1354→    cursor  int\n  1355→}\n  1356→\n  1357→// Originator\n  1358→type TextEditor struct {\n  1359→    content string\n  1360→    cursor  int\n  1361→}\n  1362→\n  1363→func (e *TextEditor) Type(text string) {\n  1364→    e.content = e.content[:e.cursor] + text + e.content[e.cursor:]\n  1365→    e.cursor += len(text)\n  1366→}\n  1367→\n  1368→func (e *TextEditor) Delete(length int) {\n  1369→    if e.cursor >= length {\n  1370→        e.content = e.content[:e.cursor-length] + e.content[e.cursor:]\n  1371→        e.cursor -= length\n  1372→    }\n  1373→}\n  1374→\n  1375→func (e *TextEditor) Save() *EditorMemento {\n  1376→    return &EditorMemento{\n  1377→        content: e.content,\n  1378→        cursor:  e.cursor,\n  1379→    }\n  1380→}\n  1381→\n  1382→func (e *TextEditor) Restore(memento *EditorMemento) {\n  1383→    e.content = memento.content\n  1384→    e.cursor = memento.cursor\n  1385→}\n  1386→\n  1387→func (e *TextEditor) String() string {\n  1388→    return fmt.Sprintf(\"Content: %s (cursor at %d)\", e.content, e.cursor)\n  1389→}\n  1390→\n  1391→// Caretaker\n  1392→type History struct {\n  1393→    mementos []*EditorMemento\n  1394→    current  int\n  1395→}\n  1396→\n  1397→func (h *History) Push(memento *EditorMemento) {\n  1398→    // Remove any states after current position\n  1399→    h.mementos = h.mementos[:h.current+1]\n  1400→    h.mementos = append(h.mementos, memento)\n  1401→    h.current++\n  1402→}\n  1403→\n  1404→func (h *History) Undo() *EditorMemento {\n  1405→    if h.current > 0 {\n  1406→        h.current--\n  1407→        return h.mementos[h.current]\n  1408→    }\n  1409→    return nil\n  1410→}\n  1411→\n  1412→func (h *History) Redo() *EditorMemento {\n  1413→    if h.current < len(h.mementos)-1 {\n  1414→        h.current++\n  1415→        return h.mementos[h.current]\n  1416→    }\n  1417→    return nil\n  1418→}\n  1419→\n  1420→// Usage\n  1421→func main() {\n  1422→    editor := &TextEditor{}\n  1423→    history := &History{}\n  1424→    \n  1425→    // Initial state\n  1426→    history.Push(editor.Save())\n  1427→    \n  1428→    editor.Type(\"Hello \")\n  1429→    history.Push(editor.Save())\n  1430→    \n  1431→    editor.Type(\"World\")\n  1432→    history.Push(editor.Save())\n  1433→    \n  1434→    editor.Type(\"!\")\n  1435→    history.Push(editor.Save())\n  1436→    \n  1437→    fmt.Println(editor)\n  1438→    \n  1439→    // Undo\n  1440→    if memento := history.Undo(); memento != nil {\n  1441→        editor.Restore(memento)\n  1442→        fmt.Println(\"After undo:\", editor)\n  1443→    }\n  1444→    \n  1445→    // Undo again\n  1446→    if memento := history.Undo(); memento != nil {\n  1447→        editor.Restore(memento)\n  1448→        fmt.Println(\"After undo:\", editor)\n  1449→    }\n  1450→    \n  1451→    // Redo\n  1452→    if memento := history.Redo(); memento != nil {\n  1453→        editor.Restore(memento)\n  1454→        fmt.Println(\"After redo:\", editor)\n  1455→    }\n  1456→}\n  1457→```\n  1458→\n  1459→### Observer\n  1460→Observer defines a one-to-many dependency between objects where state changes are automatically notified.\n  1461→\n  1462→```go\n  1463→// Observer interface\n  1464→type Observer interface {\n  1465→    Update(event string, data interface{})\n  1466→}\n  1467→\n  1468→// Subject interface\n  1469→type Subject interface {\n  1470→    Attach(observer Observer)\n  1471→    Detach(observer Observer)\n  1472→    Notify(event string, data interface{})\n  1473→}\n  1474→\n  1475→// Concrete subject\n  1476→type StockPrice struct {\n  1477→    observers map[Observer]bool\n  1478→    symbol    string\n  1479→    price     float64\n  1480→}\n  1481→\n  1482→func NewStockPrice(symbol string) *StockPrice {\n  1483→    return &StockPrice{\n  1484→        observers: make(map[Observer]bool),\n  1485→        symbol:    symbol,\n  1486→    }\n  1487→}\n  1488→\n  1489→func (s *StockPrice) Attach(observer Observer) {\n  1490→    s.observers[observer] = true\n  1491→}\n  1492→\n  1493→func (s *StockPrice) Detach(observer Observer) {\n  1494→    delete(s.observers, observer)\n  1495→}\n  1496→\n  1497→func (s *StockPrice) Notify(event string, data interface{}) {\n  1498→    for observer := range s.observers {\n  1499→        observer.Update(event, data)\n  1500→    }\n  1501→}\n  1502→\n  1503→func (s *StockPrice) SetPrice(price float64) {\n  1504→    oldPrice := s.price\n  1505→    s.price = price\n  1506→    \n  1507→    change := ((price - oldPrice) / oldPrice) * 100\n  1508→    s.Notify(\"price_changed\", map[string]interface{}{\n  1509→        \"symbol\":    s.symbol,\n  1510→        \"old_price\": oldPrice,\n  1511→        \"new_price\": price,\n  1512→        \"change\":    change,\n  1513→    })\n  1514→}\n  1515→\n  1516→// Concrete observers\n  1517→type InvestorAlert struct {\n  1518→    name string\n  1519→}\n  1520→\n  1521→func (i *InvestorAlert) Update(event string, data interface{}) {\n  1522→    if event == \"price_changed\" {\n  1523→        priceData := data.(map[string]interface{})\n  1524→        fmt.Printf(\"[%s] Price alert: %s changed from %.2f to %.2f (%.2f%%)\\n\",\n  1525→            i.name,\n  1526→            priceData[\"symbol\"],\n  1527→            priceData[\"old_price\"],\n  1528→            priceData[\"new_price\"],\n  1529→            priceData[\"change\"])\n  1530→    }\n  1531→}\n  1532→\n  1533→type TradingBot struct {\n  1534→    threshold float64\n  1535→}\n  1536→\n  1537→func (t *TradingBot) Update(event string, data interface{}) {\n  1538→    if event == \"price_changed\" {\n  1539→        priceData := data.(map[string]interface{})\n  1540→        change := priceData[\"change\"].(float64)\n  1541→        \n  1542→        if change > t.threshold {\n  1543→            fmt.Printf(\"[Bot] BUY signal: price increased by %.2f%%\\n\", change)\n  1544→        } else if change < -t.threshold {\n  1545→            fmt.Printf(\"[Bot] SELL signal: price decreased by %.2f%%\\n\", change)\n  1546→        }\n  1547→    }\n  1548→}\n  1549→\n  1550→// Usage\n  1551→func main() {\n  1552→    stock := NewStockPrice(\"AAPL\")\n  1553→    \n  1554→    investor := &InvestorAlert{name: \"John\"}\n  1555→    bot := &TradingBot{threshold: 5.0}\n  1556→    \n  1557→    stock.Attach(investor)\n  1558→    stock.Attach(bot)\n  1559→    \n  1560→    stock.SetPrice(100.00)\n  1561→    stock.SetPrice(105.50)\n  1562→    stock.SetPrice(98.00)\n  1563→}\n  1564→```\n  1565→\n  1566→### State\n  1567→State allows an object to alter its behavior when its internal state changes.\n  1568→\n  1569→```go\n  1570→// State interface\n  1571→type State interface {\n  1572→    InsertCoin(m *VendingMachine)\n  1573→    SelectProduct(m *VendingMachine)\n  1574→    Dispense(m *VendingMachine)\n  1575→    Cancel(m *VendingMachine)\n  1576→}\n  1577→\n  1578→// Context\n  1579→type VendingMachine struct {\n  1580→    state    State\n  1581→    coins    int\n  1582→    products int\n  1583→}\n  1584→\n  1585→func NewVendingMachine(products int) *VendingMachine {\n  1586→    vm := &VendingMachine{\n  1587→        products: products,\n  1588→    }\n  1589→    vm.state = &IdleState{}\n  1590→    return vm\n  1591→}\n  1592→\n  1593→func (m *VendingMachine) SetState(state State) {\n  1594→    m.state = state\n  1595→    fmt.Printf(\"State changed to: %T\\n\", state)\n  1596→}\n  1597→\n  1598→func (m *VendingMachine) InsertCoin() {\n  1599→    m.state.InsertCoin(m)\n  1600→}\n  1601→\n  1602→func (m *VendingMachine) SelectProduct() {\n  1603→    m.state.SelectProduct(m)\n  1604→}\n  1605→\n  1606→func (m *VendingMachine) Dispense() {\n  1607→    m.state.Dispense(m)\n  1608→}\n  1609→\n  1610→func (m *VendingMachine) Cancel() {\n  1611→    m.state.Cancel(m)\n  1612→}\n  1613→\n  1614→// Concrete states\n  1615→type IdleState struct{}\n  1616→\n  1617→func (s *IdleState) InsertCoin(m *VendingMachine) {\n  1618→    fmt.Println(\"Coin inserted\")\n  1619→    m.coins++\n  1620→    m.SetState(&HasCoinState{})\n  1621→}\n  1622→\n  1623→func (s *IdleState) SelectProduct(m *VendingMachine) {\n  1624→    fmt.Println(\"Please insert coin first\")\n  1625→}\n  1626→\n  1627→func (s *IdleState) Dispense(m *VendingMachine) {\n  1628→    fmt.Println(\"Please insert coin and select product\")\n  1629→}\n  1630→\n  1631→func (s *IdleState) Cancel(m *VendingMachine) {\n  1632→    fmt.Println(\"Nothing to cancel\")\n  1633→}\n  1634→\n  1635→type HasCoinState struct{}\n  1636→\n  1637→func (s *HasCoinState) InsertCoin(m *VendingMachine) {\n  1638→    fmt.Println(\"Coin already inserted\")\n  1639→}\n  1640→\n  1641→func (s *HasCoinState) SelectProduct(m *VendingMachine) {\n  1642→    if m.products > 0 {\n  1643→        fmt.Println(\"Product selected\")\n  1644→        m.SetState(&DispensingState{})\n  1645→        m.Dispense()\n  1646→    } else {\n  1647→        fmt.Println(\"Out of products\")\n  1648→        m.Cancel()\n  1649→    }\n  1650→}\n  1651→\n  1652→func (s *HasCoinState) Dispense(m *VendingMachine) {\n  1653→    fmt.Println(\"Please select product first\")\n  1654→}\n  1655→\n  1656→func (s *HasCoinState) Cancel(m *VendingMachine) {\n  1657→    fmt.Println(\"Returning coin\")\n  1658→    m.coins--\n  1659→    m.SetState(&IdleState{})\n  1660→}\n  1661→\n  1662→type DispensingState struct{}\n  1663→\n  1664→func (s *DispensingState) InsertCoin(m *VendingMachine) {\n  1665→    fmt.Println(\"Please wait, dispensing product\")\n  1666→}\n  1667→\n  1668→func (s *DispensingState) SelectProduct(m *VendingMachine) {\n  1669→    fmt.Println(\"Please wait, dispensing product\")\n  1670→}\n  1671→\n  1672→func (s *DispensingState) Dispense(m *VendingMachine) {\n  1673→    fmt.Println(\"Dispensing product\")\n  1674→    m.products--\n  1675→    m.coins--\n  1676→    m.SetState(&IdleState{})\n  1677→}\n  1678→\n  1679→func (s *DispensingState) Cancel(m *VendingMachine) {\n  1680→    fmt.Println(\"Cannot cancel, already dispensing\")\n  1681→}\n  1682→\n  1683→// Usage\n  1684→func main() {\n  1685→    machine := NewVendingMachine(2)\n  1686→    \n  1687→    machine.SelectProduct() // Error: need coin\n  1688→    machine.InsertCoin()\n  1689→    machine.SelectProduct() // OK, dispenses\n  1690→    \n  1691→    machine.InsertCoin()\n  1692→    machine.Cancel() // Returns coin\n  1693→}\n  1694→```\n  1695→\n  1696→### Strategy\n  1697→Strategy defines a family of algorithms and makes them interchangeable.\n  1698→\n  1699→```go\n  1700→// Strategy interface\n  1701→type PaymentStrategy interface {\n  1702→    Pay(amount float64) error\n  1703→    GetName() string\n  1704→}\n  1705→\n  1706→// Concrete strategies\n  1707→type CreditCardStrategy struct {\n  1708→    number string\n  1709→    cvv    string\n  1710→}\n  1711→\n  1712→func (c *CreditCardStrategy) Pay(amount float64) error {\n  1713→    fmt.Printf(\"Paying $%.2f with credit card %s\\n\", amount, c.number)\n  1714→    // Payment logic\n  1715→    return nil\n  1716→}\n  1717→\n  1718→func (c *CreditCardStrategy) GetName() string {\n  1719→    return \"Credit Card\"\n  1720→}\n  1721→\n  1722→type PayPalStrategy struct {\n  1723→    email string\n  1724→}\n  1725→\n  1726→func (p *PayPalStrategy) Pay(amount float64) error {\n  1727→    fmt.Printf(\"Paying $%.2f with PayPal account %s\\n\", amount, p.email)\n  1728→    // Payment logic\n  1729→    return nil\n  1730→}\n  1731→\n  1732→func (p *PayPalStrategy) GetName() string {\n  1733→    return \"PayPal\"\n  1734→}\n  1735→\n  1736→type CryptoStrategy struct {\n  1737→    walletAddress string\n  1738→}\n  1739→\n  1740→func (c *CryptoStrategy) Pay(amount float64) error {\n  1741→    fmt.Printf(\"Paying $%.2f with crypto wallet %s\\n\", amount, c.walletAddress)\n  1742→    // Payment logic\n  1743→    return nil\n  1744→}\n  1745→\n  1746→func (c *CryptoStrategy) GetName() string {\n  1747→    return \"Cryptocurrency\"\n  1748→}\n  1749→\n  1750→// Context\n  1751→type ShoppingCart struct {\n  1752→    items    []string\n  1753→    total    float64\n  1754→    strategy PaymentStrategy\n  1755→}\n  1756→\n  1757→func (s *ShoppingCart) AddItem(item string, price float64) {\n  1758→    s.items = append(s.items, item)\n  1759→    s.total += price\n  1760→}\n  1761→\n  1762→func (s *ShoppingCart) SetPaymentStrategy(strategy PaymentStrategy) {\n  1763→    s.strategy = strategy\n  1764→    fmt.Printf(\"Payment method set to: %s\\n\", strategy.GetName())\n  1765→}\n  1766→\n  1767→func (s *ShoppingCart) Checkout() error {\n  1768→    if s.strategy == nil {\n  1769→        return fmt.Errorf(\"no payment method selected\")\n  1770→    }\n  1771→    \n  1772→    fmt.Printf(\"Total: $%.2f\\n\", s.total)\n  1773→    return s.strategy.Pay(s.total)\n  1774→}\n  1775→\n  1776→// Usage\n  1777→func main() {\n  1778→    cart := &ShoppingCart{}\n  1779→    cart.AddItem(\"Laptop\", 999.99)\n  1780→    cart.AddItem(\"Mouse\", 29.99)\n  1781→    \n  1782→    // Pay with credit card\n  1783→    cart.SetPaymentStrategy(&CreditCardStrategy{\n  1784→        number: \"1234-5678-9012-3456\",\n  1785→        cvv:    \"123\",\n  1786→    })\n  1787→    cart.Checkout()\n  1788→    \n  1789→    // Change to PayPal\n  1790→    cart.SetPaymentStrategy(&PayPalStrategy{\n  1791→        email: \"user@example.com\",\n  1792→    })\n  1793→    cart.Checkout()\n  1794→}\n  1795→```\n  1796→\n  1797→### Template Method\n  1798→Template Method defines the skeleton of an algorithm in a base class, letting subclasses override specific steps.\n  1799→\n  1800→```go\n  1801→// Abstract class (using struct embedding in Go)\n  1802→type DataProcessor struct {\n  1803→    // Define the interface that subclasses must implement\n  1804→    processor DataProcessorInterface\n  1805→}\n  1806→\n  1807→type DataProcessorInterface interface {\n  1808→    Extract() ([]byte, error)\n  1809→    Transform(data []byte) ([]byte, error)\n  1810→    Load(data []byte) error\n  1811→}\n  1812→\n  1813→// Template method\n  1814→func (d *DataProcessor) Process() error {\n  1815→    // Extract\n  1816→    data, err := d.processor.Extract()\n  1817→    if err != nil {\n  1818→        return fmt.Errorf(\"extraction failed: %w\", err)\n  1819→    }\n  1820→    \n  1821→    // Transform\n  1822→    transformed, err := d.processor.Transform(data)\n  1823→    if err != nil {\n  1824→        return fmt.Errorf(\"transformation failed: %w\", err)\n  1825→    }\n  1826→    \n  1827→    // Load\n  1828→    if err := d.processor.Load(transformed); err != nil {\n  1829→        return fmt.Errorf(\"loading failed: %w\", err)\n  1830→    }\n  1831→    \n  1832→    return nil\n  1833→}\n  1834→\n  1835→// Concrete implementation - CSV Processor\n  1836→type CSVProcessor struct {\n  1837→    DataProcessor\n  1838→    filename string\n  1839→}\n  1840→\n  1841→func NewCSVProcessor(filename string) *CSVProcessor {\n  1842→    p := &CSVProcessor{filename: filename}\n  1843→    p.DataProcessor.processor = p\n  1844→    return p\n  1845→}\n  1846→\n  1847→func (c *CSVProcessor) Extract() ([]byte, error) {\n  1848→    fmt.Printf(\"Extracting data from CSV file: %s\\n\", c.filename)\n  1849→    // Read CSV file\n  1850→    return []byte(\"csv,data,here\"), nil\n  1851→}\n  1852→\n  1853→func (c *CSVProcessor) Transform(data []byte) ([]byte, error) {\n  1854→    fmt.Println(\"Transforming CSV data\")\n  1855→    // Transform CSV data\n  1856→    return []byte(\"transformed csv data\"), nil\n  1857→}\n  1858→\n  1859→func (c *CSVProcessor) Load(data []byte) error {\n  1860→    fmt.Println(\"Loading CSV data to database\")\n  1861→    // Load to database\n  1862→    return nil\n  1863→}\n  1864→\n  1865→// Concrete implementation - JSON Processor\n  1866→type JSONProcessor struct {\n  1867→    DataProcessor\n  1868→    url string\n  1869→}\n  1870→\n  1871→func NewJSONProcessor(url string) *JSONProcessor {\n  1872→    p := &JSONProcessor{url: url}\n  1873→    p.DataProcessor.processor = p\n  1874→    return p\n  1875→}\n  1876→\n  1877→func (j *JSONProcessor) Extract() ([]byte, error) {\n  1878→    fmt.Printf(\"Fetching JSON from API: %s\\n\", j.url)\n  1879→    // Fetch from API\n  1880→    return []byte(`{\"data\": \"value\"}`), nil\n  1881→}\n  1882→\n  1883→func (j *JSONProcessor) Transform(data []byte) ([]byte, error) {\n  1884→    fmt.Println(\"Transforming JSON data\")\n  1885→    // Transform JSON\n  1886→    return []byte(\"transformed json\"), nil\n  1887→}\n  1888→\n  1889→func (j *JSONProcessor) Load(data []byte) error {\n  1890→    fmt.Println(\"Loading JSON data to cache\")\n  1891→    // Load to cache\n  1892→    return nil\n  1893→}\n  1894→\n  1895→// Usage\n  1896→func main() {\n  1897→    csvProcessor := NewCSVProcessor(\"data.csv\")\n  1898→    if err := csvProcessor.Process(); err != nil {\n  1899→        fmt.Printf(\"CSV processing failed: %v\\n\", err)\n  1900→    }\n  1901→    \n  1902→    fmt.Println()\n  1903→    \n  1904→    jsonProcessor := NewJSONProcessor(\"https://api.example.com/data\")\n  1905→    if err := jsonProcessor.Process(); err != nil {\n  1906→        fmt.Printf(\"JSON processing failed: %v\\n\", err)\n  1907→    }\n  1908→}\n  1909→```\n  1910→\n  1911→### Visitor\n  1912→Visitor lets you define new operations without changing the classes of elements on which it operates.\n  1913→\n  1914→```go\n  1915→// Element interface\n  1916→type Shape interface {\n  1917→    Accept(visitor Visitor)\n  1918→}\n  1919→\n  1920→// Visitor interface\n  1921→type Visitor interface {\n  1922→    VisitCircle(c *Circle)\n  1923→    VisitRectangle(r *Rectangle)\n  1924→    VisitTriangle(t *Triangle)\n  1925→}\n  1926→\n  1927→// Concrete elements\n  1928→type Circle struct {\n  1929→    Radius float64\n  1930→}\n  1931→\n  1932→func (c *Circle) Accept(visitor Visitor) {\n  1933→    visitor.VisitCircle(c)\n  1934→}\n  1935→\n  1936→type Rectangle struct {\n  1937→    Width, Height float64\n  1938→}\n  1939→\n  1940→func (r *Rectangle) Accept(visitor Visitor) {\n  1941→    visitor.VisitRectangle(r)\n  1942→}\n  1943→\n  1944→type Triangle struct {\n  1945→    Base, Height float64\n  1946→}\n  1947→\n  1948→func (t *Triangle) Accept(visitor Visitor) {\n  1949→    visitor.VisitTriangle(t)\n  1950→}\n  1951→\n  1952→// Concrete visitors\n  1953→type AreaCalculator struct {\n  1954→    totalArea float64\n  1955→}\n  1956→\n  1957→func (a *AreaCalculator) VisitCircle(c *Circle) {\n  1958→    area := 3.14159 * c.Radius * c.Radius\n  1959→    fmt.Printf(\"Circle area: %.2f\\n\", area)\n  1960→    a.totalArea += area\n  1961→}\n  1962→\n  1963→func (a *AreaCalculator) VisitRectangle(r *Rectangle) {\n  1964→    area := r.Width * r.Height\n  1965→    fmt.Printf(\"Rectangle area: %.2f\\n\", area)\n  1966→    a.totalArea += area\n  1967→}\n  1968→\n  1969→func (a *AreaCalculator) VisitTriangle(t *Triangle) {\n  1970→    area := 0.5 * t.Base * t.Height\n  1971→    fmt.Printf(\"Triangle area: %.2f\\n\", area)\n  1972→    a.totalArea += area\n  1973→}\n  1974→\n  1975→type PerimeterCalculator struct {\n  1976→    totalPerimeter float64\n  1977→}\n  1978→\n  1979→func (p *PerimeterCalculator) VisitCircle(c *Circle) {\n  1980→    perimeter := 2 * 3.14159 * c.Radius\n  1981→    fmt.Printf(\"Circle perimeter: %.2f\\n\", perimeter)\n  1982→    p.totalPerimeter += perimeter\n  1983→}\n  1984→\n  1985→func (p *PerimeterCalculator) VisitRectangle(r *Rectangle) {\n  1986→    perimeter := 2 * (r.Width + r.Height)\n  1987→    fmt.Printf(\"Rectangle perimeter: %.2f\\n\", perimeter)\n  1988→    p.totalPerimeter += perimeter\n  1989→}\n  1990→\n  1991→func (p *PerimeterCalculator) VisitTriangle(t *Triangle) {\n  1992→    // Simplified: assuming equilateral triangle\n  1993→    perimeter := 3 * t.Base\n  1994→    fmt.Printf(\"Triangle perimeter: %.2f\\n\", perimeter)\n  1995→    p.totalPerimeter += perimeter\n  1996→}\n  1997→\n  1998→// Usage\n  1999→func main() {\n  2000→    shapes := []Shape{\n  2001→        &Circle{Radius: 5},\n  2002→        &Rectangle{Width: 10, Height: 5},\n  2003→        &Triangle{Base: 6, Height: 4},\n  2004→    }\n  2005→    \n  2006→    areaCalc := &AreaCalculator{}\n  2007→    for _, shape := range shapes {\n  2008→        shape.Accept(areaCalc)\n  2009→    }\n  2010→    fmt.Printf(\"Total area: %.2f\\n\\n\", areaCalc.totalArea)\n  2011→    \n  2012→    perimCalc := &PerimeterCalculator{}\n  2013→    for _, shape := range shapes {\n  2014→        shape.Accept(perimCalc)\n  2015→    }\n  2016→    fmt.Printf(\"Total perimeter: %.2f\\n\", perimCalc.totalPerimeter)\n  2017→}\n  2018→```\n  2019→\n  2020→## Architectural Patterns\n  2021→\n  2022→### Repository Pattern\n  2023→Repository encapsulates data access logic and provides a more object-oriented view of the persistence layer.\n  2024→\n  2025→```go\n  2026→// Domain model\n  2027→type User struct {\n  2028→    ID        string\n  2029→    Email     string\n  2030→    FirstName string\n  2031→    LastName  string\n  2032→    CreatedAt time.Time\n  2033→}\n  2034→\n  2035→// Repository interface\n  2036→type UserRepository interface {\n  2037→    Create(ctx context.Context, user *User) error\n  2038→    GetByID(ctx context.Context, id string) (*User, error)\n  2039→    GetByEmail(ctx context.Context, email string) (*User, error)\n  2040→    Update(ctx context.Context, user *User) error\n  2041→    Delete(ctx context.Context, id string) error\n  2042→    List(ctx context.Context, offset, limit int) ([]*User, error)\n  2043→}\n  2044→\n  2045→// PostgreSQL implementation\n  2046→type PostgresUserRepository struct {\n  2047→    db *sql.DB\n  2048→}\n  2049→\n  2050→func NewPostgresUserRepository(db *sql.DB) *PostgresUserRepository {\n  2051→    return &PostgresUserRepository{db: db}\n  2052→}\n  2053→\n  2054→func (r *PostgresUserRepository) Create(ctx context.Context, user *User) error {\n  2055→    query := `\n  2056→        INSERT INTO users (id, email, first_name, last_name, created_at)\n  2057→        VALUES ($1, $2, $3, $4, $5)\n  2058→    `\n  2059→    _, err := r.db.ExecContext(ctx, query,\n  2060→        user.ID, user.Email, user.FirstName, user.LastName, user.CreatedAt)\n  2061→    return err\n  2062→}\n  2063→\n  2064→func (r *PostgresUserRepository) GetByID(ctx context.Context, id string) (*User, error) {\n  2065→    query := `\n  2066→        SELECT id, email, first_name, last_name, created_at\n  2067→        FROM users WHERE id = $1\n  2068→    `\n  2069→    user := &User{}\n  2070→    err := r.db.QueryRowContext(ctx, query, id).Scan(\n  2071→        &user.ID, &user.Email, &user.FirstName, &user.LastName, &user.CreatedAt)\n  2072→    if err == sql.ErrNoRows {\n  2073→        return nil, fmt.Errorf(\"user not found\")\n  2074→    }\n  2075→    return user, err\n  2076→}\n  2077→\n  2078→// In-memory implementation for testing\n  2079→type InMemoryUserRepository struct {\n  2080→    mu    sync.RWMutex\n  2081→    users map[string]*User\n  2082→}\n  2083→\n  2084→func NewInMemoryUserRepository() *InMemoryUserRepository {\n  2085→    return &InMemoryUserRepository{\n  2086→        users: make(map[string]*User),\n  2087→    }\n  2088→}\n  2089→\n  2090→func (r *InMemoryUserRepository) Create(ctx context.Context, user *User) error {\n  2091→    r.mu.Lock()\n  2092→    defer r.mu.Unlock()\n  2093→    \n  2094→    if _, exists := r.users[user.ID]; exists {\n  2095→        return fmt.Errorf(\"user already exists\")\n  2096→    }\n  2097→    r.users[user.ID] = user\n  2098→    return nil\n  2099→}\n  2100→\n  2101→func (r *InMemoryUserRepository) GetByID(ctx context.Context, id string) (*User, error) {\n  2102→    r.mu.RLock()\n  2103→    defer r.mu.RUnlock()\n  2104→    \n  2105→    if user, exists := r.users[id]; exists {\n  2106→        return user, nil\n  2107→    }\n  2108→    return nil, fmt.Errorf(\"user not found\")\n  2109→}\n  2110→```\n  2111→\n  2112→### Unit of Work Pattern\n  2113→Unit of Work maintains a list of objects affected by a business transaction and coordinates writing out changes.\n  2114→\n  2115→```go\n  2116→// Unit of Work interface\n  2117→type UnitOfWork interface {\n  2118→    UserRepository() UserRepository\n  2119→    OrderRepository() OrderRepository\n  2120→    Commit() error\n  2121→    Rollback() error\n  2122→}\n  2123→\n  2124→// PostgreSQL Unit of Work\n  2125→type PostgresUnitOfWork struct {\n  2126→    tx    *sql.Tx\n  2127→    users *PostgresUserRepository\n  2128→    orders *PostgresOrderRepository\n  2129→}\n  2130→\n  2131→func NewPostgresUnitOfWork(db *sql.DB) (*PostgresUnitOfWork, error) {\n  2132→    tx, err := db.Begin()\n  2133→    if err != nil {\n  2134→        return nil, err\n  2135→    }\n  2136→    \n  2137→    return &PostgresUnitOfWork{\n  2138→        tx:     tx,\n  2139→        users:  &PostgresUserRepository{db: db},\n  2140→        orders: &PostgresOrderRepository{db: db},\n  2141→    }, nil\n  2142→}\n  2143→\n  2144→func (u *PostgresUnitOfWork) UserRepository() UserRepository {\n  2145→    return u.users\n  2146→}\n  2147→\n  2148→func (u *PostgresUnitOfWork) OrderRepository() OrderRepository {\n  2149→    return u.orders\n  2150→}\n  2151→\n  2152→func (u *PostgresUnitOfWork) Commit() error {\n  2153→    return u.tx.Commit()\n  2154→}\n  2155→\n  2156→func (u *PostgresUnitOfWork) Rollback() error {\n  2157→    return u.tx.Rollback()\n  2158→}\n  2159→\n  2160→// Service using Unit of Work\n  2161→type OrderService struct {\n  2162→    uowFactory func() (UnitOfWork, error)\n  2163→}\n  2164→\n  2165→func (s *OrderService) CreateOrder(userID string, items []OrderItem) error {\n  2166→    uow, err := s.uowFactory()\n  2167→    if err != nil {\n  2168→        return err\n  2169→    }\n  2170→    defer uow.Rollback()\n  2171→    \n  2172→    // Check user exists\n  2173→    user, err := uow.UserRepository().GetByID(context.Background(), userID)\n  2174→    if err != nil {\n  2175→        return err\n  2176→    }\n  2177→    \n  2178→    // Create order\n  2179→    order := &Order{\n  2180→        UserID: user.ID,\n  2181→        Items:  items,\n  2182→        Total:  calculateTotal(items),\n  2183→    }\n  2184→    \n  2185→    if err := uow.OrderRepository().Create(context.Background(), order); err != nil {\n  2186→        return err\n  2187→    }\n  2188→    \n  2189→    // Update user stats\n  2190→    user.TotalOrders++\n  2191→    if err := uow.UserRepository().Update(context.Background(), user); err != nil {\n  2192→        return err\n  2193→    }\n  2194→    \n  2195→    // Commit transaction\n  2196→    return uow.Commit()\n  2197→}\n  2198→```\n  2199→\n  2200→## Domain-Driven Design Patterns\n  2201→\n  2202→### Value Object\n  2203→Value Objects are immutable objects that represent a descriptive aspect of the domain.\n  2204→\n  2205→```go\n  2206→// Value Object - immutable\n  2207→type Money struct {\n  2208→    amount   decimal.Decimal\n  2209→    currency string\n  2210→}\n  2211→\n  2212→func NewMoney(amount decimal.Decimal, currency string) (Money, error) {\n  2213→    if currency == \"\" {\n  2214→        return Money{}, fmt.Errorf(\"currency is required\")\n  2215→    }\n  2216→    if amount.IsNegative() {\n  2217→        return Money{}, fmt.Errorf(\"amount cannot be negative\")\n  2218→    }\n  2219→    return Money{amount: amount, currency: currency}, nil\n  2220→}\n  2221→\n  2222→func (m Money) Amount() decimal.Decimal {\n  2223→    return m.amount\n  2224→}\n  2225→\n  2226→func (m Money) Currency() string {\n  2227→    return m.currency\n  2228→}\n  2229→\n  2230→func (m Money) Add(other Money) (Money, error) {\n  2231→    if m.currency != other.currency {\n  2232→        return Money{}, fmt.Errorf(\"cannot add different currencies\")\n  2233→    }\n  2234→    return Money{\n  2235→        amount:   m.amount.Add(other.amount),\n  2236→        currency: m.currency,\n  2237→    }, nil\n  2238→}\n  2239→\n  2240→func (m Money) Equals(other Money) bool {\n  2241→    return m.amount.Equal(other.amount) && m.currency == other.currency\n  2242→}\n  2243→\n  2244→// Another Value Object example\n  2245→type Email struct {\n  2246→    value string\n  2247→}\n  2248→\n  2249→func NewEmail(value string) (Email, error) {\n  2250→    if !isValidEmail(value) {\n  2251→        return Email{}, fmt.Errorf(\"invalid email format\")\n  2252→    }\n  2253→    return Email{value: strings.ToLower(value)}, nil\n  2254→}\n  2255→\n  2256→func (e Email) String() string {\n  2257→    return e.value\n  2258→}\n  2259→\n  2260→func (e Email) Domain() string {\n  2261→    parts := strings.Split(e.value, \"@\")\n  2262→    if len(parts) == 2 {\n  2263→        return parts[1]\n  2264→    }\n  2265→    return \"\"\n  2266→}\n  2267→```\n  2268→\n  2269→### Entity\n  2270→Entities have identity and lifecycle.\n  2271→\n  2272→```go\n  2273→// Entity with identity\n  2274→type Product struct {\n  2275→    id          ProductID // Value object as ID\n  2276→    name        string\n  2277→    description string\n  2278→    price       Money\n  2279→    stock       int\n  2280→    version     int // For optimistic locking\n  2281→}\n  2282→\n  2283→type ProductID struct {\n  2284→    value string\n  2285→}\n  2286→\n  2287→func NewProductID(value string) (ProductID, error) {\n  2288→    if value == \"\" {\n  2289→        return ProductID{}, fmt.Errorf(\"product ID cannot be empty\")\n  2290→    }\n  2291→    return ProductID{value: value}, nil\n  2292→}\n  2293→\n  2294→func (p ProductID) String() string {\n  2295→    return p.value\n  2296→}\n  2297→\n  2298→func NewProduct(id ProductID, name string, price Money) (*Product, error) {\n  2299→    if name == \"\" {\n  2300→        return nil, fmt.Errorf(\"product name is required\")\n  2301→    }\n  2302→    \n  2303→    return &Product{\n  2304→        id:    id,\n  2305→        name:  name,\n  2306→        price: price,\n  2307→        stock: 0,\n  2308→    }, nil\n  2309→}\n  2310→\n  2311→func (p *Product) ID() ProductID {\n  2312→    return p.id\n  2313→}\n  2314→\n  2315→func (p *Product) UpdatePrice(newPrice Money) error {\n  2316→    if newPrice.Amount().IsZero() {\n  2317→        return fmt.Errorf(\"price cannot be zero\")\n  2318→    }\n  2319→    p.price = newPrice\n  2320→    p.version++\n  2321→    return nil\n  2322→}\n  2323→\n  2324→func (p *Product) AddStock(quantity int) error {\n  2325→    if quantity <= 0 {\n  2326→        return fmt.Errorf(\"quantity must be positive\")\n  2327→    }\n  2328→    p.stock += quantity\n  2329→    p.version++\n  2330→    return nil\n  2331→}\n  2332→\n  2333→func (p *Product) CanFulfillOrder(quantity int) bool {\n  2334→    return p.stock >= quantity\n  2335→}\n  2336→```\n  2337→\n  2338→### Aggregate\n  2339→Aggregates are clusters of domain objects that are treated as a single unit.\n  2340→\n  2341→```go\n  2342→// Aggregate root\n  2343→type Order struct {\n  2344→    id         OrderID\n  2345→    customerID CustomerID\n  2346→    items      []OrderItem\n  2347→    status     OrderStatus\n  2348→    totalAmount Money\n  2349→    placedAt   time.Time\n  2350→    version    int\n  2351→}\n  2352→\n  2353→// Part of the aggregate\n  2354→type OrderItem struct {\n  2355→    productID ProductID\n  2356→    quantity  int\n  2357→    unitPrice Money\n  2358→}\n  2359→\n  2360→type OrderStatus string\n  2361→\n  2362→const (\n  2363→    OrderStatusPending   OrderStatus = \"PENDING\"\n  2364→    OrderStatusConfirmed OrderStatus = \"CONFIRMED\"\n  2365→    OrderStatusShipped   OrderStatus = \"SHIPPED\"\n  2366→    OrderStatusDelivered OrderStatus = \"DELIVERED\"\n  2367→    OrderStatusCancelled OrderStatus = \"CANCELLED\"\n  2368→)\n  2369→\n  2370→func NewOrder(customerID CustomerID) *Order {\n  2371→    return &Order{\n  2372→        id:         NewOrderID(),\n  2373→        customerID: customerID,\n  2374→        items:      []OrderItem{},\n  2375→        status:     OrderStatusPending,\n  2376→        placedAt:   time.Now(),\n  2377→    }\n  2378→}\n  2379→\n  2380→func (o *Order) AddItem(productID ProductID, quantity int, unitPrice Money) error {\n  2381→    if o.status != OrderStatusPending {\n  2382→        return fmt.Errorf(\"cannot modify confirmed order\")\n  2383→    }\n  2384→    \n  2385→    if quantity <= 0 {\n  2386→        return fmt.Errorf(\"quantity must be positive\")\n  2387→    }\n  2388→    \n  2389→    // Check if item already exists\n  2390→    for i, item := range o.items {\n  2391→        if item.productID == productID {\n  2392→            o.items[i].quantity += quantity\n  2393→            o.recalculateTotal()\n  2394→            return nil\n  2395→        }\n  2396→    }\n  2397→    \n  2398→    // Add new item\n  2399→    o.items = append(o.items, OrderItem{\n  2400→        productID: productID,\n  2401→        quantity:  quantity,\n  2402→        unitPrice: unitPrice,\n  2403→    })\n  2404→    \n  2405→    o.recalculateTotal()\n  2406→    return nil\n  2407→}\n  2408→\n  2409→func (o *Order) RemoveItem(productID ProductID) error {\n  2410→    if o.status != OrderStatusPending {\n  2411→        return fmt.Errorf(\"cannot modify confirmed order\")\n  2412→    }\n  2413→    \n  2414→    for i, item := range o.items {\n  2415→        if item.productID == productID {\n  2416→            o.items = append(o.items[:i], o.items[i+1:]...)\n  2417→            o.recalculateTotal()\n  2418→            return nil\n  2419→        }\n  2420→    }\n  2421→    \n  2422→    return fmt.Errorf(\"item not found\")\n  2423→}\n  2424→\n  2425→func (o *Order) Confirm() error {\n  2426→    if o.status != OrderStatusPending {\n  2427→        return fmt.Errorf(\"order is not pending\")\n  2428→    }\n  2429→    \n  2430→    if len(o.items) == 0 {\n  2431→        return fmt.Errorf(\"order has no items\")\n  2432→    }\n  2433→    \n  2434→    o.status = OrderStatusConfirmed\n  2435→    o.version++\n  2436→    return nil\n  2437→}\n  2438→\n  2439→func (o *Order) recalculateTotal() {\n  2440→    total := decimal.Zero\n  2441→    currency := \"\"\n  2442→    \n  2443→    for _, item := range o.items {\n  2444→        itemTotal := item.unitPrice.Amount().Mul(decimal.NewFromInt(int64(item.quantity)))\n  2445→        total = total.Add(itemTotal)\n  2446→        if currency == \"\" {\n  2447→            currency = item.unitPrice.Currency()\n  2448→        }\n  2449→    }\n  2450→    \n  2451→    o.totalAmount, _ = NewMoney(total, currency)\n  2452→}\n  2453→\n  2454→// Aggregate repository\n  2455→type OrderRepository interface {\n  2456→    Save(ctx context.Context, order *Order) error\n  2457→    GetByID(ctx context.Context, id OrderID) (*Order, error)\n  2458→    // Never expose internal parts of aggregate\n  2459→    // Bad: GetOrderItems(orderID) []OrderItem\n  2460→}\n  2461→```\n  2462→\n  2463→### Domain Service\n  2464→Domain Services encapsulate domain logic that doesn't naturally fit within an entity or value object.\n  2465→\n  2466→```go\n  2467→// Domain service for complex business logic\n  2468→type PricingService struct {\n  2469→    taxCalculator TaxCalculator\n  2470→    discountRepo  DiscountRepository\n  2471→}\n  2472→\n  2473→func NewPricingService(tax TaxCalculator, discounts DiscountRepository) *PricingService {\n  2474→    return &PricingService{\n  2475→        taxCalculator: tax,\n  2476→        discountRepo:  discounts,\n  2477→    }\n  2478→}\n  2479→\n  2480→func (s *PricingService) CalculateOrderTotal(order *Order, customerType CustomerType) (Money, error) {\n  2481→    subtotal := order.totalAmount\n  2482→    \n  2483→    // Apply customer discount\n  2484→    discount := s.getCustomerDiscount(customerType)\n  2485→    discountAmount := subtotal.Amount().Mul(discount)\n  2486→    afterDiscount := subtotal.Amount().Sub(discountAmount)\n  2487→    \n  2488→    // Calculate tax\n  2489→    tax := s.taxCalculator.CalculateTax(afterDiscount, order.ShippingAddress())\n  2490→    \n  2491→    // Final total\n  2492→    total := afterDiscount.Add(tax)\n  2493→    \n  2494→    return NewMoney(total, subtotal.Currency())\n  2495→}\n  2496→\n  2497→func (s *PricingService) getCustomerDiscount(customerType CustomerType) decimal.Decimal {\n  2498→    switch customerType {\n  2499→    case CustomerTypePremium:\n  2500→        return decimal.NewFromFloat(0.15) // 15% discount\n  2501→    case CustomerTypeRegular:\n  2502→        return decimal.NewFromFloat(0.05) // 5% discount\n  2503→    default:\n  2504→        return decimal.Zero\n  2505→    }\n  2506→}\n  2507→\n  2508→// Another domain service example\n  2509→type TransferService struct {\n  2510→    accountRepo AccountRepository\n  2511→}\n  2512→\n  2513→func (s *TransferService) Transfer(ctx context.Context, fromID, toID AccountID, amount Money) error {\n  2514→    // This logic doesn't belong to either account\n  2515→    // It's a domain service coordinating between aggregates\n  2516→    \n  2517→    from, err := s.accountRepo.GetByID(ctx, fromID)\n  2518→    if err != nil {\n  2519→        return err\n  2520→    }\n  2521→    \n  2522→    to, err := s.accountRepo.GetByID(ctx, toID)\n  2523→    if err != nil {\n  2524→        return err\n  2525→    }\n  2526→    \n  2527→    if err := from.Withdraw(amount); err != nil {\n  2528→        return err\n  2529→    }\n  2530→    \n  2531→    if err := to.Deposit(amount); err != nil {\n  2532→        // Compensate\n  2533→        from.Deposit(amount)\n  2534→        return err\n  2535→    }\n  2536→    \n  2537→    // Save both accounts\n  2538→    if err := s.accountRepo.Save(ctx, from); err != nil {\n  2539→        return err\n  2540→    }\n  2541→    \n  2542→    return s.accountRepo.Save(ctx, to)\n  2543→}\n  2544→```\n  2545→\n  2546→### Specification Pattern\n  2547→Specification pattern encapsulates business rules in a reusable way.\n  2548→\n  2549→```go\n  2550→// Specification interface\n  2551→type Specification[T any] interface {\n  2552→    IsSatisfiedBy(T) bool\n  2553→    And(Specification[T]) Specification[T]\n  2554→    Or(Specification[T]) Specification[T]\n  2555→    Not() Specification[T]\n  2556→}\n  2557→\n  2558→// Base specification\n  2559→type BaseSpecification[T any] struct {\n  2560→    predicate func(T) bool\n  2561→}\n  2562→\n  2563→func NewSpecification[T any](predicate func(T) bool) Specification[T] {\n  2564→    return &BaseSpecification[T]{predicate: predicate}\n  2565→}\n  2566→\n  2567→func (s *BaseSpecification[T]) IsSatisfiedBy(item T) bool {\n  2568→    return s.predicate(item)\n  2569→}\n  2570→\n  2571→func (s *BaseSpecification[T]) And(other Specification[T]) Specification[T] {\n  2572→    return &BaseSpecification[T]{\n  2573→        predicate: func(item T) bool {\n  2574→            return s.IsSatisfiedBy(item) && other.IsSatisfiedBy(item)\n  2575→        },\n  2576→    }\n  2577→}\n  2578→\n  2579→func (s *BaseSpecification[T]) Or(other Specification[T]) Specification[T] {\n  2580→    return &BaseSpecification[T]{\n  2581→        predicate: func(item T) bool {\n  2582→            return s.IsSatisfiedBy(item) || other.IsSatisfiedBy(item)\n  2583→        },\n  2584→    }\n  2585→}\n  2586→\n  2587→func (s *BaseSpecification[T]) Not() Specification[T] {\n  2588→    return &BaseSpecification[T]{\n  2589→        predicate: func(item T) bool {\n  2590→            return !s.IsSatisfiedBy(item)\n  2591→        },\n  2592→    }\n  2593→}\n  2594→\n  2595→// Concrete specifications\n  2596→type Product struct {\n  2597→    Name     string\n  2598→    Price    decimal.Decimal\n  2599→    Category string\n  2600→    InStock  bool\n  2601→}\n  2602→\n  2603→var PremiumProductSpec = NewSpecification(func(p Product) bool {\n  2604→    return p.Price.GreaterThan(decimal.NewFromInt(100))\n  2605→})\n  2606→\n  2607→var InStockSpec = NewSpecification(func(p Product) bool {\n  2608→    return p.InStock\n  2609→})\n  2610→\n  2611→var ElectronicsSpec = NewSpecification(func(p Product) bool {\n  2612→    return p.Category == \"Electronics\"\n  2613→})\n  2614→\n  2615→// Usage\n  2616→func FilterProducts(products []Product, spec Specification[Product]) []Product {\n  2617→    var result []Product\n  2618→    for _, p := range products {\n  2619→        if spec.IsSatisfiedBy(p) {\n  2620→            result = append(result, p)\n  2621→        }\n  2622→    }\n  2623→    return result\n  2624→}\n  2625→\n  2626→func main() {\n  2627→    products := []Product{\n  2628→        {Name: \"Laptop\", Price: decimal.NewFromInt(1200), Category: \"Electronics\", InStock: true},\n  2629→        {Name: \"Mouse\", Price: decimal.NewFromInt(25), Category: \"Electronics\", InStock: true},\n  2630→        {Name: \"Book\", Price: decimal.NewFromInt(15), Category: \"Books\", InStock: false},\n  2631→    }\n  2632→    \n  2633→    // Premium electronics in stock\n  2634→    spec := PremiumProductSpec.And(ElectronicsSpec).And(InStockSpec)\n  2635→    \n  2636→    filtered := FilterProducts(products, spec)\n  2637→    fmt.Printf(\"Found %d products\\n\", len(filtered))\n  2638→}\n  2639→```\n  2640→\n  2641→## Summary\n  2642→\n  2643→This comprehensive guide covers the major design patterns adapted for Go:\n  2644→\n  2645→1. **Creational Patterns**: Control object creation mechanisms\n  2646→2. **Structural Patterns**: Compose objects to form larger structures\n  2647→3. **Behavioral Patterns**: Define communication between objects\n  2648→4. **Architectural Patterns**: Organize high-level application structure\n  2649→5. **Domain-Driven Design Patterns**: Model complex business domains\n  2650→\n  2651→Each pattern includes practical Go implementations with proper error handling, concurrency considerations, and idiomatic Go practices. Choose patterns based on your specific needs, keeping in mind Go's philosophy of simplicity and clarity.\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"cf86b142-f3c2-4ebe-a00d-894e6d612e4b","timestamp":"2025-08-13T10:28:02.604Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/design-patterns.md","content":"# Design Patterns in Go\n\n## Overview\nThis document covers classic design patterns (Gang of Four) and architectural patterns as they apply to Go. For Go-specific idioms and conventions, see `practices-patterns.md`.\n\n## Table of Contents\n1. [Creational Patterns](#creational-patterns)\n2. [Structural Patterns](#structural-patterns)\n3. [Behavioral Patterns](#behavioral-patterns)\n4. [Architectural Patterns](#architectural-patterns)\n5. [Domain-Driven Design Patterns](#domain-driven-design-patterns)\n\n## Creational Patterns\n\n### Singleton\nThe singleton pattern ensures only one instance of a type exists. In Go, use `sync.Once` for thread-safe initialization.\n\n```go\npackage database\n\nimport (\n    \"database/sql\"\n    \"sync\"\n)\n\ntype DB struct {\n    conn *sql.DB\n}\n\nvar (\n    instance *DB\n    once     sync.Once\n)\n\n// GetInstance returns the singleton database instance\nfunc GetInstance() *DB {\n    once.Do(func() {\n        conn, _ := sql.Open(\"postgres\", \"connection-string\")\n        instance = &DB{conn: conn}\n    })\n    return instance\n}\n\n// Alternative: Package-level initialization (simpler for most cases)\nvar defaultDB = initDB()\n\nfunc initDB() *DB {\n    conn, _ := sql.Open(\"postgres\", \"connection-string\")\n    return &DB{conn: conn}\n}\n```\n\n### Factory Method\nFactory method defines an interface for creating objects but lets subclasses decide which class to instantiate.\n\n```go\n// Product interface\ntype Transport interface {\n    Deliver() string\n    Cost() float64\n}\n\n// Concrete products\ntype Truck struct {\n    capacity int\n}\n\nfunc (t *Truck) Deliver() string {\n    return \"Delivering by land\"\n}\n\nfunc (t *Truck) Cost() float64 {\n    return 100.0\n}\n\ntype Ship struct {\n    tonnage int\n}\n\nfunc (s *Ship) Deliver() string {\n    return \"Delivering by sea\"\n}\n\nfunc (s *Ship) Cost() float64 {\n    return 500.0\n}\n\n// Factory\ntype LogisticsFactory interface {\n    CreateTransport() Transport\n}\n\ntype RoadLogistics struct{}\n\nfunc (r *RoadLogistics) CreateTransport() Transport {\n    return &Truck{capacity: 1000}\n}\n\ntype SeaLogistics struct{}\n\nfunc (s *SeaLogistics) CreateTransport() Transport {\n    return &Ship{tonnage: 10000}\n}\n\n// Usage\nfunc planDelivery(factory LogisticsFactory) {\n    transport := factory.CreateTransport()\n    fmt.Println(transport.Deliver())\n    fmt.Printf(\"Cost: $%.2f\\n\", transport.Cost())\n}\n```\n\n### Abstract Factory\nAbstract factory provides an interface for creating families of related objects.\n\n```go\n// Abstract products\ntype Button interface {\n    Paint()\n}\n\ntype Checkbox interface {\n    Check()\n}\n\n// Concrete products - Windows family\ntype WindowsButton struct{}\n\nfunc (w *WindowsButton) Paint() {\n    fmt.Println(\"Rendering Windows button\")\n}\n\ntype WindowsCheckbox struct{}\n\nfunc (w *WindowsCheckbox) Check() {\n    fmt.Println(\"Checking Windows checkbox\")\n}\n\n// Concrete products - Mac family\ntype MacButton struct{}\n\nfunc (m *MacButton) Paint() {\n    fmt.Println(\"Rendering Mac button\")\n}\n\ntype MacCheckbox struct{}\n\nfunc (m *MacCheckbox) Check() {\n    fmt.Println(\"Checking Mac checkbox\")\n}\n\n// Abstract factory\ntype GUIFactory interface {\n    CreateButton() Button\n    CreateCheckbox() Checkbox\n}\n\n// Concrete factories\ntype WindowsFactory struct{}\n\nfunc (w *WindowsFactory) CreateButton() Button {\n    return &WindowsButton{}\n}\n\nfunc (w *WindowsFactory) CreateCheckbox() Checkbox {\n    return &WindowsCheckbox{}\n}\n\ntype MacFactory struct{}\n\nfunc (m *MacFactory) CreateButton() Button {\n    return &MacButton{}\n}\n\nfunc (m *MacFactory) CreateCheckbox() Checkbox {\n    return &MacCheckbox{}\n}\n\n// Application\ntype Application struct {\n    factory GUIFactory\n    button  Button\n    checkbox Checkbox\n}\n\nfunc NewApplication(factory GUIFactory) *Application {\n    return &Application{\n        factory:  factory,\n        button:   factory.CreateButton(),\n        checkbox: factory.CreateCheckbox(),\n    }\n}\n\nfunc (a *Application) Paint() {\n    a.button.Paint()\n    a.checkbox.Check()\n}\n```\n\n### Builder\nBuilder pattern separates the construction of complex objects from their representation.\n\n```go\n// Product\ntype House struct {\n    Foundation string\n    Structure  string\n    Roof       string\n    Interior   string\n    Garden     bool\n    Pool       bool\n}\n\n// Builder interface\ntype HouseBuilder interface {\n    SetFoundation() HouseBuilder\n    SetStructure() HouseBuilder\n    SetRoof() HouseBuilder\n    SetInterior() HouseBuilder\n    SetGarden() HouseBuilder\n    SetPool() HouseBuilder\n    Build() *House\n}\n\n// Concrete builder\ntype ModernHouseBuilder struct {\n    house *House\n}\n\nfunc NewModernHouseBuilder() *ModernHouseBuilder {\n    return &ModernHouseBuilder{\n        house: &House{},\n    }\n}\n\nfunc (b *ModernHouseBuilder) SetFoundation() HouseBuilder {\n    b.house.Foundation = \"Concrete, brick, and stone\"\n    return b\n}\n\nfunc (b *ModernHouseBuilder) SetStructure() HouseBuilder {\n    b.house.Structure = \"Steel and glass\"\n    return b\n}\n\nfunc (b *ModernHouseBuilder) SetRoof() HouseBuilder {\n    b.house.Roof = \"Flat concrete\"\n    return b\n}\n\nfunc (b *ModernHouseBuilder) SetInterior() HouseBuilder {\n    b.house.Interior = \"Modern minimalist\"\n    return b\n}\n\nfunc (b *ModernHouseBuilder) SetGarden() HouseBuilder {\n    b.house.Garden = true\n    return b\n}\n\nfunc (b *ModernHouseBuilder) SetPool() HouseBuilder {\n    b.house.Pool = true\n    return b\n}\n\nfunc (b *ModernHouseBuilder) Build() *House {\n    return b.house\n}\n\n// Director (optional)\ntype ConstructionDirector struct {\n    builder HouseBuilder\n}\n\nfunc (d *ConstructionDirector) ConstructLuxuryHouse() *House {\n    return d.builder.\n        SetFoundation().\n        SetStructure().\n        SetRoof().\n        SetInterior().\n        SetGarden().\n        SetPool().\n        Build()\n}\n\n// Usage\nfunc main() {\n    builder := NewModernHouseBuilder()\n    \n    // Direct use\n    house := builder.\n        SetFoundation().\n        SetStructure().\n        SetRoof().\n        Build()\n    \n    // Using director\n    director := &ConstructionDirector{builder: builder}\n    luxuryHouse := director.ConstructLuxuryHouse()\n}\n```\n\n### Prototype\nPrototype pattern creates objects by cloning existing instances.\n\n```go\n// Prototype interface\ntype Prototype interface {\n    Clone() Prototype\n}\n\n// Concrete prototype\ntype Document struct {\n    Title    string\n    Content  string\n    Images   []string\n    Metadata map[string]string\n}\n\nfunc (d *Document) Clone() Prototype {\n    // Deep copy\n    newDoc := &Document{\n        Title:   d.Title,\n        Content: d.Content,\n        Images:  make([]string, len(d.Images)),\n        Metadata: make(map[string]string),\n    }\n    \n    copy(newDoc.Images, d.Images)\n    \n    for k, v := range d.Metadata {\n        newDoc.Metadata[k] = v\n    }\n    \n    return newDoc\n}\n\n// Prototype registry\ntype DocumentRegistry struct {\n    prototypes map[string]Prototype\n}\n\nfunc NewDocumentRegistry() *DocumentRegistry {\n    return &DocumentRegistry{\n        prototypes: make(map[string]Prototype),\n    }\n}\n\nfunc (r *DocumentRegistry) Register(name string, prototype Prototype) {\n    r.prototypes[name] = prototype\n}\n\nfunc (r *DocumentRegistry) Create(name string) Prototype {\n    if prototype, exists := r.prototypes[name]; exists {\n        return prototype.Clone()\n    }\n    return nil\n}\n\n// Usage\nfunc main() {\n    registry := NewDocumentRegistry()\n    \n    // Register prototypes\n    registry.Register(\"report\", &Document{\n        Title:    \"Monthly Report Template\",\n        Content:  \"...\",\n        Metadata: map[string]string{\"type\": \"report\"},\n    })\n    \n    registry.Register(\"letter\", &Document{\n        Title:    \"Business Letter Template\",\n        Content:  \"...\",\n        Metadata: map[string]string{\"type\": \"letter\"},\n    })\n    \n    // Create new documents from prototypes\n    report := registry.Create(\"report\").(*Document)\n    report.Title = \"January Report\"\n}\n```\n\n## Structural Patterns\n\n### Adapter\nAdapter allows incompatible interfaces to work together.\n\n```go\n// Target interface (what client expects)\ntype PaymentProcessor interface {\n    ProcessPayment(amount float64) error\n}\n\n// Adaptee (incompatible interface)\ntype LegacyPaymentSystem struct{}\n\nfunc (l *LegacyPaymentSystem) MakePayment(sum float64, currency string) string {\n    return fmt.Sprintf(\"Payment of %.2f %s processed\", sum, currency)\n}\n\n// Adapter\ntype PaymentAdapter struct {\n    legacy   *LegacyPaymentSystem\n    currency string\n}\n\nfunc NewPaymentAdapter(legacy *LegacyPaymentSystem, currency string) *PaymentAdapter {\n    return &PaymentAdapter{\n        legacy:   legacy,\n        currency: currency,\n    }\n}\n\nfunc (a *PaymentAdapter) ProcessPayment(amount float64) error {\n    result := a.legacy.MakePayment(amount, a.currency)\n    if result != \"\" {\n        return nil\n    }\n    return fmt.Errorf(\"payment failed\")\n}\n\n// Client code\nfunc processOrder(processor PaymentProcessor, amount float64) {\n    if err := processor.ProcessPayment(amount); err != nil {\n        fmt.Printf(\"Payment failed: %v\\n\", err)\n    } else {\n        fmt.Println(\"Payment successful\")\n    }\n}\n\n// Usage\nfunc main() {\n    legacy := &LegacyPaymentSystem{}\n    adapter := NewPaymentAdapter(legacy, \"USD\")\n    processOrder(adapter, 100.00)\n}\n```\n\n### Bridge\nBridge decouples abstraction from implementation so both can vary independently.\n\n```go\n// Implementation interface\ntype MessageSender interface {\n    Send(title, body string) error\n}\n\n// Concrete implementations\ntype EmailSender struct {\n    emailAddress string\n}\n\nfunc (e *EmailSender) Send(title, body string) error {\n    fmt.Printf(\"Email to %s: %s - %s\\n\", e.emailAddress, title, body)\n    return nil\n}\n\ntype SMSSender struct {\n    phoneNumber string\n}\n\nfunc (s *SMSSender) Send(title, body string) error {\n    fmt.Printf(\"SMS to %s: %s\\n\", s.phoneNumber, body)\n    return nil\n}\n\n// Abstraction\ntype Message struct {\n    sender MessageSender\n}\n\nfunc NewMessage(sender MessageSender) *Message {\n    return &Message{sender: sender}\n}\n\nfunc (m *Message) Send(title, body string) error {\n    return m.sender.Send(title, body)\n}\n\n// Refined abstraction\ntype UrgentMessage struct {\n    Message\n}\n\nfunc NewUrgentMessage(sender MessageSender) *UrgentMessage {\n    return &UrgentMessage{\n        Message: Message{sender: sender},\n    }\n}\n\nfunc (u *UrgentMessage) Send(title, body string) error {\n    title = \"URGENT: \" + title\n    return u.sender.Send(title, body)\n}\n\n// Usage\nfunc main() {\n    // Regular email\n    email := NewMessage(&EmailSender{emailAddress: \"user@example.com\"})\n    email.Send(\"Hello\", \"This is a test message\")\n    \n    // Urgent SMS\n    sms := NewUrgentMessage(&SMSSender{phoneNumber: \"+1234567890\"})\n    sms.Send(\"Alert\", \"Server is down\")\n}\n```\n\n### Composite\nComposite lets you compose objects into tree structures to represent part-whole hierarchies.\n\n```go\n// Component interface\ntype FileSystemNode interface {\n    GetName() string\n    GetSize() int64\n    Print(indent string)\n}\n\n// Leaf\ntype File struct {\n    name string\n    size int64\n}\n\nfunc (f *File) GetName() string {\n    return f.name\n}\n\nfunc (f *File) GetSize() int64 {\n    return f.size\n}\n\nfunc (f *File) Print(indent string) {\n    fmt.Printf(\"%sFile: %s (%d bytes)\\n\", indent, f.name, f.size)\n}\n\n// Composite\ntype Directory struct {\n    name     string\n    children []FileSystemNode\n}\n\nfunc (d *Directory) GetName() string {\n    return d.name\n}\n\nfunc (d *Directory) GetSize() int64 {\n    var total int64\n    for _, child := range d.children {\n        total += child.GetSize()\n    }\n    return total\n}\n\nfunc (d *Directory) Add(node FileSystemNode) {\n    d.children = append(d.children, node)\n}\n\nfunc (d *Directory) Remove(node FileSystemNode) {\n    for i, child := range d.children {\n        if child == node {\n            d.children = append(d.children[:i], d.children[i+1:]...)\n            break\n        }\n    }\n}\n\nfunc (d *Directory) Print(indent string) {\n    fmt.Printf(\"%sDirectory: %s (%d bytes)\\n\", indent, d.name, d.GetSize())\n    for _, child := range d.children {\n        child.Print(indent + \"  \")\n    }\n}\n\n// Usage\nfunc main() {\n    root := &Directory{name: \"root\"}\n    \n    home := &Directory{name: \"home\"}\n    root.Add(home)\n    \n    documents := &Directory{name: \"documents\"}\n    home.Add(documents)\n    \n    documents.Add(&File{name: \"report.pdf\", size: 1024000})\n    documents.Add(&File{name: \"presentation.pptx\", size: 2048000})\n    \n    home.Add(&File{name: \"notes.txt\", size: 1024})\n    \n    root.Print(\"\")\n}\n```\n\n### Decorator\nDecorator adds new functionality to objects without altering their structure.\n\n```go\n// Component interface\ntype Coffee interface {\n    GetCost() float64\n    GetDescription() string\n}\n\n// Concrete component\ntype SimpleCoffee struct{}\n\nfunc (c *SimpleCoffee) GetCost() float64 {\n    return 2.0\n}\n\nfunc (c *SimpleCoffee) GetDescription() string {\n    return \"Simple coffee\"\n}\n\n// Base decorator\ntype CoffeeDecorator struct {\n    coffee Coffee\n}\n\nfunc (d *CoffeeDecorator) GetCost() float64 {\n    return d.coffee.GetCost()\n}\n\nfunc (d *CoffeeDecorator) GetDescription() string {\n    return d.coffee.GetDescription()\n}\n\n// Concrete decorators\ntype MilkDecorator struct {\n    CoffeeDecorator\n}\n\nfunc NewMilkDecorator(coffee Coffee) *MilkDecorator {\n    return &MilkDecorator{\n        CoffeeDecorator: CoffeeDecorator{coffee: coffee},\n    }\n}\n\nfunc (m *MilkDecorator) GetCost() float64 {\n    return m.coffee.GetCost() + 0.5\n}\n\nfunc (m *MilkDecorator) GetDescription() string {\n    return m.coffee.GetDescription() + \", milk\"\n}\n\ntype SugarDecorator struct {\n    CoffeeDecorator\n}\n\nfunc NewSugarDecorator(coffee Coffee) *SugarDecorator {\n    return &SugarDecorator{\n        CoffeeDecorator: CoffeeDecorator{coffee: coffee},\n    }\n}\n\nfunc (s *SugarDecorator) GetCost() float64 {\n    return s.coffee.GetCost() + 0.2\n}\n\nfunc (s *SugarDecorator) GetDescription() string {\n    return s.coffee.GetDescription() + \", sugar\"\n}\n\n// Usage\nfunc main() {\n    coffee := &SimpleCoffee{}\n    fmt.Printf(\"%s: $%.2f\\n\", coffee.GetDescription(), coffee.GetCost())\n    \n    coffeeWithMilk := NewMilkDecorator(coffee)\n    fmt.Printf(\"%s: $%.2f\\n\", coffeeWithMilk.GetDescription(), coffeeWithMilk.GetCost())\n    \n    coffeeWithMilkAndSugar := NewSugarDecorator(coffeeWithMilk)\n    fmt.Printf(\"%s: $%.2f\\n\", coffeeWithMilkAndSugar.GetDescription(), coffeeWithMilkAndSugar.GetCost())\n}\n```\n\n### Facade\nFacade provides a simplified interface to a complex subsystem.\n\n```go\n// Complex subsystem components\ntype AccountService struct{}\n\nfunc (a *AccountService) GetAccount(id string) string {\n    return fmt.Sprintf(\"Account %s\", id)\n}\n\nfunc (a *AccountService) CheckBalance(id string) float64 {\n    return 1000.00\n}\n\ntype SecurityService struct{}\n\nfunc (s *SecurityService) Authenticate(token string) bool {\n    return token == \"valid-token\"\n}\n\nfunc (s *SecurityService) Authorize(user, action string) bool {\n    return true\n}\n\ntype TransactionService struct{}\n\nfunc (t *TransactionService) CreateTransaction(from, to string, amount float64) string {\n    return fmt.Sprintf(\"Transaction: %s -> %s: %.2f\", from, to, amount)\n}\n\nfunc (t *TransactionService) ValidateTransaction(id string) bool {\n    return true\n}\n\ntype NotificationService struct{}\n\nfunc (n *NotificationService) SendEmail(to, message string) {\n    fmt.Printf(\"Email to %s: %s\\n\", to, message)\n}\n\nfunc (n *NotificationService) SendSMS(to, message string) {\n    fmt.Printf(\"SMS to %s: %s\\n\", to, message)\n}\n\n// Facade\ntype BankingFacade struct {\n    account      *AccountService\n    security     *SecurityService\n    transaction  *TransactionService\n    notification *NotificationService\n}\n\nfunc NewBankingFacade() *BankingFacade {\n    return &BankingFacade{\n        account:      &AccountService{},\n        security:     &SecurityService{},\n        transaction:  &TransactionService{},\n        notification: &NotificationService{},\n    }\n}\n\nfunc (b *BankingFacade) Transfer(token, from, to string, amount float64) error {\n    // Authenticate\n    if !b.security.Authenticate(token) {\n        return fmt.Errorf(\"authentication failed\")\n    }\n    \n    // Check authorization\n    if !b.security.Authorize(from, \"transfer\") {\n        return fmt.Errorf(\"not authorized\")\n    }\n    \n    // Check balance\n    if b.account.CheckBalance(from) < amount {\n        return fmt.Errorf(\"insufficient funds\")\n    }\n    \n    // Create transaction\n    txID := b.transaction.CreateTransaction(from, to, amount)\n    \n    // Validate\n    if !b.transaction.ValidateTransaction(txID) {\n        return fmt.Errorf(\"transaction validation failed\")\n    }\n    \n    // Notify\n    b.notification.SendEmail(from, fmt.Sprintf(\"Transfer of %.2f completed\", amount))\n    b.notification.SendSMS(to, fmt.Sprintf(\"Received %.2f\", amount))\n    \n    return nil\n}\n\n// Usage\nfunc main() {\n    banking := NewBankingFacade()\n    \n    err := banking.Transfer(\"valid-token\", \"account1\", \"account2\", 100.00)\n    if err != nil {\n        fmt.Printf(\"Transfer failed: %v\\n\", err)\n    } else {\n        fmt.Println(\"Transfer successful\")\n    }\n}\n```\n\n### Flyweight\nFlyweight minimizes memory usage by sharing efficiently large numbers of fine-grained objects.\n\n```go\n// Flyweight interface\ntype Character interface {\n    Display(font string, size int, color string)\n}\n\n// Concrete flyweight\ntype ConcreteCharacter struct {\n    symbol rune // Intrinsic state (shared)\n}\n\nfunc (c *ConcreteCharacter) Display(font string, size int, color string) {\n    // Extrinsic state (passed in)\n    fmt.Printf(\"Character: %c, Font: %s, Size: %d, Color: %s\\n\", \n        c.symbol, font, size, color)\n}\n\n// Flyweight factory\ntype CharacterFactory struct {\n    characters map[rune]*ConcreteCharacter\n}\n\nfunc NewCharacterFactory() *CharacterFactory {\n    return &CharacterFactory{\n        characters: make(map[rune]*ConcreteCharacter),\n    }\n}\n\nfunc (f *CharacterFactory) GetCharacter(symbol rune) Character {\n    if char, exists := f.characters[symbol]; exists {\n        return char\n    }\n    \n    char := &ConcreteCharacter{symbol: symbol}\n    f.characters[symbol] = char\n    return char\n}\n\n// Context that uses flyweights\ntype TextDocument struct {\n    characters []Character\n    fonts      []string\n    sizes      []int\n    colors     []string\n}\n\nfunc (d *TextDocument) AddCharacter(char Character, font string, size int, color string) {\n    d.characters = append(d.characters, char)\n    d.fonts = append(d.fonts, font)\n    d.sizes = append(d.sizes, size)\n    d.colors = append(d.colors, color)\n}\n\nfunc (d *TextDocument) Display() {\n    for i, char := range d.characters {\n        char.Display(d.fonts[i], d.sizes[i], d.colors[i])\n    }\n}\n\n// Usage\nfunc main() {\n    factory := NewCharacterFactory()\n    doc := &TextDocument{}\n    \n    text := \"Hello World\"\n    for _, r := range text {\n        char := factory.GetCharacter(r)\n        doc.AddCharacter(char, \"Arial\", 12, \"black\")\n    }\n    \n    doc.Display()\n    \n    // Characters 'l' and 'o' are reused (shared instances)\n    fmt.Printf(\"Total unique characters created: %d\\n\", len(factory.characters))\n}\n```\n\n### Proxy\nProxy provides a placeholder or surrogate for another object to control access to it.\n\n```go\n// Subject interface\ntype Database interface {\n    Query(sql string) ([]string, error)\n}\n\n// Real subject\ntype RealDatabase struct {\n    connectionString string\n}\n\nfunc (d *RealDatabase) Query(sql string) ([]string, error) {\n    fmt.Printf(\"Executing query: %s\\n\", sql)\n    // Simulate database query\n    return []string{\"result1\", \"result2\"}, nil\n}\n\n// Proxy with caching\ntype CachingDatabaseProxy struct {\n    database *RealDatabase\n    cache    map[string][]string\n}\n\nfunc NewCachingDatabaseProxy(connString string) *CachingDatabaseProxy {\n    return &CachingDatabaseProxy{\n        database: &RealDatabase{connectionString: connString},\n        cache:    make(map[string][]string),\n    }\n}\n\nfunc (p *CachingDatabaseProxy) Query(sql string) ([]string, error) {\n    // Check cache\n    if results, exists := p.cache[sql]; exists {\n        fmt.Printf(\"Returning cached results for: %s\\n\", sql)\n        return results, nil\n    }\n    \n    // Query real database\n    results, err := p.database.Query(sql)\n    if err != nil {\n        return nil, err\n    }\n    \n    // Cache results\n    p.cache[sql] = results\n    return results, nil\n}\n\n// Security proxy\ntype SecureDatabaseProxy struct {\n    database Database\n    userRole string\n}\n\nfunc NewSecureDatabaseProxy(db Database, role string) *SecureDatabaseProxy {\n    return &SecureDatabaseProxy{\n        database: db,\n        userRole: role,\n    }\n}\n\nfunc (p *SecureDatabaseProxy) Query(sql string) ([]string, error) {\n    // Check permissions\n    if strings.Contains(strings.ToLower(sql), \"delete\") && p.userRole != \"admin\" {\n        return nil, fmt.Errorf(\"permission denied: only admin can delete\")\n    }\n    \n    return p.database.Query(sql)\n}\n\n// Usage\nfunc main() {\n    // Caching proxy\n    db := NewCachingDatabaseProxy(\"connection-string\")\n    \n    // First query hits the database\n    results, _ := db.Query(\"SELECT * FROM users\")\n    fmt.Println(\"Results:\", results)\n    \n    // Second identical query uses cache\n    results, _ = db.Query(\"SELECT * FROM users\")\n    fmt.Println(\"Results:\", results)\n    \n    // Security proxy\n    secureDB := NewSecureDatabaseProxy(db, \"user\")\n    _, err := secureDB.Query(\"DELETE FROM users\")\n    if err != nil {\n        fmt.Println(\"Error:\", err)\n    }\n}\n```\n\n## Behavioral Patterns\n\n### Chain of Responsibility\nChain of Responsibility passes requests along a chain of handlers until one handles it.\n\n```go\n// Handler interface\ntype Handler interface {\n    SetNext(Handler) Handler\n    Handle(request string) string\n}\n\n// Base handler\ntype BaseHandler struct {\n    next Handler\n}\n\nfunc (h *BaseHandler) SetNext(next Handler) Handler {\n    h.next = next\n    return next\n}\n\nfunc (h *BaseHandler) Handle(request string) string {\n    if h.next != nil {\n        return h.next.Handle(request)\n    }\n    return \"\"\n}\n\n// Concrete handlers\ntype AuthenticationHandler struct {\n    BaseHandler\n}\n\nfunc (h *AuthenticationHandler) Handle(request string) string {\n    if request == \"auth\" {\n        return \"Authentication successful\"\n    }\n    return h.BaseHandler.Handle(request)\n}\n\ntype AuthorizationHandler struct {\n    BaseHandler\n}\n\nfunc (h *AuthorizationHandler) Handle(request string) string {\n    if request == \"authz\" {\n        return \"Authorization granted\"\n    }\n    return h.BaseHandler.Handle(request)\n}\n\ntype ValidationHandler struct {\n    BaseHandler\n}\n\nfunc (h *ValidationHandler) Handle(request string) string {\n    if request == \"validate\" {\n        return \"Validation passed\"\n    }\n    return h.BaseHandler.Handle(request)\n}\n\n// Usage\nfunc main() {\n    auth := &AuthenticationHandler{}\n    authz := &AuthorizationHandler{}\n    valid := &ValidationHandler{}\n    \n    // Build chain\n    auth.SetNext(authz).SetNext(valid)\n    \n    // Process requests\n    fmt.Println(auth.Handle(\"auth\"))     // Handled by auth\n    fmt.Println(auth.Handle(\"authz\"))    // Handled by authz\n    fmt.Println(auth.Handle(\"validate\")) // Handled by valid\n    fmt.Println(auth.Handle(\"unknown\"))  // Not handled\n}\n```\n\n### Command\nCommand encapsulates a request as an object, letting you parameterize clients with different requests.\n\n```go\n// Command interface\ntype Command interface {\n    Execute() error\n    Undo() error\n}\n\n// Receiver\ntype Light struct {\n    isOn bool\n}\n\nfunc (l *Light) TurnOn() {\n    l.isOn = true\n    fmt.Println(\"Light is on\")\n}\n\nfunc (l *Light) TurnOff() {\n    l.isOn = false\n    fmt.Println(\"Light is off\")\n}\n\n// Concrete commands\ntype TurnOnCommand struct {\n    light *Light\n}\n\nfunc (c *TurnOnCommand) Execute() error {\n    c.light.TurnOn()\n    return nil\n}\n\nfunc (c *TurnOnCommand) Undo() error {\n    c.light.TurnOff()\n    return nil\n}\n\ntype TurnOffCommand struct {\n    light *Light\n}\n\nfunc (c *TurnOffCommand) Execute() error {\n    c.light.TurnOff()\n    return nil\n}\n\nfunc (c *TurnOffCommand) Undo() error {\n    c.light.TurnOn()\n    return nil\n}\n\n// Invoker\ntype RemoteControl struct {\n    commands []Command\n    history  []Command\n}\n\nfunc (r *RemoteControl) SetCommand(slot int, cmd Command) {\n    if slot >= len(r.commands) {\n        r.commands = append(r.commands, make([]Command, slot-len(r.commands)+1)...)\n    }\n    r.commands[slot] = cmd\n}\n\nfunc (r *RemoteControl) PressButton(slot int) {\n    if slot < len(r.commands) && r.commands[slot] != nil {\n        r.commands[slot].Execute()\n        r.history = append(r.history, r.commands[slot])\n    }\n}\n\nfunc (r *RemoteControl) PressUndo() {\n    if len(r.history) > 0 {\n        lastCommand := r.history[len(r.history)-1]\n        lastCommand.Undo()\n        r.history = r.history[:len(r.history)-1]\n    }\n}\n\n// Macro command\ntype MacroCommand struct {\n    commands []Command\n}\n\nfunc (m *MacroCommand) Execute() error {\n    for _, cmd := range m.commands {\n        if err := cmd.Execute(); err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\nfunc (m *MacroCommand) Undo() error {\n    // Undo in reverse order\n    for i := len(m.commands) - 1; i >= 0; i-- {\n        if err := m.commands[i].Undo(); err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\n// Usage\nfunc main() {\n    light := &Light{}\n    remote := &RemoteControl{}\n    \n    turnOn := &TurnOnCommand{light: light}\n    turnOff := &TurnOffCommand{light: light}\n    \n    remote.SetCommand(0, turnOn)\n    remote.SetCommand(1, turnOff)\n    \n    remote.PressButton(0) // Turn on\n    remote.PressButton(1) // Turn off\n    remote.PressUndo()    // Turn on again\n}\n```\n\n### Iterator\nIterator provides a way to access elements of a collection sequentially without exposing its underlying representation.\n\n```go\n// Iterator interface\ntype Iterator[T any] interface {\n    HasNext() bool\n    Next() T\n}\n\n// Collection interface\ntype Collection[T any] interface {\n    CreateIterator() Iterator[T]\n}\n\n// Concrete collection\ntype BookCollection struct {\n    books []string\n}\n\nfunc (c *BookCollection) Add(book string) {\n    c.books = append(c.books, book)\n}\n\nfunc (c *BookCollection) CreateIterator() Iterator[string] {\n    return &BookIterator{\n        collection: c,\n        index:      0,\n    }\n}\n\n// Concrete iterator\ntype BookIterator struct {\n    collection *BookCollection\n    index      int\n}\n\nfunc (i *BookIterator) HasNext() bool {\n    return i.index < len(i.collection.books)\n}\n\nfunc (i *BookIterator) Next() string {\n    if i.HasNext() {\n        book := i.collection.books[i.index]\n        i.index++\n        return book\n    }\n    return \"\"\n}\n\n// Usage with channels (Go idiomatic)\ntype ChannelIterator[T any] struct {\n    ch <-chan T\n    current T\n    hasNext bool\n}\n\nfunc NewChannelIterator[T any](items []T) *ChannelIterator[T] {\n    ch := make(chan T)\n    go func() {\n        for _, item := range items {\n            ch <- item\n        }\n        close(ch)\n    }()\n    \n    iter := &ChannelIterator[T]{ch: ch}\n    iter.advance()\n    return iter\n}\n\nfunc (i *ChannelIterator[T]) advance() {\n    i.current, i.hasNext = <-i.ch\n}\n\nfunc (i *ChannelIterator[T]) HasNext() bool {\n    return i.hasNext\n}\n\nfunc (i *ChannelIterator[T]) Next() T {\n    current := i.current\n    i.advance()\n    return current\n}\n\n// Usage\nfunc main() {\n    // Traditional iterator\n    collection := &BookCollection{}\n    collection.Add(\"Design Patterns\")\n    collection.Add(\"Clean Code\")\n    collection.Add(\"The Pragmatic Programmer\")\n    \n    iterator := collection.CreateIterator()\n    for iterator.HasNext() {\n        fmt.Println(iterator.Next())\n    }\n    \n    // Channel-based iterator\n    numbers := []int{1, 2, 3, 4, 5}\n    numIter := NewChannelIterator(numbers)\n    for numIter.HasNext() {\n        fmt.Println(numIter.Next())\n    }\n}\n```\n\n### Mediator\nMediator defines how a set of objects interact, promoting loose coupling.\n\n```go\n// Mediator interface\ntype ChatRoomMediator interface {\n    SendMessage(msg string, user User)\n    AddUser(user User)\n}\n\n// Colleague interface\ntype User interface {\n    Send(msg string)\n    Receive(msg string)\n    SetMediator(mediator ChatRoomMediator)\n}\n\n// Concrete mediator\ntype ChatRoom struct {\n    users []User\n}\n\nfunc (c *ChatRoom) SendMessage(msg string, sender User) {\n    for _, user := range c.users {\n        // Don't send message back to sender\n        if user != sender {\n            user.Receive(msg)\n        }\n    }\n}\n\nfunc (c *ChatRoom) AddUser(user User) {\n    c.users = append(c.users, user)\n    user.SetMediator(c)\n}\n\n// Concrete colleague\ntype ChatUser struct {\n    name     string\n    mediator ChatRoomMediator\n}\n\nfunc NewChatUser(name string) *ChatUser {\n    return &ChatUser{name: name}\n}\n\nfunc (u *ChatUser) Send(msg string) {\n    fmt.Printf(\"%s sends: %s\\n\", u.name, msg)\n    if u.mediator != nil {\n        u.mediator.SendMessage(msg, u)\n    }\n}\n\nfunc (u *ChatUser) Receive(msg string) {\n    fmt.Printf(\"%s receives: %s\\n\", u.name, msg)\n}\n\nfunc (u *ChatUser) SetMediator(mediator ChatRoomMediator) {\n    u.mediator = mediator\n}\n\n// Usage\nfunc main() {\n    chatRoom := &ChatRoom{}\n    \n    alice := NewChatUser(\"Alice\")\n    bob := NewChatUser(\"Bob\")\n    charlie := NewChatUser(\"Charlie\")\n    \n    chatRoom.AddUser(alice)\n    chatRoom.AddUser(bob)\n    chatRoom.AddUser(charlie)\n    \n    alice.Send(\"Hello everyone!\")\n    bob.Send(\"Hey Alice!\")\n}\n```\n\n### Memento\nMemento captures and externalizes an object's internal state for later restoration.\n\n```go\n// Memento\ntype EditorMemento struct {\n    content string\n    cursor  int\n}\n\n// Originator\ntype TextEditor struct {\n    content string\n    cursor  int\n}\n\nfunc (e *TextEditor) Type(text string) {\n    e.content = e.content[:e.cursor] + text + e.content[e.cursor:]\n    e.cursor += len(text)\n}\n\nfunc (e *TextEditor) Delete(length int) {\n    if e.cursor >= length {\n        e.content = e.content[:e.cursor-length] + e.content[e.cursor:]\n        e.cursor -= length\n    }\n}\n\nfunc (e *TextEditor) Save() *EditorMemento {\n    return &EditorMemento{\n        content: e.content,\n        cursor:  e.cursor,\n    }\n}\n\nfunc (e *TextEditor) Restore(memento *EditorMemento) {\n    e.content = memento.content\n    e.cursor = memento.cursor\n}\n\nfunc (e *TextEditor) String() string {\n    return fmt.Sprintf(\"Content: %s (cursor at %d)\", e.content, e.cursor)\n}\n\n// Caretaker\ntype History struct {\n    mementos []*EditorMemento\n    current  int\n}\n\nfunc (h *History) Push(memento *EditorMemento) {\n    // Remove any states after current position\n    h.mementos = h.mementos[:h.current+1]\n    h.mementos = append(h.mementos, memento)\n    h.current++\n}\n\nfunc (h *History) Undo() *EditorMemento {\n    if h.current > 0 {\n        h.current--\n        return h.mementos[h.current]\n    }\n    return nil\n}\n\nfunc (h *History) Redo() *EditorMemento {\n    if h.current < len(h.mementos)-1 {\n        h.current++\n        return h.mementos[h.current]\n    }\n    return nil\n}\n\n// Usage\nfunc main() {\n    editor := &TextEditor{}\n    history := &History{}\n    \n    // Initial state\n    history.Push(editor.Save())\n    \n    editor.Type(\"Hello \")\n    history.Push(editor.Save())\n    \n    editor.Type(\"World\")\n    history.Push(editor.Save())\n    \n    editor.Type(\"!\")\n    history.Push(editor.Save())\n    \n    fmt.Println(editor)\n    \n    // Undo\n    if memento := history.Undo(); memento != nil {\n        editor.Restore(memento)\n        fmt.Println(\"After undo:\", editor)\n    }\n    \n    // Undo again\n    if memento := history.Undo(); memento != nil {\n        editor.Restore(memento)\n        fmt.Println(\"After undo:\", editor)\n    }\n    \n    // Redo\n    if memento := history.Redo(); memento != nil {\n        editor.Restore(memento)\n        fmt.Println(\"After redo:\", editor)\n    }\n}\n```\n\n### Observer\nObserver defines a one-to-many dependency between objects where state changes are automatically notified.\n\n```go\n// Observer interface\ntype Observer interface {\n    Update(event string, data interface{})\n}\n\n// Subject interface\ntype Subject interface {\n    Attach(observer Observer)\n    Detach(observer Observer)\n    Notify(event string, data interface{})\n}\n\n// Concrete subject\ntype StockPrice struct {\n    observers map[Observer]bool\n    symbol    string\n    price     float64\n}\n\nfunc NewStockPrice(symbol string) *StockPrice {\n    return &StockPrice{\n        observers: make(map[Observer]bool),\n        symbol:    symbol,\n    }\n}\n\nfunc (s *StockPrice) Attach(observer Observer) {\n    s.observers[observer] = true\n}\n\nfunc (s *StockPrice) Detach(observer Observer) {\n    delete(s.observers, observer)\n}\n\nfunc (s *StockPrice) Notify(event string, data interface{}) {\n    for observer := range s.observers {\n        observer.Update(event, data)\n    }\n}\n\nfunc (s *StockPrice) SetPrice(price float64) {\n    oldPrice := s.price\n    s.price = price\n    \n    change := ((price - oldPrice) / oldPrice) * 100\n    s.Notify(\"price_changed\", map[string]interface{}{\n        \"symbol\":    s.symbol,\n        \"old_price\": oldPrice,\n        \"new_price\": price,\n        \"change\":    change,\n    })\n}\n\n// Concrete observers\ntype InvestorAlert struct {\n    name string\n}\n\nfunc (i *InvestorAlert) Update(event string, data interface{}) {\n    if event == \"price_changed\" {\n        priceData := data.(map[string]interface{})\n        fmt.Printf(\"[%s] Price alert: %s changed from %.2f to %.2f (%.2f%%)\\n\",\n            i.name,\n            priceData[\"symbol\"],\n            priceData[\"old_price\"],\n            priceData[\"new_price\"],\n            priceData[\"change\"])\n    }\n}\n\ntype TradingBot struct {\n    threshold float64\n}\n\nfunc (t *TradingBot) Update(event string, data interface{}) {\n    if event == \"price_changed\" {\n        priceData := data.(map[string]interface{})\n        change := priceData[\"change\"].(float64)\n        \n        if change > t.threshold {\n            fmt.Printf(\"[Bot] BUY signal: price increased by %.2f%%\\n\", change)\n        } else if change < -t.threshold {\n            fmt.Printf(\"[Bot] SELL signal: price decreased by %.2f%%\\n\", change)\n        }\n    }\n}\n\n// Usage\nfunc main() {\n    stock := NewStockPrice(\"AAPL\")\n    \n    investor := &InvestorAlert{name: \"John\"}\n    bot := &TradingBot{threshold: 5.0}\n    \n    stock.Attach(investor)\n    stock.Attach(bot)\n    \n    stock.SetPrice(100.00)\n    stock.SetPrice(105.50)\n    stock.SetPrice(98.00)\n}\n```\n\n### State\nState allows an object to alter its behavior when its internal state changes.\n\n```go\n// State interface\ntype State interface {\n    InsertCoin(m *VendingMachine)\n    SelectProduct(m *VendingMachine)\n    Dispense(m *VendingMachine)\n    Cancel(m *VendingMachine)\n}\n\n// Context\ntype VendingMachine struct {\n    state    State\n    coins    int\n    products int\n}\n\nfunc NewVendingMachine(products int) *VendingMachine {\n    vm := &VendingMachine{\n        products: products,\n    }\n    vm.state = &IdleState{}\n    return vm\n}\n\nfunc (m *VendingMachine) SetState(state State) {\n    m.state = state\n    fmt.Printf(\"State changed to: %T\\n\", state)\n}\n\nfunc (m *VendingMachine) InsertCoin() {\n    m.state.InsertCoin(m)\n}\n\nfunc (m *VendingMachine) SelectProduct() {\n    m.state.SelectProduct(m)\n}\n\nfunc (m *VendingMachine) Dispense() {\n    m.state.Dispense(m)\n}\n\nfunc (m *VendingMachine) Cancel() {\n    m.state.Cancel(m)\n}\n\n// Concrete states\ntype IdleState struct{}\n\nfunc (s *IdleState) InsertCoin(m *VendingMachine) {\n    fmt.Println(\"Coin inserted\")\n    m.coins++\n    m.SetState(&HasCoinState{})\n}\n\nfunc (s *IdleState) SelectProduct(m *VendingMachine) {\n    fmt.Println(\"Please insert coin first\")\n}\n\nfunc (s *IdleState) Dispense(m *VendingMachine) {\n    fmt.Println(\"Please insert coin and select product\")\n}\n\nfunc (s *IdleState) Cancel(m *VendingMachine) {\n    fmt.Println(\"Nothing to cancel\")\n}\n\ntype HasCoinState struct{}\n\nfunc (s *HasCoinState) InsertCoin(m *VendingMachine) {\n    fmt.Println(\"Coin already inserted\")\n}\n\nfunc (s *HasCoinState) SelectProduct(m *VendingMachine) {\n    if m.products > 0 {\n        fmt.Println(\"Product selected\")\n        m.SetState(&DispensingState{})\n        m.Dispense()\n    } else {\n        fmt.Println(\"Out of products\")\n        m.Cancel()\n    }\n}\n\nfunc (s *HasCoinState) Dispense(m *VendingMachine) {\n    fmt.Println(\"Please select product first\")\n}\n\nfunc (s *HasCoinState) Cancel(m *VendingMachine) {\n    fmt.Println(\"Returning coin\")\n    m.coins--\n    m.SetState(&IdleState{})\n}\n\ntype DispensingState struct{}\n\nfunc (s *DispensingState) InsertCoin(m *VendingMachine) {\n    fmt.Println(\"Please wait, dispensing product\")\n}\n\nfunc (s *DispensingState) SelectProduct(m *VendingMachine) {\n    fmt.Println(\"Please wait, dispensing product\")\n}\n\nfunc (s *DispensingState) Dispense(m *VendingMachine) {\n    fmt.Println(\"Dispensing product\")\n    m.products--\n    m.coins--\n    m.SetState(&IdleState{})\n}\n\nfunc (s *DispensingState) Cancel(m *VendingMachine) {\n    fmt.Println(\"Cannot cancel, already dispensing\")\n}\n\n// Usage\nfunc main() {\n    machine := NewVendingMachine(2)\n    \n    machine.SelectProduct() // Error: need coin\n    machine.InsertCoin()\n    machine.SelectProduct() // OK, dispenses\n    \n    machine.InsertCoin()\n    machine.Cancel() // Returns coin\n}\n```\n\n### Strategy\nStrategy defines a family of algorithms and makes them interchangeable.\n\n```go\n// Strategy interface\ntype PaymentStrategy interface {\n    Pay(amount float64) error\n    GetName() string\n}\n\n// Concrete strategies\ntype CreditCardStrategy struct {\n    number string\n    cvv    string\n}\n\nfunc (c *CreditCardStrategy) Pay(amount float64) error {\n    fmt.Printf(\"Paying $%.2f with credit card %s\\n\", amount, c.number)\n    // Payment logic\n    return nil\n}\n\nfunc (c *CreditCardStrategy) GetName() string {\n    return \"Credit Card\"\n}\n\ntype PayPalStrategy struct {\n    email string\n}\n\nfunc (p *PayPalStrategy) Pay(amount float64) error {\n    fmt.Printf(\"Paying $%.2f with PayPal account %s\\n\", amount, p.email)\n    // Payment logic\n    return nil\n}\n\nfunc (p *PayPalStrategy) GetName() string {\n    return \"PayPal\"\n}\n\ntype CryptoStrategy struct {\n    walletAddress string\n}\n\nfunc (c *CryptoStrategy) Pay(amount float64) error {\n    fmt.Printf(\"Paying $%.2f with crypto wallet %s\\n\", amount, c.walletAddress)\n    // Payment logic\n    return nil\n}\n\nfunc (c *CryptoStrategy) GetName() string {\n    return \"Cryptocurrency\"\n}\n\n// Context\ntype ShoppingCart struct {\n    items    []string\n    total    float64\n    strategy PaymentStrategy\n}\n\nfunc (s *ShoppingCart) AddItem(item string, price float64) {\n    s.items = append(s.items, item)\n    s.total += price\n}\n\nfunc (s *ShoppingCart) SetPaymentStrategy(strategy PaymentStrategy) {\n    s.strategy = strategy\n    fmt.Printf(\"Payment method set to: %s\\n\", strategy.GetName())\n}\n\nfunc (s *ShoppingCart) Checkout() error {\n    if s.strategy == nil {\n        return fmt.Errorf(\"no payment method selected\")\n    }\n    \n    fmt.Printf(\"Total: $%.2f\\n\", s.total)\n    return s.strategy.Pay(s.total)\n}\n\n// Usage\nfunc main() {\n    cart := &ShoppingCart{}\n    cart.AddItem(\"Laptop\", 999.99)\n    cart.AddItem(\"Mouse\", 29.99)\n    \n    // Pay with credit card\n    cart.SetPaymentStrategy(&CreditCardStrategy{\n        number: \"1234-5678-9012-3456\",\n        cvv:    \"123\",\n    })\n    cart.Checkout()\n    \n    // Change to PayPal\n    cart.SetPaymentStrategy(&PayPalStrategy{\n        email: \"user@example.com\",\n    })\n    cart.Checkout()\n}\n```\n\n### Template Method\nTemplate Method defines the skeleton of an algorithm in a base class, letting subclasses override specific steps.\n\n```go\n// Abstract class (using struct embedding in Go)\ntype DataProcessor struct {\n    // Define the interface that subclasses must implement\n    processor DataProcessorInterface\n}\n\ntype DataProcessorInterface interface {\n    Extract() ([]byte, error)\n    Transform(data []byte) ([]byte, error)\n    Load(data []byte) error\n}\n\n// Template method\nfunc (d *DataProcessor) Process() error {\n    // Extract\n    data, err := d.processor.Extract()\n    if err != nil {\n        return fmt.Errorf(\"extraction failed: %w\", err)\n    }\n    \n    // Transform\n    transformed, err := d.processor.Transform(data)\n    if err != nil {\n        return fmt.Errorf(\"transformation failed: %w\", err)\n    }\n    \n    // Load\n    if err := d.processor.Load(transformed); err != nil {\n        return fmt.Errorf(\"loading failed: %w\", err)\n    }\n    \n    return nil\n}\n\n// Concrete implementation - CSV Processor\ntype CSVProcessor struct {\n    DataProcessor\n    filename string\n}\n\nfunc NewCSVProcessor(filename string) *CSVProcessor {\n    p := &CSVProcessor{filename: filename}\n    p.DataProcessor.processor = p\n    return p\n}\n\nfunc (c *CSVProcessor) Extract() ([]byte, error) {\n    fmt.Printf(\"Extracting data from CSV file: %s\\n\", c.filename)\n    // Read CSV file\n    return []byte(\"csv,data,here\"), nil\n}\n\nfunc (c *CSVProcessor) Transform(data []byte) ([]byte, error) {\n    fmt.Println(\"Transforming CSV data\")\n    // Transform CSV data\n    return []byte(\"transformed csv data\"), nil\n}\n\nfunc (c *CSVProcessor) Load(data []byte) error {\n    fmt.Println(\"Loading CSV data to database\")\n    // Load to database\n    return nil\n}\n\n// Concrete implementation - JSON Processor\ntype JSONProcessor struct {\n    DataProcessor\n    url string\n}\n\nfunc NewJSONProcessor(url string) *JSONProcessor {\n    p := &JSONProcessor{url: url}\n    p.DataProcessor.processor = p\n    return p\n}\n\nfunc (j *JSONProcessor) Extract() ([]byte, error) {\n    fmt.Printf(\"Fetching JSON from API: %s\\n\", j.url)\n    // Fetch from API\n    return []byte(`{\"data\": \"value\"}`), nil\n}\n\nfunc (j *JSONProcessor) Transform(data []byte) ([]byte, error) {\n    fmt.Println(\"Transforming JSON data\")\n    // Transform JSON\n    return []byte(\"transformed json\"), nil\n}\n\nfunc (j *JSONProcessor) Load(data []byte) error {\n    fmt.Println(\"Loading JSON data to cache\")\n    // Load to cache\n    return nil\n}\n\n// Usage\nfunc main() {\n    csvProcessor := NewCSVProcessor(\"data.csv\")\n    if err := csvProcessor.Process(); err != nil {\n        fmt.Printf(\"CSV processing failed: %v\\n\", err)\n    }\n    \n    fmt.Println()\n    \n    jsonProcessor := NewJSONProcessor(\"https://api.example.com/data\")\n    if err := jsonProcessor.Process(); err != nil {\n        fmt.Printf(\"JSON processing failed: %v\\n\", err)\n    }\n}\n```\n\n### Visitor\nVisitor lets you define new operations without changing the classes of elements on which it operates.\n\n```go\n// Element interface\ntype Shape interface {\n    Accept(visitor Visitor)\n}\n\n// Visitor interface\ntype Visitor interface {\n    VisitCircle(c *Circle)\n    VisitRectangle(r *Rectangle)\n    VisitTriangle(t *Triangle)\n}\n\n// Concrete elements\ntype Circle struct {\n    Radius float64\n}\n\nfunc (c *Circle) Accept(visitor Visitor) {\n    visitor.VisitCircle(c)\n}\n\ntype Rectangle struct {\n    Width, Height float64\n}\n\nfunc (r *Rectangle) Accept(visitor Visitor) {\n    visitor.VisitRectangle(r)\n}\n\ntype Triangle struct {\n    Base, Height float64\n}\n\nfunc (t *Triangle) Accept(visitor Visitor) {\n    visitor.VisitTriangle(t)\n}\n\n// Concrete visitors\ntype AreaCalculator struct {\n    totalArea float64\n}\n\nfunc (a *AreaCalculator) VisitCircle(c *Circle) {\n    area := 3.14159 * c.Radius * c.Radius\n    fmt.Printf(\"Circle area: %.2f\\n\", area)\n    a.totalArea += area\n}\n\nfunc (a *AreaCalculator) VisitRectangle(r *Rectangle) {\n    area := r.Width * r.Height\n    fmt.Printf(\"Rectangle area: %.2f\\n\", area)\n    a.totalArea += area\n}\n\nfunc (a *AreaCalculator) VisitTriangle(t *Triangle) {\n    area := 0.5 * t.Base * t.Height\n    fmt.Printf(\"Triangle area: %.2f\\n\", area)\n    a.totalArea += area\n}\n\ntype PerimeterCalculator struct {\n    totalPerimeter float64\n}\n\nfunc (p *PerimeterCalculator) VisitCircle(c *Circle) {\n    perimeter := 2 * 3.14159 * c.Radius\n    fmt.Printf(\"Circle perimeter: %.2f\\n\", perimeter)\n    p.totalPerimeter += perimeter\n}\n\nfunc (p *PerimeterCalculator) VisitRectangle(r *Rectangle) {\n    perimeter := 2 * (r.Width + r.Height)\n    fmt.Printf(\"Rectangle perimeter: %.2f\\n\", perimeter)\n    p.totalPerimeter += perimeter\n}\n\nfunc (p *PerimeterCalculator) VisitTriangle(t *Triangle) {\n    // Simplified: assuming equilateral triangle\n    perimeter := 3 * t.Base\n    fmt.Printf(\"Triangle perimeter: %.2f\\n\", perimeter)\n    p.totalPerimeter += perimeter\n}\n\n// Usage\nfunc main() {\n    shapes := []Shape{\n        &Circle{Radius: 5},\n        &Rectangle{Width: 10, Height: 5},\n        &Triangle{Base: 6, Height: 4},\n    }\n    \n    areaCalc := &AreaCalculator{}\n    for _, shape := range shapes {\n        shape.Accept(areaCalc)\n    }\n    fmt.Printf(\"Total area: %.2f\\n\\n\", areaCalc.totalArea)\n    \n    perimCalc := &PerimeterCalculator{}\n    for _, shape := range shapes {\n        shape.Accept(perimCalc)\n    }\n    fmt.Printf(\"Total perimeter: %.2f\\n\", perimCalc.totalPerimeter)\n}\n```\n\n## Architectural Patterns\n\n### Repository Pattern\nRepository encapsulates data access logic and provides a more object-oriented view of the persistence layer.\n\n```go\n// Domain model\ntype User struct {\n    ID        string\n    Email     string\n    FirstName string\n    LastName  string\n    CreatedAt time.Time\n}\n\n// Repository interface\ntype UserRepository interface {\n    Create(ctx context.Context, user *User) error\n    GetByID(ctx context.Context, id string) (*User, error)\n    GetByEmail(ctx context.Context, email string) (*User, error)\n    Update(ctx context.Context, user *User) error\n    Delete(ctx context.Context, id string) error\n    List(ctx context.Context, offset, limit int) ([]*User, error)\n}\n\n// PostgreSQL implementation\ntype PostgresUserRepository struct {\n    db *sql.DB\n}\n\nfunc NewPostgresUserRepository(db *sql.DB) *PostgresUserRepository {\n    return &PostgresUserRepository{db: db}\n}\n\nfunc (r *PostgresUserRepository) Create(ctx context.Context, user *User) error {\n    query := `\n        INSERT INTO users (id, email, first_name, last_name, created_at)\n        VALUES ($1, $2, $3, $4, $5)\n    `\n    _, err := r.db.ExecContext(ctx, query,\n        user.ID, user.Email, user.FirstName, user.LastName, user.CreatedAt)\n    return err\n}\n\nfunc (r *PostgresUserRepository) GetByID(ctx context.Context, id string) (*User, error) {\n    query := `\n        SELECT id, email, first_name, last_name, created_at\n        FROM users WHERE id = $1\n    `\n    user := &User{}\n    err := r.db.QueryRowContext(ctx, query, id).Scan(\n        &user.ID, &user.Email, &user.FirstName, &user.LastName, &user.CreatedAt)\n    if err == sql.ErrNoRows {\n        return nil, fmt.Errorf(\"user not found\")\n    }\n    return user, err\n}\n\n// In-memory implementation for testing\ntype InMemoryUserRepository struct {\n    mu    sync.RWMutex\n    users map[string]*User\n}\n\nfunc NewInMemoryUserRepository() *InMemoryUserRepository {\n    return &InMemoryUserRepository{\n        users: make(map[string]*User),\n    }\n}\n\nfunc (r *InMemoryUserRepository) Create(ctx context.Context, user *User) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    \n    if _, exists := r.users[user.ID]; exists {\n        return fmt.Errorf(\"user already exists\")\n    }\n    r.users[user.ID] = user\n    return nil\n}\n\nfunc (r *InMemoryUserRepository) GetByID(ctx context.Context, id string) (*User, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    \n    if user, exists := r.users[id]; exists {\n        return user, nil\n    }\n    return nil, fmt.Errorf(\"user not found\")\n}\n```\n\n### Unit of Work Pattern\nUnit of Work maintains a list of objects affected by a business transaction and coordinates writing out changes.\n\n```go\n// Unit of Work interface\ntype UnitOfWork interface {\n    UserRepository() UserRepository\n    OrderRepository() OrderRepository\n    Commit() error\n    Rollback() error\n}\n\n// PostgreSQL Unit of Work\ntype PostgresUnitOfWork struct {\n    tx    *sql.Tx\n    users *PostgresUserRepository\n    orders *PostgresOrderRepository\n}\n\nfunc NewPostgresUnitOfWork(db *sql.DB) (*PostgresUnitOfWork, error) {\n    tx, err := db.Begin()\n    if err != nil {\n        return nil, err\n    }\n    \n    return &PostgresUnitOfWork{\n        tx:     tx,\n        users:  &PostgresUserRepository{db: db},\n        orders: &PostgresOrderRepository{db: db},\n    }, nil\n}\n\nfunc (u *PostgresUnitOfWork) UserRepository() UserRepository {\n    return u.users\n}\n\nfunc (u *PostgresUnitOfWork) OrderRepository() OrderRepository {\n    return u.orders\n}\n\nfunc (u *PostgresUnitOfWork) Commit() error {\n    return u.tx.Commit()\n}\n\nfunc (u *PostgresUnitOfWork) Rollback() error {\n    return u.tx.Rollback()\n}\n\n// Service using Unit of Work\ntype OrderService struct {\n    uowFactory func() (UnitOfWork, error)\n}\n\nfunc (s *OrderService) CreateOrder(userID string, items []OrderItem) error {\n    uow, err := s.uowFactory()\n    if err != nil {\n        return err\n    }\n    defer uow.Rollback()\n    \n    // Check user exists\n    user, err := uow.UserRepository().GetByID(context.Background(), userID)\n    if err != nil {\n        return err\n    }\n    \n    // Create order\n    order := &Order{\n        UserID: user.ID,\n        Items:  items,\n        Total:  calculateTotal(items),\n    }\n    \n    if err := uow.OrderRepository().Create(context.Background(), order); err != nil {\n        return err\n    }\n    \n    // Update user stats\n    user.TotalOrders++\n    if err := uow.UserRepository().Update(context.Background(), user); err != nil {\n        return err\n    }\n    \n    // Commit transaction\n    return uow.Commit()\n}\n```\n\n## Domain-Driven Design Patterns\n\n### Value Object\nValue Objects are immutable objects that represent a descriptive aspect of the domain.\n\n```go\n// Value Object - immutable\ntype Money struct {\n    amount   decimal.Decimal\n    currency string\n}\n\nfunc NewMoney(amount decimal.Decimal, currency string) (Money, error) {\n    if currency == \"\" {\n        return Money{}, fmt.Errorf(\"currency is required\")\n    }\n    if amount.IsNegative() {\n        return Money{}, fmt.Errorf(\"amount cannot be negative\")\n    }\n    return Money{amount: amount, currency: currency}, nil\n}\n\nfunc (m Money) Amount() decimal.Decimal {\n    return m.amount\n}\n\nfunc (m Money) Currency() string {\n    return m.currency\n}\n\nfunc (m Money) Add(other Money) (Money, error) {\n    if m.currency != other.currency {\n        return Money{}, fmt.Errorf(\"cannot add different currencies\")\n    }\n    return Money{\n        amount:   m.amount.Add(other.amount),\n        currency: m.currency,\n    }, nil\n}\n\nfunc (m Money) Equals(other Money) bool {\n    return m.amount.Equal(other.amount) && m.currency == other.currency\n}\n\n// Another Value Object example\ntype Email struct {\n    value string\n}\n\nfunc NewEmail(value string) (Email, error) {\n    if !isValidEmail(value) {\n        return Email{}, fmt.Errorf(\"invalid email format\")\n    }\n    return Email{value: strings.ToLower(value)}, nil\n}\n\nfunc (e Email) String() string {\n    return e.value\n}\n\nfunc (e Email) Domain() string {\n    parts := strings.Split(e.value, \"@\")\n    if len(parts) == 2 {\n        return parts[1]\n    }\n    return \"\"\n}\n```\n\n### Entity\nEntities have identity and lifecycle.\n\n```go\n// Entity with identity\ntype Product struct {\n    id          ProductID // Value object as ID\n    name        string\n    description string\n    price       Money\n    stock       int\n    version     int // For optimistic locking\n}\n\ntype ProductID struct {\n    value string\n}\n\nfunc NewProductID(value string) (ProductID, error) {\n    if value == \"\" {\n        return ProductID{}, fmt.Errorf(\"product ID cannot be empty\")\n    }\n    return ProductID{value: value}, nil\n}\n\nfunc (p ProductID) String() string {\n    return p.value\n}\n\nfunc NewProduct(id ProductID, name string, price Money) (*Product, error) {\n    if name == \"\" {\n        return nil, fmt.Errorf(\"product name is required\")\n    }\n    \n    return &Product{\n        id:    id,\n        name:  name,\n        price: price,\n        stock: 0,\n    }, nil\n}\n\nfunc (p *Product) ID() ProductID {\n    return p.id\n}\n\nfunc (p *Product) UpdatePrice(newPrice Money) error {\n    if newPrice.Amount().IsZero() {\n        return fmt.Errorf(\"price cannot be zero\")\n    }\n    p.price = newPrice\n    p.version++\n    return nil\n}\n\nfunc (p *Product) AddStock(quantity int) error {\n    if quantity <= 0 {\n        return fmt.Errorf(\"quantity must be positive\")\n    }\n    p.stock += quantity\n    p.version++\n    return nil\n}\n\nfunc (p *Product) CanFulfillOrder(quantity int) bool {\n    return p.stock >= quantity\n}\n```\n\n### Aggregate\nAggregates are clusters of domain objects that are treated as a single unit.\n\n```go\n// Aggregate root\ntype Order struct {\n    id         OrderID\n    customerID CustomerID\n    items      []OrderItem\n    status     OrderStatus\n    totalAmount Money\n    placedAt   time.Time\n    version    int\n}\n\n// Part of the aggregate\ntype OrderItem struct {\n    productID ProductID\n    quantity  int\n    unitPrice Money\n}\n\ntype OrderStatus string\n\nconst (\n    OrderStatusPending   OrderStatus = \"PENDING\"\n    OrderStatusConfirmed OrderStatus = \"CONFIRMED\"\n    OrderStatusShipped   OrderStatus = \"SHIPPED\"\n    OrderStatusDelivered OrderStatus = \"DELIVERED\"\n    OrderStatusCancelled OrderStatus = \"CANCELLED\"\n)\n\nfunc NewOrder(customerID CustomerID) *Order {\n    return &Order{\n        id:         NewOrderID(),\n        customerID: customerID,\n        items:      []OrderItem{},\n        status:     OrderStatusPending,\n        placedAt:   time.Now(),\n    }\n}\n\nfunc (o *Order) AddItem(productID ProductID, quantity int, unitPrice Money) error {\n    if o.status != OrderStatusPending {\n        return fmt.Errorf(\"cannot modify confirmed order\")\n    }\n    \n    if quantity <= 0 {\n        return fmt.Errorf(\"quantity must be positive\")\n    }\n    \n    // Check if item already exists\n    for i, item := range o.items {\n        if item.productID == productID {\n            o.items[i].quantity += quantity\n            o.recalculateTotal()\n            return nil\n        }\n    }\n    \n    // Add new item\n    o.items = append(o.items, OrderItem{\n        productID: productID,\n        quantity:  quantity,\n        unitPrice: unitPrice,\n    })\n    \n    o.recalculateTotal()\n    return nil\n}\n\nfunc (o *Order) RemoveItem(productID ProductID) error {\n    if o.status != OrderStatusPending {\n        return fmt.Errorf(\"cannot modify confirmed order\")\n    }\n    \n    for i, item := range o.items {\n        if item.productID == productID {\n            o.items = append(o.items[:i], o.items[i+1:]...)\n            o.recalculateTotal()\n            return nil\n        }\n    }\n    \n    return fmt.Errorf(\"item not found\")\n}\n\nfunc (o *Order) Confirm() error {\n    if o.status != OrderStatusPending {\n        return fmt.Errorf(\"order is not pending\")\n    }\n    \n    if len(o.items) == 0 {\n        return fmt.Errorf(\"order has no items\")\n    }\n    \n    o.status = OrderStatusConfirmed\n    o.version++\n    return nil\n}\n\nfunc (o *Order) recalculateTotal() {\n    total := decimal.Zero\n    currency := \"\"\n    \n    for _, item := range o.items {\n        itemTotal := item.unitPrice.Amount().Mul(decimal.NewFromInt(int64(item.quantity)))\n        total = total.Add(itemTotal)\n        if currency == \"\" {\n            currency = item.unitPrice.Currency()\n        }\n    }\n    \n    o.totalAmount, _ = NewMoney(total, currency)\n}\n\n// Aggregate repository\ntype OrderRepository interface {\n    Save(ctx context.Context, order *Order) error\n    GetByID(ctx context.Context, id OrderID) (*Order, error)\n    // Never expose internal parts of aggregate\n    // Bad: GetOrderItems(orderID) []OrderItem\n}\n```\n\n### Domain Service\nDomain Services encapsulate domain logic that doesn't naturally fit within an entity or value object.\n\n```go\n// Domain service for complex business logic\ntype PricingService struct {\n    taxCalculator TaxCalculator\n    discountRepo  DiscountRepository\n}\n\nfunc NewPricingService(tax TaxCalculator, discounts DiscountRepository) *PricingService {\n    return &PricingService{\n        taxCalculator: tax,\n        discountRepo:  discounts,\n    }\n}\n\nfunc (s *PricingService) CalculateOrderTotal(order *Order, customerType CustomerType) (Money, error) {\n    subtotal := order.totalAmount\n    \n    // Apply customer discount\n    discount := s.getCustomerDiscount(customerType)\n    discountAmount := subtotal.Amount().Mul(discount)\n    afterDiscount := subtotal.Amount().Sub(discountAmount)\n    \n    // Calculate tax\n    tax := s.taxCalculator.CalculateTax(afterDiscount, order.ShippingAddress())\n    \n    // Final total\n    total := afterDiscount.Add(tax)\n    \n    return NewMoney(total, subtotal.Currency())\n}\n\nfunc (s *PricingService) getCustomerDiscount(customerType CustomerType) decimal.Decimal {\n    switch customerType {\n    case CustomerTypePremium:\n        return decimal.NewFromFloat(0.15) // 15% discount\n    case CustomerTypeRegular:\n        return decimal.NewFromFloat(0.05) // 5% discount\n    default:\n        return decimal.Zero\n    }\n}\n\n// Another domain service example\ntype TransferService struct {\n    accountRepo AccountRepository\n}\n\nfunc (s *TransferService) Transfer(ctx context.Context, fromID, toID AccountID, amount Money) error {\n    // This logic doesn't belong to either account\n    // It's a domain service coordinating between aggregates\n    \n    from, err := s.accountRepo.GetByID(ctx, fromID)\n    if err != nil {\n        return err\n    }\n    \n    to, err := s.accountRepo.GetByID(ctx, toID)\n    if err != nil {\n        return err\n    }\n    \n    if err := from.Withdraw(amount); err != nil {\n        return err\n    }\n    \n    if err := to.Deposit(amount); err != nil {\n        // Compensate\n        from.Deposit(amount)\n        return err\n    }\n    \n    // Save both accounts\n    if err := s.accountRepo.Save(ctx, from); err != nil {\n        return err\n    }\n    \n    return s.accountRepo.Save(ctx, to)\n}\n```\n\n### Specification Pattern\nSpecification pattern encapsulates business rules in a reusable way.\n\n```go\n// Specification interface\ntype Specification[T any] interface {\n    IsSatisfiedBy(T) bool\n    And(Specification[T]) Specification[T]\n    Or(Specification[T]) Specification[T]\n    Not() Specification[T]\n}\n\n// Base specification\ntype BaseSpecification[T any] struct {\n    predicate func(T) bool\n}\n\nfunc NewSpecification[T any](predicate func(T) bool) Specification[T] {\n    return &BaseSpecification[T]{predicate: predicate}\n}\n\nfunc (s *BaseSpecification[T]) IsSatisfiedBy(item T) bool {\n    return s.predicate(item)\n}\n\nfunc (s *BaseSpecification[T]) And(other Specification[T]) Specification[T] {\n    return &BaseSpecification[T]{\n        predicate: func(item T) bool {\n            return s.IsSatisfiedBy(item) && other.IsSatisfiedBy(item)\n        },\n    }\n}\n\nfunc (s *BaseSpecification[T]) Or(other Specification[T]) Specification[T] {\n    return &BaseSpecification[T]{\n        predicate: func(item T) bool {\n            return s.IsSatisfiedBy(item) || other.IsSatisfiedBy(item)\n        },\n    }\n}\n\nfunc (s *BaseSpecification[T]) Not() Specification[T] {\n    return &BaseSpecification[T]{\n        predicate: func(item T) bool {\n            return !s.IsSatisfiedBy(item)\n        },\n    }\n}\n\n// Concrete specifications\ntype Product struct {\n    Name     string\n    Price    decimal.Decimal\n    Category string\n    InStock  bool\n}\n\nvar PremiumProductSpec = NewSpecification(func(p Product) bool {\n    return p.Price.GreaterThan(decimal.NewFromInt(100))\n})\n\nvar InStockSpec = NewSpecification(func(p Product) bool {\n    return p.InStock\n})\n\nvar ElectronicsSpec = NewSpecification(func(p Product) bool {\n    return p.Category == \"Electronics\"\n})\n\n// Usage\nfunc FilterProducts(products []Product, spec Specification[Product]) []Product {\n    var result []Product\n    for _, p := range products {\n        if spec.IsSatisfiedBy(p) {\n            result = append(result, p)\n        }\n    }\n    return result\n}\n\nfunc main() {\n    products := []Product{\n        {Name: \"Laptop\", Price: decimal.NewFromInt(1200), Category: \"Electronics\", InStock: true},\n        {Name: \"Mouse\", Price: decimal.NewFromInt(25), Category: \"Electronics\", InStock: true},\n        {Name: \"Book\", Price: decimal.NewFromInt(15), Category: \"Books\", InStock: false},\n    }\n    \n    // Premium electronics in stock\n    spec := PremiumProductSpec.And(ElectronicsSpec).And(InStockSpec)\n    \n    filtered := FilterProducts(products, spec)\n    fmt.Printf(\"Found %d products\\n\", len(filtered))\n}\n```\n\n## Summary\n\nThis comprehensive guide covers the major design patterns adapted for Go:\n\n1. **Creational Patterns**: Control object creation mechanisms\n2. **Structural Patterns**: Compose objects to form larger structures\n3. **Behavioral Patterns**: Define communication between objects\n4. **Architectural Patterns**: Organize high-level application structure\n5. **Domain-Driven Design Patterns**: Model complex business domains\n\nEach pattern includes practical Go implementations with proper error handling, concurrency considerations, and idiomatic Go practices. Choose patterns based on your specific needs, keeping in mind Go's philosophy of simplicity and clarity.","numLines":2651,"startLine":1,"totalLines":2651}}}
{"parentUuid":"cf86b142-f3c2-4ebe-a00d-894e6d612e4b","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UL6hGznRrBWszB1LE1jGJw","type":"tool_result","content":"     1→# Go Error Handling - Excellence in Error Management\n     2→\n     3→## Table of Contents\n     4→1. [Error Basics](#error-basics)\n     5→2. [Error Types](#error-types)\n     6→3. [Error Wrapping](#error-wrapping)\n     7→4. [Sentinel Errors](#sentinel-errors)\n     8→5. [Custom Errors](#custom-errors)\n     9→6. [Error Design Patterns](#error-design-patterns)\n    10→7. [Panic and Recover](#panic-and-recover)\n    11→8. [Error Handling Strategies](#error-handling-strategies)\n    12→9. [Testing Errors](#testing-errors)\n    13→10. [Best Practices](#best-practices)\n    14→\n    15→## Error Basics\n    16→\n    17→### The Error Interface\n    18→```go\n    19→// Built-in error interface\n    20→type error interface {\n    21→    Error() string\n    22→}\n    23→\n    24→// Basic error creation\n    25→import \"errors\"\n    26→\n    27→err := errors.New(\"something went wrong\")\n    28→\n    29→// Formatted errors\n    30→err := fmt.Errorf(\"failed to process item %d: %s\", id, reason)\n    31→\n    32→// Checking errors\n    33→result, err := doSomething()\n    34→if err != nil {\n    35→    // Handle error\n    36→    return err\n    37→}\n    38→\n    39→// Multiple return values with error\n    40→func divide(a, b float64) (float64, error) {\n    41→    if b == 0 {\n    42→        return 0, errors.New(\"division by zero\")\n    43→    }\n    44→    return a / b, nil\n    45→}\n    46→\n    47→// Named returns with error\n    48→func readFile(path string) (data []byte, err error) {\n    49→    data, err = os.ReadFile(path)\n    50→    if err != nil {\n    51→        return nil, err // Explicit return preferred\n    52→    }\n    53→    return data, nil\n    54→}\n    55→\n    56→// Defer with error handling\n    57→func writeFile(path string, data []byte) (err error) {\n    58→    f, err := os.Create(path)\n    59→    if err != nil {\n    60→        return err\n    61→    }\n    62→    defer func() {\n    63→        if cerr := f.Close(); cerr != nil && err == nil {\n    64→            err = cerr // Capture close error if no other error\n    65→        }\n    66→    }()\n    67→    \n    68→    _, err = f.Write(data)\n    69→    return err\n    70→}\n    71→```\n    72→\n    73→### Error Checking Patterns\n    74→```go\n    75→// Immediate return pattern\n    76→if err := doSomething(); err != nil {\n    77→    return fmt.Errorf(\"doSomething failed: %w\", err)\n    78→}\n    79→\n    80→// Guard clause pattern\n    81→func process(input string) error {\n    82→    if input == \"\" {\n    83→        return errors.New(\"input cannot be empty\")\n    84→    }\n    85→    \n    86→    if len(input) > 100 {\n    87→        return errors.New(\"input too long\")\n    88→    }\n    89→    \n    90→    // Main logic here\n    91→    return nil\n    92→}\n    93→\n    94→// Error accumulation\n    95→func processMultiple(items []Item) error {\n    96→    var errs []error\n    97→    \n    98→    for _, item := range items {\n    99→        if err := processItem(item); err != nil {\n   100→            errs = append(errs, fmt.Errorf(\"item %v: %w\", item.ID, err))\n   101→        }\n   102→    }\n   103→    \n   104→    if len(errs) > 0 {\n   105→        return fmt.Errorf(\"multiple errors: %v\", errs)\n   106→    }\n   107→    \n   108→    return nil\n   109→}\n   110→\n   111→// First error wins\n   112→func firstErrorWins(tasks []func() error) error {\n   113→    for _, task := range tasks {\n   114→        if err := task(); err != nil {\n   115→            return err\n   116→        }\n   117→    }\n   118→    return nil\n   119→}\n   120→\n   121→// All errors matter\n   122→import \"golang.org/x/sync/errgroup\"\n   123→\n   124→func allErrorsMatter(ctx context.Context) error {\n   125→    g, ctx := errgroup.WithContext(ctx)\n   126→    \n   127→    g.Go(func() error {\n   128→        return task1(ctx)\n   129→    })\n   130→    \n   131→    g.Go(func() error {\n   132→        return task2(ctx)\n   133→    })\n   134→    \n   135→    g.Go(func() error {\n   136→        return task3(ctx)\n   137→    })\n   138→    \n   139→    return g.Wait() // Returns first error\n   140→}\n   141→```\n   142→\n   143→## Error Types\n   144→\n   145→### Implementing Error Types\n   146→```go\n   147→// Simple error type\n   148→type ValidationError struct {\n   149→    Field string\n   150→    Value interface{}\n   151→    Msg   string\n   152→}\n   153→\n   154→func (e ValidationError) Error() string {\n   155→    return fmt.Sprintf(\"validation failed for %s with value %v: %s\", \n   156→        e.Field, e.Value, e.Msg)\n   157→}\n   158→\n   159→// Error type with code\n   160→type APIError struct {\n   161→    Code    int\n   162→    Message string\n   163→    Details map[string]interface{}\n   164→}\n   165→\n   166→func (e APIError) Error() string {\n   167→    return fmt.Sprintf(\"API error %d: %s\", e.Code, e.Message)\n   168→}\n   169→\n   170→// Temporary error interface\n   171→type temporary interface {\n   172→    Temporary() bool\n   173→}\n   174→\n   175→type NetworkError struct {\n   176→    Op         string\n   177→    Err        error\n   178→    Temporary  bool\n   179→    Timeout    bool\n   180→}\n   181→\n   182→func (e NetworkError) Error() string {\n   183→    return fmt.Sprintf(\"network error during %s: %v\", e.Op, e.Err)\n   184→}\n   185→\n   186→func (e NetworkError) Unwrap() error {\n   187→    return e.Err\n   188→}\n   189→\n   190→func (e NetworkError) IsTemporary() bool {\n   191→    return e.Temporary\n   192→}\n   193→\n   194→func (e NetworkError) IsTimeout() bool {\n   195→    return e.Timeout\n   196→}\n   197→\n   198→// Rich error type\n   199→type RichError struct {\n   200→    Op         string                 // Operation\n   201→    Kind       ErrorKind              // Category\n   202→    Err        error                  // Wrapped error\n   203→    Severity   Severity               // Error severity\n   204→    Context    map[string]interface{} // Additional context\n   205→    StackTrace string                 // Stack trace\n   206→    Timestamp  time.Time              // When it occurred\n   207→}\n   208→\n   209→type ErrorKind int\n   210→\n   211→const (\n   212→    KindOther ErrorKind = iota\n   213→    KindInvalid\n   214→    KindPermission\n   215→    KindIO\n   216→    KindExist\n   217→    KindNotExist\n   218→    KindNetwork\n   219→)\n   220→\n   221→type Severity int\n   222→\n   223→const (\n   224→    SeverityLow Severity = iota\n   225→    SeverityMedium\n   226→    SeverityHigh\n   227→    SeverityCritical\n   228→)\n   229→\n   230→func (e *RichError) Error() string {\n   231→    var b strings.Builder\n   232→    b.WriteString(e.Op)\n   233→    b.WriteString(\": \")\n   234→    b.WriteString(e.Kind.String())\n   235→    if e.Err != nil {\n   236→        b.WriteString(\": \")\n   237→        b.WriteString(e.Err.Error())\n   238→    }\n   239→    return b.String()\n   240→}\n   241→\n   242→func (e *RichError) Unwrap() error {\n   243→    return e.Err\n   244→}\n   245→```\n   246→\n   247→### Structured Errors\n   248→```go\n   249→// Multi-error type\n   250→type MultiError struct {\n   251→    Errors []error\n   252→}\n   253→\n   254→func (m *MultiError) Error() string {\n   255→    var msgs []string\n   256→    for _, err := range m.Errors {\n   257→        msgs = append(msgs, err.Error())\n   258→    }\n   259→    return strings.Join(msgs, \"; \")\n   260→}\n   261→\n   262→func (m *MultiError) Add(err error) {\n   263→    if err != nil {\n   264→        m.Errors = append(m.Errors, err)\n   265→    }\n   266→}\n   267→\n   268→func (m *MultiError) HasErrors() bool {\n   269→    return len(m.Errors) > 0\n   270→}\n   271→\n   272→// Causal error chain\n   273→type CausalError struct {\n   274→    Op    string\n   275→    Cause error\n   276→}\n   277→\n   278→func (e *CausalError) Error() string {\n   279→    if e.Cause != nil {\n   280→        return fmt.Sprintf(\"%s: %v\", e.Op, e.Cause)\n   281→    }\n   282→    return e.Op\n   283→}\n   284→\n   285→func (e *CausalError) Unwrap() error {\n   286→    return e.Cause\n   287→}\n   288→\n   289→// HTTP error response\n   290→type HTTPError struct {\n   291→    Status  int         `json:\"status\"`\n   292→    Code    string      `json:\"code\"`\n   293→    Message string      `json:\"message\"`\n   294→    Details interface{} `json:\"details,omitempty\"`\n   295→    TraceID string      `json:\"trace_id,omitempty\"`\n   296→}\n   297→\n   298→func (e HTTPError) Error() string {\n   299→    return fmt.Sprintf(\"HTTP %d: %s\", e.Status, e.Message)\n   300→}\n   301→\n   302→func (e HTTPError) StatusCode() int {\n   303→    return e.Status\n   304→}\n   305→```\n   306→\n   307→## Error Wrapping\n   308→\n   309→### Wrapping with fmt.Errorf\n   310→```go\n   311→// Basic wrapping (Go 1.13+)\n   312→func readConfig(path string) (*Config, error) {\n   313→    data, err := os.ReadFile(path)\n   314→    if err != nil {\n   315→        return nil, fmt.Errorf(\"failed to read config file %s: %w\", path, err)\n   316→    }\n   317→    \n   318→    var config Config\n   319→    if err := json.Unmarshal(data, &config); err != nil {\n   320→        return nil, fmt.Errorf(\"failed to parse config: %w\", err)\n   321→    }\n   322→    \n   323→    return &config, nil\n   324→}\n   325→\n   326→// Multiple wrapping layers\n   327→func highlevel() error {\n   328→    if err := midlevel(); err != nil {\n   329→        return fmt.Errorf(\"highlevel failed: %w\", err)\n   330→    }\n   331→    return nil\n   332→}\n   333→\n   334→func midlevel() error {\n   335→    if err := lowlevel(); err != nil {\n   336→        return fmt.Errorf(\"midlevel failed: %w\", err)\n   337→    }\n   338→    return nil\n   339→}\n   340→\n   341→func lowlevel() error {\n   342→    return errors.New(\"disk full\")\n   343→}\n   344→\n   345→// Result: \"highlevel failed: midlevel failed: disk full\"\n   346→\n   347→// Wrapping with additional context\n   348→type contextError struct {\n   349→    op      string\n   350→    path    string\n   351→    user    string\n   352→    wrapped error\n   353→}\n   354→\n   355→func (e *contextError) Error() string {\n   356→    return fmt.Sprintf(\"op=%s path=%s user=%s: %v\", \n   357→        e.op, e.path, e.user, e.wrapped)\n   358→}\n   359→\n   360→func (e *contextError) Unwrap() error {\n   361→    return e.wrapped\n   362→}\n   363→\n   364→func wrapWithContext(op, path, user string, err error) error {\n   365→    if err == nil {\n   366→        return nil\n   367→    }\n   368→    return &contextError{\n   369→        op:      op,\n   370→        path:    path,\n   371→        user:    user,\n   372→        wrapped: err,\n   373→    }\n   374→}\n   375→```\n   376→\n   377→### Unwrapping Errors\n   378→```go\n   379→// Using errors.Is (Go 1.13+)\n   380→var ErrPermission = errors.New(\"permission denied\")\n   381→\n   382→func checkPermission() error {\n   383→    // Some checks...\n   384→    return fmt.Errorf(\"user %s: %w\", username, ErrPermission)\n   385→}\n   386→\n   387→func main() {\n   388→    err := checkPermission()\n   389→    if errors.Is(err, ErrPermission) {\n   390→        // Handle permission error\n   391→    }\n   392→}\n   393→\n   394→// Using errors.As (Go 1.13+)\n   395→type PathError struct {\n   396→    Op   string\n   397→    Path string\n   398→    Err  error\n   399→}\n   400→\n   401→func (e *PathError) Error() string {\n   402→    return fmt.Sprintf(\"%s %s: %v\", e.Op, e.Path, e.Err)\n   403→}\n   404→\n   405→func handleError(err error) {\n   406→    var pathErr *PathError\n   407→    if errors.As(err, &pathErr) {\n   408→        fmt.Printf(\"Path error: %s\\n\", pathErr.Path)\n   409→    }\n   410→}\n   411→\n   412→// Custom Is implementation\n   413→type MyError struct {\n   414→    Code string\n   415→    Msg  string\n   416→}\n   417→\n   418→func (e MyError) Error() string {\n   419→    return fmt.Sprintf(\"%s: %s\", e.Code, e.Msg)\n   420→}\n   421→\n   422→func (e MyError) Is(target error) bool {\n   423→    t, ok := target.(MyError)\n   424→    if !ok {\n   425→        return false\n   426→    }\n   427→    return e.Code == t.Code\n   428→}\n   429→\n   430→// Custom As implementation\n   431→func (e *MyError) As(target interface{}) bool {\n   432→    switch v := target.(type) {\n   433→    case **MyError:\n   434→        *v = e\n   435→        return true\n   436→    case *MyError:\n   437→        *v = *e\n   438→        return true\n   439→    default:\n   440→        return false\n   441→    }\n   442→}\n   443→```\n   444→\n   445→## Sentinel Errors\n   446→\n   447→### Defining Sentinel Errors\n   448→```go\n   449→// Package-level sentinel errors\n   450→package mypackage\n   451→\n   452→var (\n   453→    // ErrNotFound is returned when a requested resource is not found.\n   454→    ErrNotFound = errors.New(\"not found\")\n   455→    \n   456→    // ErrAlreadyExists is returned when attempting to create a resource that already exists.\n   457→    ErrAlreadyExists = errors.New(\"already exists\")\n   458→    \n   459→    // ErrInvalidInput is returned when input validation fails.\n   460→    ErrInvalidInput = errors.New(\"invalid input\")\n   461→    \n   462→    // ErrUnauthorized is returned when authentication fails.\n   463→    ErrUnauthorized = errors.New(\"unauthorized\")\n   464→    \n   465→    // ErrForbidden is returned when the user lacks permission.\n   466→    ErrForbidden = errors.New(\"forbidden\")\n   467→    \n   468→    // ErrTimeout is returned when an operation times out.\n   469→    ErrTimeout = errors.New(\"operation timeout\")\n   470→    \n   471→    // ErrCanceled is returned when an operation is canceled.\n   472→    ErrCanceled = errors.New(\"operation canceled\")\n   473→)\n   474→\n   475→// Using sentinel errors\n   476→func GetUser(id string) (*User, error) {\n   477→    user, err := db.Query(id)\n   478→    if err != nil {\n   479→        if errors.Is(err, sql.ErrNoRows) {\n   480→            return nil, ErrNotFound\n   481→        }\n   482→        return nil, fmt.Errorf(\"database query failed: %w\", err)\n   483→    }\n   484→    return user, nil\n   485→}\n   486→\n   487→// Checking sentinel errors\n   488→user, err := GetUser(id)\n   489→if err != nil {\n   490→    if errors.Is(err, ErrNotFound) {\n   491→        // Handle not found case\n   492→        return http.StatusNotFound\n   493→    }\n   494→    // Handle other errors\n   495→    return http.StatusInternalServerError\n   496→}\n   497→\n   498→// Sentinel errors with types\n   499→type NotFoundError struct {\n   500→    Resource string\n   501→    ID       string\n   502→}\n   503→\n   504→func (e NotFoundError) Error() string {\n   505→    return fmt.Sprintf(\"%s with ID %s not found\", e.Resource, e.ID)\n   506→}\n   507→\n   508→var errNotFoundSentinel = NotFoundError{}\n   509→\n   510→func (e NotFoundError) Is(target error) bool {\n   511→    _, ok := target.(NotFoundError)\n   512→    return ok\n   513→}\n   514→```\n   515→\n   516→### Sentinel Error Best Practices\n   517→```go\n   518→// DO: Export sentinel errors that callers need to check\n   519→var ErrInvalidFormat = errors.New(\"invalid format\")\n   520→\n   521→// DON'T: Export errors that are implementation details\n   522→var errInternalState = errors.New(\"internal state corrupted\") // unexported\n   523→\n   524→// DO: Use descriptive names\n   525→var ErrUserNotFound = errors.New(\"user not found\")\n   526→var ErrInsufficientFunds = errors.New(\"insufficient funds\")\n   527→\n   528→// DON'T: Use generic names\n   529→var ErrBad = errors.New(\"bad\")\n   530→var ErrFail = errors.New(\"fail\")\n   531→\n   532→// DO: Document sentinel errors\n   533→// ErrRateLimitExceeded is returned when the rate limit is exceeded.\n   534→// Callers should implement exponential backoff when receiving this error.\n   535→var ErrRateLimitExceeded = errors.New(\"rate limit exceeded\")\n   536→\n   537→// DO: Group related errors\n   538→var (\n   539→    // Database errors\n   540→    ErrDBConnection = errors.New(\"database connection failed\")\n   541→    ErrDBTimeout    = errors.New(\"database timeout\")\n   542→    ErrDBLocked     = errors.New(\"database locked\")\n   543→    \n   544→    // Validation errors\n   545→    ErrValidationFailed = errors.New(\"validation failed\")\n   546→    ErrMissingField     = errors.New(\"required field missing\")\n   547→    ErrInvalidFormat    = errors.New(\"invalid format\")\n   548→)\n   549→```\n   550→\n   551→## Custom Errors\n   552→\n   553→### Domain-Specific Errors\n   554→```go\n   555→// Business logic errors\n   556→type InsufficientFundsError struct {\n   557→    Account   string\n   558→    Available decimal.Decimal\n   559→    Required  decimal.Decimal\n   560→}\n   561→\n   562→func (e InsufficientFundsError) Error() string {\n   563→    return fmt.Sprintf(\"insufficient funds in account %s: available %s, required %s\",\n   564→        e.Account, e.Available, e.Required)\n   565→}\n   566→\n   567→// Validation errors\n   568→type ValidationErrors struct {\n   569→    Errors map[string][]string\n   570→}\n   571→\n   572→func (v ValidationErrors) Error() string {\n   573→    var msgs []string\n   574→    for field, errors := range v.Errors {\n   575→        msgs = append(msgs, fmt.Sprintf(\"%s: %s\", field, strings.Join(errors, \", \")))\n   576→    }\n   577→    return \"validation failed: \" + strings.Join(msgs, \"; \")\n   578→}\n   579→\n   580→func (v *ValidationErrors) Add(field, message string) {\n   581→    if v.Errors == nil {\n   582→        v.Errors = make(map[string][]string)\n   583→    }\n   584→    v.Errors[field] = append(v.Errors[field], message)\n   585→}\n   586→\n   587→func (v ValidationErrors) HasErrors() bool {\n   588→    return len(v.Errors) > 0\n   589→}\n   590→\n   591→// State machine errors\n   592→type StateTransitionError struct {\n   593→    From  State\n   594→    To    State\n   595→    Event Event\n   596→}\n   597→\n   598→func (e StateTransitionError) Error() string {\n   599→    return fmt.Sprintf(\"invalid state transition from %s to %s on event %s\",\n   600→        e.From, e.To, e.Event)\n   601→}\n   602→\n   603→// Configuration errors\n   604→type ConfigError struct {\n   605→    File    string\n   606→    Section string\n   607→    Key     string\n   608→    Value   interface{}\n   609→    Reason  string\n   610→}\n   611→\n   612→func (e ConfigError) Error() string {\n   613→    return fmt.Sprintf(\"config error in %s [%s] %s=%v: %s\",\n   614→        e.File, e.Section, e.Key, e.Value, e.Reason)\n   615→}\n   616→```\n   617→\n   618→### Error Builders\n   619→```go\n   620→// Fluent error builder\n   621→type ErrorBuilder struct {\n   622→    err      error\n   623→    code     string\n   624→    message  string\n   625→    details  map[string]interface{}\n   626→    wrapped  error\n   627→}\n   628→\n   629→func NewError() *ErrorBuilder {\n   630→    return &ErrorBuilder{\n   631→        details: make(map[string]interface{}),\n   632→    }\n   633→}\n   634→\n   635→func (b *ErrorBuilder) WithCode(code string) *ErrorBuilder {\n   636→    b.code = code\n   637→    return b\n   638→}\n   639→\n   640→func (b *ErrorBuilder) WithMessage(msg string) *ErrorBuilder {\n   641→    b.message = msg\n   642→    return b\n   643→}\n   644→\n   645→func (b *ErrorBuilder) WithDetail(key string, value interface{}) *ErrorBuilder {\n   646→    b.details[key] = value\n   647→    return b\n   648→}\n   649→\n   650→func (b *ErrorBuilder) Wrap(err error) *ErrorBuilder {\n   651→    b.wrapped = err\n   652→    return b\n   653→}\n   654→\n   655→func (b *ErrorBuilder) Build() error {\n   656→    return &builtError{\n   657→        code:    b.code,\n   658→        message: b.message,\n   659→        details: b.details,\n   660→        wrapped: b.wrapped,\n   661→    }\n   662→}\n   663→\n   664→type builtError struct {\n   665→    code    string\n   666→    message string\n   667→    details map[string]interface{}\n   668→    wrapped error\n   669→}\n   670→\n   671→func (e builtError) Error() string {\n   672→    if e.wrapped != nil {\n   673→        return fmt.Sprintf(\"[%s] %s: %v\", e.code, e.message, e.wrapped)\n   674→    }\n   675→    return fmt.Sprintf(\"[%s] %s\", e.code, e.message)\n   676→}\n   677→\n   678→func (e builtError) Unwrap() error {\n   679→    return e.wrapped\n   680→}\n   681→\n   682→// Usage\n   683→err := NewError().\n   684→    WithCode(\"VALIDATION_ERROR\").\n   685→    WithMessage(\"Invalid user input\").\n   686→    WithDetail(\"field\", \"email\").\n   687→    WithDetail(\"value\", userEmail).\n   688→    Wrap(originalErr).\n   689→    Build()\n   690→```\n   691→\n   692→## Error Design Patterns\n   693→\n   694→### Error Handler Pattern\n   695→```go\n   696→// Centralized error handler\n   697→type ErrorHandler interface {\n   698→    Handle(error) error\n   699→}\n   700→\n   701→type errorHandler struct {\n   702→    logger    Logger\n   703→    metrics   Metrics\n   704→    notifier  Notifier\n   705→}\n   706→\n   707→func (h *errorHandler) Handle(err error) error {\n   708→    // Log error\n   709→    h.logger.Error(\"error occurred\", \"error\", err)\n   710→    \n   711→    // Record metrics\n   712→    h.metrics.IncrementErrorCount(errorType(err))\n   713→    \n   714→    // Notify if critical\n   715→    if isCritical(err) {\n   716→        h.notifier.NotifyCritical(err)\n   717→    }\n   718→    \n   719→    // Transform for client\n   720→    return transformError(err)\n   721→}\n   722→\n   723→func errorType(err error) string {\n   724→    switch {\n   725→    case errors.Is(err, ErrNotFound):\n   726→        return \"not_found\"\n   727→    case errors.Is(err, ErrUnauthorized):\n   728→        return \"unauthorized\"\n   729→    default:\n   730→        return \"internal\"\n   731→    }\n   732→}\n   733→\n   734→func isCritical(err error) bool {\n   735→    var criticalErr CriticalError\n   736→    return errors.As(err, &criticalErr)\n   737→}\n   738→\n   739→func transformError(err error) error {\n   740→    // Hide internal details from client\n   741→    switch {\n   742→    case errors.Is(err, ErrNotFound):\n   743→        return NewHTTPError(404, \"Resource not found\")\n   744→    case errors.Is(err, ErrUnauthorized):\n   745→        return NewHTTPError(401, \"Unauthorized\")\n   746→    default:\n   747→        return NewHTTPError(500, \"Internal server error\")\n   748→    }\n   749→}\n   750→```\n   751→\n   752→### Result Type Pattern\n   753→```go\n   754→// Result type for explicit error handling\n   755→type Result[T any] struct {\n   756→    value T\n   757→    err   error\n   758→}\n   759→\n   760→func Ok[T any](value T) Result[T] {\n   761→    return Result[T]{value: value}\n   762→}\n   763→\n   764→func Err[T any](err error) Result[T] {\n   765→    return Result[T]{err: err}\n   766→}\n   767→\n   768→func (r Result[T]) IsOk() bool {\n   769→    return r.err == nil\n   770→}\n   771→\n   772→func (r Result[T]) IsErr() bool {\n   773→    return r.err != nil\n   774→}\n   775→\n   776→func (r Result[T]) Unwrap() (T, error) {\n   777→    return r.value, r.err\n   778→}\n   779→\n   780→func (r Result[T]) UnwrapOr(defaultValue T) T {\n   781→    if r.err != nil {\n   782→        return defaultValue\n   783→    }\n   784→    return r.value\n   785→}\n   786→\n   787→func (r Result[T]) Map(fn func(T) T) Result[T] {\n   788→    if r.err != nil {\n   789→        return r\n   790→    }\n   791→    return Ok(fn(r.value))\n   792→}\n   793→\n   794→// Usage\n   795→func divide(a, b float64) Result[float64] {\n   796→    if b == 0 {\n   797→        return Err[float64](errors.New(\"division by zero\"))\n   798→    }\n   799→    return Ok(a / b)\n   800→}\n   801→\n   802→result := divide(10, 2)\n   803→if result.IsOk() {\n   804→    value, _ := result.Unwrap()\n   805→    fmt.Println(value)\n   806→}\n   807→```\n   808→\n   809→### Error Recovery Pattern\n   810→```go\n   811→// Retry with exponential backoff\n   812→func retryWithBackoff(fn func() error, maxRetries int) error {\n   813→    var err error\n   814→    backoff := 100 * time.Millisecond\n   815→    \n   816→    for i := 0; i < maxRetries; i++ {\n   817→        err = fn()\n   818→        if err == nil {\n   819→            return nil\n   820→        }\n   821→        \n   822→        // Check if error is retryable\n   823→        if !isRetryable(err) {\n   824→            return err\n   825→        }\n   826→        \n   827→        if i < maxRetries-1 {\n   828→            time.Sleep(backoff)\n   829→            backoff *= 2\n   830→            if backoff > 10*time.Second {\n   831→                backoff = 10 * time.Second\n   832→            }\n   833→        }\n   834→    }\n   835→    \n   836→    return fmt.Errorf(\"failed after %d retries: %w\", maxRetries, err)\n   837→}\n   838→\n   839→func isRetryable(err error) bool {\n   840→    // Check for temporary errors\n   841→    var tempErr interface{ Temporary() bool }\n   842→    if errors.As(err, &tempErr) && tempErr.Temporary() {\n   843→        return true\n   844→    }\n   845→    \n   846→    // Check for specific retryable errors\n   847→    return errors.Is(err, ErrTimeout) || \n   848→           errors.Is(err, ErrRateLimited) ||\n   849→           errors.Is(err, ErrServiceUnavailable)\n   850→}\n   851→\n   852→// Circuit breaker pattern\n   853→type CircuitBreaker struct {\n   854→    mu           sync.RWMutex\n   855→    failureCount int\n   856→    lastFailTime time.Time\n   857→    state        string // \"closed\", \"open\", \"half-open\"\n   858→    threshold    int\n   859→    timeout      time.Duration\n   860→}\n   861→\n   862→func (cb *CircuitBreaker) Call(fn func() error) error {\n   863→    cb.mu.RLock()\n   864→    state := cb.state\n   865→    cb.mu.RUnlock()\n   866→    \n   867→    if state == \"open\" {\n   868→        cb.mu.RLock()\n   869→        if time.Since(cb.lastFailTime) > cb.timeout {\n   870→            cb.mu.RUnlock()\n   871→            cb.mu.Lock()\n   872→            cb.state = \"half-open\"\n   873→            cb.mu.Unlock()\n   874→        } else {\n   875→            cb.mu.RUnlock()\n   876→            return ErrCircuitBreakerOpen\n   877→        }\n   878→    }\n   879→    \n   880→    err := fn()\n   881→    \n   882→    cb.mu.Lock()\n   883→    defer cb.mu.Unlock()\n   884→    \n   885→    if err != nil {\n   886→        cb.failureCount++\n   887→        cb.lastFailTime = time.Now()\n   888→        \n   889→        if cb.failureCount >= cb.threshold {\n   890→            cb.state = \"open\"\n   891→        }\n   892→        return err\n   893→    }\n   894→    \n   895→    if cb.state == \"half-open\" {\n   896→        cb.state = \"closed\"\n   897→    }\n   898→    cb.failureCount = 0\n   899→    return nil\n   900→}\n   901→```\n   902→\n   903→## Panic and Recover\n   904→\n   905→### When to Panic\n   906→```go\n   907→// Panic for unrecoverable errors during initialization\n   908→func MustConnect(dsn string) *sql.DB {\n   909→    db, err := sql.Open(\"postgres\", dsn)\n   910→    if err != nil {\n   911→        panic(fmt.Sprintf(\"failed to connect to database: %v\", err))\n   912→    }\n   913→    return db\n   914→}\n   915→\n   916→// Panic for programming errors\n   917→func (s *Stack) Pop() interface{} {\n   918→    if len(s.items) == 0 {\n   919→        panic(\"pop from empty stack\") // Programming error\n   920→    }\n   921→    item := s.items[len(s.items)-1]\n   922→    s.items = s.items[:len(s.items)-1]\n   923→    return item\n   924→}\n   925→\n   926→// Panic for impossible conditions\n   927→func processValue(v interface{}) {\n   928→    switch v := v.(type) {\n   929→    case int:\n   930→        // handle int\n   931→    case string:\n   932→        // handle string\n   933→    default:\n   934→        panic(fmt.Sprintf(\"unexpected type %T\", v))\n   935→    }\n   936→}\n   937→\n   938→// DON'T panic for normal errors\n   939→func badExample(input string) {\n   940→    if input == \"\" {\n   941→        panic(\"input is empty\") // Bad! Use error return instead\n   942→    }\n   943→}\n   944→\n   945→func goodExample(input string) error {\n   946→    if input == \"\" {\n   947→        return errors.New(\"input is empty\")\n   948→    }\n   949→    return nil\n   950→}\n   951→```\n   952→\n   953→### Recover Pattern\n   954→```go\n   955→// Basic recover\n   956→func safeCall(fn func()) (err error) {\n   957→    defer func() {\n   958→        if r := recover(); r != nil {\n   959→            err = fmt.Errorf(\"panic recovered: %v\", r)\n   960→        }\n   961→    }()\n   962→    \n   963→    fn()\n   964→    return nil\n   965→}\n   966→\n   967→// Recover with stack trace\n   968→import \"runtime/debug\"\n   969→\n   970→func recoverWithStack() {\n   971→    if r := recover(); r != nil {\n   972→        log.Printf(\"Panic: %v\\nStack: %s\", r, debug.Stack())\n   973→    }\n   974→}\n   975→\n   976→// HTTP middleware with recover\n   977→func RecoverMiddleware(next http.Handler) http.Handler {\n   978→    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n   979→        defer func() {\n   980→            if err := recover(); err != nil {\n   981→                log.Printf(\"Panic in handler: %v\\nStack: %s\", err, debug.Stack())\n   982→                http.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n   983→            }\n   984→        }()\n   985→        \n   986→        next.ServeHTTP(w, r)\n   987→    })\n   988→}\n   989→\n   990→// Goroutine with recover\n   991→func SafeGo(fn func()) {\n   992→    go func() {\n   993→        defer func() {\n   994→            if r := recover(); r != nil {\n   995→                log.Printf(\"Panic in goroutine: %v\\nStack: %s\", r, debug.Stack())\n   996→            }\n   997→        }()\n   998→        \n   999→        fn()\n  1000→    }()\n  1001→}\n  1002→\n  1003→// Convert panic to error\n  1004→func callExternalLibrary() (err error) {\n  1005→    defer func() {\n  1006→        if r := recover(); r != nil {\n  1007→            err = fmt.Errorf(\"external library panicked: %v\", r)\n  1008→        }\n  1009→    }()\n  1010→    \n  1011→    // Call potentially panicking external code\n  1012→    externalLibrary.DangerousOperation()\n  1013→    \n  1014→    return nil\n  1015→}\n  1016→```\n  1017→\n  1018→## Error Handling Strategies\n  1019→\n  1020→### Fail Fast\n  1021→```go\n  1022→// Fail fast on critical errors\n  1023→func Initialize() error {\n  1024→    // Check prerequisites first\n  1025→    if err := checkDependencies(); err != nil {\n  1026→        return fmt.Errorf(\"dependency check failed: %w\", err)\n  1027→    }\n  1028→    \n  1029→    if err := validateConfig(); err != nil {\n  1030→        return fmt.Errorf(\"config validation failed: %w\", err)\n  1031→    }\n  1032→    \n  1033→    // Only proceed if everything is valid\n  1034→    return startServices()\n  1035→}\n  1036→\n  1037→// Validate early\n  1038→func ProcessRequest(req Request) error {\n  1039→    // Validate input immediately\n  1040→    if err := req.Validate(); err != nil {\n  1041→        return fmt.Errorf(\"invalid request: %w\", err)\n  1042→    }\n  1043→    \n  1044→    // Check permissions early\n  1045→    if err := checkPermissions(req.UserID); err != nil {\n  1046→        return fmt.Errorf(\"permission denied: %w\", err)\n  1047→    }\n  1048→    \n  1049→    // Process only after validation\n  1050→    return process(req)\n  1051→}\n  1052→```\n  1053→\n  1054→### Graceful Degradation\n  1055→```go\n  1056→// Fallback on error\n  1057→func GetUserPreferences(userID string) (*Preferences, error) {\n  1058→    // Try to get from cache\n  1059→    prefs, err := cache.Get(userID)\n  1060→    if err == nil {\n  1061→        return prefs, nil\n  1062→    }\n  1063→    \n  1064→    // Fallback to database\n  1065→    prefs, err = db.GetPreferences(userID)\n  1066→    if err == nil {\n  1067→        // Update cache for next time\n  1068→        go cache.Set(userID, prefs)\n  1069→        return prefs, nil\n  1070→    }\n  1071→    \n  1072→    // Return defaults if all fails\n  1073→    log.Printf(\"Failed to get preferences for %s: %v\", userID, err)\n  1074→    return DefaultPreferences(), nil\n  1075→}\n  1076→\n  1077→// Partial success\n  1078→func ProcessBatch(items []Item) error {\n  1079→    var successCount int\n  1080→    var errors []error\n  1081→    \n  1082→    for _, item := range items {\n  1083→        if err := processItem(item); err != nil {\n  1084→            errors = append(errors, fmt.Errorf(\"item %v: %w\", item.ID, err))\n  1085→            continue\n  1086→        }\n  1087→        successCount++\n  1088→    }\n  1089→    \n  1090→    if len(errors) > 0 {\n  1091→        log.Printf(\"Processed %d/%d items successfully\", successCount, len(items))\n  1092→        return &PartialError{\n  1093→            Successful: successCount,\n  1094→            Failed:     len(errors),\n  1095→            Errors:     errors,\n  1096→        }\n  1097→    }\n  1098→    \n  1099→    return nil\n  1100→}\n  1101→```\n  1102→\n  1103→### Error Aggregation\n  1104→```go\n  1105→// Collect all errors\n  1106→type ErrorCollector struct {\n  1107→    mu     sync.Mutex\n  1108→    errors []error\n  1109→}\n  1110→\n  1111→func (c *ErrorCollector) Add(err error) {\n  1112→    if err == nil {\n  1113→        return\n  1114→    }\n  1115→    \n  1116→    c.mu.Lock()\n  1117→    defer c.mu.Unlock()\n  1118→    c.errors = append(c.errors, err)\n  1119→}\n  1120→\n  1121→func (c *ErrorCollector) Error() error {\n  1122→    c.mu.Lock()\n  1123→    defer c.mu.Unlock()\n  1124→    \n  1125→    switch len(c.errors) {\n  1126→    case 0:\n  1127→        return nil\n  1128→    case 1:\n  1129→        return c.errors[0]\n  1130→    default:\n  1131→        return &MultiError{Errors: c.errors}\n  1132→    }\n  1133→}\n  1134→\n  1135→// Usage with goroutines\n  1136→func ProcessConcurrently(items []Item) error {\n  1137→    var wg sync.WaitGroup\n  1138→    collector := &ErrorCollector{}\n  1139→    \n  1140→    for _, item := range items {\n  1141→        wg.Add(1)\n  1142→        go func(i Item) {\n  1143→            defer wg.Done()\n  1144→            if err := processItem(i); err != nil {\n  1145→                collector.Add(fmt.Errorf(\"item %v: %w\", i.ID, err))\n  1146→            }\n  1147→        }(item)\n  1148→    }\n  1149→    \n  1150→    wg.Wait()\n  1151→    return collector.Error()\n  1152→}\n  1153→```\n  1154→\n  1155→## Testing Errors\n  1156→\n  1157→### Testing Error Cases\n  1158→```go\n  1159→func TestDivide(t *testing.T) {\n  1160→    tests := []struct {\n  1161→        name    string\n  1162→        a, b    float64\n  1163→        want    float64\n  1164→        wantErr bool\n  1165→        errMsg  string\n  1166→    }{\n  1167→        {\n  1168→            name: \"normal division\",\n  1169→            a:    10,\n  1170→            b:    2,\n  1171→            want: 5,\n  1172→        },\n  1173→        {\n  1174→            name:    \"divide by zero\",\n  1175→            a:       10,\n  1176→            b:       0,\n  1177→            wantErr: true,\n  1178→            errMsg:  \"division by zero\",\n  1179→        },\n  1180→    }\n  1181→    \n  1182→    for _, tt := range tests {\n  1183→        t.Run(tt.name, func(t *testing.T) {\n  1184→            got, err := Divide(tt.a, tt.b)\n  1185→            \n  1186→            if (err != nil) != tt.wantErr {\n  1187→                t.Errorf(\"Divide() error = %v, wantErr %v\", err, tt.wantErr)\n  1188→                return\n  1189→            }\n  1190→            \n  1191→            if tt.wantErr {\n  1192→                if !strings.Contains(err.Error(), tt.errMsg) {\n  1193→                    t.Errorf(\"Divide() error = %v, want error containing %v\", \n  1194→                        err, tt.errMsg)\n  1195→                }\n  1196→                return\n  1197→            }\n  1198→            \n  1199→            if got != tt.want {\n  1200→                t.Errorf(\"Divide() = %v, want %v\", got, tt.want)\n  1201→            }\n  1202→        })\n  1203→    }\n  1204→}\n  1205→\n  1206→// Testing sentinel errors\n  1207→func TestGetUser_NotFound(t *testing.T) {\n  1208→    repo := NewMockRepository()\n  1209→    repo.ReturnError = sql.ErrNoRows\n  1210→    \n  1211→    service := NewService(repo)\n  1212→    _, err := service.GetUser(\"123\")\n  1213→    \n  1214→    if !errors.Is(err, ErrNotFound) {\n  1215→        t.Errorf(\"expected ErrNotFound, got %v\", err)\n  1216→    }\n  1217→}\n  1218→\n  1219→// Testing error types\n  1220→func TestValidationError(t *testing.T) {\n  1221→    err := ValidateUser(User{})\n  1222→    \n  1223→    var validationErr ValidationError\n  1224→    if !errors.As(err, &validationErr) {\n  1225→        t.Fatalf(\"expected ValidationError, got %T\", err)\n  1226→    }\n  1227→    \n  1228→    if validationErr.Field != \"email\" {\n  1229→        t.Errorf(\"expected field 'email', got %s\", validationErr.Field)\n  1230→    }\n  1231→}\n  1232→\n  1233→// Testing error wrapping\n  1234→func TestErrorWrapping(t *testing.T) {\n  1235→    rootErr := errors.New(\"root cause\")\n  1236→    wrappedErr := fmt.Errorf(\"wrapped: %w\", rootErr)\n  1237→    \n  1238→    if !errors.Is(wrappedErr, rootErr) {\n  1239→        t.Error(\"expected wrapped error to contain root cause\")\n  1240→    }\n  1241→}\n  1242→```\n  1243→\n  1244→### Mocking Errors\n  1245→```go\n  1246→// Error injection for testing\n  1247→type ErrorInjector struct {\n  1248→    errors map[string]error\n  1249→    calls  map[string]int\n  1250→}\n  1251→\n  1252→func (e *ErrorInjector) ShouldFail(operation string) error {\n  1253→    e.calls[operation]++\n  1254→    \n  1255→    if err, ok := e.errors[operation]; ok {\n  1256→        // Return error on specific call count\n  1257→        if callErr, ok := err.(*CallCountError); ok {\n  1258→            if e.calls[operation] == callErr.OnCall {\n  1259→                return callErr.Err\n  1260→            }\n  1261→            return nil\n  1262→        }\n  1263→        return err\n  1264→    }\n  1265→    \n  1266→    return nil\n  1267→}\n  1268→\n  1269→type CallCountError struct {\n  1270→    OnCall int\n  1271→    Err    error\n  1272→}\n  1273→\n  1274→// Usage in tests\n  1275→func TestRetry(t *testing.T) {\n  1276→    injector := &ErrorInjector{\n  1277→        errors: map[string]error{\n  1278→            \"connect\": &CallCountError{\n  1279→                OnCall: 1, // Fail on first call\n  1280→                Err:    errors.New(\"connection failed\"),\n  1281→            },\n  1282→        },\n  1283→        calls: make(map[string]int),\n  1284→    }\n  1285→    \n  1286→    service := NewService(injector)\n  1287→    err := service.ConnectWithRetry()\n  1288→    \n  1289→    if err != nil {\n  1290→        t.Errorf(\"expected success after retry, got %v\", err)\n  1291→    }\n  1292→    \n  1293→    if injector.calls[\"connect\"] != 2 {\n  1294→        t.Errorf(\"expected 2 connection attempts, got %d\", \n  1295→            injector.calls[\"connect\"])\n  1296→    }\n  1297→}\n  1298→```\n  1299→\n  1300→## Best Practices\n  1301→\n  1302→### Error Design Guidelines\n  1303→```go\n  1304→// 1. Return error as last value\n  1305→func Good() (Result, error)\n  1306→func Bad() (error, Result)  // Don't do this\n  1307→\n  1308→// 2. Check errors immediately\n  1309→result, err := doSomething()\n  1310→if err != nil {\n  1311→    return err\n  1312→}\n  1313→\n  1314→// 3. Add context when wrapping\n  1315→if err != nil {\n  1316→    return fmt.Errorf(\"failed to process user %s: %w\", userID, err)\n  1317→}\n  1318→\n  1319→// 4. Use sentinel errors for known conditions\n  1320→var ErrNotFound = errors.New(\"not found\")\n  1321→\n  1322→// 5. Create specific error types for rich information\n  1323→type ValidationError struct {\n  1324→    Field string\n  1325→    Value interface{}\n  1326→}\n  1327→\n  1328→// 6. Don't ignore errors\n  1329→_ = os.Remove(tempFile)  // Bad\n  1330→if err := os.Remove(tempFile); err != nil {\n  1331→    log.Printf(\"failed to remove temp file: %v\", err)\n  1332→}\n  1333→\n  1334→// 7. Handle errors once\n  1335→// Don't log AND return - let caller decide\n  1336→\n  1337→// 8. Use errors.Is and errors.As for checking\n  1338→if errors.Is(err, ErrNotFound) { }\n  1339→var validErr ValidationError\n  1340→if errors.As(err, &validErr) { }\n  1341→\n  1342→// 9. Keep error messages lowercase\n  1343→errors.New(\"not found\")  // Good\n  1344→errors.New(\"Not Found\")  // Bad\n  1345→\n  1346→// 10. Include relevant context\n  1347→fmt.Errorf(\"user %s: %w\", userID, err)  // Good\n  1348→fmt.Errorf(\"error: %w\", err)  // Too generic\n  1349→```\n  1350→\n  1351→### Common Pitfalls\n  1352→```go\n  1353→// Shadowing err variable\n  1354→err := doFirst()\n  1355→if err != nil {\n  1356→    err := doSecond()  // Shadows outer err!\n  1357→    if err != nil {\n  1358→        return err\n  1359→    }\n  1360→}\n  1361→\n  1362→// Checking wrong error\n  1363→result, err := doSomething()\n  1364→if err != nil {\n  1365→    anotherResult, err := doAnother()  // Reuses err\n  1366→    if err != nil {  // Might be checking wrong error\n  1367→        return err\n  1368→    }\n  1369→}\n  1370→\n  1371→// Nil interface gotcha\n  1372→func returnsError() error {\n  1373→    var err *MyError  // nil pointer\n  1374→    return err        // Returns non-nil error interface!\n  1375→}\n  1376→\n  1377→// Fix:\n  1378→func returnsError() error {\n  1379→    var err *MyError\n  1380→    if someCondition {\n  1381→        err = &MyError{}\n  1382→    }\n  1383→    if err != nil {\n  1384→        return err\n  1385→    }\n  1386→    return nil  // Explicitly return nil\n  1387→}\n  1388→```\n  1389→\n  1390→## Best Practices Summary\n  1391→\n  1392→1. **Always check errors** - Never ignore returned errors\n  1393→2. **Add context when wrapping** - Help debugging with good messages\n  1394→3. **Use sentinel errors wisely** - For known, actionable conditions\n  1395→4. **Create custom error types** - When you need rich error information\n  1396→5. **Fail fast** - Return early on errors\n  1397→6. **Don't panic** - Reserve for truly exceptional cases\n  1398→7. **Test error paths** - Ensure error handling works correctly\n  1399→8. **Use errors.Is/As** - For robust error checking\n  1400→9. **Keep errors actionable** - Help users understand what went wrong\n  1401→10. **Document error behavior** - Specify what errors functions can return\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"85aaaa26-b23d-46f1-b5f9-2fcc7a1f4a27","timestamp":"2025-08-13T10:28:02.636Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/errors.md","content":"# Go Error Handling - Excellence in Error Management\n\n## Table of Contents\n1. [Error Basics](#error-basics)\n2. [Error Types](#error-types)\n3. [Error Wrapping](#error-wrapping)\n4. [Sentinel Errors](#sentinel-errors)\n5. [Custom Errors](#custom-errors)\n6. [Error Design Patterns](#error-design-patterns)\n7. [Panic and Recover](#panic-and-recover)\n8. [Error Handling Strategies](#error-handling-strategies)\n9. [Testing Errors](#testing-errors)\n10. [Best Practices](#best-practices)\n\n## Error Basics\n\n### The Error Interface\n```go\n// Built-in error interface\ntype error interface {\n    Error() string\n}\n\n// Basic error creation\nimport \"errors\"\n\nerr := errors.New(\"something went wrong\")\n\n// Formatted errors\nerr := fmt.Errorf(\"failed to process item %d: %s\", id, reason)\n\n// Checking errors\nresult, err := doSomething()\nif err != nil {\n    // Handle error\n    return err\n}\n\n// Multiple return values with error\nfunc divide(a, b float64) (float64, error) {\n    if b == 0 {\n        return 0, errors.New(\"division by zero\")\n    }\n    return a / b, nil\n}\n\n// Named returns with error\nfunc readFile(path string) (data []byte, err error) {\n    data, err = os.ReadFile(path)\n    if err != nil {\n        return nil, err // Explicit return preferred\n    }\n    return data, nil\n}\n\n// Defer with error handling\nfunc writeFile(path string, data []byte) (err error) {\n    f, err := os.Create(path)\n    if err != nil {\n        return err\n    }\n    defer func() {\n        if cerr := f.Close(); cerr != nil && err == nil {\n            err = cerr // Capture close error if no other error\n        }\n    }()\n    \n    _, err = f.Write(data)\n    return err\n}\n```\n\n### Error Checking Patterns\n```go\n// Immediate return pattern\nif err := doSomething(); err != nil {\n    return fmt.Errorf(\"doSomething failed: %w\", err)\n}\n\n// Guard clause pattern\nfunc process(input string) error {\n    if input == \"\" {\n        return errors.New(\"input cannot be empty\")\n    }\n    \n    if len(input) > 100 {\n        return errors.New(\"input too long\")\n    }\n    \n    // Main logic here\n    return nil\n}\n\n// Error accumulation\nfunc processMultiple(items []Item) error {\n    var errs []error\n    \n    for _, item := range items {\n        if err := processItem(item); err != nil {\n            errs = append(errs, fmt.Errorf(\"item %v: %w\", item.ID, err))\n        }\n    }\n    \n    if len(errs) > 0 {\n        return fmt.Errorf(\"multiple errors: %v\", errs)\n    }\n    \n    return nil\n}\n\n// First error wins\nfunc firstErrorWins(tasks []func() error) error {\n    for _, task := range tasks {\n        if err := task(); err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\n// All errors matter\nimport \"golang.org/x/sync/errgroup\"\n\nfunc allErrorsMatter(ctx context.Context) error {\n    g, ctx := errgroup.WithContext(ctx)\n    \n    g.Go(func() error {\n        return task1(ctx)\n    })\n    \n    g.Go(func() error {\n        return task2(ctx)\n    })\n    \n    g.Go(func() error {\n        return task3(ctx)\n    })\n    \n    return g.Wait() // Returns first error\n}\n```\n\n## Error Types\n\n### Implementing Error Types\n```go\n// Simple error type\ntype ValidationError struct {\n    Field string\n    Value interface{}\n    Msg   string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"validation failed for %s with value %v: %s\", \n        e.Field, e.Value, e.Msg)\n}\n\n// Error type with code\ntype APIError struct {\n    Code    int\n    Message string\n    Details map[string]interface{}\n}\n\nfunc (e APIError) Error() string {\n    return fmt.Sprintf(\"API error %d: %s\", e.Code, e.Message)\n}\n\n// Temporary error interface\ntype temporary interface {\n    Temporary() bool\n}\n\ntype NetworkError struct {\n    Op         string\n    Err        error\n    Temporary  bool\n    Timeout    bool\n}\n\nfunc (e NetworkError) Error() string {\n    return fmt.Sprintf(\"network error during %s: %v\", e.Op, e.Err)\n}\n\nfunc (e NetworkError) Unwrap() error {\n    return e.Err\n}\n\nfunc (e NetworkError) IsTemporary() bool {\n    return e.Temporary\n}\n\nfunc (e NetworkError) IsTimeout() bool {\n    return e.Timeout\n}\n\n// Rich error type\ntype RichError struct {\n    Op         string                 // Operation\n    Kind       ErrorKind              // Category\n    Err        error                  // Wrapped error\n    Severity   Severity               // Error severity\n    Context    map[string]interface{} // Additional context\n    StackTrace string                 // Stack trace\n    Timestamp  time.Time              // When it occurred\n}\n\ntype ErrorKind int\n\nconst (\n    KindOther ErrorKind = iota\n    KindInvalid\n    KindPermission\n    KindIO\n    KindExist\n    KindNotExist\n    KindNetwork\n)\n\ntype Severity int\n\nconst (\n    SeverityLow Severity = iota\n    SeverityMedium\n    SeverityHigh\n    SeverityCritical\n)\n\nfunc (e *RichError) Error() string {\n    var b strings.Builder\n    b.WriteString(e.Op)\n    b.WriteString(\": \")\n    b.WriteString(e.Kind.String())\n    if e.Err != nil {\n        b.WriteString(\": \")\n        b.WriteString(e.Err.Error())\n    }\n    return b.String()\n}\n\nfunc (e *RichError) Unwrap() error {\n    return e.Err\n}\n```\n\n### Structured Errors\n```go\n// Multi-error type\ntype MultiError struct {\n    Errors []error\n}\n\nfunc (m *MultiError) Error() string {\n    var msgs []string\n    for _, err := range m.Errors {\n        msgs = append(msgs, err.Error())\n    }\n    return strings.Join(msgs, \"; \")\n}\n\nfunc (m *MultiError) Add(err error) {\n    if err != nil {\n        m.Errors = append(m.Errors, err)\n    }\n}\n\nfunc (m *MultiError) HasErrors() bool {\n    return len(m.Errors) > 0\n}\n\n// Causal error chain\ntype CausalError struct {\n    Op    string\n    Cause error\n}\n\nfunc (e *CausalError) Error() string {\n    if e.Cause != nil {\n        return fmt.Sprintf(\"%s: %v\", e.Op, e.Cause)\n    }\n    return e.Op\n}\n\nfunc (e *CausalError) Unwrap() error {\n    return e.Cause\n}\n\n// HTTP error response\ntype HTTPError struct {\n    Status  int         `json:\"status\"`\n    Code    string      `json:\"code\"`\n    Message string      `json:\"message\"`\n    Details interface{} `json:\"details,omitempty\"`\n    TraceID string      `json:\"trace_id,omitempty\"`\n}\n\nfunc (e HTTPError) Error() string {\n    return fmt.Sprintf(\"HTTP %d: %s\", e.Status, e.Message)\n}\n\nfunc (e HTTPError) StatusCode() int {\n    return e.Status\n}\n```\n\n## Error Wrapping\n\n### Wrapping with fmt.Errorf\n```go\n// Basic wrapping (Go 1.13+)\nfunc readConfig(path string) (*Config, error) {\n    data, err := os.ReadFile(path)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to read config file %s: %w\", path, err)\n    }\n    \n    var config Config\n    if err := json.Unmarshal(data, &config); err != nil {\n        return nil, fmt.Errorf(\"failed to parse config: %w\", err)\n    }\n    \n    return &config, nil\n}\n\n// Multiple wrapping layers\nfunc highlevel() error {\n    if err := midlevel(); err != nil {\n        return fmt.Errorf(\"highlevel failed: %w\", err)\n    }\n    return nil\n}\n\nfunc midlevel() error {\n    if err := lowlevel(); err != nil {\n        return fmt.Errorf(\"midlevel failed: %w\", err)\n    }\n    return nil\n}\n\nfunc lowlevel() error {\n    return errors.New(\"disk full\")\n}\n\n// Result: \"highlevel failed: midlevel failed: disk full\"\n\n// Wrapping with additional context\ntype contextError struct {\n    op      string\n    path    string\n    user    string\n    wrapped error\n}\n\nfunc (e *contextError) Error() string {\n    return fmt.Sprintf(\"op=%s path=%s user=%s: %v\", \n        e.op, e.path, e.user, e.wrapped)\n}\n\nfunc (e *contextError) Unwrap() error {\n    return e.wrapped\n}\n\nfunc wrapWithContext(op, path, user string, err error) error {\n    if err == nil {\n        return nil\n    }\n    return &contextError{\n        op:      op,\n        path:    path,\n        user:    user,\n        wrapped: err,\n    }\n}\n```\n\n### Unwrapping Errors\n```go\n// Using errors.Is (Go 1.13+)\nvar ErrPermission = errors.New(\"permission denied\")\n\nfunc checkPermission() error {\n    // Some checks...\n    return fmt.Errorf(\"user %s: %w\", username, ErrPermission)\n}\n\nfunc main() {\n    err := checkPermission()\n    if errors.Is(err, ErrPermission) {\n        // Handle permission error\n    }\n}\n\n// Using errors.As (Go 1.13+)\ntype PathError struct {\n    Op   string\n    Path string\n    Err  error\n}\n\nfunc (e *PathError) Error() string {\n    return fmt.Sprintf(\"%s %s: %v\", e.Op, e.Path, e.Err)\n}\n\nfunc handleError(err error) {\n    var pathErr *PathError\n    if errors.As(err, &pathErr) {\n        fmt.Printf(\"Path error: %s\\n\", pathErr.Path)\n    }\n}\n\n// Custom Is implementation\ntype MyError struct {\n    Code string\n    Msg  string\n}\n\nfunc (e MyError) Error() string {\n    return fmt.Sprintf(\"%s: %s\", e.Code, e.Msg)\n}\n\nfunc (e MyError) Is(target error) bool {\n    t, ok := target.(MyError)\n    if !ok {\n        return false\n    }\n    return e.Code == t.Code\n}\n\n// Custom As implementation\nfunc (e *MyError) As(target interface{}) bool {\n    switch v := target.(type) {\n    case **MyError:\n        *v = e\n        return true\n    case *MyError:\n        *v = *e\n        return true\n    default:\n        return false\n    }\n}\n```\n\n## Sentinel Errors\n\n### Defining Sentinel Errors\n```go\n// Package-level sentinel errors\npackage mypackage\n\nvar (\n    // ErrNotFound is returned when a requested resource is not found.\n    ErrNotFound = errors.New(\"not found\")\n    \n    // ErrAlreadyExists is returned when attempting to create a resource that already exists.\n    ErrAlreadyExists = errors.New(\"already exists\")\n    \n    // ErrInvalidInput is returned when input validation fails.\n    ErrInvalidInput = errors.New(\"invalid input\")\n    \n    // ErrUnauthorized is returned when authentication fails.\n    ErrUnauthorized = errors.New(\"unauthorized\")\n    \n    // ErrForbidden is returned when the user lacks permission.\n    ErrForbidden = errors.New(\"forbidden\")\n    \n    // ErrTimeout is returned when an operation times out.\n    ErrTimeout = errors.New(\"operation timeout\")\n    \n    // ErrCanceled is returned when an operation is canceled.\n    ErrCanceled = errors.New(\"operation canceled\")\n)\n\n// Using sentinel errors\nfunc GetUser(id string) (*User, error) {\n    user, err := db.Query(id)\n    if err != nil {\n        if errors.Is(err, sql.ErrNoRows) {\n            return nil, ErrNotFound\n        }\n        return nil, fmt.Errorf(\"database query failed: %w\", err)\n    }\n    return user, nil\n}\n\n// Checking sentinel errors\nuser, err := GetUser(id)\nif err != nil {\n    if errors.Is(err, ErrNotFound) {\n        // Handle not found case\n        return http.StatusNotFound\n    }\n    // Handle other errors\n    return http.StatusInternalServerError\n}\n\n// Sentinel errors with types\ntype NotFoundError struct {\n    Resource string\n    ID       string\n}\n\nfunc (e NotFoundError) Error() string {\n    return fmt.Sprintf(\"%s with ID %s not found\", e.Resource, e.ID)\n}\n\nvar errNotFoundSentinel = NotFoundError{}\n\nfunc (e NotFoundError) Is(target error) bool {\n    _, ok := target.(NotFoundError)\n    return ok\n}\n```\n\n### Sentinel Error Best Practices\n```go\n// DO: Export sentinel errors that callers need to check\nvar ErrInvalidFormat = errors.New(\"invalid format\")\n\n// DON'T: Export errors that are implementation details\nvar errInternalState = errors.New(\"internal state corrupted\") // unexported\n\n// DO: Use descriptive names\nvar ErrUserNotFound = errors.New(\"user not found\")\nvar ErrInsufficientFunds = errors.New(\"insufficient funds\")\n\n// DON'T: Use generic names\nvar ErrBad = errors.New(\"bad\")\nvar ErrFail = errors.New(\"fail\")\n\n// DO: Document sentinel errors\n// ErrRateLimitExceeded is returned when the rate limit is exceeded.\n// Callers should implement exponential backoff when receiving this error.\nvar ErrRateLimitExceeded = errors.New(\"rate limit exceeded\")\n\n// DO: Group related errors\nvar (\n    // Database errors\n    ErrDBConnection = errors.New(\"database connection failed\")\n    ErrDBTimeout    = errors.New(\"database timeout\")\n    ErrDBLocked     = errors.New(\"database locked\")\n    \n    // Validation errors\n    ErrValidationFailed = errors.New(\"validation failed\")\n    ErrMissingField     = errors.New(\"required field missing\")\n    ErrInvalidFormat    = errors.New(\"invalid format\")\n)\n```\n\n## Custom Errors\n\n### Domain-Specific Errors\n```go\n// Business logic errors\ntype InsufficientFundsError struct {\n    Account   string\n    Available decimal.Decimal\n    Required  decimal.Decimal\n}\n\nfunc (e InsufficientFundsError) Error() string {\n    return fmt.Sprintf(\"insufficient funds in account %s: available %s, required %s\",\n        e.Account, e.Available, e.Required)\n}\n\n// Validation errors\ntype ValidationErrors struct {\n    Errors map[string][]string\n}\n\nfunc (v ValidationErrors) Error() string {\n    var msgs []string\n    for field, errors := range v.Errors {\n        msgs = append(msgs, fmt.Sprintf(\"%s: %s\", field, strings.Join(errors, \", \")))\n    }\n    return \"validation failed: \" + strings.Join(msgs, \"; \")\n}\n\nfunc (v *ValidationErrors) Add(field, message string) {\n    if v.Errors == nil {\n        v.Errors = make(map[string][]string)\n    }\n    v.Errors[field] = append(v.Errors[field], message)\n}\n\nfunc (v ValidationErrors) HasErrors() bool {\n    return len(v.Errors) > 0\n}\n\n// State machine errors\ntype StateTransitionError struct {\n    From  State\n    To    State\n    Event Event\n}\n\nfunc (e StateTransitionError) Error() string {\n    return fmt.Sprintf(\"invalid state transition from %s to %s on event %s\",\n        e.From, e.To, e.Event)\n}\n\n// Configuration errors\ntype ConfigError struct {\n    File    string\n    Section string\n    Key     string\n    Value   interface{}\n    Reason  string\n}\n\nfunc (e ConfigError) Error() string {\n    return fmt.Sprintf(\"config error in %s [%s] %s=%v: %s\",\n        e.File, e.Section, e.Key, e.Value, e.Reason)\n}\n```\n\n### Error Builders\n```go\n// Fluent error builder\ntype ErrorBuilder struct {\n    err      error\n    code     string\n    message  string\n    details  map[string]interface{}\n    wrapped  error\n}\n\nfunc NewError() *ErrorBuilder {\n    return &ErrorBuilder{\n        details: make(map[string]interface{}),\n    }\n}\n\nfunc (b *ErrorBuilder) WithCode(code string) *ErrorBuilder {\n    b.code = code\n    return b\n}\n\nfunc (b *ErrorBuilder) WithMessage(msg string) *ErrorBuilder {\n    b.message = msg\n    return b\n}\n\nfunc (b *ErrorBuilder) WithDetail(key string, value interface{}) *ErrorBuilder {\n    b.details[key] = value\n    return b\n}\n\nfunc (b *ErrorBuilder) Wrap(err error) *ErrorBuilder {\n    b.wrapped = err\n    return b\n}\n\nfunc (b *ErrorBuilder) Build() error {\n    return &builtError{\n        code:    b.code,\n        message: b.message,\n        details: b.details,\n        wrapped: b.wrapped,\n    }\n}\n\ntype builtError struct {\n    code    string\n    message string\n    details map[string]interface{}\n    wrapped error\n}\n\nfunc (e builtError) Error() string {\n    if e.wrapped != nil {\n        return fmt.Sprintf(\"[%s] %s: %v\", e.code, e.message, e.wrapped)\n    }\n    return fmt.Sprintf(\"[%s] %s\", e.code, e.message)\n}\n\nfunc (e builtError) Unwrap() error {\n    return e.wrapped\n}\n\n// Usage\nerr := NewError().\n    WithCode(\"VALIDATION_ERROR\").\n    WithMessage(\"Invalid user input\").\n    WithDetail(\"field\", \"email\").\n    WithDetail(\"value\", userEmail).\n    Wrap(originalErr).\n    Build()\n```\n\n## Error Design Patterns\n\n### Error Handler Pattern\n```go\n// Centralized error handler\ntype ErrorHandler interface {\n    Handle(error) error\n}\n\ntype errorHandler struct {\n    logger    Logger\n    metrics   Metrics\n    notifier  Notifier\n}\n\nfunc (h *errorHandler) Handle(err error) error {\n    // Log error\n    h.logger.Error(\"error occurred\", \"error\", err)\n    \n    // Record metrics\n    h.metrics.IncrementErrorCount(errorType(err))\n    \n    // Notify if critical\n    if isCritical(err) {\n        h.notifier.NotifyCritical(err)\n    }\n    \n    // Transform for client\n    return transformError(err)\n}\n\nfunc errorType(err error) string {\n    switch {\n    case errors.Is(err, ErrNotFound):\n        return \"not_found\"\n    case errors.Is(err, ErrUnauthorized):\n        return \"unauthorized\"\n    default:\n        return \"internal\"\n    }\n}\n\nfunc isCritical(err error) bool {\n    var criticalErr CriticalError\n    return errors.As(err, &criticalErr)\n}\n\nfunc transformError(err error) error {\n    // Hide internal details from client\n    switch {\n    case errors.Is(err, ErrNotFound):\n        return NewHTTPError(404, \"Resource not found\")\n    case errors.Is(err, ErrUnauthorized):\n        return NewHTTPError(401, \"Unauthorized\")\n    default:\n        return NewHTTPError(500, \"Internal server error\")\n    }\n}\n```\n\n### Result Type Pattern\n```go\n// Result type for explicit error handling\ntype Result[T any] struct {\n    value T\n    err   error\n}\n\nfunc Ok[T any](value T) Result[T] {\n    return Result[T]{value: value}\n}\n\nfunc Err[T any](err error) Result[T] {\n    return Result[T]{err: err}\n}\n\nfunc (r Result[T]) IsOk() bool {\n    return r.err == nil\n}\n\nfunc (r Result[T]) IsErr() bool {\n    return r.err != nil\n}\n\nfunc (r Result[T]) Unwrap() (T, error) {\n    return r.value, r.err\n}\n\nfunc (r Result[T]) UnwrapOr(defaultValue T) T {\n    if r.err != nil {\n        return defaultValue\n    }\n    return r.value\n}\n\nfunc (r Result[T]) Map(fn func(T) T) Result[T] {\n    if r.err != nil {\n        return r\n    }\n    return Ok(fn(r.value))\n}\n\n// Usage\nfunc divide(a, b float64) Result[float64] {\n    if b == 0 {\n        return Err[float64](errors.New(\"division by zero\"))\n    }\n    return Ok(a / b)\n}\n\nresult := divide(10, 2)\nif result.IsOk() {\n    value, _ := result.Unwrap()\n    fmt.Println(value)\n}\n```\n\n### Error Recovery Pattern\n```go\n// Retry with exponential backoff\nfunc retryWithBackoff(fn func() error, maxRetries int) error {\n    var err error\n    backoff := 100 * time.Millisecond\n    \n    for i := 0; i < maxRetries; i++ {\n        err = fn()\n        if err == nil {\n            return nil\n        }\n        \n        // Check if error is retryable\n        if !isRetryable(err) {\n            return err\n        }\n        \n        if i < maxRetries-1 {\n            time.Sleep(backoff)\n            backoff *= 2\n            if backoff > 10*time.Second {\n                backoff = 10 * time.Second\n            }\n        }\n    }\n    \n    return fmt.Errorf(\"failed after %d retries: %w\", maxRetries, err)\n}\n\nfunc isRetryable(err error) bool {\n    // Check for temporary errors\n    var tempErr interface{ Temporary() bool }\n    if errors.As(err, &tempErr) && tempErr.Temporary() {\n        return true\n    }\n    \n    // Check for specific retryable errors\n    return errors.Is(err, ErrTimeout) || \n           errors.Is(err, ErrRateLimited) ||\n           errors.Is(err, ErrServiceUnavailable)\n}\n\n// Circuit breaker pattern\ntype CircuitBreaker struct {\n    mu           sync.RWMutex\n    failureCount int\n    lastFailTime time.Time\n    state        string // \"closed\", \"open\", \"half-open\"\n    threshold    int\n    timeout      time.Duration\n}\n\nfunc (cb *CircuitBreaker) Call(fn func() error) error {\n    cb.mu.RLock()\n    state := cb.state\n    cb.mu.RUnlock()\n    \n    if state == \"open\" {\n        cb.mu.RLock()\n        if time.Since(cb.lastFailTime) > cb.timeout {\n            cb.mu.RUnlock()\n            cb.mu.Lock()\n            cb.state = \"half-open\"\n            cb.mu.Unlock()\n        } else {\n            cb.mu.RUnlock()\n            return ErrCircuitBreakerOpen\n        }\n    }\n    \n    err := fn()\n    \n    cb.mu.Lock()\n    defer cb.mu.Unlock()\n    \n    if err != nil {\n        cb.failureCount++\n        cb.lastFailTime = time.Now()\n        \n        if cb.failureCount >= cb.threshold {\n            cb.state = \"open\"\n        }\n        return err\n    }\n    \n    if cb.state == \"half-open\" {\n        cb.state = \"closed\"\n    }\n    cb.failureCount = 0\n    return nil\n}\n```\n\n## Panic and Recover\n\n### When to Panic\n```go\n// Panic for unrecoverable errors during initialization\nfunc MustConnect(dsn string) *sql.DB {\n    db, err := sql.Open(\"postgres\", dsn)\n    if err != nil {\n        panic(fmt.Sprintf(\"failed to connect to database: %v\", err))\n    }\n    return db\n}\n\n// Panic for programming errors\nfunc (s *Stack) Pop() interface{} {\n    if len(s.items) == 0 {\n        panic(\"pop from empty stack\") // Programming error\n    }\n    item := s.items[len(s.items)-1]\n    s.items = s.items[:len(s.items)-1]\n    return item\n}\n\n// Panic for impossible conditions\nfunc processValue(v interface{}) {\n    switch v := v.(type) {\n    case int:\n        // handle int\n    case string:\n        // handle string\n    default:\n        panic(fmt.Sprintf(\"unexpected type %T\", v))\n    }\n}\n\n// DON'T panic for normal errors\nfunc badExample(input string) {\n    if input == \"\" {\n        panic(\"input is empty\") // Bad! Use error return instead\n    }\n}\n\nfunc goodExample(input string) error {\n    if input == \"\" {\n        return errors.New(\"input is empty\")\n    }\n    return nil\n}\n```\n\n### Recover Pattern\n```go\n// Basic recover\nfunc safeCall(fn func()) (err error) {\n    defer func() {\n        if r := recover(); r != nil {\n            err = fmt.Errorf(\"panic recovered: %v\", r)\n        }\n    }()\n    \n    fn()\n    return nil\n}\n\n// Recover with stack trace\nimport \"runtime/debug\"\n\nfunc recoverWithStack() {\n    if r := recover(); r != nil {\n        log.Printf(\"Panic: %v\\nStack: %s\", r, debug.Stack())\n    }\n}\n\n// HTTP middleware with recover\nfunc RecoverMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        defer func() {\n            if err := recover(); err != nil {\n                log.Printf(\"Panic in handler: %v\\nStack: %s\", err, debug.Stack())\n                http.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n            }\n        }()\n        \n        next.ServeHTTP(w, r)\n    })\n}\n\n// Goroutine with recover\nfunc SafeGo(fn func()) {\n    go func() {\n        defer func() {\n            if r := recover(); r != nil {\n                log.Printf(\"Panic in goroutine: %v\\nStack: %s\", r, debug.Stack())\n            }\n        }()\n        \n        fn()\n    }()\n}\n\n// Convert panic to error\nfunc callExternalLibrary() (err error) {\n    defer func() {\n        if r := recover(); r != nil {\n            err = fmt.Errorf(\"external library panicked: %v\", r)\n        }\n    }()\n    \n    // Call potentially panicking external code\n    externalLibrary.DangerousOperation()\n    \n    return nil\n}\n```\n\n## Error Handling Strategies\n\n### Fail Fast\n```go\n// Fail fast on critical errors\nfunc Initialize() error {\n    // Check prerequisites first\n    if err := checkDependencies(); err != nil {\n        return fmt.Errorf(\"dependency check failed: %w\", err)\n    }\n    \n    if err := validateConfig(); err != nil {\n        return fmt.Errorf(\"config validation failed: %w\", err)\n    }\n    \n    // Only proceed if everything is valid\n    return startServices()\n}\n\n// Validate early\nfunc ProcessRequest(req Request) error {\n    // Validate input immediately\n    if err := req.Validate(); err != nil {\n        return fmt.Errorf(\"invalid request: %w\", err)\n    }\n    \n    // Check permissions early\n    if err := checkPermissions(req.UserID); err != nil {\n        return fmt.Errorf(\"permission denied: %w\", err)\n    }\n    \n    // Process only after validation\n    return process(req)\n}\n```\n\n### Graceful Degradation\n```go\n// Fallback on error\nfunc GetUserPreferences(userID string) (*Preferences, error) {\n    // Try to get from cache\n    prefs, err := cache.Get(userID)\n    if err == nil {\n        return prefs, nil\n    }\n    \n    // Fallback to database\n    prefs, err = db.GetPreferences(userID)\n    if err == nil {\n        // Update cache for next time\n        go cache.Set(userID, prefs)\n        return prefs, nil\n    }\n    \n    // Return defaults if all fails\n    log.Printf(\"Failed to get preferences for %s: %v\", userID, err)\n    return DefaultPreferences(), nil\n}\n\n// Partial success\nfunc ProcessBatch(items []Item) error {\n    var successCount int\n    var errors []error\n    \n    for _, item := range items {\n        if err := processItem(item); err != nil {\n            errors = append(errors, fmt.Errorf(\"item %v: %w\", item.ID, err))\n            continue\n        }\n        successCount++\n    }\n    \n    if len(errors) > 0 {\n        log.Printf(\"Processed %d/%d items successfully\", successCount, len(items))\n        return &PartialError{\n            Successful: successCount,\n            Failed:     len(errors),\n            Errors:     errors,\n        }\n    }\n    \n    return nil\n}\n```\n\n### Error Aggregation\n```go\n// Collect all errors\ntype ErrorCollector struct {\n    mu     sync.Mutex\n    errors []error\n}\n\nfunc (c *ErrorCollector) Add(err error) {\n    if err == nil {\n        return\n    }\n    \n    c.mu.Lock()\n    defer c.mu.Unlock()\n    c.errors = append(c.errors, err)\n}\n\nfunc (c *ErrorCollector) Error() error {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    switch len(c.errors) {\n    case 0:\n        return nil\n    case 1:\n        return c.errors[0]\n    default:\n        return &MultiError{Errors: c.errors}\n    }\n}\n\n// Usage with goroutines\nfunc ProcessConcurrently(items []Item) error {\n    var wg sync.WaitGroup\n    collector := &ErrorCollector{}\n    \n    for _, item := range items {\n        wg.Add(1)\n        go func(i Item) {\n            defer wg.Done()\n            if err := processItem(i); err != nil {\n                collector.Add(fmt.Errorf(\"item %v: %w\", i.ID, err))\n            }\n        }(item)\n    }\n    \n    wg.Wait()\n    return collector.Error()\n}\n```\n\n## Testing Errors\n\n### Testing Error Cases\n```go\nfunc TestDivide(t *testing.T) {\n    tests := []struct {\n        name    string\n        a, b    float64\n        want    float64\n        wantErr bool\n        errMsg  string\n    }{\n        {\n            name: \"normal division\",\n            a:    10,\n            b:    2,\n            want: 5,\n        },\n        {\n            name:    \"divide by zero\",\n            a:       10,\n            b:       0,\n            wantErr: true,\n            errMsg:  \"division by zero\",\n        },\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got, err := Divide(tt.a, tt.b)\n            \n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Divide() error = %v, wantErr %v\", err, tt.wantErr)\n                return\n            }\n            \n            if tt.wantErr {\n                if !strings.Contains(err.Error(), tt.errMsg) {\n                    t.Errorf(\"Divide() error = %v, want error containing %v\", \n                        err, tt.errMsg)\n                }\n                return\n            }\n            \n            if got != tt.want {\n                t.Errorf(\"Divide() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n\n// Testing sentinel errors\nfunc TestGetUser_NotFound(t *testing.T) {\n    repo := NewMockRepository()\n    repo.ReturnError = sql.ErrNoRows\n    \n    service := NewService(repo)\n    _, err := service.GetUser(\"123\")\n    \n    if !errors.Is(err, ErrNotFound) {\n        t.Errorf(\"expected ErrNotFound, got %v\", err)\n    }\n}\n\n// Testing error types\nfunc TestValidationError(t *testing.T) {\n    err := ValidateUser(User{})\n    \n    var validationErr ValidationError\n    if !errors.As(err, &validationErr) {\n        t.Fatalf(\"expected ValidationError, got %T\", err)\n    }\n    \n    if validationErr.Field != \"email\" {\n        t.Errorf(\"expected field 'email', got %s\", validationErr.Field)\n    }\n}\n\n// Testing error wrapping\nfunc TestErrorWrapping(t *testing.T) {\n    rootErr := errors.New(\"root cause\")\n    wrappedErr := fmt.Errorf(\"wrapped: %w\", rootErr)\n    \n    if !errors.Is(wrappedErr, rootErr) {\n        t.Error(\"expected wrapped error to contain root cause\")\n    }\n}\n```\n\n### Mocking Errors\n```go\n// Error injection for testing\ntype ErrorInjector struct {\n    errors map[string]error\n    calls  map[string]int\n}\n\nfunc (e *ErrorInjector) ShouldFail(operation string) error {\n    e.calls[operation]++\n    \n    if err, ok := e.errors[operation]; ok {\n        // Return error on specific call count\n        if callErr, ok := err.(*CallCountError); ok {\n            if e.calls[operation] == callErr.OnCall {\n                return callErr.Err\n            }\n            return nil\n        }\n        return err\n    }\n    \n    return nil\n}\n\ntype CallCountError struct {\n    OnCall int\n    Err    error\n}\n\n// Usage in tests\nfunc TestRetry(t *testing.T) {\n    injector := &ErrorInjector{\n        errors: map[string]error{\n            \"connect\": &CallCountError{\n                OnCall: 1, // Fail on first call\n                Err:    errors.New(\"connection failed\"),\n            },\n        },\n        calls: make(map[string]int),\n    }\n    \n    service := NewService(injector)\n    err := service.ConnectWithRetry()\n    \n    if err != nil {\n        t.Errorf(\"expected success after retry, got %v\", err)\n    }\n    \n    if injector.calls[\"connect\"] != 2 {\n        t.Errorf(\"expected 2 connection attempts, got %d\", \n            injector.calls[\"connect\"])\n    }\n}\n```\n\n## Best Practices\n\n### Error Design Guidelines\n```go\n// 1. Return error as last value\nfunc Good() (Result, error)\nfunc Bad() (error, Result)  // Don't do this\n\n// 2. Check errors immediately\nresult, err := doSomething()\nif err != nil {\n    return err\n}\n\n// 3. Add context when wrapping\nif err != nil {\n    return fmt.Errorf(\"failed to process user %s: %w\", userID, err)\n}\n\n// 4. Use sentinel errors for known conditions\nvar ErrNotFound = errors.New(\"not found\")\n\n// 5. Create specific error types for rich information\ntype ValidationError struct {\n    Field string\n    Value interface{}\n}\n\n// 6. Don't ignore errors\n_ = os.Remove(tempFile)  // Bad\nif err := os.Remove(tempFile); err != nil {\n    log.Printf(\"failed to remove temp file: %v\", err)\n}\n\n// 7. Handle errors once\n// Don't log AND return - let caller decide\n\n// 8. Use errors.Is and errors.As for checking\nif errors.Is(err, ErrNotFound) { }\nvar validErr ValidationError\nif errors.As(err, &validErr) { }\n\n// 9. Keep error messages lowercase\nerrors.New(\"not found\")  // Good\nerrors.New(\"Not Found\")  // Bad\n\n// 10. Include relevant context\nfmt.Errorf(\"user %s: %w\", userID, err)  // Good\nfmt.Errorf(\"error: %w\", err)  // Too generic\n```\n\n### Common Pitfalls\n```go\n// Shadowing err variable\nerr := doFirst()\nif err != nil {\n    err := doSecond()  // Shadows outer err!\n    if err != nil {\n        return err\n    }\n}\n\n// Checking wrong error\nresult, err := doSomething()\nif err != nil {\n    anotherResult, err := doAnother()  // Reuses err\n    if err != nil {  // Might be checking wrong error\n        return err\n    }\n}\n\n// Nil interface gotcha\nfunc returnsError() error {\n    var err *MyError  // nil pointer\n    return err        // Returns non-nil error interface!\n}\n\n// Fix:\nfunc returnsError() error {\n    var err *MyError\n    if someCondition {\n        err = &MyError{}\n    }\n    if err != nil {\n        return err\n    }\n    return nil  // Explicitly return nil\n}\n```\n\n## Best Practices Summary\n\n1. **Always check errors** - Never ignore returned errors\n2. **Add context when wrapping** - Help debugging with good messages\n3. **Use sentinel errors wisely** - For known, actionable conditions\n4. **Create custom error types** - When you need rich error information\n5. **Fail fast** - Return early on errors\n6. **Don't panic** - Reserve for truly exceptional cases\n7. **Test error paths** - Ensure error handling works correctly\n8. **Use errors.Is/As** - For robust error checking\n9. **Keep errors actionable** - Help users understand what went wrong\n10. **Document error behavior** - Specify what errors functions can return","numLines":1401,"startLine":1,"totalLines":1401}}}
{"parentUuid":"85aaaa26-b23d-46f1-b5f9-2fcc7a1f4a27","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019WsA8iNvJUkfFVSLJwM3dL","type":"tool_result","content":"     1→# Go Concurrency - Mastering Concurrent Programming\n     2→\n     3→## Table of Contents\n     4→1. [Goroutines](#goroutines)\n     5→2. [Channels](#channels)\n     6→3. [Select Statement](#select-statement)\n     7→4. [Sync Package](#sync-package)\n     8→5. [Atomic Operations](#atomic-operations)\n     9→6. [Concurrency Patterns](#concurrency-patterns)\n    10→7. [Context Package](#context-package)\n    11→8. [Race Conditions](#race-conditions)\n    12→9. [Deadlocks](#deadlocks)\n    13→10. [Performance and Optimization](#performance-and-optimization)\n    14→\n    15→## Goroutines\n    16→\n    17→### Goroutine Basics\n    18→```go\n    19→// Starting a goroutine\n    20→go functionName()\n    21→go func() {\n    22→    // Anonymous function as goroutine\n    23→}()\n    24→\n    25→// Goroutines with parameters\n    26→go processItem(item)\n    27→\n    28→// Common mistake: loop variable capture\n    29→// WRONG:\n    30→for _, item := range items {\n    31→    go func() {\n    32→        process(item)  // All goroutines get last item!\n    33→    }()\n    34→}\n    35→\n    36→// CORRECT:\n    37→for _, item := range items {\n    38→    item := item  // Create new variable\n    39→    go func() {\n    40→        process(item)\n    41→    }()\n    42→}\n    43→\n    44→// Alternative: pass as parameter\n    45→for _, item := range items {\n    46→    go func(i Item) {\n    47→        process(i)\n    48→    }(item)\n    49→}\n    50→\n    51→// Waiting for goroutines to complete\n    52→var wg sync.WaitGroup\n    53→\n    54→for i := 0; i < 10; i++ {\n    55→    wg.Add(1)\n    56→    go func(id int) {\n    57→        defer wg.Done()\n    58→        doWork(id)\n    59→    }(i)\n    60→}\n    61→\n    62→wg.Wait()  // Block until all complete\n    63→\n    64→// Goroutine lifecycle management\n    65→type Worker struct {\n    66→    done chan struct{}\n    67→}\n    68→\n    69→func (w *Worker) Start() {\n    70→    go w.run()\n    71→}\n    72→\n    73→func (w *Worker) run() {\n    74→    ticker := time.NewTicker(1 * time.Second)\n    75→    defer ticker.Stop()\n    76→    \n    77→    for {\n    78→        select {\n    79→        case <-ticker.C:\n    80→            w.doWork()\n    81→        case <-w.done:\n    82→            return\n    83→        }\n    84→    }\n    85→}\n    86→\n    87→func (w *Worker) Stop() {\n    88→    close(w.done)\n    89→}\n    90→```\n    91→\n    92→### Goroutine Patterns\n    93→```go\n    94→// Limiting concurrent goroutines\n    95→const maxWorkers = 10\n    96→sem := make(chan struct{}, maxWorkers)\n    97→\n    98→for _, item := range items {\n    99→    sem <- struct{}{}  // Acquire\n   100→    go func(i Item) {\n   101→        defer func() { <-sem }()  // Release\n   102→        process(i)\n   103→    }(item)\n   104→}\n   105→\n   106→// Wait for all to complete\n   107→for i := 0; i < maxWorkers; i++ {\n   108→    sem <- struct{}{}\n   109→}\n   110→\n   111→// Error handling in goroutines\n   112→type Result struct {\n   113→    Value interface{}\n   114→    Err   error\n   115→}\n   116→\n   117→results := make(chan Result, len(items))\n   118→\n   119→for _, item := range items {\n   120→    go func(i Item) {\n   121→        value, err := process(i)\n   122→        results <- Result{Value: value, Err: err}\n   123→    }(item)\n   124→}\n   125→\n   126→// Collect results\n   127→for i := 0; i < len(items); i++ {\n   128→    result := <-results\n   129→    if result.Err != nil {\n   130→        log.Printf(\"Error: %v\", result.Err)\n   131→    }\n   132→}\n   133→\n   134→// Goroutine pool pattern\n   135→type Pool struct {\n   136→    work chan func()\n   137→    wg   sync.WaitGroup\n   138→}\n   139→\n   140→func NewPool(workers int) *Pool {\n   141→    p := &Pool{\n   142→        work: make(chan func(), 100),\n   143→    }\n   144→    \n   145→    p.wg.Add(workers)\n   146→    for i := 0; i < workers; i++ {\n   147→        go p.worker()\n   148→    }\n   149→    \n   150→    return p\n   151→}\n   152→\n   153→func (p *Pool) worker() {\n   154→    defer p.wg.Done()\n   155→    for fn := range p.work {\n   156→        fn()\n   157→    }\n   158→}\n   159→\n   160→func (p *Pool) Submit(fn func()) {\n   161→    p.work <- fn\n   162→}\n   163→\n   164→func (p *Pool) Shutdown() {\n   165→    close(p.work)\n   166→    p.wg.Wait()\n   167→}\n   168→```\n   169→\n   170→## Channels\n   171→\n   172→### Channel Basics\n   173→```go\n   174→// Creating channels\n   175→ch := make(chan int)       // Unbuffered\n   176→ch := make(chan int, 10)   // Buffered with capacity 10\n   177→\n   178→// Channel operations\n   179→ch <- 42        // Send\n   180→value := <-ch   // Receive\n   181→value, ok := <-ch  // Receive with closed check\n   182→\n   183→// Closing channels\n   184→close(ch)\n   185→\n   186→// Check if channel is closed\n   187→if v, ok := <-ch; !ok {\n   188→    // Channel is closed\n   189→}\n   190→\n   191→// Directional channels\n   192→func send(ch chan<- int) {  // Send-only\n   193→    ch <- 42\n   194→}\n   195→\n   196→func receive(ch <-chan int) {  // Receive-only\n   197→    value := <-ch\n   198→}\n   199→\n   200→// Channel zero value is nil\n   201→var ch chan int\n   202→// ch <- 1  // Blocks forever!\n   203→// <-ch     // Blocks forever!\n   204→\n   205→// Range over channel\n   206→ch := make(chan int)\n   207→go func() {\n   208→    for i := 0; i < 5; i++ {\n   209→        ch <- i\n   210→    }\n   211→    close(ch)\n   212→}()\n   213→\n   214→for value := range ch {\n   215→    fmt.Println(value)\n   216→}\n   217→```\n   218→\n   219→### Buffered vs Unbuffered Channels\n   220→```go\n   221→// Unbuffered channels - synchronous\n   222→ch := make(chan int)\n   223→go func() {\n   224→    ch <- 42  // Blocks until someone receives\n   225→}()\n   226→value := <-ch  // Blocks until someone sends\n   227→\n   228→// Buffered channels - asynchronous up to capacity\n   229→ch := make(chan int, 3)\n   230→ch <- 1  // Doesn't block\n   231→ch <- 2  // Doesn't block\n   232→ch <- 3  // Doesn't block\n   233→// ch <- 4  // Would block!\n   234→\n   235→// Using buffered channels as semaphores\n   236→type Semaphore chan struct{}\n   237→\n   238→func NewSemaphore(n int) Semaphore {\n   239→    return make(Semaphore, n)\n   240→}\n   241→\n   242→func (s Semaphore) Acquire() {\n   243→    s <- struct{}{}\n   244→}\n   245→\n   246→func (s Semaphore) Release() {\n   247→    <-s\n   248→}\n   249→\n   250→// Channel of channels\n   251→type Request struct {\n   252→    data  string\n   253→    reply chan Response\n   254→}\n   255→\n   256→requests := make(chan Request)\n   257→\n   258→// Server\n   259→go func() {\n   260→    for req := range requests {\n   261→        response := processRequest(req.data)\n   262→        req.reply <- response\n   263→    }\n   264→}()\n   265→\n   266→// Client\n   267→reply := make(chan Response)\n   268→requests <- Request{data: \"hello\", reply: reply}\n   269→response := <-reply\n   270→```\n   271→\n   272→### Channel Patterns\n   273→```go\n   274→// Fan-in: Merge multiple channels\n   275→func fanIn(channels ...<-chan int) <-chan int {\n   276→    out := make(chan int)\n   277→    var wg sync.WaitGroup\n   278→    \n   279→    for _, ch := range channels {\n   280→        wg.Add(1)\n   281→        go func(c <-chan int) {\n   282→            defer wg.Done()\n   283→            for val := range c {\n   284→                out <- val\n   285→            }\n   286→        }(ch)\n   287→    }\n   288→    \n   289→    go func() {\n   290→        wg.Wait()\n   291→        close(out)\n   292→    }()\n   293→    \n   294→    return out\n   295→}\n   296→\n   297→// Fan-out: Distribute work\n   298→func fanOut(in <-chan int, workers int) []<-chan int {\n   299→    channels := make([]<-chan int, workers)\n   300→    \n   301→    for i := 0; i < workers; i++ {\n   302→        ch := make(chan int)\n   303→        channels[i] = ch\n   304→        \n   305→        go func(out chan int) {\n   306→            for val := range in {\n   307→                out <- process(val)\n   308→            }\n   309→            close(out)\n   310→        }(ch)\n   311→    }\n   312→    \n   313→    return channels\n   314→}\n   315→\n   316→// Pipeline pattern\n   317→func pipeline() {\n   318→    // Stage 1: Generate numbers\n   319→    numbers := make(chan int)\n   320→    go func() {\n   321→        for i := 1; i <= 100; i++ {\n   322→            numbers <- i\n   323→        }\n   324→        close(numbers)\n   325→    }()\n   326→    \n   327→    // Stage 2: Square numbers\n   328→    squares := make(chan int)\n   329→    go func() {\n   330→        for n := range numbers {\n   331→            squares <- n * n\n   332→        }\n   333→        close(squares)\n   334→    }()\n   335→    \n   336→    // Stage 3: Filter even\n   337→    evens := make(chan int)\n   338→    go func() {\n   339→        for sq := range squares {\n   340→            if sq%2 == 0 {\n   341→                evens <- sq\n   342→            }\n   343→        }\n   344→        close(evens)\n   345→    }()\n   346→    \n   347→    // Consume\n   348→    for even := range evens {\n   349→        fmt.Println(even)\n   350→    }\n   351→}\n   352→\n   353→// Timeout pattern\n   354→func timeoutExample() {\n   355→    ch := make(chan string)\n   356→    \n   357→    go func() {\n   358→        time.Sleep(2 * time.Second)\n   359→        ch <- \"result\"\n   360→    }()\n   361→    \n   362→    select {\n   363→    case result := <-ch:\n   364→        fmt.Println(\"Got:\", result)\n   365→    case <-time.After(1 * time.Second):\n   366→        fmt.Println(\"Timeout!\")\n   367→    }\n   368→}\n   369→```\n   370→\n   371→## Select Statement\n   372→\n   373→### Select Basics\n   374→```go\n   375→// Basic select\n   376→select {\n   377→case v1 := <-ch1:\n   378→    fmt.Println(\"Received from ch1:\", v1)\n   379→case v2 := <-ch2:\n   380→    fmt.Println(\"Received from ch2:\", v2)\n   381→case ch3 <- 42:\n   382→    fmt.Println(\"Sent to ch3\")\n   383→default:\n   384→    fmt.Println(\"No channels ready\")\n   385→}\n   386→\n   387→// Non-blocking receive\n   388→select {\n   389→case msg := <-ch:\n   390→    fmt.Println(\"Received:\", msg)\n   391→default:\n   392→    fmt.Println(\"No message available\")\n   393→}\n   394→\n   395→// Non-blocking send\n   396→select {\n   397→case ch <- msg:\n   398→    fmt.Println(\"Sent message\")\n   399→default:\n   400→    fmt.Println(\"Channel full or not ready\")\n   401→}\n   402→\n   403→// Timeout with select\n   404→select {\n   405→case result := <-ch:\n   406→    fmt.Println(\"Got result:\", result)\n   407→case <-time.After(5 * time.Second):\n   408→    fmt.Println(\"Timeout after 5 seconds\")\n   409→}\n   410→\n   411→// Ticker with select\n   412→ticker := time.NewTicker(1 * time.Second)\n   413→defer ticker.Stop()\n   414→\n   415→done := make(chan bool)\n   416→go func() {\n   417→    time.Sleep(5 * time.Second)\n   418→    done <- true\n   419→}()\n   420→\n   421→for {\n   422→    select {\n   423→    case <-ticker.C:\n   424→        fmt.Println(\"Tick\")\n   425→    case <-done:\n   426→        fmt.Println(\"Done!\")\n   427→        return\n   428→    }\n   429→}\n   430→```\n   431→\n   432→### Advanced Select Patterns\n   433→```go\n   434→// Priority select using default\n   435→func prioritySelect(high, low <-chan int) int {\n   436→    select {\n   437→    case val := <-high:\n   438→        return val\n   439→    default:\n   440→        select {\n   441→        case val := <-high:\n   442→            return val\n   443→        case val := <-low:\n   444→            return val\n   445→        }\n   446→    }\n   447→}\n   448→\n   449→// Quit channel pattern\n   450→func worker(work <-chan int, quit <-chan struct{}) {\n   451→    for {\n   452→        select {\n   453→        case w := <-work:\n   454→            process(w)\n   455→        case <-quit:\n   456→            cleanup()\n   457→            return\n   458→        }\n   459→    }\n   460→}\n   461→\n   462→// Multiple return channels\n   463→func multiReturn() (chan int, chan error) {\n   464→    results := make(chan int)\n   465→    errors := make(chan error)\n   466→    \n   467→    go func() {\n   468→        defer close(results)\n   469→        defer close(errors)\n   470→        \n   471→        for i := 0; i < 10; i++ {\n   472→            if i%3 == 0 {\n   473→                errors <- fmt.Errorf(\"error at %d\", i)\n   474→            } else {\n   475→                results <- i * i\n   476→            }\n   477→        }\n   478→    }()\n   479→    \n   480→    return results, errors\n   481→}\n   482→\n   483→// Using nil channels in select\n   484→func dynamicSelect() {\n   485→    ch1 := make(chan int)\n   486→    ch2 := make(chan int)\n   487→    \n   488→    go func() {\n   489→        for i := 0; i < 5; i++ {\n   490→            ch1 <- i\n   491→            time.Sleep(100 * time.Millisecond)\n   492→        }\n   493→        close(ch1)\n   494→    }()\n   495→    \n   496→    go func() {\n   497→        for i := 5; i < 10; i++ {\n   498→            ch2 <- i\n   499→            time.Sleep(150 * time.Millisecond)\n   500→        }\n   501→        close(ch2)\n   502→    }()\n   503→    \n   504→    for ch1 != nil || ch2 != nil {\n   505→        select {\n   506→        case v, ok := <-ch1:\n   507→            if !ok {\n   508→                ch1 = nil  // Disable this case\n   509→                continue\n   510→            }\n   511→            fmt.Println(\"ch1:\", v)\n   512→        case v, ok := <-ch2:\n   513→            if !ok {\n   514→                ch2 = nil  // Disable this case\n   515→                continue\n   516→            }\n   517→            fmt.Println(\"ch2:\", v)\n   518→        }\n   519→    }\n   520→}\n   521→```\n   522→\n   523→## Sync Package\n   524→\n   525→### WaitGroup\n   526→```go\n   527→var wg sync.WaitGroup\n   528→\n   529→// Basic usage\n   530→for i := 0; i < 5; i++ {\n   531→    wg.Add(1)\n   532→    go func(id int) {\n   533→        defer wg.Done()\n   534→        doWork(id)\n   535→    }(i)\n   536→}\n   537→wg.Wait()\n   538→\n   539→// Reusable WaitGroup\n   540→type Task struct {\n   541→    wg sync.WaitGroup\n   542→}\n   543→\n   544→func (t *Task) Run(workers int) {\n   545→    t.wg.Add(workers)\n   546→    for i := 0; i < workers; i++ {\n   547→        go t.worker(i)\n   548→    }\n   549→    t.wg.Wait()\n   550→}\n   551→\n   552→func (t *Task) worker(id int) {\n   553→    defer t.wg.Done()\n   554→    // Do work\n   555→}\n   556→```\n   557→\n   558→### Mutex\n   559→```go\n   560→// Basic mutex\n   561→type Counter struct {\n   562→    mu    sync.Mutex\n   563→    value int\n   564→}\n   565→\n   566→func (c *Counter) Inc() {\n   567→    c.mu.Lock()\n   568→    defer c.mu.Unlock()\n   569→    c.value++\n   570→}\n   571→\n   572→func (c *Counter) Value() int {\n   573→    c.mu.Lock()\n   574→    defer c.mu.Unlock()\n   575→    return c.value\n   576→}\n   577→\n   578→// RWMutex for read-heavy workloads\n   579→type Cache struct {\n   580→    mu    sync.RWMutex\n   581→    data  map[string]string\n   582→}\n   583→\n   584→func (c *Cache) Get(key string) (string, bool) {\n   585→    c.mu.RLock()\n   586→    defer c.mu.RUnlock()\n   587→    val, ok := c.data[key]\n   588→    return val, ok\n   589→}\n   590→\n   591→func (c *Cache) Set(key, value string) {\n   592→    c.mu.Lock()\n   593→    defer c.mu.Unlock()\n   594→    c.data[key] = value\n   595→}\n   596→\n   597→// Mutex embedding pattern\n   598→type SafeMap struct {\n   599→    sync.RWMutex\n   600→    m map[string]int\n   601→}\n   602→\n   603→func (sm *SafeMap) Load(key string) (int, bool) {\n   604→    sm.RLock()\n   605→    defer sm.RUnlock()\n   606→    val, ok := sm.m[key]\n   607→    return val, ok\n   608→}\n   609→```\n   610→\n   611→### Once\n   612→```go\n   613→var once sync.Once\n   614→var instance *Singleton\n   615→\n   616→type Singleton struct {\n   617→    // fields\n   618→}\n   619→\n   620→func GetInstance() *Singleton {\n   621→    once.Do(func() {\n   622→        instance = &Singleton{}\n   623→        // Initialize\n   624→    })\n   625→    return instance\n   626→}\n   627→\n   628→// Once for expensive initialization\n   629→type Service struct {\n   630→    once   sync.Once\n   631→    client *http.Client\n   632→}\n   633→\n   634→func (s *Service) getClient() *http.Client {\n   635→    s.once.Do(func() {\n   636→        s.client = &http.Client{\n   637→            Timeout: 30 * time.Second,\n   638→            Transport: &http.Transport{\n   639→                MaxIdleConns:    100,\n   640→                IdleConnTimeout: 90 * time.Second,\n   641→            },\n   642→        }\n   643→    })\n   644→    return s.client\n   645→}\n   646→```\n   647→\n   648→### Cond\n   649→```go\n   650→// Condition variable for signaling\n   651→type Queue struct {\n   652→    mu    sync.Mutex\n   653→    cond  *sync.Cond\n   654→    items []interface{}\n   655→}\n   656→\n   657→func NewQueue() *Queue {\n   658→    q := &Queue{}\n   659→    q.cond = sync.NewCond(&q.mu)\n   660→    return q\n   661→}\n   662→\n   663→func (q *Queue) Put(item interface{}) {\n   664→    q.mu.Lock()\n   665→    defer q.mu.Unlock()\n   666→    q.items = append(q.items, item)\n   667→    q.cond.Signal()  // Wake one waiter\n   668→}\n   669→\n   670→func (q *Queue) Get() interface{} {\n   671→    q.mu.Lock()\n   672→    defer q.mu.Unlock()\n   673→    \n   674→    for len(q.items) == 0 {\n   675→        q.cond.Wait()  // Releases lock while waiting\n   676→    }\n   677→    \n   678→    item := q.items[0]\n   679→    q.items = q.items[1:]\n   680→    return item\n   681→}\n   682→\n   683→// Broadcast to all waiters\n   684→func (q *Queue) Close() {\n   685→    q.mu.Lock()\n   686→    defer q.mu.Unlock()\n   687→    q.cond.Broadcast()  // Wake all waiters\n   688→}\n   689→```\n   690→\n   691→### Pool\n   692→```go\n   693→// Object pool for reuse\n   694→var bufferPool = sync.Pool{\n   695→    New: func() interface{} {\n   696→        return new(bytes.Buffer)\n   697→    },\n   698→}\n   699→\n   700→func processData(data []byte) {\n   701→    buf := bufferPool.Get().(*bytes.Buffer)\n   702→    defer func() {\n   703→        buf.Reset()\n   704→        bufferPool.Put(buf)\n   705→    }()\n   706→    \n   707→    buf.Write(data)\n   708→    // Process buffer\n   709→}\n   710→\n   711→// Connection pool pattern\n   712→type ConnPool struct {\n   713→    pool chan net.Conn\n   714→}\n   715→\n   716→func NewConnPool(size int, dial func() (net.Conn, error)) (*ConnPool, error) {\n   717→    pool := make(chan net.Conn, size)\n   718→    for i := 0; i < size; i++ {\n   719→        conn, err := dial()\n   720→        if err != nil {\n   721→            return nil, err\n   722→        }\n   723→        pool <- conn\n   724→    }\n   725→    return &ConnPool{pool: pool}, nil\n   726→}\n   727→\n   728→func (p *ConnPool) Get() net.Conn {\n   729→    return <-p.pool\n   730→}\n   731→\n   732→func (p *ConnPool) Put(conn net.Conn) {\n   733→    p.pool <- conn\n   734→}\n   735→```\n   736→\n   737→### Map (sync.Map)\n   738→```go\n   739→// Thread-safe map without explicit locking\n   740→var m sync.Map\n   741→\n   742→// Store\n   743→m.Store(\"key\", \"value\")\n   744→m.Store(123, \"numeric key\")\n   745→\n   746→// Load\n   747→if val, ok := m.Load(\"key\"); ok {\n   748→    fmt.Println(val.(string))\n   749→}\n   750→\n   751→// LoadOrStore\n   752→actual, loaded := m.LoadOrStore(\"key\", \"new value\")\n   753→if loaded {\n   754→    fmt.Println(\"Key existed:\", actual)\n   755→}\n   756→\n   757→// Delete\n   758→m.Delete(\"key\")\n   759→\n   760→// Range\n   761→m.Range(func(key, value interface{}) bool {\n   762→    fmt.Printf(\"%v: %v\\n\", key, value)\n   763→    return true  // Continue iteration\n   764→})\n   765→\n   766→// Use cases for sync.Map:\n   767→// 1. Keys are written once but read many times\n   768→// 2. Different goroutines read/write disjoint key sets\n   769→// 3. When lock contention would be a problem\n   770→```\n   771→\n   772→## Atomic Operations\n   773→\n   774→### Atomic Package\n   775→```go\n   776→import \"sync/atomic\"\n   777→\n   778→// Atomic integers\n   779→var counter int64\n   780→\n   781→atomic.AddInt64(&counter, 1)           // Increment\n   782→atomic.AddInt64(&counter, -1)          // Decrement\n   783→val := atomic.LoadInt64(&counter)      // Read\n   784→atomic.StoreInt64(&counter, 100)       // Write\n   785→old := atomic.SwapInt64(&counter, 200) // Swap\n   786→\n   787→// Compare and swap (CAS)\n   788→if atomic.CompareAndSwapInt64(&counter, 100, 200) {\n   789→    // Successfully changed from 100 to 200\n   790→}\n   791→\n   792→// Atomic boolean using int32\n   793→type AtomicBool struct {\n   794→    flag int32\n   795→}\n   796→\n   797→func (b *AtomicBool) Set(value bool) {\n   798→    var i int32\n   799→    if value {\n   800→        i = 1\n   801→    }\n   802→    atomic.StoreInt32(&b.flag, i)\n   803→}\n   804→\n   805→func (b *AtomicBool) Get() bool {\n   806→    return atomic.LoadInt32(&b.flag) != 0\n   807→}\n   808→\n   809→// Atomic pointer\n   810→type Config struct {\n   811→    // fields\n   812→}\n   813→\n   814→var config atomic.Value\n   815→\n   816→// Store new config\n   817→config.Store(&Config{})\n   818→\n   819→// Load config\n   820→cfg := config.Load().(*Config)\n   821→\n   822→// Atomic counter implementation\n   823→type Counter struct {\n   824→    value int64\n   825→}\n   826→\n   827→func (c *Counter) Inc() int64 {\n   828→    return atomic.AddInt64(&c.value, 1)\n   829→}\n   830→\n   831→func (c *Counter) Dec() int64 {\n   832→    return atomic.AddInt64(&c.value, -1)\n   833→}\n   834→\n   835→func (c *Counter) Value() int64 {\n   836→    return atomic.LoadInt64(&c.value)\n   837→}\n   838→\n   839→func (c *Counter) Reset() {\n   840→    atomic.StoreInt64(&c.value, 0)\n   841→}\n   842→```\n   843→\n   844→### Atomic Patterns\n   845→```go\n   846→// Lock-free stack\n   847→type Stack struct {\n   848→    head atomic.Value\n   849→}\n   850→\n   851→type node struct {\n   852→    value interface{}\n   853→    next  *node\n   854→}\n   855→\n   856→func (s *Stack) Push(v interface{}) {\n   857→    n := &node{value: v}\n   858→    for {\n   859→        head := s.head.Load()\n   860→        if head != nil {\n   861→            n.next = head.(*node)\n   862→        }\n   863→        if s.head.CompareAndSwap(head, n) {\n   864→            return\n   865→        }\n   866→    }\n   867→}\n   868→\n   869→func (s *Stack) Pop() interface{} {\n   870→    for {\n   871→        head := s.head.Load()\n   872→        if head == nil {\n   873→            return nil\n   874→        }\n   875→        n := head.(*node)\n   876→        if s.head.CompareAndSwap(head, n.next) {\n   877→            return n.value\n   878→        }\n   879→    }\n   880→}\n   881→\n   882→// Atomic statistics collector\n   883→type Stats struct {\n   884→    requests  int64\n   885→    errors    int64\n   886→    totalTime int64\n   887→}\n   888→\n   889→func (s *Stats) RecordRequest(duration time.Duration, err error) {\n   890→    atomic.AddInt64(&s.requests, 1)\n   891→    atomic.AddInt64(&s.totalTime, int64(duration))\n   892→    if err != nil {\n   893→        atomic.AddInt64(&s.errors, 1)\n   894→    }\n   895→}\n   896→\n   897→func (s *Stats) Snapshot() (requests, errors, avgTime int64) {\n   898→    requests = atomic.LoadInt64(&s.requests)\n   899→    errors = atomic.LoadInt64(&s.errors)\n   900→    totalTime := atomic.LoadInt64(&s.totalTime)\n   901→    if requests > 0 {\n   902→        avgTime = totalTime / requests\n   903→    }\n   904→    return\n   905→}\n   906→```\n   907→\n   908→## Concurrency Patterns\n   909→\n   910→### Worker Pool\n   911→```go\n   912→type Job struct {\n   913→    ID   int\n   914→    Data string\n   915→}\n   916→\n   917→type Result struct {\n   918→    JobID  int\n   919→    Output string\n   920→    Err    error\n   921→}\n   922→\n   923→func workerPool(jobs <-chan Job, results chan<- Result, workers int) {\n   924→    var wg sync.WaitGroup\n   925→    \n   926→    for i := 0; i < workers; i++ {\n   927→        wg.Add(1)\n   928→        go func(workerID int) {\n   929→            defer wg.Done()\n   930→            for job := range jobs {\n   931→                output, err := processJob(job)\n   932→                results <- Result{\n   933→                    JobID:  job.ID,\n   934→                    Output: output,\n   935→                    Err:    err,\n   936→                }\n   937→            }\n   938→        }(i)\n   939→    }\n   940→    \n   941→    wg.Wait()\n   942→    close(results)\n   943→}\n   944→\n   945→// Usage\n   946→jobs := make(chan Job, 100)\n   947→results := make(chan Result, 100)\n   948→\n   949→go workerPool(jobs, results, 10)\n   950→\n   951→// Send jobs\n   952→go func() {\n   953→    for i := 0; i < 1000; i++ {\n   954→        jobs <- Job{ID: i, Data: fmt.Sprintf(\"job-%d\", i)}\n   955→    }\n   956→    close(jobs)\n   957→}()\n   958→\n   959→// Collect results\n   960→for result := range results {\n   961→    if result.Err != nil {\n   962→        log.Printf(\"Job %d failed: %v\", result.JobID, result.Err)\n   963→    } else {\n   964→        fmt.Printf(\"Job %d completed: %s\\n\", result.JobID, result.Output)\n   965→    }\n   966→}\n   967→```\n   968→\n   969→### Rate Limiting\n   970→```go\n   971→// Simple rate limiter\n   972→func rateLimiter() {\n   973→    rate := time.Second / 10  // 10 requests per second\n   974→    ticker := time.NewTicker(rate)\n   975→    defer ticker.Stop()\n   976→    \n   977→    requests := make(chan int, 100)\n   978→    \n   979→    go func() {\n   980→        for i := 0; i < 100; i++ {\n   981→            requests <- i\n   982→        }\n   983→        close(requests)\n   984→    }()\n   985→    \n   986→    for req := range requests {\n   987→        <-ticker.C  // Wait for tick\n   988→        go process(req)\n   989→    }\n   990→}\n   991→\n   992→// Token bucket rate limiter\n   993→type RateLimiter struct {\n   994→    tokens chan struct{}\n   995→}\n   996→\n   997→func NewRateLimiter(rate int, burst int) *RateLimiter {\n   998→    rl := &RateLimiter{\n   999→        tokens: make(chan struct{}, burst),\n  1000→    }\n  1001→    \n  1002→    // Fill bucket\n  1003→    for i := 0; i < burst; i++ {\n  1004→        rl.tokens <- struct{}{}\n  1005→    }\n  1006→    \n  1007→    // Refill tokens\n  1008→    go func() {\n  1009→        ticker := time.NewTicker(time.Second / time.Duration(rate))\n  1010→        defer ticker.Stop()\n  1011→        \n  1012→        for range ticker.C {\n  1013→            select {\n  1014→            case rl.tokens <- struct{}{}:\n  1015→            default:\n  1016→                // Bucket full\n  1017→            }\n  1018→        }\n  1019→    }()\n  1020→    \n  1021→    return rl\n  1022→}\n  1023→\n  1024→func (rl *RateLimiter) Allow() bool {\n  1025→    select {\n  1026→    case <-rl.tokens:\n  1027→        return true\n  1028→    default:\n  1029→        return false\n  1030→    }\n  1031→}\n  1032→\n  1033→func (rl *RateLimiter) Wait() {\n  1034→    <-rl.tokens\n  1035→}\n  1036→```\n  1037→\n  1038→### Circuit Breaker\n  1039→```go\n  1040→type CircuitBreaker struct {\n  1041→    mu            sync.RWMutex\n  1042→    failures      int\n  1043→    lastFailTime  time.Time\n  1044→    state         string // \"closed\", \"open\", \"half-open\"\n  1045→    maxFailures   int\n  1046→    resetTimeout  time.Duration\n  1047→}\n  1048→\n  1049→func NewCircuitBreaker(maxFailures int, resetTimeout time.Duration) *CircuitBreaker {\n  1050→    return &CircuitBreaker{\n  1051→        maxFailures:  maxFailures,\n  1052→        resetTimeout: resetTimeout,\n  1053→        state:        \"closed\",\n  1054→    }\n  1055→}\n  1056→\n  1057→func (cb *CircuitBreaker) Call(fn func() error) error {\n  1058→    cb.mu.RLock()\n  1059→    state := cb.state\n  1060→    cb.mu.RUnlock()\n  1061→    \n  1062→    if state == \"open\" {\n  1063→        cb.mu.RLock()\n  1064→        if time.Since(cb.lastFailTime) > cb.resetTimeout {\n  1065→            cb.mu.RUnlock()\n  1066→            cb.mu.Lock()\n  1067→            cb.state = \"half-open\"\n  1068→            cb.failures = 0\n  1069→            cb.mu.Unlock()\n  1070→        } else {\n  1071→            cb.mu.RUnlock()\n  1072→            return errors.New(\"circuit breaker is open\")\n  1073→        }\n  1074→    }\n  1075→    \n  1076→    err := fn()\n  1077→    \n  1078→    cb.mu.Lock()\n  1079→    defer cb.mu.Unlock()\n  1080→    \n  1081→    if err != nil {\n  1082→        cb.failures++\n  1083→        cb.lastFailTime = time.Now()\n  1084→        \n  1085→        if cb.failures >= cb.maxFailures {\n  1086→            cb.state = \"open\"\n  1087→        }\n  1088→        return err\n  1089→    }\n  1090→    \n  1091→    if cb.state == \"half-open\" {\n  1092→        cb.state = \"closed\"\n  1093→    }\n  1094→    cb.failures = 0\n  1095→    return nil\n  1096→}\n  1097→```\n  1098→\n  1099→### Pub-Sub Pattern\n  1100→```go\n  1101→type PubSub struct {\n  1102→    mu   sync.RWMutex\n  1103→    subs map[string][]chan interface{}\n  1104→}\n  1105→\n  1106→func NewPubSub() *PubSub {\n  1107→    return &PubSub{\n  1108→        subs: make(map[string][]chan interface{}),\n  1109→    }\n  1110→}\n  1111→\n  1112→func (ps *PubSub) Subscribe(topic string) <-chan interface{} {\n  1113→    ps.mu.Lock()\n  1114→    defer ps.mu.Unlock()\n  1115→    \n  1116→    ch := make(chan interface{}, 10)\n  1117→    ps.subs[topic] = append(ps.subs[topic], ch)\n  1118→    return ch\n  1119→}\n  1120→\n  1121→func (ps *PubSub) Publish(topic string, msg interface{}) {\n  1122→    ps.mu.RLock()\n  1123→    defer ps.mu.RUnlock()\n  1124→    \n  1125→    for _, ch := range ps.subs[topic] {\n  1126→        select {\n  1127→        case ch <- msg:\n  1128→        default:\n  1129→            // Subscriber is slow, skip\n  1130→        }\n  1131→    }\n  1132→}\n  1133→\n  1134→func (ps *PubSub) Unsubscribe(topic string, sub <-chan interface{}) {\n  1135→    ps.mu.Lock()\n  1136→    defer ps.mu.Unlock()\n  1137→    \n  1138→    subscribers := ps.subs[topic]\n  1139→    for i, ch := range subscribers {\n  1140→        if ch == sub {\n  1141→            close(ch)\n  1142→            ps.subs[topic] = append(subscribers[:i], subscribers[i+1:]...)\n  1143→            break\n  1144→        }\n  1145→    }\n  1146→}\n  1147→```\n  1148→\n  1149→## Context Package\n  1150→\n  1151→### Context Basics\n  1152→```go\n  1153→// Creating contexts\n  1154→ctx := context.Background()  // Root context\n  1155→ctx := context.TODO()        // When unsure what to use\n  1156→\n  1157→// With cancel\n  1158→ctx, cancel := context.WithCancel(context.Background())\n  1159→defer cancel()  // Always call cancel\n  1160→\n  1161→// With timeout\n  1162→ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n  1163→defer cancel()\n  1164→\n  1165→// With deadline\n  1166→deadline := time.Now().Add(5 * time.Second)\n  1167→ctx, cancel := context.WithDeadline(context.Background(), deadline)\n  1168→defer cancel()\n  1169→\n  1170→// With value\n  1171→ctx := context.WithValue(context.Background(), \"userID\", 123)\n  1172→\n  1173→// Using context\n  1174→func doWork(ctx context.Context) error {\n  1175→    select {\n  1176→    case <-time.After(2 * time.Second):\n  1177→        return nil\n  1178→    case <-ctx.Done():\n  1179→        return ctx.Err()\n  1180→    }\n  1181→}\n  1182→\n  1183→// HTTP request with context\n  1184→func fetchData(ctx context.Context, url string) (*http.Response, error) {\n  1185→    req, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n  1186→    if err != nil {\n  1187→        return nil, err\n  1188→    }\n  1189→    \n  1190→    return http.DefaultClient.Do(req)\n  1191→}\n  1192→```\n  1193→\n  1194→### Context Patterns\n  1195→```go\n  1196→// Propagating cancellation\n  1197→func pipeline(ctx context.Context) error {\n  1198→    ctx, cancel := context.WithCancel(ctx)\n  1199→    defer cancel()\n  1200→    \n  1201→    errc := make(chan error, 3)\n  1202→    \n  1203→    go func() {\n  1204→        errc <- stage1(ctx)\n  1205→    }()\n  1206→    \n  1207→    go func() {\n  1208→        errc <- stage2(ctx)\n  1209→    }()\n  1210→    \n  1211→    go func() {\n  1212→        errc <- stage3(ctx)\n  1213→    }()\n  1214→    \n  1215→    // Wait for first error or all complete\n  1216→    for i := 0; i < 3; i++ {\n  1217→        if err := <-errc; err != nil {\n  1218→            return err  // Cancel will stop other stages\n  1219→        }\n  1220→    }\n  1221→    \n  1222→    return nil\n  1223→}\n  1224→\n  1225→// Request scoped values\n  1226→type contextKey string\n  1227→\n  1228→const (\n  1229→    userIDKey contextKey = \"userID\"\n  1230→    traceIDKey contextKey = \"traceID\"\n  1231→)\n  1232→\n  1233→func WithUserID(ctx context.Context, userID string) context.Context {\n  1234→    return context.WithValue(ctx, userIDKey, userID)\n  1235→}\n  1236→\n  1237→func GetUserID(ctx context.Context) (string, bool) {\n  1238→    userID, ok := ctx.Value(userIDKey).(string)\n  1239→    return userID, ok\n  1240→}\n  1241→\n  1242→// Graceful shutdown\n  1243→func server(ctx context.Context) error {\n  1244→    srv := &http.Server{Addr: \":8080\"}\n  1245→    \n  1246→    go func() {\n  1247→        <-ctx.Done()\n  1248→        shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n  1249→        defer cancel()\n  1250→        srv.Shutdown(shutdownCtx)\n  1251→    }()\n  1252→    \n  1253→    return srv.ListenAndServe()\n  1254→}\n  1255→```\n  1256→\n  1257→## Race Conditions\n  1258→\n  1259→### Detecting Race Conditions\n  1260→```go\n  1261→// Run with race detector: go run -race main.go\n  1262→// Test with race detector: go test -race ./...\n  1263→\n  1264→// Common race condition\n  1265→type Counter struct {\n  1266→    value int  // Not protected!\n  1267→}\n  1268→\n  1269→func (c *Counter) Inc() {\n  1270→    c.value++  // Race condition!\n  1271→}\n  1272→\n  1273→// Fixed version\n  1274→type SafeCounter struct {\n  1275→    mu    sync.Mutex\n  1276→    value int\n  1277→}\n  1278→\n  1279→func (c *SafeCounter) Inc() {\n  1280→    c.mu.Lock()\n  1281→    defer c.mu.Unlock()\n  1282→    c.value++\n  1283→}\n  1284→\n  1285→// Race on map\n  1286→m := make(map[string]int)\n  1287→\n  1288→go func() {\n  1289→    m[\"key\"] = 1  // Write\n  1290→}()\n  1291→\n  1292→go func() {\n  1293→    _ = m[\"key\"]  // Read - RACE!\n  1294→}()\n  1295→\n  1296→// Race on slice append\n  1297→var slice []int\n  1298→\n  1299→go func() {\n  1300→    slice = append(slice, 1)  // Race!\n  1301→}()\n  1302→\n  1303→go func() {\n  1304→    slice = append(slice, 2)  // Race!\n  1305→}()\n  1306→```\n  1307→\n  1308→### Preventing Race Conditions\n  1309→```go\n  1310→// Use channels instead of shared memory\n  1311→type SafeCounter struct {\n  1312→    ch chan int\n  1313→}\n  1314→\n  1315→func NewSafeCounter() *SafeCounter {\n  1316→    c := &SafeCounter{\n  1317→        ch: make(chan int),\n  1318→    }\n  1319→    go c.run()\n  1320→    return c\n  1321→}\n  1322→\n  1323→func (c *SafeCounter) run() {\n  1324→    var value int\n  1325→    for delta := range c.ch {\n  1326→        value += delta\n  1327→    }\n  1328→}\n  1329→\n  1330→func (c *SafeCounter) Inc() {\n  1331→    c.ch <- 1\n  1332→}\n  1333→\n  1334→// Immutability pattern\n  1335→type Config struct {\n  1336→    values map[string]string\n  1337→}\n  1338→\n  1339→func (c *Config) With(key, value string) *Config {\n  1340→    newValues := make(map[string]string)\n  1341→    for k, v := range c.values {\n  1342→        newValues[k] = v\n  1343→    }\n  1344→    newValues[key] = value\n  1345→    return &Config{values: newValues}\n  1346→}\n  1347→\n  1348→// Copy-on-write pattern\n  1349→type Data struct {\n  1350→    mu    sync.RWMutex\n  1351→    items []Item\n  1352→}\n  1353→\n  1354→func (d *Data) Append(item Item) {\n  1355→    d.mu.Lock()\n  1356→    defer d.mu.Unlock()\n  1357→    \n  1358→    // Create new slice\n  1359→    newItems := make([]Item, len(d.items)+1)\n  1360→    copy(newItems, d.items)\n  1361→    newItems[len(newItems)-1] = item\n  1362→    d.items = newItems\n  1363→}\n  1364→\n  1365→func (d *Data) Items() []Item {\n  1366→    d.mu.RLock()\n  1367→    defer d.mu.RUnlock()\n  1368→    return d.items  // Safe because we copy on write\n  1369→}\n  1370→```\n  1371→\n  1372→## Deadlocks\n  1373→\n  1374→### Common Deadlock Patterns\n  1375→```go\n  1376→// Deadlock: Circular wait\n  1377→var mu1, mu2 sync.Mutex\n  1378→\n  1379→// Goroutine 1\n  1380→go func() {\n  1381→    mu1.Lock()\n  1382→    time.Sleep(10 * time.Millisecond)\n  1383→    mu2.Lock()  // Waits for mu2\n  1384→    // ...\n  1385→    mu2.Unlock()\n  1386→    mu1.Unlock()\n  1387→}()\n  1388→\n  1389→// Goroutine 2\n  1390→go func() {\n  1391→    mu2.Lock()\n  1392→    time.Sleep(10 * time.Millisecond)\n  1393→    mu1.Lock()  // Waits for mu1 - DEADLOCK!\n  1394→    // ...\n  1395→    mu1.Unlock()\n  1396→    mu2.Unlock()\n  1397→}()\n  1398→\n  1399→// Fix: Always acquire locks in same order\n  1400→func transfer(from, to *Account, amount int) {\n  1401→    // Order accounts by ID to prevent deadlock\n  1402→    if from.ID < to.ID {\n  1403→        from.mu.Lock()\n  1404→        defer from.mu.Unlock()\n  1405→        to.mu.Lock()\n  1406→        defer to.mu.Unlock()\n  1407→    } else {\n  1408→        to.mu.Lock()\n  1409→        defer to.mu.Unlock()\n  1410→        from.mu.Lock()\n  1411→        defer from.mu.Unlock()\n  1412→    }\n  1413→    // Transfer logic\n  1414→}\n  1415→\n  1416→// Deadlock: Channel misuse\n  1417→ch := make(chan int)\n  1418→ch <- 42  // Blocks forever - no receiver!\n  1419→\n  1420→// Deadlock: Waiting for yourself\n  1421→ch := make(chan int)\n  1422→val := <-ch  // Blocks forever\n  1423→ch <- val    // Never reached\n  1424→\n  1425→// Deadlock: Select without default\n  1426→ch1 := make(chan int)\n  1427→ch2 := make(chan int)\n  1428→\n  1429→select {\n  1430→case <-ch1:\n  1431→case <-ch2:\n  1432→// No default case - blocks forever if neither ready\n  1433→}\n  1434→```\n  1435→\n  1436→### Preventing Deadlocks\n  1437→```go\n  1438→// Use timeouts\n  1439→func safeLock(mu *sync.Mutex, timeout time.Duration) bool {\n  1440→    done := make(chan struct{})\n  1441→    go func() {\n  1442→        mu.Lock()\n  1443→        close(done)\n  1444→    }()\n  1445→    \n  1446→    select {\n  1447→    case <-done:\n  1448→        return true\n  1449→    case <-time.After(timeout):\n  1450→        return false\n  1451→    }\n  1452→}\n  1453→\n  1454→// Try-lock pattern\n  1455→type TryMutex struct {\n  1456→    ch chan struct{}\n  1457→}\n  1458→\n  1459→func NewTryMutex() *TryMutex {\n  1460→    ch := make(chan struct{}, 1)\n  1461→    ch <- struct{}{}\n  1462→    return &TryMutex{ch: ch}\n  1463→}\n  1464→\n  1465→func (m *TryMutex) Lock() {\n  1466→    <-m.ch\n  1467→}\n  1468→\n  1469→func (m *TryMutex) Unlock() {\n  1470→    m.ch <- struct{}{}\n  1471→}\n  1472→\n  1473→func (m *TryMutex) TryLock() bool {\n  1474→    select {\n  1475→    case <-m.ch:\n  1476→        return true\n  1477→    default:\n  1478→        return false\n  1479→    }\n  1480→}\n  1481→\n  1482→// Deadlock detection\n  1483→type DeadlockDetector struct {\n  1484→    mu       sync.Mutex\n  1485→    holding  map[string]string  // goroutine -> resource\n  1486→    waiting  map[string]string  // goroutine -> resource\n  1487→}\n  1488→\n  1489→func (d *DeadlockDetector) BeforeLock(goroutine, resource string) {\n  1490→    d.mu.Lock()\n  1491→    defer d.mu.Unlock()\n  1492→    \n  1493→    d.waiting[goroutine] = resource\n  1494→    // Check for cycle in wait graph\n  1495→    if d.hasCycle() {\n  1496→        panic(\"Potential deadlock detected!\")\n  1497→    }\n  1498→}\n  1499→\n  1500→func (d *DeadlockDetector) AfterLock(goroutine, resource string) {\n  1501→    d.mu.Lock()\n  1502→    defer d.mu.Unlock()\n  1503→    \n  1504→    delete(d.waiting, goroutine)\n  1505→    d.holding[goroutine] = resource\n  1506→}\n  1507→```\n  1508→\n  1509→## Performance and Optimization\n  1510→\n  1511→### Goroutine Performance\n  1512→```go\n  1513→// Limiting goroutines\n  1514→const maxGoroutines = 100\n  1515→sem := make(chan struct{}, maxGoroutines)\n  1516→\n  1517→for i := 0; i < 10000; i++ {\n  1518→    sem <- struct{}{}\n  1519→    go func(id int) {\n  1520→        defer func() { <-sem }()\n  1521→        process(id)\n  1522→    }(i)\n  1523→}\n  1524→\n  1525→// Reusing goroutines (worker pool)\n  1526→type WorkerPool struct {\n  1527→    workers int\n  1528→    jobs    chan func()\n  1529→    wg      sync.WaitGroup\n  1530→}\n  1531→\n  1532→func NewWorkerPool(workers int) *WorkerPool {\n  1533→    pool := &WorkerPool{\n  1534→        workers: workers,\n  1535→        jobs:    make(chan func(), workers*2),\n  1536→    }\n  1537→    pool.start()\n  1538→    return pool\n  1539→}\n  1540→\n  1541→func (p *WorkerPool) start() {\n  1542→    for i := 0; i < p.workers; i++ {\n  1543→        p.wg.Add(1)\n  1544→        go func() {\n  1545→            defer p.wg.Done()\n  1546→            for job := range p.jobs {\n  1547→                job()\n  1548→            }\n  1549→        }()\n  1550→    }\n  1551→}\n  1552→\n  1553→func (p *WorkerPool) Submit(job func()) {\n  1554→    p.jobs <- job\n  1555→}\n  1556→\n  1557→func (p *WorkerPool) Stop() {\n  1558→    close(p.jobs)\n  1559→    p.wg.Wait()\n  1560→}\n  1561→\n  1562→// Batching for efficiency\n  1563→func batchProcessor(items <-chan Item) {\n  1564→    batch := make([]Item, 0, 100)\n  1565→    ticker := time.NewTicker(1 * time.Second)\n  1566→    defer ticker.Stop()\n  1567→    \n  1568→    for {\n  1569→        select {\n  1570→        case item, ok := <-items:\n  1571→            if !ok {\n  1572→                if len(batch) > 0 {\n  1573→                    processBatch(batch)\n  1574→                }\n  1575→                return\n  1576→            }\n  1577→            batch = append(batch, item)\n  1578→            if len(batch) >= 100 {\n  1579→                processBatch(batch)\n  1580→                batch = batch[:0]\n  1581→            }\n  1582→        case <-ticker.C:\n  1583→            if len(batch) > 0 {\n  1584→                processBatch(batch)\n  1585→                batch = batch[:0]\n  1586→            }\n  1587→        }\n  1588→    }\n  1589→}\n  1590→```\n  1591→\n  1592→### Channel Performance\n  1593→```go\n  1594→// Buffered channels for performance\n  1595→ch := make(chan int, 1000)  // Reduce blocking\n  1596→\n  1597→// Channel direction for optimization\n  1598→func producer() <-chan int {  // Read-only return\n  1599→    ch := make(chan int)\n  1600→    go func() {\n  1601→        defer close(ch)\n  1602→        for i := 0; i < 100; i++ {\n  1603→            ch <- i\n  1604→        }\n  1605→    }()\n  1606→    return ch\n  1607→}\n  1608→\n  1609→// Avoid channel operations in hot paths\n  1610→// Bad:\n  1611→for i := 0; i < 1000000; i++ {\n  1612→    ch <- i  // Channel operation in tight loop\n  1613→}\n  1614→\n  1615→// Good:\n  1616→batch := make([]int, 0, 1000)\n  1617→for i := 0; i < 1000000; i++ {\n  1618→    batch = append(batch, i)\n  1619→    if len(batch) >= 1000 {\n  1620→        ch <- batch\n  1621→        batch = make([]int, 0, 1000)\n  1622→    }\n  1623→}\n  1624→\n  1625→// Select with default for non-blocking\n  1626→select {\n  1627→case ch <- value:\n  1628→    // Sent\n  1629→default:\n  1630→    // Channel full, handle accordingly\n  1631→}\n  1632→```\n  1633→\n  1634→### Memory and Lock Optimization\n  1635→```go\n  1636→// Reduce lock contention with sharding\n  1637→type ShardedMap struct {\n  1638→    shards [16]struct {\n  1639→        sync.RWMutex\n  1640→        m map[string]interface{}\n  1641→    }\n  1642→}\n  1643→\n  1644→func (sm *ShardedMap) getShard(key string) *struct {\n  1645→    sync.RWMutex\n  1646→    m map[string]interface{}\n  1647→} {\n  1648→    hash := fnv32(key)\n  1649→    return &sm.shards[hash%16]\n  1650→}\n  1651→\n  1652→func (sm *ShardedMap) Get(key string) (interface{}, bool) {\n  1653→    shard := sm.getShard(key)\n  1654→    shard.RLock()\n  1655→    defer shard.RUnlock()\n  1656→    val, ok := shard.m[key]\n  1657→    return val, ok\n  1658→}\n  1659→\n  1660→// Lock-free with atomic\n  1661→type Config struct {\n  1662→    v atomic.Value\n  1663→}\n  1664→\n  1665→func (c *Config) Load() *ConfigData {\n  1666→    return c.v.Load().(*ConfigData)\n  1667→}\n  1668→\n  1669→func (c *Config) Store(cfg *ConfigData) {\n  1670→    c.v.Store(cfg)\n  1671→}\n  1672→\n  1673→// Reduce allocations\n  1674→var bufferPool = sync.Pool{\n  1675→    New: func() interface{} {\n  1676→        return make([]byte, 1024)\n  1677→    },\n  1678→}\n  1679→\n  1680→func process() {\n  1681→    buf := bufferPool.Get().([]byte)\n  1682→    defer bufferPool.Put(buf)\n  1683→    // Use buf\n  1684→}\n  1685→```\n  1686→\n  1687→## Best Practices Summary\n  1688→\n  1689→1. **Start goroutines responsibly** - Always know how they'll stop\n  1690→2. **Don't leak goroutines** - Ensure cleanup with context or channels\n  1691→3. **Prefer channels over shared memory** - But use sync primitives when appropriate\n  1692→4. **Always handle context cancellation** - Check ctx.Done() in loops\n  1693→5. **Close channels from sender side only** - Never close from receiver\n  1694→6. **Use buffered channels thoughtfully** - Not just to \"fix\" synchronization\n  1695→7. **Protect shared state** - Use mutex, channels, or atomic operations\n  1696→8. **Run with -race during development** - Catch races early\n  1697→9. **Design for graceful shutdown** - Handle signals and cleanup\n  1698→10. **Profile before optimizing** - Measure, don't guess performance issues\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d1b1f047-f60d-4da3-af0a-0b69303dbdc1","timestamp":"2025-08-13T10:28:02.828Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/concurrency.md","content":"# Go Concurrency - Mastering Concurrent Programming\n\n## Table of Contents\n1. [Goroutines](#goroutines)\n2. [Channels](#channels)\n3. [Select Statement](#select-statement)\n4. [Sync Package](#sync-package)\n5. [Atomic Operations](#atomic-operations)\n6. [Concurrency Patterns](#concurrency-patterns)\n7. [Context Package](#context-package)\n8. [Race Conditions](#race-conditions)\n9. [Deadlocks](#deadlocks)\n10. [Performance and Optimization](#performance-and-optimization)\n\n## Goroutines\n\n### Goroutine Basics\n```go\n// Starting a goroutine\ngo functionName()\ngo func() {\n    // Anonymous function as goroutine\n}()\n\n// Goroutines with parameters\ngo processItem(item)\n\n// Common mistake: loop variable capture\n// WRONG:\nfor _, item := range items {\n    go func() {\n        process(item)  // All goroutines get last item!\n    }()\n}\n\n// CORRECT:\nfor _, item := range items {\n    item := item  // Create new variable\n    go func() {\n        process(item)\n    }()\n}\n\n// Alternative: pass as parameter\nfor _, item := range items {\n    go func(i Item) {\n        process(i)\n    }(item)\n}\n\n// Waiting for goroutines to complete\nvar wg sync.WaitGroup\n\nfor i := 0; i < 10; i++ {\n    wg.Add(1)\n    go func(id int) {\n        defer wg.Done()\n        doWork(id)\n    }(i)\n}\n\nwg.Wait()  // Block until all complete\n\n// Goroutine lifecycle management\ntype Worker struct {\n    done chan struct{}\n}\n\nfunc (w *Worker) Start() {\n    go w.run()\n}\n\nfunc (w *Worker) run() {\n    ticker := time.NewTicker(1 * time.Second)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case <-ticker.C:\n            w.doWork()\n        case <-w.done:\n            return\n        }\n    }\n}\n\nfunc (w *Worker) Stop() {\n    close(w.done)\n}\n```\n\n### Goroutine Patterns\n```go\n// Limiting concurrent goroutines\nconst maxWorkers = 10\nsem := make(chan struct{}, maxWorkers)\n\nfor _, item := range items {\n    sem <- struct{}{}  // Acquire\n    go func(i Item) {\n        defer func() { <-sem }()  // Release\n        process(i)\n    }(item)\n}\n\n// Wait for all to complete\nfor i := 0; i < maxWorkers; i++ {\n    sem <- struct{}{}\n}\n\n// Error handling in goroutines\ntype Result struct {\n    Value interface{}\n    Err   error\n}\n\nresults := make(chan Result, len(items))\n\nfor _, item := range items {\n    go func(i Item) {\n        value, err := process(i)\n        results <- Result{Value: value, Err: err}\n    }(item)\n}\n\n// Collect results\nfor i := 0; i < len(items); i++ {\n    result := <-results\n    if result.Err != nil {\n        log.Printf(\"Error: %v\", result.Err)\n    }\n}\n\n// Goroutine pool pattern\ntype Pool struct {\n    work chan func()\n    wg   sync.WaitGroup\n}\n\nfunc NewPool(workers int) *Pool {\n    p := &Pool{\n        work: make(chan func(), 100),\n    }\n    \n    p.wg.Add(workers)\n    for i := 0; i < workers; i++ {\n        go p.worker()\n    }\n    \n    return p\n}\n\nfunc (p *Pool) worker() {\n    defer p.wg.Done()\n    for fn := range p.work {\n        fn()\n    }\n}\n\nfunc (p *Pool) Submit(fn func()) {\n    p.work <- fn\n}\n\nfunc (p *Pool) Shutdown() {\n    close(p.work)\n    p.wg.Wait()\n}\n```\n\n## Channels\n\n### Channel Basics\n```go\n// Creating channels\nch := make(chan int)       // Unbuffered\nch := make(chan int, 10)   // Buffered with capacity 10\n\n// Channel operations\nch <- 42        // Send\nvalue := <-ch   // Receive\nvalue, ok := <-ch  // Receive with closed check\n\n// Closing channels\nclose(ch)\n\n// Check if channel is closed\nif v, ok := <-ch; !ok {\n    // Channel is closed\n}\n\n// Directional channels\nfunc send(ch chan<- int) {  // Send-only\n    ch <- 42\n}\n\nfunc receive(ch <-chan int) {  // Receive-only\n    value := <-ch\n}\n\n// Channel zero value is nil\nvar ch chan int\n// ch <- 1  // Blocks forever!\n// <-ch     // Blocks forever!\n\n// Range over channel\nch := make(chan int)\ngo func() {\n    for i := 0; i < 5; i++ {\n        ch <- i\n    }\n    close(ch)\n}()\n\nfor value := range ch {\n    fmt.Println(value)\n}\n```\n\n### Buffered vs Unbuffered Channels\n```go\n// Unbuffered channels - synchronous\nch := make(chan int)\ngo func() {\n    ch <- 42  // Blocks until someone receives\n}()\nvalue := <-ch  // Blocks until someone sends\n\n// Buffered channels - asynchronous up to capacity\nch := make(chan int, 3)\nch <- 1  // Doesn't block\nch <- 2  // Doesn't block\nch <- 3  // Doesn't block\n// ch <- 4  // Would block!\n\n// Using buffered channels as semaphores\ntype Semaphore chan struct{}\n\nfunc NewSemaphore(n int) Semaphore {\n    return make(Semaphore, n)\n}\n\nfunc (s Semaphore) Acquire() {\n    s <- struct{}{}\n}\n\nfunc (s Semaphore) Release() {\n    <-s\n}\n\n// Channel of channels\ntype Request struct {\n    data  string\n    reply chan Response\n}\n\nrequests := make(chan Request)\n\n// Server\ngo func() {\n    for req := range requests {\n        response := processRequest(req.data)\n        req.reply <- response\n    }\n}()\n\n// Client\nreply := make(chan Response)\nrequests <- Request{data: \"hello\", reply: reply}\nresponse := <-reply\n```\n\n### Channel Patterns\n```go\n// Fan-in: Merge multiple channels\nfunc fanIn(channels ...<-chan int) <-chan int {\n    out := make(chan int)\n    var wg sync.WaitGroup\n    \n    for _, ch := range channels {\n        wg.Add(1)\n        go func(c <-chan int) {\n            defer wg.Done()\n            for val := range c {\n                out <- val\n            }\n        }(ch)\n    }\n    \n    go func() {\n        wg.Wait()\n        close(out)\n    }()\n    \n    return out\n}\n\n// Fan-out: Distribute work\nfunc fanOut(in <-chan int, workers int) []<-chan int {\n    channels := make([]<-chan int, workers)\n    \n    for i := 0; i < workers; i++ {\n        ch := make(chan int)\n        channels[i] = ch\n        \n        go func(out chan int) {\n            for val := range in {\n                out <- process(val)\n            }\n            close(out)\n        }(ch)\n    }\n    \n    return channels\n}\n\n// Pipeline pattern\nfunc pipeline() {\n    // Stage 1: Generate numbers\n    numbers := make(chan int)\n    go func() {\n        for i := 1; i <= 100; i++ {\n            numbers <- i\n        }\n        close(numbers)\n    }()\n    \n    // Stage 2: Square numbers\n    squares := make(chan int)\n    go func() {\n        for n := range numbers {\n            squares <- n * n\n        }\n        close(squares)\n    }()\n    \n    // Stage 3: Filter even\n    evens := make(chan int)\n    go func() {\n        for sq := range squares {\n            if sq%2 == 0 {\n                evens <- sq\n            }\n        }\n        close(evens)\n    }()\n    \n    // Consume\n    for even := range evens {\n        fmt.Println(even)\n    }\n}\n\n// Timeout pattern\nfunc timeoutExample() {\n    ch := make(chan string)\n    \n    go func() {\n        time.Sleep(2 * time.Second)\n        ch <- \"result\"\n    }()\n    \n    select {\n    case result := <-ch:\n        fmt.Println(\"Got:\", result)\n    case <-time.After(1 * time.Second):\n        fmt.Println(\"Timeout!\")\n    }\n}\n```\n\n## Select Statement\n\n### Select Basics\n```go\n// Basic select\nselect {\ncase v1 := <-ch1:\n    fmt.Println(\"Received from ch1:\", v1)\ncase v2 := <-ch2:\n    fmt.Println(\"Received from ch2:\", v2)\ncase ch3 <- 42:\n    fmt.Println(\"Sent to ch3\")\ndefault:\n    fmt.Println(\"No channels ready\")\n}\n\n// Non-blocking receive\nselect {\ncase msg := <-ch:\n    fmt.Println(\"Received:\", msg)\ndefault:\n    fmt.Println(\"No message available\")\n}\n\n// Non-blocking send\nselect {\ncase ch <- msg:\n    fmt.Println(\"Sent message\")\ndefault:\n    fmt.Println(\"Channel full or not ready\")\n}\n\n// Timeout with select\nselect {\ncase result := <-ch:\n    fmt.Println(\"Got result:\", result)\ncase <-time.After(5 * time.Second):\n    fmt.Println(\"Timeout after 5 seconds\")\n}\n\n// Ticker with select\nticker := time.NewTicker(1 * time.Second)\ndefer ticker.Stop()\n\ndone := make(chan bool)\ngo func() {\n    time.Sleep(5 * time.Second)\n    done <- true\n}()\n\nfor {\n    select {\n    case <-ticker.C:\n        fmt.Println(\"Tick\")\n    case <-done:\n        fmt.Println(\"Done!\")\n        return\n    }\n}\n```\n\n### Advanced Select Patterns\n```go\n// Priority select using default\nfunc prioritySelect(high, low <-chan int) int {\n    select {\n    case val := <-high:\n        return val\n    default:\n        select {\n        case val := <-high:\n            return val\n        case val := <-low:\n            return val\n        }\n    }\n}\n\n// Quit channel pattern\nfunc worker(work <-chan int, quit <-chan struct{}) {\n    for {\n        select {\n        case w := <-work:\n            process(w)\n        case <-quit:\n            cleanup()\n            return\n        }\n    }\n}\n\n// Multiple return channels\nfunc multiReturn() (chan int, chan error) {\n    results := make(chan int)\n    errors := make(chan error)\n    \n    go func() {\n        defer close(results)\n        defer close(errors)\n        \n        for i := 0; i < 10; i++ {\n            if i%3 == 0 {\n                errors <- fmt.Errorf(\"error at %d\", i)\n            } else {\n                results <- i * i\n            }\n        }\n    }()\n    \n    return results, errors\n}\n\n// Using nil channels in select\nfunc dynamicSelect() {\n    ch1 := make(chan int)\n    ch2 := make(chan int)\n    \n    go func() {\n        for i := 0; i < 5; i++ {\n            ch1 <- i\n            time.Sleep(100 * time.Millisecond)\n        }\n        close(ch1)\n    }()\n    \n    go func() {\n        for i := 5; i < 10; i++ {\n            ch2 <- i\n            time.Sleep(150 * time.Millisecond)\n        }\n        close(ch2)\n    }()\n    \n    for ch1 != nil || ch2 != nil {\n        select {\n        case v, ok := <-ch1:\n            if !ok {\n                ch1 = nil  // Disable this case\n                continue\n            }\n            fmt.Println(\"ch1:\", v)\n        case v, ok := <-ch2:\n            if !ok {\n                ch2 = nil  // Disable this case\n                continue\n            }\n            fmt.Println(\"ch2:\", v)\n        }\n    }\n}\n```\n\n## Sync Package\n\n### WaitGroup\n```go\nvar wg sync.WaitGroup\n\n// Basic usage\nfor i := 0; i < 5; i++ {\n    wg.Add(1)\n    go func(id int) {\n        defer wg.Done()\n        doWork(id)\n    }(i)\n}\nwg.Wait()\n\n// Reusable WaitGroup\ntype Task struct {\n    wg sync.WaitGroup\n}\n\nfunc (t *Task) Run(workers int) {\n    t.wg.Add(workers)\n    for i := 0; i < workers; i++ {\n        go t.worker(i)\n    }\n    t.wg.Wait()\n}\n\nfunc (t *Task) worker(id int) {\n    defer t.wg.Done()\n    // Do work\n}\n```\n\n### Mutex\n```go\n// Basic mutex\ntype Counter struct {\n    mu    sync.Mutex\n    value int\n}\n\nfunc (c *Counter) Inc() {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    c.value++\n}\n\nfunc (c *Counter) Value() int {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    return c.value\n}\n\n// RWMutex for read-heavy workloads\ntype Cache struct {\n    mu    sync.RWMutex\n    data  map[string]string\n}\n\nfunc (c *Cache) Get(key string) (string, bool) {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    val, ok := c.data[key]\n    return val, ok\n}\n\nfunc (c *Cache) Set(key, value string) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    c.data[key] = value\n}\n\n// Mutex embedding pattern\ntype SafeMap struct {\n    sync.RWMutex\n    m map[string]int\n}\n\nfunc (sm *SafeMap) Load(key string) (int, bool) {\n    sm.RLock()\n    defer sm.RUnlock()\n    val, ok := sm.m[key]\n    return val, ok\n}\n```\n\n### Once\n```go\nvar once sync.Once\nvar instance *Singleton\n\ntype Singleton struct {\n    // fields\n}\n\nfunc GetInstance() *Singleton {\n    once.Do(func() {\n        instance = &Singleton{}\n        // Initialize\n    })\n    return instance\n}\n\n// Once for expensive initialization\ntype Service struct {\n    once   sync.Once\n    client *http.Client\n}\n\nfunc (s *Service) getClient() *http.Client {\n    s.once.Do(func() {\n        s.client = &http.Client{\n            Timeout: 30 * time.Second,\n            Transport: &http.Transport{\n                MaxIdleConns:    100,\n                IdleConnTimeout: 90 * time.Second,\n            },\n        }\n    })\n    return s.client\n}\n```\n\n### Cond\n```go\n// Condition variable for signaling\ntype Queue struct {\n    mu    sync.Mutex\n    cond  *sync.Cond\n    items []interface{}\n}\n\nfunc NewQueue() *Queue {\n    q := &Queue{}\n    q.cond = sync.NewCond(&q.mu)\n    return q\n}\n\nfunc (q *Queue) Put(item interface{}) {\n    q.mu.Lock()\n    defer q.mu.Unlock()\n    q.items = append(q.items, item)\n    q.cond.Signal()  // Wake one waiter\n}\n\nfunc (q *Queue) Get() interface{} {\n    q.mu.Lock()\n    defer q.mu.Unlock()\n    \n    for len(q.items) == 0 {\n        q.cond.Wait()  // Releases lock while waiting\n    }\n    \n    item := q.items[0]\n    q.items = q.items[1:]\n    return item\n}\n\n// Broadcast to all waiters\nfunc (q *Queue) Close() {\n    q.mu.Lock()\n    defer q.mu.Unlock()\n    q.cond.Broadcast()  // Wake all waiters\n}\n```\n\n### Pool\n```go\n// Object pool for reuse\nvar bufferPool = sync.Pool{\n    New: func() interface{} {\n        return new(bytes.Buffer)\n    },\n}\n\nfunc processData(data []byte) {\n    buf := bufferPool.Get().(*bytes.Buffer)\n    defer func() {\n        buf.Reset()\n        bufferPool.Put(buf)\n    }()\n    \n    buf.Write(data)\n    // Process buffer\n}\n\n// Connection pool pattern\ntype ConnPool struct {\n    pool chan net.Conn\n}\n\nfunc NewConnPool(size int, dial func() (net.Conn, error)) (*ConnPool, error) {\n    pool := make(chan net.Conn, size)\n    for i := 0; i < size; i++ {\n        conn, err := dial()\n        if err != nil {\n            return nil, err\n        }\n        pool <- conn\n    }\n    return &ConnPool{pool: pool}, nil\n}\n\nfunc (p *ConnPool) Get() net.Conn {\n    return <-p.pool\n}\n\nfunc (p *ConnPool) Put(conn net.Conn) {\n    p.pool <- conn\n}\n```\n\n### Map (sync.Map)\n```go\n// Thread-safe map without explicit locking\nvar m sync.Map\n\n// Store\nm.Store(\"key\", \"value\")\nm.Store(123, \"numeric key\")\n\n// Load\nif val, ok := m.Load(\"key\"); ok {\n    fmt.Println(val.(string))\n}\n\n// LoadOrStore\nactual, loaded := m.LoadOrStore(\"key\", \"new value\")\nif loaded {\n    fmt.Println(\"Key existed:\", actual)\n}\n\n// Delete\nm.Delete(\"key\")\n\n// Range\nm.Range(func(key, value interface{}) bool {\n    fmt.Printf(\"%v: %v\\n\", key, value)\n    return true  // Continue iteration\n})\n\n// Use cases for sync.Map:\n// 1. Keys are written once but read many times\n// 2. Different goroutines read/write disjoint key sets\n// 3. When lock contention would be a problem\n```\n\n## Atomic Operations\n\n### Atomic Package\n```go\nimport \"sync/atomic\"\n\n// Atomic integers\nvar counter int64\n\natomic.AddInt64(&counter, 1)           // Increment\natomic.AddInt64(&counter, -1)          // Decrement\nval := atomic.LoadInt64(&counter)      // Read\natomic.StoreInt64(&counter, 100)       // Write\nold := atomic.SwapInt64(&counter, 200) // Swap\n\n// Compare and swap (CAS)\nif atomic.CompareAndSwapInt64(&counter, 100, 200) {\n    // Successfully changed from 100 to 200\n}\n\n// Atomic boolean using int32\ntype AtomicBool struct {\n    flag int32\n}\n\nfunc (b *AtomicBool) Set(value bool) {\n    var i int32\n    if value {\n        i = 1\n    }\n    atomic.StoreInt32(&b.flag, i)\n}\n\nfunc (b *AtomicBool) Get() bool {\n    return atomic.LoadInt32(&b.flag) != 0\n}\n\n// Atomic pointer\ntype Config struct {\n    // fields\n}\n\nvar config atomic.Value\n\n// Store new config\nconfig.Store(&Config{})\n\n// Load config\ncfg := config.Load().(*Config)\n\n// Atomic counter implementation\ntype Counter struct {\n    value int64\n}\n\nfunc (c *Counter) Inc() int64 {\n    return atomic.AddInt64(&c.value, 1)\n}\n\nfunc (c *Counter) Dec() int64 {\n    return atomic.AddInt64(&c.value, -1)\n}\n\nfunc (c *Counter) Value() int64 {\n    return atomic.LoadInt64(&c.value)\n}\n\nfunc (c *Counter) Reset() {\n    atomic.StoreInt64(&c.value, 0)\n}\n```\n\n### Atomic Patterns\n```go\n// Lock-free stack\ntype Stack struct {\n    head atomic.Value\n}\n\ntype node struct {\n    value interface{}\n    next  *node\n}\n\nfunc (s *Stack) Push(v interface{}) {\n    n := &node{value: v}\n    for {\n        head := s.head.Load()\n        if head != nil {\n            n.next = head.(*node)\n        }\n        if s.head.CompareAndSwap(head, n) {\n            return\n        }\n    }\n}\n\nfunc (s *Stack) Pop() interface{} {\n    for {\n        head := s.head.Load()\n        if head == nil {\n            return nil\n        }\n        n := head.(*node)\n        if s.head.CompareAndSwap(head, n.next) {\n            return n.value\n        }\n    }\n}\n\n// Atomic statistics collector\ntype Stats struct {\n    requests  int64\n    errors    int64\n    totalTime int64\n}\n\nfunc (s *Stats) RecordRequest(duration time.Duration, err error) {\n    atomic.AddInt64(&s.requests, 1)\n    atomic.AddInt64(&s.totalTime, int64(duration))\n    if err != nil {\n        atomic.AddInt64(&s.errors, 1)\n    }\n}\n\nfunc (s *Stats) Snapshot() (requests, errors, avgTime int64) {\n    requests = atomic.LoadInt64(&s.requests)\n    errors = atomic.LoadInt64(&s.errors)\n    totalTime := atomic.LoadInt64(&s.totalTime)\n    if requests > 0 {\n        avgTime = totalTime / requests\n    }\n    return\n}\n```\n\n## Concurrency Patterns\n\n### Worker Pool\n```go\ntype Job struct {\n    ID   int\n    Data string\n}\n\ntype Result struct {\n    JobID  int\n    Output string\n    Err    error\n}\n\nfunc workerPool(jobs <-chan Job, results chan<- Result, workers int) {\n    var wg sync.WaitGroup\n    \n    for i := 0; i < workers; i++ {\n        wg.Add(1)\n        go func(workerID int) {\n            defer wg.Done()\n            for job := range jobs {\n                output, err := processJob(job)\n                results <- Result{\n                    JobID:  job.ID,\n                    Output: output,\n                    Err:    err,\n                }\n            }\n        }(i)\n    }\n    \n    wg.Wait()\n    close(results)\n}\n\n// Usage\njobs := make(chan Job, 100)\nresults := make(chan Result, 100)\n\ngo workerPool(jobs, results, 10)\n\n// Send jobs\ngo func() {\n    for i := 0; i < 1000; i++ {\n        jobs <- Job{ID: i, Data: fmt.Sprintf(\"job-%d\", i)}\n    }\n    close(jobs)\n}()\n\n// Collect results\nfor result := range results {\n    if result.Err != nil {\n        log.Printf(\"Job %d failed: %v\", result.JobID, result.Err)\n    } else {\n        fmt.Printf(\"Job %d completed: %s\\n\", result.JobID, result.Output)\n    }\n}\n```\n\n### Rate Limiting\n```go\n// Simple rate limiter\nfunc rateLimiter() {\n    rate := time.Second / 10  // 10 requests per second\n    ticker := time.NewTicker(rate)\n    defer ticker.Stop()\n    \n    requests := make(chan int, 100)\n    \n    go func() {\n        for i := 0; i < 100; i++ {\n            requests <- i\n        }\n        close(requests)\n    }()\n    \n    for req := range requests {\n        <-ticker.C  // Wait for tick\n        go process(req)\n    }\n}\n\n// Token bucket rate limiter\ntype RateLimiter struct {\n    tokens chan struct{}\n}\n\nfunc NewRateLimiter(rate int, burst int) *RateLimiter {\n    rl := &RateLimiter{\n        tokens: make(chan struct{}, burst),\n    }\n    \n    // Fill bucket\n    for i := 0; i < burst; i++ {\n        rl.tokens <- struct{}{}\n    }\n    \n    // Refill tokens\n    go func() {\n        ticker := time.NewTicker(time.Second / time.Duration(rate))\n        defer ticker.Stop()\n        \n        for range ticker.C {\n            select {\n            case rl.tokens <- struct{}{}:\n            default:\n                // Bucket full\n            }\n        }\n    }()\n    \n    return rl\n}\n\nfunc (rl *RateLimiter) Allow() bool {\n    select {\n    case <-rl.tokens:\n        return true\n    default:\n        return false\n    }\n}\n\nfunc (rl *RateLimiter) Wait() {\n    <-rl.tokens\n}\n```\n\n### Circuit Breaker\n```go\ntype CircuitBreaker struct {\n    mu            sync.RWMutex\n    failures      int\n    lastFailTime  time.Time\n    state         string // \"closed\", \"open\", \"half-open\"\n    maxFailures   int\n    resetTimeout  time.Duration\n}\n\nfunc NewCircuitBreaker(maxFailures int, resetTimeout time.Duration) *CircuitBreaker {\n    return &CircuitBreaker{\n        maxFailures:  maxFailures,\n        resetTimeout: resetTimeout,\n        state:        \"closed\",\n    }\n}\n\nfunc (cb *CircuitBreaker) Call(fn func() error) error {\n    cb.mu.RLock()\n    state := cb.state\n    cb.mu.RUnlock()\n    \n    if state == \"open\" {\n        cb.mu.RLock()\n        if time.Since(cb.lastFailTime) > cb.resetTimeout {\n            cb.mu.RUnlock()\n            cb.mu.Lock()\n            cb.state = \"half-open\"\n            cb.failures = 0\n            cb.mu.Unlock()\n        } else {\n            cb.mu.RUnlock()\n            return errors.New(\"circuit breaker is open\")\n        }\n    }\n    \n    err := fn()\n    \n    cb.mu.Lock()\n    defer cb.mu.Unlock()\n    \n    if err != nil {\n        cb.failures++\n        cb.lastFailTime = time.Now()\n        \n        if cb.failures >= cb.maxFailures {\n            cb.state = \"open\"\n        }\n        return err\n    }\n    \n    if cb.state == \"half-open\" {\n        cb.state = \"closed\"\n    }\n    cb.failures = 0\n    return nil\n}\n```\n\n### Pub-Sub Pattern\n```go\ntype PubSub struct {\n    mu   sync.RWMutex\n    subs map[string][]chan interface{}\n}\n\nfunc NewPubSub() *PubSub {\n    return &PubSub{\n        subs: make(map[string][]chan interface{}),\n    }\n}\n\nfunc (ps *PubSub) Subscribe(topic string) <-chan interface{} {\n    ps.mu.Lock()\n    defer ps.mu.Unlock()\n    \n    ch := make(chan interface{}, 10)\n    ps.subs[topic] = append(ps.subs[topic], ch)\n    return ch\n}\n\nfunc (ps *PubSub) Publish(topic string, msg interface{}) {\n    ps.mu.RLock()\n    defer ps.mu.RUnlock()\n    \n    for _, ch := range ps.subs[topic] {\n        select {\n        case ch <- msg:\n        default:\n            // Subscriber is slow, skip\n        }\n    }\n}\n\nfunc (ps *PubSub) Unsubscribe(topic string, sub <-chan interface{}) {\n    ps.mu.Lock()\n    defer ps.mu.Unlock()\n    \n    subscribers := ps.subs[topic]\n    for i, ch := range subscribers {\n        if ch == sub {\n            close(ch)\n            ps.subs[topic] = append(subscribers[:i], subscribers[i+1:]...)\n            break\n        }\n    }\n}\n```\n\n## Context Package\n\n### Context Basics\n```go\n// Creating contexts\nctx := context.Background()  // Root context\nctx := context.TODO()        // When unsure what to use\n\n// With cancel\nctx, cancel := context.WithCancel(context.Background())\ndefer cancel()  // Always call cancel\n\n// With timeout\nctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\ndefer cancel()\n\n// With deadline\ndeadline := time.Now().Add(5 * time.Second)\nctx, cancel := context.WithDeadline(context.Background(), deadline)\ndefer cancel()\n\n// With value\nctx := context.WithValue(context.Background(), \"userID\", 123)\n\n// Using context\nfunc doWork(ctx context.Context) error {\n    select {\n    case <-time.After(2 * time.Second):\n        return nil\n    case <-ctx.Done():\n        return ctx.Err()\n    }\n}\n\n// HTTP request with context\nfunc fetchData(ctx context.Context, url string) (*http.Response, error) {\n    req, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n    if err != nil {\n        return nil, err\n    }\n    \n    return http.DefaultClient.Do(req)\n}\n```\n\n### Context Patterns\n```go\n// Propagating cancellation\nfunc pipeline(ctx context.Context) error {\n    ctx, cancel := context.WithCancel(ctx)\n    defer cancel()\n    \n    errc := make(chan error, 3)\n    \n    go func() {\n        errc <- stage1(ctx)\n    }()\n    \n    go func() {\n        errc <- stage2(ctx)\n    }()\n    \n    go func() {\n        errc <- stage3(ctx)\n    }()\n    \n    // Wait for first error or all complete\n    for i := 0; i < 3; i++ {\n        if err := <-errc; err != nil {\n            return err  // Cancel will stop other stages\n        }\n    }\n    \n    return nil\n}\n\n// Request scoped values\ntype contextKey string\n\nconst (\n    userIDKey contextKey = \"userID\"\n    traceIDKey contextKey = \"traceID\"\n)\n\nfunc WithUserID(ctx context.Context, userID string) context.Context {\n    return context.WithValue(ctx, userIDKey, userID)\n}\n\nfunc GetUserID(ctx context.Context) (string, bool) {\n    userID, ok := ctx.Value(userIDKey).(string)\n    return userID, ok\n}\n\n// Graceful shutdown\nfunc server(ctx context.Context) error {\n    srv := &http.Server{Addr: \":8080\"}\n    \n    go func() {\n        <-ctx.Done()\n        shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n        defer cancel()\n        srv.Shutdown(shutdownCtx)\n    }()\n    \n    return srv.ListenAndServe()\n}\n```\n\n## Race Conditions\n\n### Detecting Race Conditions\n```go\n// Run with race detector: go run -race main.go\n// Test with race detector: go test -race ./...\n\n// Common race condition\ntype Counter struct {\n    value int  // Not protected!\n}\n\nfunc (c *Counter) Inc() {\n    c.value++  // Race condition!\n}\n\n// Fixed version\ntype SafeCounter struct {\n    mu    sync.Mutex\n    value int\n}\n\nfunc (c *SafeCounter) Inc() {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    c.value++\n}\n\n// Race on map\nm := make(map[string]int)\n\ngo func() {\n    m[\"key\"] = 1  // Write\n}()\n\ngo func() {\n    _ = m[\"key\"]  // Read - RACE!\n}()\n\n// Race on slice append\nvar slice []int\n\ngo func() {\n    slice = append(slice, 1)  // Race!\n}()\n\ngo func() {\n    slice = append(slice, 2)  // Race!\n}()\n```\n\n### Preventing Race Conditions\n```go\n// Use channels instead of shared memory\ntype SafeCounter struct {\n    ch chan int\n}\n\nfunc NewSafeCounter() *SafeCounter {\n    c := &SafeCounter{\n        ch: make(chan int),\n    }\n    go c.run()\n    return c\n}\n\nfunc (c *SafeCounter) run() {\n    var value int\n    for delta := range c.ch {\n        value += delta\n    }\n}\n\nfunc (c *SafeCounter) Inc() {\n    c.ch <- 1\n}\n\n// Immutability pattern\ntype Config struct {\n    values map[string]string\n}\n\nfunc (c *Config) With(key, value string) *Config {\n    newValues := make(map[string]string)\n    for k, v := range c.values {\n        newValues[k] = v\n    }\n    newValues[key] = value\n    return &Config{values: newValues}\n}\n\n// Copy-on-write pattern\ntype Data struct {\n    mu    sync.RWMutex\n    items []Item\n}\n\nfunc (d *Data) Append(item Item) {\n    d.mu.Lock()\n    defer d.mu.Unlock()\n    \n    // Create new slice\n    newItems := make([]Item, len(d.items)+1)\n    copy(newItems, d.items)\n    newItems[len(newItems)-1] = item\n    d.items = newItems\n}\n\nfunc (d *Data) Items() []Item {\n    d.mu.RLock()\n    defer d.mu.RUnlock()\n    return d.items  // Safe because we copy on write\n}\n```\n\n## Deadlocks\n\n### Common Deadlock Patterns\n```go\n// Deadlock: Circular wait\nvar mu1, mu2 sync.Mutex\n\n// Goroutine 1\ngo func() {\n    mu1.Lock()\n    time.Sleep(10 * time.Millisecond)\n    mu2.Lock()  // Waits for mu2\n    // ...\n    mu2.Unlock()\n    mu1.Unlock()\n}()\n\n// Goroutine 2\ngo func() {\n    mu2.Lock()\n    time.Sleep(10 * time.Millisecond)\n    mu1.Lock()  // Waits for mu1 - DEADLOCK!\n    // ...\n    mu1.Unlock()\n    mu2.Unlock()\n}()\n\n// Fix: Always acquire locks in same order\nfunc transfer(from, to *Account, amount int) {\n    // Order accounts by ID to prevent deadlock\n    if from.ID < to.ID {\n        from.mu.Lock()\n        defer from.mu.Unlock()\n        to.mu.Lock()\n        defer to.mu.Unlock()\n    } else {\n        to.mu.Lock()\n        defer to.mu.Unlock()\n        from.mu.Lock()\n        defer from.mu.Unlock()\n    }\n    // Transfer logic\n}\n\n// Deadlock: Channel misuse\nch := make(chan int)\nch <- 42  // Blocks forever - no receiver!\n\n// Deadlock: Waiting for yourself\nch := make(chan int)\nval := <-ch  // Blocks forever\nch <- val    // Never reached\n\n// Deadlock: Select without default\nch1 := make(chan int)\nch2 := make(chan int)\n\nselect {\ncase <-ch1:\ncase <-ch2:\n// No default case - blocks forever if neither ready\n}\n```\n\n### Preventing Deadlocks\n```go\n// Use timeouts\nfunc safeLock(mu *sync.Mutex, timeout time.Duration) bool {\n    done := make(chan struct{})\n    go func() {\n        mu.Lock()\n        close(done)\n    }()\n    \n    select {\n    case <-done:\n        return true\n    case <-time.After(timeout):\n        return false\n    }\n}\n\n// Try-lock pattern\ntype TryMutex struct {\n    ch chan struct{}\n}\n\nfunc NewTryMutex() *TryMutex {\n    ch := make(chan struct{}, 1)\n    ch <- struct{}{}\n    return &TryMutex{ch: ch}\n}\n\nfunc (m *TryMutex) Lock() {\n    <-m.ch\n}\n\nfunc (m *TryMutex) Unlock() {\n    m.ch <- struct{}{}\n}\n\nfunc (m *TryMutex) TryLock() bool {\n    select {\n    case <-m.ch:\n        return true\n    default:\n        return false\n    }\n}\n\n// Deadlock detection\ntype DeadlockDetector struct {\n    mu       sync.Mutex\n    holding  map[string]string  // goroutine -> resource\n    waiting  map[string]string  // goroutine -> resource\n}\n\nfunc (d *DeadlockDetector) BeforeLock(goroutine, resource string) {\n    d.mu.Lock()\n    defer d.mu.Unlock()\n    \n    d.waiting[goroutine] = resource\n    // Check for cycle in wait graph\n    if d.hasCycle() {\n        panic(\"Potential deadlock detected!\")\n    }\n}\n\nfunc (d *DeadlockDetector) AfterLock(goroutine, resource string) {\n    d.mu.Lock()\n    defer d.mu.Unlock()\n    \n    delete(d.waiting, goroutine)\n    d.holding[goroutine] = resource\n}\n```\n\n## Performance and Optimization\n\n### Goroutine Performance\n```go\n// Limiting goroutines\nconst maxGoroutines = 100\nsem := make(chan struct{}, maxGoroutines)\n\nfor i := 0; i < 10000; i++ {\n    sem <- struct{}{}\n    go func(id int) {\n        defer func() { <-sem }()\n        process(id)\n    }(i)\n}\n\n// Reusing goroutines (worker pool)\ntype WorkerPool struct {\n    workers int\n    jobs    chan func()\n    wg      sync.WaitGroup\n}\n\nfunc NewWorkerPool(workers int) *WorkerPool {\n    pool := &WorkerPool{\n        workers: workers,\n        jobs:    make(chan func(), workers*2),\n    }\n    pool.start()\n    return pool\n}\n\nfunc (p *WorkerPool) start() {\n    for i := 0; i < p.workers; i++ {\n        p.wg.Add(1)\n        go func() {\n            defer p.wg.Done()\n            for job := range p.jobs {\n                job()\n            }\n        }()\n    }\n}\n\nfunc (p *WorkerPool) Submit(job func()) {\n    p.jobs <- job\n}\n\nfunc (p *WorkerPool) Stop() {\n    close(p.jobs)\n    p.wg.Wait()\n}\n\n// Batching for efficiency\nfunc batchProcessor(items <-chan Item) {\n    batch := make([]Item, 0, 100)\n    ticker := time.NewTicker(1 * time.Second)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case item, ok := <-items:\n            if !ok {\n                if len(batch) > 0 {\n                    processBatch(batch)\n                }\n                return\n            }\n            batch = append(batch, item)\n            if len(batch) >= 100 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n        case <-ticker.C:\n            if len(batch) > 0 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n        }\n    }\n}\n```\n\n### Channel Performance\n```go\n// Buffered channels for performance\nch := make(chan int, 1000)  // Reduce blocking\n\n// Channel direction for optimization\nfunc producer() <-chan int {  // Read-only return\n    ch := make(chan int)\n    go func() {\n        defer close(ch)\n        for i := 0; i < 100; i++ {\n            ch <- i\n        }\n    }()\n    return ch\n}\n\n// Avoid channel operations in hot paths\n// Bad:\nfor i := 0; i < 1000000; i++ {\n    ch <- i  // Channel operation in tight loop\n}\n\n// Good:\nbatch := make([]int, 0, 1000)\nfor i := 0; i < 1000000; i++ {\n    batch = append(batch, i)\n    if len(batch) >= 1000 {\n        ch <- batch\n        batch = make([]int, 0, 1000)\n    }\n}\n\n// Select with default for non-blocking\nselect {\ncase ch <- value:\n    // Sent\ndefault:\n    // Channel full, handle accordingly\n}\n```\n\n### Memory and Lock Optimization\n```go\n// Reduce lock contention with sharding\ntype ShardedMap struct {\n    shards [16]struct {\n        sync.RWMutex\n        m map[string]interface{}\n    }\n}\n\nfunc (sm *ShardedMap) getShard(key string) *struct {\n    sync.RWMutex\n    m map[string]interface{}\n} {\n    hash := fnv32(key)\n    return &sm.shards[hash%16]\n}\n\nfunc (sm *ShardedMap) Get(key string) (interface{}, bool) {\n    shard := sm.getShard(key)\n    shard.RLock()\n    defer shard.RUnlock()\n    val, ok := shard.m[key]\n    return val, ok\n}\n\n// Lock-free with atomic\ntype Config struct {\n    v atomic.Value\n}\n\nfunc (c *Config) Load() *ConfigData {\n    return c.v.Load().(*ConfigData)\n}\n\nfunc (c *Config) Store(cfg *ConfigData) {\n    c.v.Store(cfg)\n}\n\n// Reduce allocations\nvar bufferPool = sync.Pool{\n    New: func() interface{} {\n        return make([]byte, 1024)\n    },\n}\n\nfunc process() {\n    buf := bufferPool.Get().([]byte)\n    defer bufferPool.Put(buf)\n    // Use buf\n}\n```\n\n## Best Practices Summary\n\n1. **Start goroutines responsibly** - Always know how they'll stop\n2. **Don't leak goroutines** - Ensure cleanup with context or channels\n3. **Prefer channels over shared memory** - But use sync primitives when appropriate\n4. **Always handle context cancellation** - Check ctx.Done() in loops\n5. **Close channels from sender side only** - Never close from receiver\n6. **Use buffered channels thoughtfully** - Not just to \"fix\" synchronization\n7. **Protect shared state** - Use mutex, channels, or atomic operations\n8. **Run with -race during development** - Catch races early\n9. **Design for graceful shutdown** - Handle signals and cleanup\n10. **Profile before optimizing** - Measure, don't guess performance issues","numLines":1698,"startLine":1,"totalLines":1698}}}
{"parentUuid":"d1b1f047-f60d-4da3-af0a-0b69303dbdc1","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012Ld6knAwnn1v9oWFsjkE2C","type":"tool_result","content":"     1→# Go Performance - Optimization Mastery\n     2→\n     3→## Table of Contents\n     4→1. [Profiling](#profiling)\n     5→2. [Benchmarking](#benchmarking)\n     6→3. [Memory Management](#memory-management)\n     7→4. [CPU Optimization](#cpu-optimization)\n     8→5. [Compiler Optimizations](#compiler-optimizations)\n     9→6. [Caching Strategies](#caching-strategies)\n    10→7. [Concurrency Performance](#concurrency-performance)\n    11→8. [I/O Optimization](#io-optimization)\n    12→9. [Data Structure Optimization](#data-structure-optimization)\n    13→10. [Performance Best Practices](#performance-best-practices)\n    14→\n    15→## Profiling\n    16→\n    17→### CPU Profiling\n    18→```go\n    19→import (\n    20→    \"runtime/pprof\"\n    21→    \"os\"\n    22→    \"runtime\"\n    23→)\n    24→\n    25→// Basic CPU profiling\n    26→func main() {\n    27→    // Create CPU profile file\n    28→    f, err := os.Create(\"cpu.prof\")\n    29→    if err != nil {\n    30→        log.Fatal(err)\n    31→    }\n    32→    defer f.Close()\n    33→    \n    34→    // Start CPU profiling\n    35→    if err := pprof.StartCPUProfile(f); err != nil {\n    36→        log.Fatal(err)\n    37→    }\n    38→    defer pprof.StopCPUProfile()\n    39→    \n    40→    // Your application code\n    41→    runApplication()\n    42→}\n    43→\n    44→// HTTP profiling server\n    45→import _ \"net/http/pprof\"\n    46→\n    47→func main() {\n    48→    go func() {\n    49→        log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n    50→    }()\n    51→    \n    52→    // Your application code\n    53→    runApplication()\n    54→}\n    55→\n    56→// Analyze profiles:\n    57→// go tool pprof cpu.prof\n    58→// go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n    59→// go tool pprof -http=:8080 cpu.prof  # Web interface\n    60→\n    61→// Profile with benchmarks\n    62→func BenchmarkFunction(b *testing.B) {\n    63→    // Start profiling in benchmark\n    64→    f, _ := os.Create(\"bench.prof\")\n    65→    pprof.StartCPUProfile(f)\n    66→    defer pprof.StopCPUProfile()\n    67→    \n    68→    for i := 0; i < b.N; i++ {\n    69→        FunctionToProfile()\n    70→    }\n    71→}\n    72→```\n    73→\n    74→### Memory Profiling\n    75→```go\n    76→// Memory profiling\n    77→func writeMemProfile() {\n    78→    f, err := os.Create(\"mem.prof\")\n    79→    if err != nil {\n    80→        log.Fatal(err)\n    81→    }\n    82→    defer f.Close()\n    83→    \n    84→    runtime.GC() // Force GC before profiling\n    85→    if err := pprof.WriteHeapProfile(f); err != nil {\n    86→        log.Fatal(err)\n    87→    }\n    88→}\n    89→\n    90→// Allocation profiling\n    91→func writeAllocProfile() {\n    92→    f, err := os.Create(\"alloc.prof\")\n    93→    if err != nil {\n    94→        log.Fatal(err)\n    95→    }\n    96→    defer f.Close()\n    97→    \n    98→    // Profile allocations\n    99→    runtime.MemProfileRate = 1 // Profile every allocation\n   100→    defer func() { runtime.MemProfileRate = 512 * 1024 }() // Reset\n   101→    \n   102→    // Run code\n   103→    runApplication()\n   104→    \n   105→    pprof.Lookup(\"allocs\").WriteTo(f, 0)\n   106→}\n   107→\n   108→// Memory stats\n   109→func printMemStats() {\n   110→    var m runtime.MemStats\n   111→    runtime.ReadMemStats(&m)\n   112→    \n   113→    fmt.Printf(\"Alloc = %v MB\", m.Alloc / 1024 / 1024)\n   114→    fmt.Printf(\"TotalAlloc = %v MB\", m.TotalAlloc / 1024 / 1024)\n   115→    fmt.Printf(\"Sys = %v MB\", m.Sys / 1024 / 1024)\n   116→    fmt.Printf(\"NumGC = %v\\n\", m.NumGC)\n   117→    fmt.Printf(\"HeapAlloc = %v MB\", m.HeapAlloc / 1024 / 1024)\n   118→    fmt.Printf(\"HeapObjects = %v\", m.HeapObjects)\n   119→}\n   120→\n   121→// Track allocations in specific code\n   122→func trackAllocations() {\n   123→    var m1, m2 runtime.MemStats\n   124→    \n   125→    runtime.ReadMemStats(&m1)\n   126→    \n   127→    // Code to measure\n   128→    expensiveOperation()\n   129→    \n   130→    runtime.ReadMemStats(&m2)\n   131→    \n   132→    fmt.Printf(\"Allocated: %d bytes\\n\", m2.Alloc - m1.Alloc)\n   133→    fmt.Printf(\"Total Allocated: %d bytes\\n\", m2.TotalAlloc - m1.TotalAlloc)\n   134→    fmt.Printf(\"Number of allocations: %d\\n\", m2.Mallocs - m1.Mallocs)\n   135→}\n   136→```\n   137→\n   138→### Goroutine Profiling\n   139→```go\n   140→// Goroutine profiling\n   141→func writeGoroutineProfile() {\n   142→    f, err := os.Create(\"goroutine.prof\")\n   143→    if err != nil {\n   144→        log.Fatal(err)\n   145→    }\n   146→    defer f.Close()\n   147→    \n   148→    pprof.Lookup(\"goroutine\").WriteTo(f, 1)\n   149→}\n   150→\n   151→// Monitor goroutine count\n   152→func monitorGoroutines() {\n   153→    ticker := time.NewTicker(1 * time.Second)\n   154→    defer ticker.Stop()\n   155→    \n   156→    for range ticker.C {\n   157→        fmt.Printf(\"Goroutines: %d\\n\", runtime.NumGoroutine())\n   158→    }\n   159→}\n   160→\n   161→// Block profiling (mutex contention)\n   162→func enableBlockProfiling() {\n   163→    runtime.SetBlockProfileRate(1)\n   164→    defer runtime.SetBlockProfileRate(0)\n   165→    \n   166→    // Run application\n   167→    runApplication()\n   168→    \n   169→    f, _ := os.Create(\"block.prof\")\n   170→    defer f.Close()\n   171→    pprof.Lookup(\"block\").WriteTo(f, 0)\n   172→}\n   173→\n   174→// Mutex profiling\n   175→func enableMutexProfiling() {\n   176→    runtime.SetMutexProfileFraction(1)\n   177→    defer runtime.SetMutexProfileFraction(0)\n   178→    \n   179→    // Run application\n   180→    runApplication()\n   181→    \n   182→    f, _ := os.Create(\"mutex.prof\")\n   183→    defer f.Close()\n   184→    pprof.Lookup(\"mutex\").WriteTo(f, 0)\n   185→}\n   186→```\n   187→\n   188→### Trace Profiling\n   189→```go\n   190→import \"runtime/trace\"\n   191→\n   192→// Execution tracing\n   193→func main() {\n   194→    f, err := os.Create(\"trace.out\")\n   195→    if err != nil {\n   196→        log.Fatal(err)\n   197→    }\n   198→    defer f.Close()\n   199→    \n   200→    err = trace.Start(f)\n   201→    if err != nil {\n   202→        log.Fatal(err)\n   203→    }\n   204→    defer trace.Stop()\n   205→    \n   206→    // Your application\n   207→    runApplication()\n   208→}\n   209→\n   210→// Analyze: go tool trace trace.out\n   211→\n   212→// Custom trace regions\n   213→func processRequest(ctx context.Context) {\n   214→    defer trace.StartRegion(ctx, \"processRequest\").End()\n   215→    \n   216→    trace.WithRegion(ctx, \"validate\", func() {\n   217→        validateInput()\n   218→    })\n   219→    \n   220→    trace.WithRegion(ctx, \"compute\", func() {\n   221→        computeResult()\n   222→    })\n   223→    \n   224→    trace.WithRegion(ctx, \"respond\", func() {\n   225→        sendResponse()\n   226→    })\n   227→}\n   228→\n   229→// Trace logging\n   230→func traceLog(ctx context.Context, message string) {\n   231→    trace.Log(ctx, \"app\", message)\n   232→}\n   233→```\n   234→\n   235→## Benchmarking\n   236→\n   237→### Advanced Benchmarking\n   238→```go\n   239→// Benchmark with different inputs\n   240→func BenchmarkSort(b *testing.B) {\n   241→    sizes := []int{10, 100, 1000, 10000}\n   242→    \n   243→    for _, size := range sizes {\n   244→        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n   245→            data := generateRandomSlice(size)\n   246→            \n   247→            b.ResetTimer()\n   248→            for i := 0; i < b.N; i++ {\n   249→                b.StopTimer()\n   250→                tmp := make([]int, len(data))\n   251→                copy(tmp, data)\n   252→                b.StartTimer()\n   253→                \n   254→                sort.Ints(tmp)\n   255→            }\n   256→        })\n   257→    }\n   258→}\n   259→\n   260→// Comparative benchmarks\n   261→func BenchmarkStringBuilding(b *testing.B) {\n   262→    strs := []string{\"hello\", \"world\", \"foo\", \"bar\", \"baz\"}\n   263→    \n   264→    b.Run(\"Concatenation\", func(b *testing.B) {\n   265→        for i := 0; i < b.N; i++ {\n   266→            var result string\n   267→            for _, s := range strs {\n   268→                result += s\n   269→            }\n   270→        }\n   271→    })\n   272→    \n   273→    b.Run(\"StringBuilder\", func(b *testing.B) {\n   274→        for i := 0; i < b.N; i++ {\n   275→            var builder strings.Builder\n   276→            for _, s := range strs {\n   277→                builder.WriteString(s)\n   278→            }\n   279→            _ = builder.String()\n   280→        }\n   281→    })\n   282→    \n   283→    b.Run(\"BytesBuffer\", func(b *testing.B) {\n   284→        for i := 0; i < b.N; i++ {\n   285→            var buffer bytes.Buffer\n   286→            for _, s := range strs {\n   287→                buffer.WriteString(s)\n   288→            }\n   289→            _ = buffer.String()\n   290→        }\n   291→    })\n   292→    \n   293→    b.Run(\"Join\", func(b *testing.B) {\n   294→        for i := 0; i < b.N; i++ {\n   295→            _ = strings.Join(strs, \"\")\n   296→        }\n   297→    })\n   298→}\n   299→\n   300→// Memory benchmarks\n   301→func BenchmarkMemory(b *testing.B) {\n   302→    b.Run(\"WithAllocation\", func(b *testing.B) {\n   303→        b.ReportAllocs()\n   304→        for i := 0; i < b.N; i++ {\n   305→            s := make([]int, 1000)\n   306→            _ = s\n   307→        }\n   308→    })\n   309→    \n   310→    b.Run(\"WithPool\", func(b *testing.B) {\n   311→        b.ReportAllocs()\n   312→        pool := sync.Pool{\n   313→            New: func() interface{} {\n   314→                return make([]int, 1000)\n   315→            },\n   316→        }\n   317→        \n   318→        for i := 0; i < b.N; i++ {\n   319→            s := pool.Get().([]int)\n   320→            pool.Put(s)\n   321→        }\n   322→    })\n   323→}\n   324→\n   325→// Custom metrics\n   326→func BenchmarkThroughput(b *testing.B) {\n   327→    data := make([]byte, 1024*1024) // 1MB\n   328→    \n   329→    b.SetBytes(int64(len(data)))\n   330→    b.ResetTimer()\n   331→    \n   332→    for i := 0; i < b.N; i++ {\n   333→        process(data)\n   334→    }\n   335→    \n   336→    b.ReportMetric(float64(b.N)*float64(len(data))/b.Elapsed().Seconds()/1024/1024, \"MB/s\")\n   337→}\n   338→```\n   339→\n   340→## Memory Management\n   341→\n   342→### Reducing Allocations\n   343→```go\n   344→// Avoid allocations in loops\n   345→// Bad: Allocates in loop\n   346→func bad() []string {\n   347→    var results []string\n   348→    for i := 0; i < 1000; i++ {\n   349→        results = append(results, fmt.Sprintf(\"item-%d\", i))\n   350→    }\n   351→    return results\n   352→}\n   353→\n   354→// Good: Preallocate\n   355→func good() []string {\n   356→    results := make([]string, 0, 1000)\n   357→    for i := 0; i < 1000; i++ {\n   358→        results = append(results, fmt.Sprintf(\"item-%d\", i))\n   359→    }\n   360→    return results\n   361→}\n   362→\n   363→// Reuse buffers\n   364→var bufferPool = sync.Pool{\n   365→    New: func() interface{} {\n   366→        return new(bytes.Buffer)\n   367→    },\n   368→}\n   369→\n   370→func processWithPool(data []byte) string {\n   371→    buf := bufferPool.Get().(*bytes.Buffer)\n   372→    defer func() {\n   373→        buf.Reset()\n   374→        bufferPool.Put(buf)\n   375→    }()\n   376→    \n   377→    buf.Write(data)\n   378→    // Process...\n   379→    return buf.String()\n   380→}\n   381→\n   382→// Avoid string allocations\n   383→func avoidStringAllocs(b []byte) string {\n   384→    // Bad: Multiple allocations\n   385→    s := string(b)\n   386→    s = strings.ToUpper(s)\n   387→    s = strings.TrimSpace(s)\n   388→    \n   389→    // Better: Work with bytes\n   390→    b = bytes.ToUpper(b)\n   391→    b = bytes.TrimSpace(b)\n   392→    return string(b)\n   393→}\n   394→\n   395→// String interning for repeated strings\n   396→type StringInterner struct {\n   397→    mu    sync.RWMutex\n   398→    cache map[string]string\n   399→}\n   400→\n   401→func (si *StringInterner) Intern(s string) string {\n   402→    si.mu.RLock()\n   403→    if interned, ok := si.cache[s]; ok {\n   404→        si.mu.RUnlock()\n   405→        return interned\n   406→    }\n   407→    si.mu.RUnlock()\n   408→    \n   409→    si.mu.Lock()\n   410→    defer si.mu.Unlock()\n   411→    \n   412→    si.cache[s] = s\n   413→    return s\n   414→}\n   415→```\n   416→\n   417→### Memory Layout Optimization\n   418→```go\n   419→// Struct field alignment\n   420→// Bad: 32 bytes due to padding\n   421→type Inefficient struct {\n   422→    a bool    // 1 byte + 7 padding\n   423→    b int64   // 8 bytes\n   424→    c bool    // 1 byte + 7 padding\n   425→    d int64   // 8 bytes\n   426→}\n   427→\n   428→// Good: 24 bytes with better alignment\n   429→type Efficient struct {\n   430→    b int64   // 8 bytes\n   431→    d int64   // 8 bytes\n   432→    a bool    // 1 byte\n   433→    c bool    // 1 byte + 6 padding\n   434→}\n   435→\n   436→// Use smaller types when possible\n   437→type Flags struct {\n   438→    // Bad: 4 bools = potentially 4 bytes + padding\n   439→    IsActive   bool\n   440→    IsVerified bool\n   441→    IsPremium  bool\n   442→    IsAdmin    bool\n   443→}\n   444→\n   445→// Good: 1 byte using bit flags\n   446→type CompactFlags uint8\n   447→\n   448→const (\n   449→    FlagActive CompactFlags = 1 << iota\n   450→    FlagVerified\n   451→    FlagPremium\n   452→    FlagAdmin\n   453→)\n   454→\n   455→func (f CompactFlags) IsActive() bool { return f&FlagActive != 0 }\n   456→func (f CompactFlags) IsVerified() bool { return f&FlagVerified != 0 }\n   457→\n   458→// Array vs slice for fixed size\n   459→type Record struct {\n   460→    // Bad: slice has 24 bytes overhead (pointer, len, cap)\n   461→    IDSlice []byte\n   462→    \n   463→    // Good: array for fixed size, no overhead\n   464→    IDArray [16]byte\n   465→}\n   466→```\n   467→\n   468→### Escape Analysis\n   469→```go\n   470→// Understanding escape analysis\n   471→// go build -gcflags=\"-m\" to see escape analysis\n   472→\n   473→// Doesn't escape - allocated on stack\n   474→func noEscape() int {\n   475→    x := 42\n   476→    return x\n   477→}\n   478→\n   479→// Escapes to heap - returned pointer\n   480→func escapes() *int {\n   481→    x := 42\n   482→    return &x // x escapes to heap\n   483→}\n   484→\n   485→// Avoid unnecessary escapes\n   486→type Data struct {\n   487→    values [1000]int\n   488→}\n   489→\n   490→// Bad: Escapes to heap\n   491→func (d *Data) Sum() int {\n   492→    sum := 0\n   493→    for _, v := range d.values { // d.values escapes\n   494→        sum += v\n   495→    }\n   496→    return sum\n   497→}\n   498→\n   499→// Good: Doesn't escape\n   500→func (d Data) SumValue() int {\n   501→    sum := 0\n   502→    for i := 0; i < len(d.values); i++ {\n   503→        sum += d.values[i]\n   504→    }\n   505→    return sum\n   506→}\n   507→\n   508→// Interface causes escape\n   509→func processInterface(i interface{}) {\n   510→    // i escapes to heap\n   511→}\n   512→\n   513→func avoidEscape() {\n   514→    x := 42\n   515→    processInterface(x) // x escapes\n   516→    \n   517→    // Avoid by not using interface\n   518→    processInt(x) // x doesn't escape\n   519→}\n   520→\n   521→func processInt(i int) {\n   522→    // Process int directly\n   523→}\n   524→```\n   525→\n   526→## CPU Optimization\n   527→\n   528→### Hot Path Optimization\n   529→```go\n   530→// Optimize hot paths\n   531→func processData(data []int) int {\n   532→    // Move invariants out of loop\n   533→    length := len(data)\n   534→    if length == 0 {\n   535→        return 0\n   536→    }\n   537→    \n   538→    sum := 0\n   539→    // Unroll loop for better performance\n   540→    for i := 0; i < length-3; i += 4 {\n   541→        sum += data[i] + data[i+1] + data[i+2] + data[i+3]\n   542→    }\n   543→    \n   544→    // Handle remaining elements\n   545→    for i := length - length%4; i < length; i++ {\n   546→        sum += data[i]\n   547→    }\n   548→    \n   549→    return sum\n   550→}\n   551→\n   552→// Branch prediction optimization\n   553→func findMax(data []int) int {\n   554→    if len(data) == 0 {\n   555→        return 0\n   556→    }\n   557→    \n   558→    max := data[0]\n   559→    for i := 1; i < len(data); i++ {\n   560→        // Branchless max (may be faster)\n   561→        if data[i] > max {\n   562→            max = data[i]\n   563→        }\n   564→    }\n   565→    return max\n   566→}\n   567→\n   568→// Cache-friendly iteration\n   569→func sumMatrix(matrix [][]int) int {\n   570→    sum := 0\n   571→    // Row-major order (cache-friendly)\n   572→    for i := 0; i < len(matrix); i++ {\n   573→        for j := 0; j < len(matrix[i]); j++ {\n   574→            sum += matrix[i][j]\n   575→        }\n   576→    }\n   577→    return sum\n   578→}\n   579→\n   580→// SIMD-friendly code\n   581→func addSlices(a, b []float64) []float64 {\n   582→    result := make([]float64, len(a))\n   583→    \n   584→    // Compiler may vectorize this\n   585→    for i := range a {\n   586→        result[i] = a[i] + b[i]\n   587→    }\n   588→    \n   589→    return result\n   590→}\n   591→```\n   592→\n   593→### Inlining\n   594→```go\n   595→// Encourage inlining for small functions\n   596→//go:inline\n   597→func add(a, b int) int {\n   598→    return a + b\n   599→}\n   600→\n   601→// Prevent inlining for rarely used functions\n   602→//go:noinline\n   603→func rarelyUsedFunction() {\n   604→    // Complex logic\n   605→}\n   606→\n   607→// Check inlining decisions\n   608→// go build -gcflags=\"-m=2\"\n   609→\n   610→// Inline-friendly functions\n   611→func abs(x int) int {\n   612→    if x < 0 {\n   613→        return -x\n   614→    }\n   615→    return x\n   616→}\n   617→\n   618→// Too complex to inline (default threshold ~80 nodes)\n   619→func complexFunction(x int) int {\n   620→    // Many operations...\n   621→    return result\n   622→}\n   623→```\n   624→\n   625→## Compiler Optimizations\n   626→\n   627→### Compiler Directives\n   628→```go\n   629→// Bounds check elimination\n   630→func sumArray(arr []int) int {\n   631→    if len(arr) == 0 {\n   632→        return 0\n   633→    }\n   634→    \n   635→    sum := 0\n   636→    // Compiler can eliminate bounds checks\n   637→    for i := 0; i < len(arr); i++ {\n   638→        sum += arr[i]\n   639→    }\n   640→    return sum\n   641→}\n   642→\n   643→// Help compiler with hints\n   644→func process(data []byte) {\n   645→    // Tell compiler minimum length\n   646→    _ = data[3] // Bounds check once\n   647→    \n   648→    // Now these don't need bounds checks\n   649→    a := data[0]\n   650→    b := data[1]\n   651→    c := data[2]\n   652→    d := data[3]\n   653→    \n   654→    // Process a, b, c, d\n   655→}\n   656→\n   657→// Const propagation\n   658→const bufferSize = 1024\n   659→\n   660→func allocateBuffer() []byte {\n   661→    // Compiler knows size at compile time\n   662→    return make([]byte, bufferSize)\n   663→}\n   664→\n   665→// Dead code elimination\n   666→func example(debug bool) {\n   667→    if false { // Compiler removes this\n   668→        expensiveDebugOperation()\n   669→    }\n   670→    \n   671→    const debugMode = false\n   672→    if debugMode { // Also removed\n   673→        fmt.Println(\"Debug mode\")\n   674→    }\n   675→}\n   676→```\n   677→\n   678→### Build Flags\n   679→```go\n   680→// Build tags for optimization\n   681→//go:build !debug\n   682→\n   683→package main\n   684→\n   685→func log(msg string) {\n   686→    // No-op in release builds\n   687→}\n   688→\n   689→// Alternative file for debug builds\n   690→//go:build debug\n   691→\n   692→package main\n   693→\n   694→func log(msg string) {\n   695→    fmt.Println(msg)\n   696→}\n   697→\n   698→// Compile with optimizations\n   699→// go build -ldflags=\"-s -w\" # Strip debug info\n   700→// go build -tags release\n   701→// GOOS=linux GOARCH=amd64 go build # Cross-compile\n   702→```\n   703→\n   704→## Caching Strategies\n   705→\n   706→### In-Memory Caching\n   707→```go\n   708→// Simple cache with TTL\n   709→type Cache struct {\n   710→    mu      sync.RWMutex\n   711→    items   map[string]*cacheItem\n   712→    ttl     time.Duration\n   713→}\n   714→\n   715→type cacheItem struct {\n   716→    value      interface{}\n   717→    expiration time.Time\n   718→}\n   719→\n   720→func NewCache(ttl time.Duration) *Cache {\n   721→    c := &Cache{\n   722→        items: make(map[string]*cacheItem),\n   723→        ttl:   ttl,\n   724→    }\n   725→    go c.cleanup()\n   726→    return c\n   727→}\n   728→\n   729→func (c *Cache) Set(key string, value interface{}) {\n   730→    c.mu.Lock()\n   731→    defer c.mu.Unlock()\n   732→    \n   733→    c.items[key] = &cacheItem{\n   734→        value:      value,\n   735→        expiration: time.Now().Add(c.ttl),\n   736→    }\n   737→}\n   738→\n   739→func (c *Cache) Get(key string) (interface{}, bool) {\n   740→    c.mu.RLock()\n   741→    defer c.mu.RUnlock()\n   742→    \n   743→    item, found := c.items[key]\n   744→    if !found {\n   745→        return nil, false\n   746→    }\n   747→    \n   748→    if time.Now().After(item.expiration) {\n   749→        return nil, false\n   750→    }\n   751→    \n   752→    return item.value, true\n   753→}\n   754→\n   755→func (c *Cache) cleanup() {\n   756→    ticker := time.NewTicker(c.ttl / 2)\n   757→    defer ticker.Stop()\n   758→    \n   759→    for range ticker.C {\n   760→        c.mu.Lock()\n   761→        now := time.Now()\n   762→        for key, item := range c.items {\n   763→            if now.After(item.expiration) {\n   764→                delete(c.items, key)\n   765→            }\n   766→        }\n   767→        c.mu.Unlock()\n   768→    }\n   769→}\n   770→\n   771→// LRU Cache\n   772→type LRUCache struct {\n   773→    capacity int\n   774→    items    map[string]*list.Element\n   775→    order    *list.List\n   776→    mu       sync.Mutex\n   777→}\n   778→\n   779→type lruItem struct {\n   780→    key   string\n   781→    value interface{}\n   782→}\n   783→\n   784→func NewLRUCache(capacity int) *LRUCache {\n   785→    return &LRUCache{\n   786→        capacity: capacity,\n   787→        items:    make(map[string]*list.Element),\n   788→        order:    list.New(),\n   789→    }\n   790→}\n   791→\n   792→func (c *LRUCache) Get(key string) (interface{}, bool) {\n   793→    c.mu.Lock()\n   794→    defer c.mu.Unlock()\n   795→    \n   796→    if elem, ok := c.items[key]; ok {\n   797→        c.order.MoveToFront(elem)\n   798→        return elem.Value.(*lruItem).value, true\n   799→    }\n   800→    return nil, false\n   801→}\n   802→\n   803→func (c *LRUCache) Set(key string, value interface{}) {\n   804→    c.mu.Lock()\n   805→    defer c.mu.Unlock()\n   806→    \n   807→    if elem, ok := c.items[key]; ok {\n   808→        c.order.MoveToFront(elem)\n   809→        elem.Value.(*lruItem).value = value\n   810→        return\n   811→    }\n   812→    \n   813→    if c.order.Len() >= c.capacity {\n   814→        oldest := c.order.Back()\n   815→        if oldest != nil {\n   816→            c.order.Remove(oldest)\n   817→            delete(c.items, oldest.Value.(*lruItem).key)\n   818→        }\n   819→    }\n   820→    \n   821→    item := &lruItem{key: key, value: value}\n   822→    elem := c.order.PushFront(item)\n   823→    c.items[key] = elem\n   824→}\n   825→```\n   826→\n   827→### Memoization\n   828→```go\n   829→// Function memoization\n   830→type Memoizer struct {\n   831→    mu    sync.RWMutex\n   832→    cache map[string]interface{}\n   833→    fn    func(string) interface{}\n   834→}\n   835→\n   836→func NewMemoizer(fn func(string) interface{}) *Memoizer {\n   837→    return &Memoizer{\n   838→        cache: make(map[string]interface{}),\n   839→        fn:    fn,\n   840→    }\n   841→}\n   842→\n   843→func (m *Memoizer) Get(key string) interface{} {\n   844→    m.mu.RLock()\n   845→    if val, ok := m.cache[key]; ok {\n   846→        m.mu.RUnlock()\n   847→        return val\n   848→    }\n   849→    m.mu.RUnlock()\n   850→    \n   851→    m.mu.Lock()\n   852→    defer m.mu.Unlock()\n   853→    \n   854→    // Double-check\n   855→    if val, ok := m.cache[key]; ok {\n   856→        return val\n   857→    }\n   858→    \n   859→    val := m.fn(key)\n   860→    m.cache[key] = val\n   861→    return val\n   862→}\n   863→\n   864→// Concurrent-safe memoization with singleflight\n   865→import \"golang.org/x/sync/singleflight\"\n   866→\n   867→type ConcurrentMemoizer struct {\n   868→    cache map[string]interface{}\n   869→    mu    sync.RWMutex\n   870→    group singleflight.Group\n   871→}\n   872→\n   873→func (m *ConcurrentMemoizer) Get(key string) (interface{}, error) {\n   874→    m.mu.RLock()\n   875→    if val, ok := m.cache[key]; ok {\n   876→        m.mu.RUnlock()\n   877→        return val, nil\n   878→    }\n   879→    m.mu.RUnlock()\n   880→    \n   881→    // Ensure only one goroutine computes the value\n   882→    val, err, _ := m.group.Do(key, func() (interface{}, error) {\n   883→        result := expensiveComputation(key)\n   884→        \n   885→        m.mu.Lock()\n   886→        m.cache[key] = result\n   887→        m.mu.Unlock()\n   888→        \n   889→        return result, nil\n   890→    })\n   891→    \n   892→    return val, err\n   893→}\n   894→```\n   895→\n   896→## Concurrency Performance\n   897→\n   898→### Goroutine Pool\n   899→```go\n   900→// Efficient goroutine pool\n   901→type WorkerPool struct {\n   902→    workers   int\n   903→    jobQueue  chan Job\n   904→    results   chan Result\n   905→    wg        sync.WaitGroup\n   906→}\n   907→\n   908→func NewWorkerPool(workers int, queueSize int) *WorkerPool {\n   909→    return &WorkerPool{\n   910→        workers:  workers,\n   911→        jobQueue: make(chan Job, queueSize),\n   912→        results:  make(chan Result, queueSize),\n   913→    }\n   914→}\n   915→\n   916→func (p *WorkerPool) Start() {\n   917→    for i := 0; i < p.workers; i++ {\n   918→        p.wg.Add(1)\n   919→        go p.worker(i)\n   920→    }\n   921→}\n   922→\n   923→func (p *WorkerPool) worker(id int) {\n   924→    defer p.wg.Done()\n   925→    \n   926→    for job := range p.jobQueue {\n   927→        result := processJob(job)\n   928→        p.results <- result\n   929→    }\n   930→}\n   931→\n   932→func (p *WorkerPool) Submit(job Job) {\n   933→    p.jobQueue <- job\n   934→}\n   935→\n   936→func (p *WorkerPool) Stop() {\n   937→    close(p.jobQueue)\n   938→    p.wg.Wait()\n   939→    close(p.results)\n   940→}\n   941→\n   942→// Lock-free structures\n   943→type LockFreeStack struct {\n   944→    head atomic.Pointer[node]\n   945→}\n   946→\n   947→type node struct {\n   948→    value interface{}\n   949→    next  *node\n   950→}\n   951→\n   952→func (s *LockFreeStack) Push(v interface{}) {\n   953→    n := &node{value: v}\n   954→    for {\n   955→        head := s.head.Load()\n   956→        n.next = head\n   957→        if s.head.CompareAndSwap(head, n) {\n   958→            return\n   959→        }\n   960→    }\n   961→}\n   962→\n   963→func (s *LockFreeStack) Pop() interface{} {\n   964→    for {\n   965→        head := s.head.Load()\n   966→        if head == nil {\n   967→            return nil\n   968→        }\n   969→        if s.head.CompareAndSwap(head, head.next) {\n   970→            return head.value\n   971→        }\n   972→    }\n   973→}\n   974→```\n   975→\n   976→### Channel Optimization\n   977→```go\n   978→// Buffered channels for performance\n   979→func efficientPipeline() {\n   980→    // Use buffered channels to reduce blocking\n   981→    input := make(chan int, 100)\n   982→    output := make(chan int, 100)\n   983→    \n   984→    // Producer\n   985→    go func() {\n   986→        defer close(input)\n   987→        for i := 0; i < 1000; i++ {\n   988→            input <- i\n   989→        }\n   990→    }()\n   991→    \n   992→    // Workers\n   993→    var wg sync.WaitGroup\n   994→    for i := 0; i < 10; i++ {\n   995→        wg.Add(1)\n   996→        go func() {\n   997→            defer wg.Done()\n   998→            for val := range input {\n   999→                output <- process(val)\n  1000→            }\n  1001→        }()\n  1002→    }\n  1003→    \n  1004→    // Close output when workers done\n  1005→    go func() {\n  1006→        wg.Wait()\n  1007→        close(output)\n  1008→    }()\n  1009→    \n  1010→    // Consumer\n  1011→    for result := range output {\n  1012→        handleResult(result)\n  1013→    }\n  1014→}\n  1015→\n  1016→// Batch processing for efficiency\n  1017→func batchProcessor(input <-chan Item) {\n  1018→    batch := make([]Item, 0, 100)\n  1019→    ticker := time.NewTicker(100 * time.Millisecond)\n  1020→    defer ticker.Stop()\n  1021→    \n  1022→    for {\n  1023→        select {\n  1024→        case item, ok := <-input:\n  1025→            if !ok {\n  1026→                if len(batch) > 0 {\n  1027→                    processBatch(batch)\n  1028→                }\n  1029→                return\n  1030→            }\n  1031→            batch = append(batch, item)\n  1032→            \n  1033→            if len(batch) >= 100 {\n  1034→                processBatch(batch)\n  1035→                batch = batch[:0]\n  1036→            }\n  1037→            \n  1038→        case <-ticker.C:\n  1039→            if len(batch) > 0 {\n  1040→                processBatch(batch)\n  1041→                batch = batch[:0]\n  1042→            }\n  1043→        }\n  1044→    }\n  1045→}\n  1046→```\n  1047→\n  1048→## I/O Optimization\n  1049→\n  1050→### Buffered I/O\n  1051→```go\n  1052→// Use buffered I/O\n  1053→func efficientFileRead(filename string) error {\n  1054→    file, err := os.Open(filename)\n  1055→    if err != nil {\n  1056→        return err\n  1057→    }\n  1058→    defer file.Close()\n  1059→    \n  1060→    // Use buffered reader\n  1061→    reader := bufio.NewReader(file)\n  1062→    \n  1063→    for {\n  1064→        line, err := reader.ReadString('\\n')\n  1065→        if err == io.EOF {\n  1066→            break\n  1067→        }\n  1068→        if err != nil {\n  1069→            return err\n  1070→        }\n  1071→        \n  1072→        processLine(line)\n  1073→    }\n  1074→    \n  1075→    return nil\n  1076→}\n  1077→\n  1078→// Efficient file writing\n  1079→func efficientFileWrite(filename string, data []string) error {\n  1080→    file, err := os.Create(filename)\n  1081→    if err != nil {\n  1082→        return err\n  1083→    }\n  1084→    defer file.Close()\n  1085→    \n  1086→    // Use buffered writer\n  1087→    writer := bufio.NewWriter(file)\n  1088→    defer writer.Flush()\n  1089→    \n  1090→    for _, line := range data {\n  1091→        _, err := writer.WriteString(line + \"\\n\")\n  1092→        if err != nil {\n  1093→            return err\n  1094→        }\n  1095→    }\n  1096→    \n  1097→    return nil\n  1098→}\n  1099→\n  1100→// Memory-mapped files for large files\n  1101→import \"golang.org/x/exp/mmap\"\n  1102→\n  1103→func readLargeFile(filename string) error {\n  1104→    reader, err := mmap.Open(filename)\n  1105→    if err != nil {\n  1106→        return err\n  1107→    }\n  1108→    defer reader.Close()\n  1109→    \n  1110→    // Read without loading entire file into memory\n  1111→    data := make([]byte, 1024)\n  1112→    for offset := int64(0); offset < reader.Len(); offset += 1024 {\n  1113→        n, err := reader.ReadAt(data, offset)\n  1114→        if err != nil && err != io.EOF {\n  1115→            return err\n  1116→        }\n  1117→        \n  1118→        processChunk(data[:n])\n  1119→    }\n  1120→    \n  1121→    return nil\n  1122→}\n  1123→```\n  1124→\n  1125→### Network I/O\n  1126→```go\n  1127→// Connection pooling\n  1128→type ConnectionPool struct {\n  1129→    connections chan net.Conn\n  1130→    factory     func() (net.Conn, error)\n  1131→}\n  1132→\n  1133→func NewConnectionPool(size int, factory func() (net.Conn, error)) (*ConnectionPool, error) {\n  1134→    pool := &ConnectionPool{\n  1135→        connections: make(chan net.Conn, size),\n  1136→        factory:     factory,\n  1137→    }\n  1138→    \n  1139→    for i := 0; i < size; i++ {\n  1140→        conn, err := factory()\n  1141→        if err != nil {\n  1142→            return nil, err\n  1143→        }\n  1144→        pool.connections <- conn\n  1145→    }\n  1146→    \n  1147→    return pool, nil\n  1148→}\n  1149→\n  1150→func (p *ConnectionPool) Get() net.Conn {\n  1151→    return <-p.connections\n  1152→}\n  1153→\n  1154→func (p *ConnectionPool) Put(conn net.Conn) {\n  1155→    p.connections <- conn\n  1156→}\n  1157→\n  1158→// HTTP client optimization\n  1159→var httpClient = &http.Client{\n  1160→    Timeout: 30 * time.Second,\n  1161→    Transport: &http.Transport{\n  1162→        MaxIdleConns:        100,\n  1163→        MaxIdleConnsPerHost: 10,\n  1164→        IdleConnTimeout:     90 * time.Second,\n  1165→        DisableCompression:  false,\n  1166→        DisableKeepAlives:   false,\n  1167→    },\n  1168→}\n  1169→\n  1170→// Batch HTTP requests\n  1171→func batchHTTPRequests(urls []string) []Response {\n  1172→    results := make([]Response, len(urls))\n  1173→    var wg sync.WaitGroup\n  1174→    \n  1175→    // Limit concurrent requests\n  1176→    sem := make(chan struct{}, 10)\n  1177→    \n  1178→    for i, url := range urls {\n  1179→        wg.Add(1)\n  1180→        go func(idx int, u string) {\n  1181→            defer wg.Done()\n  1182→            \n  1183→            sem <- struct{}{}\n  1184→            defer func() { <-sem }()\n  1185→            \n  1186→            resp, err := httpClient.Get(u)\n  1187→            if err != nil {\n  1188→                results[idx] = Response{Error: err}\n  1189→                return\n  1190→            }\n  1191→            defer resp.Body.Close()\n  1192→            \n  1193→            body, _ := io.ReadAll(resp.Body)\n  1194→            results[idx] = Response{Data: body}\n  1195→        }(i, url)\n  1196→    }\n  1197→    \n  1198→    wg.Wait()\n  1199→    return results\n  1200→}\n  1201→```\n  1202→\n  1203→## Data Structure Optimization\n  1204→\n  1205→### Slice Optimization\n  1206→```go\n  1207→// Preallocate slices\n  1208→func optimizedSliceOperations() {\n  1209→    // Know the capacity\n  1210→    slice := make([]int, 0, 1000)\n  1211→    \n  1212→    // Grow efficiently\n  1213→    if cap(slice) < requiredSize {\n  1214→        newSlice := make([]int, len(slice), requiredSize*2)\n  1215→        copy(newSlice, slice)\n  1216→        slice = newSlice\n  1217→    }\n  1218→    \n  1219→    // Clear slice for reuse\n  1220→    slice = slice[:0]\n  1221→    \n  1222→    // Remove element efficiently\n  1223→    func removeAt(s []int, i int) []int {\n  1224→        s[i] = s[len(s)-1]\n  1225→        return s[:len(s)-1]\n  1226→    }\n  1227→}\n  1228→\n  1229→// Custom growing strategy\n  1230→type GrowableBuffer struct {\n  1231→    data []byte\n  1232→}\n  1233→\n  1234→func (b *GrowableBuffer) grow(n int) {\n  1235→    if cap(b.data)-len(b.data) < n {\n  1236→        newCap := cap(b.data) * 2\n  1237→        if newCap < len(b.data)+n {\n  1238→            newCap = len(b.data) + n\n  1239→        }\n  1240→        newData := make([]byte, len(b.data), newCap)\n  1241→        copy(newData, b.data)\n  1242→        b.data = newData\n  1243→    }\n  1244→}\n  1245→```\n  1246→\n  1247→### Map Optimization\n  1248→```go\n  1249→// Preallocate maps\n  1250→m := make(map[string]int, 1000)\n  1251→\n  1252→// Use appropriate key types\n  1253→// Faster: int keys\n  1254→fastMap := make(map[int]string)\n  1255→\n  1256→// Slower: string keys (requires hashing)\n  1257→slowMap := make(map[string]string)\n  1258→\n  1259→// Custom hash map for specific use case\n  1260→type FastStringMap struct {\n  1261→    buckets [][]entry\n  1262→    size    int\n  1263→}\n  1264→\n  1265→type entry struct {\n  1266→    key   string\n  1267→    value interface{}\n  1268→}\n  1269→\n  1270→func (m *FastStringMap) hash(key string) uint32 {\n  1271→    // Fast hash function\n  1272→    h := uint32(2166136261)\n  1273→    for i := 0; i < len(key); i++ {\n  1274→        h *= 16777619\n  1275→        h ^= uint32(key[i])\n  1276→    }\n  1277→    return h\n  1278→}\n  1279→\n  1280→func (m *FastStringMap) Get(key string) (interface{}, bool) {\n  1281→    h := m.hash(key) % uint32(len(m.buckets))\n  1282→    bucket := m.buckets[h]\n  1283→    \n  1284→    for _, e := range bucket {\n  1285→        if e.key == key {\n  1286→            return e.value, true\n  1287→        }\n  1288→    }\n  1289→    return nil, false\n  1290→}\n  1291→```\n  1292→\n  1293→### String Optimization\n  1294→```go\n  1295→// String concatenation optimization\n  1296→func efficientStringConcat(strs []string) string {\n  1297→    // Calculate total length\n  1298→    var totalLen int\n  1299→    for _, s := range strs {\n  1300→        totalLen += len(s)\n  1301→    }\n  1302→    \n  1303→    // Preallocate builder\n  1304→    var builder strings.Builder\n  1305→    builder.Grow(totalLen)\n  1306→    \n  1307→    for _, s := range strs {\n  1308→        builder.WriteString(s)\n  1309→    }\n  1310→    \n  1311→    return builder.String()\n  1312→}\n  1313→\n  1314→// String/Byte Conversion\n  1315→// WARNING: The unsafe package bypasses Go's type safety and memory safety.\n  1316→// Only use these patterns if you fully understand the implications.\n  1317→\n  1318→// DANGEROUS: Zero-copy conversions (USE WITH EXTREME CAUTION)\n  1319→// These can cause segmentation faults, data corruption, and crashes.\n  1320→// Only use when:\n  1321→// 1. Performance is absolutely critical\n  1322→// 2. You can guarantee the underlying data won't be modified\n  1323→// 3. You've profiled and proven this is a bottleneck\n  1324→\n  1325→// Example of the DANGEROUS approach (NOT RECOMMENDED):\n  1326→// func unsafeStringToBytes(s string) []byte {\n  1327→//     // NEVER modify the returned byte slice!\n  1328→//     return unsafe.Slice(unsafe.StringData(s), len(s))\n  1329→// }\n  1330→\n  1331→// SAFE approach (RECOMMENDED):\n  1332→func safeStringToBytes(s string) []byte {\n  1333→    // Creates a copy - safe but allocates\n  1334→    return []byte(s)\n  1335→}\n  1336→\n  1337→func safeBytesToString(b []byte) string {\n  1338→    // Creates a copy - safe but allocates\n  1339→    return string(b)\n  1340→}\n  1341→\n  1342→// For performance-critical paths, use builders:\n  1343→func efficientStringBuilding(parts []string) string {\n  1344→    var b strings.Builder\n  1345→    b.Grow(calculateTotalLen(parts))\n  1346→    for _, s := range parts {\n  1347→        b.WriteString(s)\n  1348→    }\n  1349→    return b.String()\n  1350→}\n  1351→```\n  1352→\n  1353→## Performance Best Practices\n  1354→\n  1355→### Measurement and Profiling\n  1356→```go\n  1357→// Always measure before optimizing\n  1358→func measurePerformance() {\n  1359→    start := time.Now()\n  1360→    defer func() {\n  1361→        elapsed := time.Since(start)\n  1362→        log.Printf(\"Operation took %v\", elapsed)\n  1363→    }()\n  1364→    \n  1365→    // Operation to measure\n  1366→}\n  1367→\n  1368→// Use benchmarks for micro-optimizations\n  1369→func BenchmarkOptimization(b *testing.B) {\n  1370→    // Test different approaches\n  1371→}\n  1372→\n  1373→// Profile in production\n  1374→import _ \"net/http/pprof\"\n  1375→// Access profiles at /debug/pprof/\n  1376→```\n  1377→\n  1378→### Common Optimizations\n  1379→```go\n  1380→// 1. Avoid premature optimization\n  1381→// Profile first, optimize bottlenecks\n  1382→\n  1383→// 2. Reduce allocations\n  1384→// Use sync.Pool, preallocate slices\n  1385→\n  1386→// 3. Optimize hot paths\n  1387→// Focus on frequently executed code\n  1388→\n  1389→// 4. Use efficient algorithms\n  1390→// O(n) vs O(n²) matters at scale\n  1391→\n  1392→// 5. Cache computed values\n  1393→// Memoization, lookup tables\n  1394→\n  1395→// 6. Batch operations\n  1396→// Reduce system calls, network requests\n  1397→\n  1398→// 7. Use appropriate data structures\n  1399→// Map vs slice, array vs slice\n  1400→\n  1401→// 8. Leverage concurrency wisely\n  1402→// Don't overuse goroutines\n  1403→\n  1404→// 9. Minimize interface conversions\n  1405→// Interfaces cause allocations\n  1406→\n  1407→// 10. Profile regularly\n  1408→// Performance can degrade over time\n  1409→```\n  1410→\n  1411→## Best Practices Summary\n  1412→\n  1413→1. **Profile before optimizing** - Measure, don't guess\n  1414→2. **Focus on algorithms first** - Better algorithm beats micro-optimizations\n  1415→3. **Reduce allocations** - Use pools, preallocate, reuse\n  1416→4. **Optimize hot paths** - 80/20 rule applies\n  1417→5. **Cache aggressively** - But invalidate correctly\n  1418→6. **Use buffered I/O** - For file and network operations\n  1419→7. **Batch operations** - Amortize overhead\n  1420→8. **Choose right data structures** - Map vs slice matters\n  1421→9. **Leverage compiler optimizations** - Write optimizer-friendly code\n  1422→10. **Monitor production performance** - Use pprof, metrics, tracing\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"33348885-c8d9-46a1-9cbb-8dcf3e3d4495","timestamp":"2025-08-13T10:28:02.851Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/performance.md","content":"# Go Performance - Optimization Mastery\n\n## Table of Contents\n1. [Profiling](#profiling)\n2. [Benchmarking](#benchmarking)\n3. [Memory Management](#memory-management)\n4. [CPU Optimization](#cpu-optimization)\n5. [Compiler Optimizations](#compiler-optimizations)\n6. [Caching Strategies](#caching-strategies)\n7. [Concurrency Performance](#concurrency-performance)\n8. [I/O Optimization](#io-optimization)\n9. [Data Structure Optimization](#data-structure-optimization)\n10. [Performance Best Practices](#performance-best-practices)\n\n## Profiling\n\n### CPU Profiling\n```go\nimport (\n    \"runtime/pprof\"\n    \"os\"\n    \"runtime\"\n)\n\n// Basic CPU profiling\nfunc main() {\n    // Create CPU profile file\n    f, err := os.Create(\"cpu.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    // Start CPU profiling\n    if err := pprof.StartCPUProfile(f); err != nil {\n        log.Fatal(err)\n    }\n    defer pprof.StopCPUProfile()\n    \n    // Your application code\n    runApplication()\n}\n\n// HTTP profiling server\nimport _ \"net/http/pprof\"\n\nfunc main() {\n    go func() {\n        log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n    }()\n    \n    // Your application code\n    runApplication()\n}\n\n// Analyze profiles:\n// go tool pprof cpu.prof\n// go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n// go tool pprof -http=:8080 cpu.prof  # Web interface\n\n// Profile with benchmarks\nfunc BenchmarkFunction(b *testing.B) {\n    // Start profiling in benchmark\n    f, _ := os.Create(\"bench.prof\")\n    pprof.StartCPUProfile(f)\n    defer pprof.StopCPUProfile()\n    \n    for i := 0; i < b.N; i++ {\n        FunctionToProfile()\n    }\n}\n```\n\n### Memory Profiling\n```go\n// Memory profiling\nfunc writeMemProfile() {\n    f, err := os.Create(\"mem.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    runtime.GC() // Force GC before profiling\n    if err := pprof.WriteHeapProfile(f); err != nil {\n        log.Fatal(err)\n    }\n}\n\n// Allocation profiling\nfunc writeAllocProfile() {\n    f, err := os.Create(\"alloc.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    // Profile allocations\n    runtime.MemProfileRate = 1 // Profile every allocation\n    defer func() { runtime.MemProfileRate = 512 * 1024 }() // Reset\n    \n    // Run code\n    runApplication()\n    \n    pprof.Lookup(\"allocs\").WriteTo(f, 0)\n}\n\n// Memory stats\nfunc printMemStats() {\n    var m runtime.MemStats\n    runtime.ReadMemStats(&m)\n    \n    fmt.Printf(\"Alloc = %v MB\", m.Alloc / 1024 / 1024)\n    fmt.Printf(\"TotalAlloc = %v MB\", m.TotalAlloc / 1024 / 1024)\n    fmt.Printf(\"Sys = %v MB\", m.Sys / 1024 / 1024)\n    fmt.Printf(\"NumGC = %v\\n\", m.NumGC)\n    fmt.Printf(\"HeapAlloc = %v MB\", m.HeapAlloc / 1024 / 1024)\n    fmt.Printf(\"HeapObjects = %v\", m.HeapObjects)\n}\n\n// Track allocations in specific code\nfunc trackAllocations() {\n    var m1, m2 runtime.MemStats\n    \n    runtime.ReadMemStats(&m1)\n    \n    // Code to measure\n    expensiveOperation()\n    \n    runtime.ReadMemStats(&m2)\n    \n    fmt.Printf(\"Allocated: %d bytes\\n\", m2.Alloc - m1.Alloc)\n    fmt.Printf(\"Total Allocated: %d bytes\\n\", m2.TotalAlloc - m1.TotalAlloc)\n    fmt.Printf(\"Number of allocations: %d\\n\", m2.Mallocs - m1.Mallocs)\n}\n```\n\n### Goroutine Profiling\n```go\n// Goroutine profiling\nfunc writeGoroutineProfile() {\n    f, err := os.Create(\"goroutine.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    pprof.Lookup(\"goroutine\").WriteTo(f, 1)\n}\n\n// Monitor goroutine count\nfunc monitorGoroutines() {\n    ticker := time.NewTicker(1 * time.Second)\n    defer ticker.Stop()\n    \n    for range ticker.C {\n        fmt.Printf(\"Goroutines: %d\\n\", runtime.NumGoroutine())\n    }\n}\n\n// Block profiling (mutex contention)\nfunc enableBlockProfiling() {\n    runtime.SetBlockProfileRate(1)\n    defer runtime.SetBlockProfileRate(0)\n    \n    // Run application\n    runApplication()\n    \n    f, _ := os.Create(\"block.prof\")\n    defer f.Close()\n    pprof.Lookup(\"block\").WriteTo(f, 0)\n}\n\n// Mutex profiling\nfunc enableMutexProfiling() {\n    runtime.SetMutexProfileFraction(1)\n    defer runtime.SetMutexProfileFraction(0)\n    \n    // Run application\n    runApplication()\n    \n    f, _ := os.Create(\"mutex.prof\")\n    defer f.Close()\n    pprof.Lookup(\"mutex\").WriteTo(f, 0)\n}\n```\n\n### Trace Profiling\n```go\nimport \"runtime/trace\"\n\n// Execution tracing\nfunc main() {\n    f, err := os.Create(\"trace.out\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer f.Close()\n    \n    err = trace.Start(f)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer trace.Stop()\n    \n    // Your application\n    runApplication()\n}\n\n// Analyze: go tool trace trace.out\n\n// Custom trace regions\nfunc processRequest(ctx context.Context) {\n    defer trace.StartRegion(ctx, \"processRequest\").End()\n    \n    trace.WithRegion(ctx, \"validate\", func() {\n        validateInput()\n    })\n    \n    trace.WithRegion(ctx, \"compute\", func() {\n        computeResult()\n    })\n    \n    trace.WithRegion(ctx, \"respond\", func() {\n        sendResponse()\n    })\n}\n\n// Trace logging\nfunc traceLog(ctx context.Context, message string) {\n    trace.Log(ctx, \"app\", message)\n}\n```\n\n## Benchmarking\n\n### Advanced Benchmarking\n```go\n// Benchmark with different inputs\nfunc BenchmarkSort(b *testing.B) {\n    sizes := []int{10, 100, 1000, 10000}\n    \n    for _, size := range sizes {\n        b.Run(fmt.Sprintf(\"size-%d\", size), func(b *testing.B) {\n            data := generateRandomSlice(size)\n            \n            b.ResetTimer()\n            for i := 0; i < b.N; i++ {\n                b.StopTimer()\n                tmp := make([]int, len(data))\n                copy(tmp, data)\n                b.StartTimer()\n                \n                sort.Ints(tmp)\n            }\n        })\n    }\n}\n\n// Comparative benchmarks\nfunc BenchmarkStringBuilding(b *testing.B) {\n    strs := []string{\"hello\", \"world\", \"foo\", \"bar\", \"baz\"}\n    \n    b.Run(\"Concatenation\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var result string\n            for _, s := range strs {\n                result += s\n            }\n        }\n    })\n    \n    b.Run(\"StringBuilder\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var builder strings.Builder\n            for _, s := range strs {\n                builder.WriteString(s)\n            }\n            _ = builder.String()\n        }\n    })\n    \n    b.Run(\"BytesBuffer\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            var buffer bytes.Buffer\n            for _, s := range strs {\n                buffer.WriteString(s)\n            }\n            _ = buffer.String()\n        }\n    })\n    \n    b.Run(\"Join\", func(b *testing.B) {\n        for i := 0; i < b.N; i++ {\n            _ = strings.Join(strs, \"\")\n        }\n    })\n}\n\n// Memory benchmarks\nfunc BenchmarkMemory(b *testing.B) {\n    b.Run(\"WithAllocation\", func(b *testing.B) {\n        b.ReportAllocs()\n        for i := 0; i < b.N; i++ {\n            s := make([]int, 1000)\n            _ = s\n        }\n    })\n    \n    b.Run(\"WithPool\", func(b *testing.B) {\n        b.ReportAllocs()\n        pool := sync.Pool{\n            New: func() interface{} {\n                return make([]int, 1000)\n            },\n        }\n        \n        for i := 0; i < b.N; i++ {\n            s := pool.Get().([]int)\n            pool.Put(s)\n        }\n    })\n}\n\n// Custom metrics\nfunc BenchmarkThroughput(b *testing.B) {\n    data := make([]byte, 1024*1024) // 1MB\n    \n    b.SetBytes(int64(len(data)))\n    b.ResetTimer()\n    \n    for i := 0; i < b.N; i++ {\n        process(data)\n    }\n    \n    b.ReportMetric(float64(b.N)*float64(len(data))/b.Elapsed().Seconds()/1024/1024, \"MB/s\")\n}\n```\n\n## Memory Management\n\n### Reducing Allocations\n```go\n// Avoid allocations in loops\n// Bad: Allocates in loop\nfunc bad() []string {\n    var results []string\n    for i := 0; i < 1000; i++ {\n        results = append(results, fmt.Sprintf(\"item-%d\", i))\n    }\n    return results\n}\n\n// Good: Preallocate\nfunc good() []string {\n    results := make([]string, 0, 1000)\n    for i := 0; i < 1000; i++ {\n        results = append(results, fmt.Sprintf(\"item-%d\", i))\n    }\n    return results\n}\n\n// Reuse buffers\nvar bufferPool = sync.Pool{\n    New: func() interface{} {\n        return new(bytes.Buffer)\n    },\n}\n\nfunc processWithPool(data []byte) string {\n    buf := bufferPool.Get().(*bytes.Buffer)\n    defer func() {\n        buf.Reset()\n        bufferPool.Put(buf)\n    }()\n    \n    buf.Write(data)\n    // Process...\n    return buf.String()\n}\n\n// Avoid string allocations\nfunc avoidStringAllocs(b []byte) string {\n    // Bad: Multiple allocations\n    s := string(b)\n    s = strings.ToUpper(s)\n    s = strings.TrimSpace(s)\n    \n    // Better: Work with bytes\n    b = bytes.ToUpper(b)\n    b = bytes.TrimSpace(b)\n    return string(b)\n}\n\n// String interning for repeated strings\ntype StringInterner struct {\n    mu    sync.RWMutex\n    cache map[string]string\n}\n\nfunc (si *StringInterner) Intern(s string) string {\n    si.mu.RLock()\n    if interned, ok := si.cache[s]; ok {\n        si.mu.RUnlock()\n        return interned\n    }\n    si.mu.RUnlock()\n    \n    si.mu.Lock()\n    defer si.mu.Unlock()\n    \n    si.cache[s] = s\n    return s\n}\n```\n\n### Memory Layout Optimization\n```go\n// Struct field alignment\n// Bad: 32 bytes due to padding\ntype Inefficient struct {\n    a bool    // 1 byte + 7 padding\n    b int64   // 8 bytes\n    c bool    // 1 byte + 7 padding\n    d int64   // 8 bytes\n}\n\n// Good: 24 bytes with better alignment\ntype Efficient struct {\n    b int64   // 8 bytes\n    d int64   // 8 bytes\n    a bool    // 1 byte\n    c bool    // 1 byte + 6 padding\n}\n\n// Use smaller types when possible\ntype Flags struct {\n    // Bad: 4 bools = potentially 4 bytes + padding\n    IsActive   bool\n    IsVerified bool\n    IsPremium  bool\n    IsAdmin    bool\n}\n\n// Good: 1 byte using bit flags\ntype CompactFlags uint8\n\nconst (\n    FlagActive CompactFlags = 1 << iota\n    FlagVerified\n    FlagPremium\n    FlagAdmin\n)\n\nfunc (f CompactFlags) IsActive() bool { return f&FlagActive != 0 }\nfunc (f CompactFlags) IsVerified() bool { return f&FlagVerified != 0 }\n\n// Array vs slice for fixed size\ntype Record struct {\n    // Bad: slice has 24 bytes overhead (pointer, len, cap)\n    IDSlice []byte\n    \n    // Good: array for fixed size, no overhead\n    IDArray [16]byte\n}\n```\n\n### Escape Analysis\n```go\n// Understanding escape analysis\n// go build -gcflags=\"-m\" to see escape analysis\n\n// Doesn't escape - allocated on stack\nfunc noEscape() int {\n    x := 42\n    return x\n}\n\n// Escapes to heap - returned pointer\nfunc escapes() *int {\n    x := 42\n    return &x // x escapes to heap\n}\n\n// Avoid unnecessary escapes\ntype Data struct {\n    values [1000]int\n}\n\n// Bad: Escapes to heap\nfunc (d *Data) Sum() int {\n    sum := 0\n    for _, v := range d.values { // d.values escapes\n        sum += v\n    }\n    return sum\n}\n\n// Good: Doesn't escape\nfunc (d Data) SumValue() int {\n    sum := 0\n    for i := 0; i < len(d.values); i++ {\n        sum += d.values[i]\n    }\n    return sum\n}\n\n// Interface causes escape\nfunc processInterface(i interface{}) {\n    // i escapes to heap\n}\n\nfunc avoidEscape() {\n    x := 42\n    processInterface(x) // x escapes\n    \n    // Avoid by not using interface\n    processInt(x) // x doesn't escape\n}\n\nfunc processInt(i int) {\n    // Process int directly\n}\n```\n\n## CPU Optimization\n\n### Hot Path Optimization\n```go\n// Optimize hot paths\nfunc processData(data []int) int {\n    // Move invariants out of loop\n    length := len(data)\n    if length == 0 {\n        return 0\n    }\n    \n    sum := 0\n    // Unroll loop for better performance\n    for i := 0; i < length-3; i += 4 {\n        sum += data[i] + data[i+1] + data[i+2] + data[i+3]\n    }\n    \n    // Handle remaining elements\n    for i := length - length%4; i < length; i++ {\n        sum += data[i]\n    }\n    \n    return sum\n}\n\n// Branch prediction optimization\nfunc findMax(data []int) int {\n    if len(data) == 0 {\n        return 0\n    }\n    \n    max := data[0]\n    for i := 1; i < len(data); i++ {\n        // Branchless max (may be faster)\n        if data[i] > max {\n            max = data[i]\n        }\n    }\n    return max\n}\n\n// Cache-friendly iteration\nfunc sumMatrix(matrix [][]int) int {\n    sum := 0\n    // Row-major order (cache-friendly)\n    for i := 0; i < len(matrix); i++ {\n        for j := 0; j < len(matrix[i]); j++ {\n            sum += matrix[i][j]\n        }\n    }\n    return sum\n}\n\n// SIMD-friendly code\nfunc addSlices(a, b []float64) []float64 {\n    result := make([]float64, len(a))\n    \n    // Compiler may vectorize this\n    for i := range a {\n        result[i] = a[i] + b[i]\n    }\n    \n    return result\n}\n```\n\n### Inlining\n```go\n// Encourage inlining for small functions\n//go:inline\nfunc add(a, b int) int {\n    return a + b\n}\n\n// Prevent inlining for rarely used functions\n//go:noinline\nfunc rarelyUsedFunction() {\n    // Complex logic\n}\n\n// Check inlining decisions\n// go build -gcflags=\"-m=2\"\n\n// Inline-friendly functions\nfunc abs(x int) int {\n    if x < 0 {\n        return -x\n    }\n    return x\n}\n\n// Too complex to inline (default threshold ~80 nodes)\nfunc complexFunction(x int) int {\n    // Many operations...\n    return result\n}\n```\n\n## Compiler Optimizations\n\n### Compiler Directives\n```go\n// Bounds check elimination\nfunc sumArray(arr []int) int {\n    if len(arr) == 0 {\n        return 0\n    }\n    \n    sum := 0\n    // Compiler can eliminate bounds checks\n    for i := 0; i < len(arr); i++ {\n        sum += arr[i]\n    }\n    return sum\n}\n\n// Help compiler with hints\nfunc process(data []byte) {\n    // Tell compiler minimum length\n    _ = data[3] // Bounds check once\n    \n    // Now these don't need bounds checks\n    a := data[0]\n    b := data[1]\n    c := data[2]\n    d := data[3]\n    \n    // Process a, b, c, d\n}\n\n// Const propagation\nconst bufferSize = 1024\n\nfunc allocateBuffer() []byte {\n    // Compiler knows size at compile time\n    return make([]byte, bufferSize)\n}\n\n// Dead code elimination\nfunc example(debug bool) {\n    if false { // Compiler removes this\n        expensiveDebugOperation()\n    }\n    \n    const debugMode = false\n    if debugMode { // Also removed\n        fmt.Println(\"Debug mode\")\n    }\n}\n```\n\n### Build Flags\n```go\n// Build tags for optimization\n//go:build !debug\n\npackage main\n\nfunc log(msg string) {\n    // No-op in release builds\n}\n\n// Alternative file for debug builds\n//go:build debug\n\npackage main\n\nfunc log(msg string) {\n    fmt.Println(msg)\n}\n\n// Compile with optimizations\n// go build -ldflags=\"-s -w\" # Strip debug info\n// go build -tags release\n// GOOS=linux GOARCH=amd64 go build # Cross-compile\n```\n\n## Caching Strategies\n\n### In-Memory Caching\n```go\n// Simple cache with TTL\ntype Cache struct {\n    mu      sync.RWMutex\n    items   map[string]*cacheItem\n    ttl     time.Duration\n}\n\ntype cacheItem struct {\n    value      interface{}\n    expiration time.Time\n}\n\nfunc NewCache(ttl time.Duration) *Cache {\n    c := &Cache{\n        items: make(map[string]*cacheItem),\n        ttl:   ttl,\n    }\n    go c.cleanup()\n    return c\n}\n\nfunc (c *Cache) Set(key string, value interface{}) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    c.items[key] = &cacheItem{\n        value:      value,\n        expiration: time.Now().Add(c.ttl),\n    }\n}\n\nfunc (c *Cache) Get(key string) (interface{}, bool) {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    \n    item, found := c.items[key]\n    if !found {\n        return nil, false\n    }\n    \n    if time.Now().After(item.expiration) {\n        return nil, false\n    }\n    \n    return item.value, true\n}\n\nfunc (c *Cache) cleanup() {\n    ticker := time.NewTicker(c.ttl / 2)\n    defer ticker.Stop()\n    \n    for range ticker.C {\n        c.mu.Lock()\n        now := time.Now()\n        for key, item := range c.items {\n            if now.After(item.expiration) {\n                delete(c.items, key)\n            }\n        }\n        c.mu.Unlock()\n    }\n}\n\n// LRU Cache\ntype LRUCache struct {\n    capacity int\n    items    map[string]*list.Element\n    order    *list.List\n    mu       sync.Mutex\n}\n\ntype lruItem struct {\n    key   string\n    value interface{}\n}\n\nfunc NewLRUCache(capacity int) *LRUCache {\n    return &LRUCache{\n        capacity: capacity,\n        items:    make(map[string]*list.Element),\n        order:    list.New(),\n    }\n}\n\nfunc (c *LRUCache) Get(key string) (interface{}, bool) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    if elem, ok := c.items[key]; ok {\n        c.order.MoveToFront(elem)\n        return elem.Value.(*lruItem).value, true\n    }\n    return nil, false\n}\n\nfunc (c *LRUCache) Set(key string, value interface{}) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    \n    if elem, ok := c.items[key]; ok {\n        c.order.MoveToFront(elem)\n        elem.Value.(*lruItem).value = value\n        return\n    }\n    \n    if c.order.Len() >= c.capacity {\n        oldest := c.order.Back()\n        if oldest != nil {\n            c.order.Remove(oldest)\n            delete(c.items, oldest.Value.(*lruItem).key)\n        }\n    }\n    \n    item := &lruItem{key: key, value: value}\n    elem := c.order.PushFront(item)\n    c.items[key] = elem\n}\n```\n\n### Memoization\n```go\n// Function memoization\ntype Memoizer struct {\n    mu    sync.RWMutex\n    cache map[string]interface{}\n    fn    func(string) interface{}\n}\n\nfunc NewMemoizer(fn func(string) interface{}) *Memoizer {\n    return &Memoizer{\n        cache: make(map[string]interface{}),\n        fn:    fn,\n    }\n}\n\nfunc (m *Memoizer) Get(key string) interface{} {\n    m.mu.RLock()\n    if val, ok := m.cache[key]; ok {\n        m.mu.RUnlock()\n        return val\n    }\n    m.mu.RUnlock()\n    \n    m.mu.Lock()\n    defer m.mu.Unlock()\n    \n    // Double-check\n    if val, ok := m.cache[key]; ok {\n        return val\n    }\n    \n    val := m.fn(key)\n    m.cache[key] = val\n    return val\n}\n\n// Concurrent-safe memoization with singleflight\nimport \"golang.org/x/sync/singleflight\"\n\ntype ConcurrentMemoizer struct {\n    cache map[string]interface{}\n    mu    sync.RWMutex\n    group singleflight.Group\n}\n\nfunc (m *ConcurrentMemoizer) Get(key string) (interface{}, error) {\n    m.mu.RLock()\n    if val, ok := m.cache[key]; ok {\n        m.mu.RUnlock()\n        return val, nil\n    }\n    m.mu.RUnlock()\n    \n    // Ensure only one goroutine computes the value\n    val, err, _ := m.group.Do(key, func() (interface{}, error) {\n        result := expensiveComputation(key)\n        \n        m.mu.Lock()\n        m.cache[key] = result\n        m.mu.Unlock()\n        \n        return result, nil\n    })\n    \n    return val, err\n}\n```\n\n## Concurrency Performance\n\n### Goroutine Pool\n```go\n// Efficient goroutine pool\ntype WorkerPool struct {\n    workers   int\n    jobQueue  chan Job\n    results   chan Result\n    wg        sync.WaitGroup\n}\n\nfunc NewWorkerPool(workers int, queueSize int) *WorkerPool {\n    return &WorkerPool{\n        workers:  workers,\n        jobQueue: make(chan Job, queueSize),\n        results:  make(chan Result, queueSize),\n    }\n}\n\nfunc (p *WorkerPool) Start() {\n    for i := 0; i < p.workers; i++ {\n        p.wg.Add(1)\n        go p.worker(i)\n    }\n}\n\nfunc (p *WorkerPool) worker(id int) {\n    defer p.wg.Done()\n    \n    for job := range p.jobQueue {\n        result := processJob(job)\n        p.results <- result\n    }\n}\n\nfunc (p *WorkerPool) Submit(job Job) {\n    p.jobQueue <- job\n}\n\nfunc (p *WorkerPool) Stop() {\n    close(p.jobQueue)\n    p.wg.Wait()\n    close(p.results)\n}\n\n// Lock-free structures\ntype LockFreeStack struct {\n    head atomic.Pointer[node]\n}\n\ntype node struct {\n    value interface{}\n    next  *node\n}\n\nfunc (s *LockFreeStack) Push(v interface{}) {\n    n := &node{value: v}\n    for {\n        head := s.head.Load()\n        n.next = head\n        if s.head.CompareAndSwap(head, n) {\n            return\n        }\n    }\n}\n\nfunc (s *LockFreeStack) Pop() interface{} {\n    for {\n        head := s.head.Load()\n        if head == nil {\n            return nil\n        }\n        if s.head.CompareAndSwap(head, head.next) {\n            return head.value\n        }\n    }\n}\n```\n\n### Channel Optimization\n```go\n// Buffered channels for performance\nfunc efficientPipeline() {\n    // Use buffered channels to reduce blocking\n    input := make(chan int, 100)\n    output := make(chan int, 100)\n    \n    // Producer\n    go func() {\n        defer close(input)\n        for i := 0; i < 1000; i++ {\n            input <- i\n        }\n    }()\n    \n    // Workers\n    var wg sync.WaitGroup\n    for i := 0; i < 10; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for val := range input {\n                output <- process(val)\n            }\n        }()\n    }\n    \n    // Close output when workers done\n    go func() {\n        wg.Wait()\n        close(output)\n    }()\n    \n    // Consumer\n    for result := range output {\n        handleResult(result)\n    }\n}\n\n// Batch processing for efficiency\nfunc batchProcessor(input <-chan Item) {\n    batch := make([]Item, 0, 100)\n    ticker := time.NewTicker(100 * time.Millisecond)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case item, ok := <-input:\n            if !ok {\n                if len(batch) > 0 {\n                    processBatch(batch)\n                }\n                return\n            }\n            batch = append(batch, item)\n            \n            if len(batch) >= 100 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n            \n        case <-ticker.C:\n            if len(batch) > 0 {\n                processBatch(batch)\n                batch = batch[:0]\n            }\n        }\n    }\n}\n```\n\n## I/O Optimization\n\n### Buffered I/O\n```go\n// Use buffered I/O\nfunc efficientFileRead(filename string) error {\n    file, err := os.Open(filename)\n    if err != nil {\n        return err\n    }\n    defer file.Close()\n    \n    // Use buffered reader\n    reader := bufio.NewReader(file)\n    \n    for {\n        line, err := reader.ReadString('\\n')\n        if err == io.EOF {\n            break\n        }\n        if err != nil {\n            return err\n        }\n        \n        processLine(line)\n    }\n    \n    return nil\n}\n\n// Efficient file writing\nfunc efficientFileWrite(filename string, data []string) error {\n    file, err := os.Create(filename)\n    if err != nil {\n        return err\n    }\n    defer file.Close()\n    \n    // Use buffered writer\n    writer := bufio.NewWriter(file)\n    defer writer.Flush()\n    \n    for _, line := range data {\n        _, err := writer.WriteString(line + \"\\n\")\n        if err != nil {\n            return err\n        }\n    }\n    \n    return nil\n}\n\n// Memory-mapped files for large files\nimport \"golang.org/x/exp/mmap\"\n\nfunc readLargeFile(filename string) error {\n    reader, err := mmap.Open(filename)\n    if err != nil {\n        return err\n    }\n    defer reader.Close()\n    \n    // Read without loading entire file into memory\n    data := make([]byte, 1024)\n    for offset := int64(0); offset < reader.Len(); offset += 1024 {\n        n, err := reader.ReadAt(data, offset)\n        if err != nil && err != io.EOF {\n            return err\n        }\n        \n        processChunk(data[:n])\n    }\n    \n    return nil\n}\n```\n\n### Network I/O\n```go\n// Connection pooling\ntype ConnectionPool struct {\n    connections chan net.Conn\n    factory     func() (net.Conn, error)\n}\n\nfunc NewConnectionPool(size int, factory func() (net.Conn, error)) (*ConnectionPool, error) {\n    pool := &ConnectionPool{\n        connections: make(chan net.Conn, size),\n        factory:     factory,\n    }\n    \n    for i := 0; i < size; i++ {\n        conn, err := factory()\n        if err != nil {\n            return nil, err\n        }\n        pool.connections <- conn\n    }\n    \n    return pool, nil\n}\n\nfunc (p *ConnectionPool) Get() net.Conn {\n    return <-p.connections\n}\n\nfunc (p *ConnectionPool) Put(conn net.Conn) {\n    p.connections <- conn\n}\n\n// HTTP client optimization\nvar httpClient = &http.Client{\n    Timeout: 30 * time.Second,\n    Transport: &http.Transport{\n        MaxIdleConns:        100,\n        MaxIdleConnsPerHost: 10,\n        IdleConnTimeout:     90 * time.Second,\n        DisableCompression:  false,\n        DisableKeepAlives:   false,\n    },\n}\n\n// Batch HTTP requests\nfunc batchHTTPRequests(urls []string) []Response {\n    results := make([]Response, len(urls))\n    var wg sync.WaitGroup\n    \n    // Limit concurrent requests\n    sem := make(chan struct{}, 10)\n    \n    for i, url := range urls {\n        wg.Add(1)\n        go func(idx int, u string) {\n            defer wg.Done()\n            \n            sem <- struct{}{}\n            defer func() { <-sem }()\n            \n            resp, err := httpClient.Get(u)\n            if err != nil {\n                results[idx] = Response{Error: err}\n                return\n            }\n            defer resp.Body.Close()\n            \n            body, _ := io.ReadAll(resp.Body)\n            results[idx] = Response{Data: body}\n        }(i, url)\n    }\n    \n    wg.Wait()\n    return results\n}\n```\n\n## Data Structure Optimization\n\n### Slice Optimization\n```go\n// Preallocate slices\nfunc optimizedSliceOperations() {\n    // Know the capacity\n    slice := make([]int, 0, 1000)\n    \n    // Grow efficiently\n    if cap(slice) < requiredSize {\n        newSlice := make([]int, len(slice), requiredSize*2)\n        copy(newSlice, slice)\n        slice = newSlice\n    }\n    \n    // Clear slice for reuse\n    slice = slice[:0]\n    \n    // Remove element efficiently\n    func removeAt(s []int, i int) []int {\n        s[i] = s[len(s)-1]\n        return s[:len(s)-1]\n    }\n}\n\n// Custom growing strategy\ntype GrowableBuffer struct {\n    data []byte\n}\n\nfunc (b *GrowableBuffer) grow(n int) {\n    if cap(b.data)-len(b.data) < n {\n        newCap := cap(b.data) * 2\n        if newCap < len(b.data)+n {\n            newCap = len(b.data) + n\n        }\n        newData := make([]byte, len(b.data), newCap)\n        copy(newData, b.data)\n        b.data = newData\n    }\n}\n```\n\n### Map Optimization\n```go\n// Preallocate maps\nm := make(map[string]int, 1000)\n\n// Use appropriate key types\n// Faster: int keys\nfastMap := make(map[int]string)\n\n// Slower: string keys (requires hashing)\nslowMap := make(map[string]string)\n\n// Custom hash map for specific use case\ntype FastStringMap struct {\n    buckets [][]entry\n    size    int\n}\n\ntype entry struct {\n    key   string\n    value interface{}\n}\n\nfunc (m *FastStringMap) hash(key string) uint32 {\n    // Fast hash function\n    h := uint32(2166136261)\n    for i := 0; i < len(key); i++ {\n        h *= 16777619\n        h ^= uint32(key[i])\n    }\n    return h\n}\n\nfunc (m *FastStringMap) Get(key string) (interface{}, bool) {\n    h := m.hash(key) % uint32(len(m.buckets))\n    bucket := m.buckets[h]\n    \n    for _, e := range bucket {\n        if e.key == key {\n            return e.value, true\n        }\n    }\n    return nil, false\n}\n```\n\n### String Optimization\n```go\n// String concatenation optimization\nfunc efficientStringConcat(strs []string) string {\n    // Calculate total length\n    var totalLen int\n    for _, s := range strs {\n        totalLen += len(s)\n    }\n    \n    // Preallocate builder\n    var builder strings.Builder\n    builder.Grow(totalLen)\n    \n    for _, s := range strs {\n        builder.WriteString(s)\n    }\n    \n    return builder.String()\n}\n\n// String/Byte Conversion\n// WARNING: The unsafe package bypasses Go's type safety and memory safety.\n// Only use these patterns if you fully understand the implications.\n\n// DANGEROUS: Zero-copy conversions (USE WITH EXTREME CAUTION)\n// These can cause segmentation faults, data corruption, and crashes.\n// Only use when:\n// 1. Performance is absolutely critical\n// 2. You can guarantee the underlying data won't be modified\n// 3. You've profiled and proven this is a bottleneck\n\n// Example of the DANGEROUS approach (NOT RECOMMENDED):\n// func unsafeStringToBytes(s string) []byte {\n//     // NEVER modify the returned byte slice!\n//     return unsafe.Slice(unsafe.StringData(s), len(s))\n// }\n\n// SAFE approach (RECOMMENDED):\nfunc safeStringToBytes(s string) []byte {\n    // Creates a copy - safe but allocates\n    return []byte(s)\n}\n\nfunc safeBytesToString(b []byte) string {\n    // Creates a copy - safe but allocates\n    return string(b)\n}\n\n// For performance-critical paths, use builders:\nfunc efficientStringBuilding(parts []string) string {\n    var b strings.Builder\n    b.Grow(calculateTotalLen(parts))\n    for _, s := range parts {\n        b.WriteString(s)\n    }\n    return b.String()\n}\n```\n\n## Performance Best Practices\n\n### Measurement and Profiling\n```go\n// Always measure before optimizing\nfunc measurePerformance() {\n    start := time.Now()\n    defer func() {\n        elapsed := time.Since(start)\n        log.Printf(\"Operation took %v\", elapsed)\n    }()\n    \n    // Operation to measure\n}\n\n// Use benchmarks for micro-optimizations\nfunc BenchmarkOptimization(b *testing.B) {\n    // Test different approaches\n}\n\n// Profile in production\nimport _ \"net/http/pprof\"\n// Access profiles at /debug/pprof/\n```\n\n### Common Optimizations\n```go\n// 1. Avoid premature optimization\n// Profile first, optimize bottlenecks\n\n// 2. Reduce allocations\n// Use sync.Pool, preallocate slices\n\n// 3. Optimize hot paths\n// Focus on frequently executed code\n\n// 4. Use efficient algorithms\n// O(n) vs O(n²) matters at scale\n\n// 5. Cache computed values\n// Memoization, lookup tables\n\n// 6. Batch operations\n// Reduce system calls, network requests\n\n// 7. Use appropriate data structures\n// Map vs slice, array vs slice\n\n// 8. Leverage concurrency wisely\n// Don't overuse goroutines\n\n// 9. Minimize interface conversions\n// Interfaces cause allocations\n\n// 10. Profile regularly\n// Performance can degrade over time\n```\n\n## Best Practices Summary\n\n1. **Profile before optimizing** - Measure, don't guess\n2. **Focus on algorithms first** - Better algorithm beats micro-optimizations\n3. **Reduce allocations** - Use pools, preallocate, reuse\n4. **Optimize hot paths** - 80/20 rule applies\n5. **Cache aggressively** - But invalidate correctly\n6. **Use buffered I/O** - For file and network operations\n7. **Batch operations** - Amortize overhead\n8. **Choose right data structures** - Map vs slice matters\n9. **Leverage compiler optimizations** - Write optimizer-friendly code\n10. **Monitor production performance** - Use pprof, metrics, tracing","numLines":1422,"startLine":1,"totalLines":1422}}}
{"parentUuid":"33348885-c8d9-46a1-9cbb-8dcf3e3d4495","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01HTuyEZqKEUs9R2o81KhgVK","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Now let me examine the actual codebase to compare it against the documented patterns and identify any gaps."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":90353,"cache_read_input_tokens":78740,"output_tokens":121,"service_tier":"standard"}},"requestId":"req_011CS5YtowZxpGVGJdapTVpy","type":"assistant","uuid":"8d5efdaf-b14b-4a32-a0df-a2ab432e10f7","timestamp":"2025-08-13T10:28:08.184Z"}
{"parentUuid":"8d5efdaf-b14b-4a32-a0df-a2ab432e10f7","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01HTuyEZqKEUs9R2o81KhgVK","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01XC537ZCy8gNXkKdCdaJK6T","name":"Bash","input":{"command":"find /home/aural/Code/bigmeanie -name \"*.go\" | head -20","description":"Find Go files to understand actual codebase structure"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":90353,"cache_read_input_tokens":78740,"output_tokens":121,"service_tier":"standard"}},"requestId":"req_011CS5YtowZxpGVGJdapTVpy","type":"assistant","uuid":"371710f3-3912-4253-bd28-d0ceffed2cfa","timestamp":"2025-08-13T10:28:09.937Z"}
{"parentUuid":"371710f3-3912-4253-bd28-d0ceffed2cfa","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XC537ZCy8gNXkKdCdaJK6T","type":"tool_result","content":"/home/aural/Code/bigmeanie/back/pkg/clock/mock.go\n/home/aural/Code/bigmeanie/back/pkg/clock/clock.go\n/home/aural/Code/bigmeanie/back/pkg/clock/clock_test.go\n/home/aural/Code/bigmeanie/back/pkg/errors/errors_test.go\n/home/aural/Code/bigmeanie/back/pkg/errors/errors.go\n/home/aural/Code/bigmeanie/back/pkg/decimal_math/decimal_math.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/mfi.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/vroc.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/rsi.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/vol_ma_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/obv.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/vwap_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/rsi_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/cmf.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/atr_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/vroc_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/obv_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/sr_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/mfi_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/cmf_test.go","is_error":false}]},"uuid":"5f9f9220-a081-4bdf-86f3-2c528f9cc665","timestamp":"2025-08-13T10:28:10.007Z","toolUseResult":{"stdout":"/home/aural/Code/bigmeanie/back/pkg/clock/mock.go\n/home/aural/Code/bigmeanie/back/pkg/clock/clock.go\n/home/aural/Code/bigmeanie/back/pkg/clock/clock_test.go\n/home/aural/Code/bigmeanie/back/pkg/errors/errors_test.go\n/home/aural/Code/bigmeanie/back/pkg/errors/errors.go\n/home/aural/Code/bigmeanie/back/pkg/decimal_math/decimal_math.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/mfi.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/vroc.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/rsi.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/vol_ma_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/obv.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/vwap_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/rsi_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/cmf.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/atr_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/vroc_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/obv_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/sr_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/mfi_test.go\n/home/aural/Code/bigmeanie/back/pkg/indicators/common/cmf_test.go","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"5f9f9220-a081-4bdf-86f3-2c528f9cc665","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01ARx6LKQMxtjFXkqLdyyCiK","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"I'll continue the documentation review by examining the actual codebase to compare implementation patterns against the documented practices. Let me start by reading the actual Go code files in the `/back/pkg/` directory."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":32030,"cache_read_input_tokens":30920,"output_tokens":116,"service_tier":"standard"}},"requestId":"req_011CS5YxZmQ5J9sZSrBisjiV","type":"assistant","uuid":"ecff6913-e1cb-4673-a0cd-db07628bf338","timestamp":"2025-08-13T10:28:58.204Z"}
{"parentUuid":"ecff6913-e1cb-4673-a0cd-db07628bf338","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01ARx6LKQMxtjFXkqLdyyCiK","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01CoXi7mMVXvQ4rvxon4BTZu","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/errors/errors.go"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":32030,"cache_read_input_tokens":30920,"output_tokens":116,"service_tier":"standard"}},"requestId":"req_011CS5YxZmQ5J9sZSrBisjiV","type":"assistant","uuid":"6703fccc-2a13-4cfe-bbb8-9ad7cfeb6160","timestamp":"2025-08-13T10:28:58.511Z"}
{"parentUuid":"6703fccc-2a13-4cfe-bbb8-9ad7cfeb6160","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CoXi7mMVXvQ4rvxon4BTZu","type":"tool_result","content":"     1→// Package errors provides a structured error handling framework for the BigMeanie trading system.\n     2→// It extends Go's standard error handling with trading-specific context, error categorization,\n     3→// and stack trace capture for better debugging and operational visibility.\n     4→package errors\n     5→\n     6→import (\n     7→\t\"errors\"\n     8→\t\"fmt\"\n     9→\t\"runtime\"\n    10→\t\"strings\"\n    11→)\n    12→\n    13→// ErrorType categorizes errors for proper handling and retry logic\n    14→type ErrorType int\n    15→\n    16→const (\n    17→\t// ErrTypeUnknown is for uncategorized errors\n    18→\tErrTypeUnknown ErrorType = iota\n    19→\n    20→\t// ErrTypeRetryable indicates the operation can be retried\n    21→\tErrTypeRetryable\n    22→\n    23→\t// ErrTypeFatal indicates a non-recoverable error requiring immediate attention\n    24→\tErrTypeFatal\n    25→\n    26→\t// ErrTypeValidation indicates input validation failure\n    27→\tErrTypeValidation\n    28→\n    29→\t// ErrTypeConfiguration indicates system configuration issues\n    30→\tErrTypeConfiguration\n    31→\n    32→\t// ErrTypeMarket indicates market-related errors (e.g., market closed)\n    33→\tErrTypeMarket\n    34→\n    35→\t// ErrTypeOrder indicates order-specific errors\n    36→\tErrTypeOrder\n    37→\n    38→\t// ErrTypeInsufficientFunds indicates not enough balance\n    39→\tErrTypeInsufficientFunds\n    40→\n    41→\t// ErrTypeRateLimit indicates API rate limit exceeded\n    42→\tErrTypeRateLimit\n    43→\n    44→\t// ErrTypeConnection indicates network/connection issues\n    45→\tErrTypeConnection\n    46→\n    47→\t// ErrTypeAuth indicates authentication/authorization failures\n    48→\tErrTypeAuth\n    49→\n    50→\t// ErrTypeData indicates data integrity or availability issues\n    51→\tErrTypeData\n    52→)\n    53→\n    54→// String returns a human-readable error type\n    55→func (t ErrorType) String() string {\n    56→\tswitch t {\n    57→\tcase ErrTypeUnknown:\n    58→\t\treturn \"Unknown\"\n    59→\tcase ErrTypeRetryable:\n    60→\t\treturn \"Retryable\"\n    61→\tcase ErrTypeFatal:\n    62→\t\treturn \"Fatal\"\n    63→\tcase ErrTypeValidation:\n    64→\t\treturn \"Validation\"\n    65→\tcase ErrTypeConfiguration:\n    66→\t\treturn \"Configuration\"\n    67→\tcase ErrTypeMarket:\n    68→\t\treturn \"Market\"\n    69→\tcase ErrTypeOrder:\n    70→\t\treturn \"Order\"\n    71→\tcase ErrTypeInsufficientFunds:\n    72→\t\treturn \"InsufficientFunds\"\n    73→\tcase ErrTypeRateLimit:\n    74→\t\treturn \"RateLimit\"\n    75→\tcase ErrTypeConnection:\n    76→\t\treturn \"Connection\"\n    77→\tcase ErrTypeAuth:\n    78→\t\treturn \"Authentication\"\n    79→\tcase ErrTypeData:\n    80→\t\treturn \"Data\"\n    81→\tdefault:\n    82→\t\treturn \"Unknown\"\n    83→\t}\n    84→}\n    85→\n    86→// TradingError provides structured error information for the trading system\n    87→type TradingError struct {\n    88→\tType    ErrorType              // Error category\n    89→\tOp      string                 // Operation that failed (e.g., \"OrderExecutor.PlaceOrder\")\n    90→\tSymbol  string                 // Trading symbol if applicable\n    91→\tErr     error                  // Wrapped error\n    92→\tContext map[string]interface{} // Additional context\n    93→\tStack   string                 // Stack trace (only captured for non-retryable errors)\n    94→}\n    95→\n    96→// Error implements the error interface\n    97→func (e *TradingError) Error() string {\n    98→\tvar b strings.Builder\n    99→\tb.WriteString(e.Op)\n   100→\tb.WriteString(\": \")\n   101→\tb.WriteString(e.Type.String())\n   102→\n   103→\tif e.Symbol != \"\" {\n   104→\t\tb.WriteString(\" [\")\n   105→\t\tb.WriteString(e.Symbol)\n   106→\t\tb.WriteString(\"]\")\n   107→\t}\n   108→\n   109→\tif e.Err != nil {\n   110→\t\tb.WriteString(\": \")\n   111→\t\tb.WriteString(e.Err.Error())\n   112→\t}\n   113→\n   114→\treturn b.String()\n   115→}\n   116→\n   117→// Unwrap returns the wrapped error for errors.Is and errors.As\n   118→func (e *TradingError) Unwrap() error {\n   119→\treturn e.Err\n   120→}\n   121→\n   122→// New creates a new trading error\n   123→func New(op string, errType ErrorType, err error) *TradingError {\n   124→\tte := &TradingError{\n   125→\t\tType: errType,\n   126→\t\tOp:   op,\n   127→\t\tErr:  err,\n   128→\t}\n   129→\n   130→\t// Only capture stack for non-retryable errors to reduce overhead\n   131→\tif errType == ErrTypeFatal || errType == ErrTypeConfiguration || errType == ErrTypeAuth {\n   132→\t\tte.Stack = captureStack()\n   133→\t}\n   134→\n   135→\treturn te\n   136→}\n   137→\n   138→// Newf creates a new trading error with formatted message\n   139→func Newf(op string, errType ErrorType, format string, args ...interface{}) *TradingError {\n   140→\treturn New(op, errType, fmt.Errorf(format, args...))\n   141→}\n   142→\n   143→// WithSymbol adds symbol context\n   144→func (e *TradingError) WithSymbol(symbol string) *TradingError {\n   145→\te.Symbol = symbol\n   146→\treturn e\n   147→}\n   148→\n   149→// WithContext adds additional context\n   150→func (e *TradingError) WithContext(key string, value interface{}) *TradingError {\n   151→\tif e.Context == nil {\n   152→\t\te.Context = make(map[string]interface{})\n   153→\t}\n   154→\te.Context[key] = value\n   155→\treturn e\n   156→}\n   157→\n   158→// WithStack forces stack trace capture\n   159→func (e *TradingError) WithStack() *TradingError {\n   160→\tif e.Stack == \"\" {\n   161→\t\te.Stack = captureStack()\n   162→\t}\n   163→\treturn e\n   164→}\n   165→\n   166→// Wrap wraps an existing error with trading context\n   167→func Wrap(op string, errType ErrorType, err error) *TradingError {\n   168→\tif err == nil {\n   169→\t\treturn nil\n   170→\t}\n   171→\n   172→\t// If already a TradingError, preserve the original context\n   173→\tvar te *TradingError\n   174→\tif errors.As(err, &te) {\n   175→\t\t// Create new error that wraps the original\n   176→\t\tnewErr := New(op, errType, err)\n   177→\t\t// Preserve symbol if not set\n   178→\t\tif newErr.Symbol == \"\" && te.Symbol != \"\" {\n   179→\t\t\tnewErr.Symbol = te.Symbol\n   180→\t\t}\n   181→\t\treturn newErr\n   182→\t}\n   183→\n   184→\treturn New(op, errType, err)\n   185→}\n   186→\n   187→// IsType checks if an error is of a specific type\n   188→func IsType(err error, errType ErrorType) bool {\n   189→\tvar te *TradingError\n   190→\tif errors.As(err, &te) {\n   191→\t\treturn te.Type == errType\n   192→\t}\n   193→\treturn false\n   194→}\n   195→\n   196→// IsRetryable checks if error can be retried\n   197→func IsRetryable(err error) bool {\n   198→\tvar te *TradingError\n   199→\tif errors.As(err, &te) {\n   200→\t\tswitch te.Type {\n   201→\t\tcase ErrTypeRetryable, ErrTypeConnection, ErrTypeRateLimit:\n   202→\t\t\treturn true\n   203→\t\tdefault:\n   204→\t\t\treturn false\n   205→\t\t}\n   206→\t}\n   207→\treturn false\n   208→}\n   209→\n   210→// IsFatal checks if error is fatal\n   211→func IsFatal(err error) bool {\n   212→\treturn IsType(err, ErrTypeFatal)\n   213→}\n   214→\n   215→// GetType returns the error type if it's a TradingError\n   216→func GetType(err error) ErrorType {\n   217→\tvar te *TradingError\n   218→\tif errors.As(err, &te) {\n   219→\t\treturn te.Type\n   220→\t}\n   221→\treturn ErrTypeUnknown\n   222→}\n   223→\n   224→// GetContext extracts context from a TradingError\n   225→func GetContext(err error) map[string]interface{} {\n   226→\tvar te *TradingError\n   227→\tif errors.As(err, &te) {\n   228→\t\treturn te.Context\n   229→\t}\n   230→\treturn nil\n   231→}\n   232→\n   233→// captureStack captures the current stack trace\n   234→func captureStack() string {\n   235→\tconst maxStackSize = 4096\n   236→\tbuf := make([]byte, maxStackSize)\n   237→\tn := runtime.Stack(buf, false)\n   238→\n   239→\t// Skip the first few frames to remove error package internals\n   240→\tstack := string(buf[:n])\n   241→\tlines := strings.Split(stack, \"\\n\")\n   242→\n   243→\t// Find where to start (skip runtime and error package frames)\n   244→\tstartIdx := 0\n   245→\tfor i, line := range lines {\n   246→\t\tif strings.Contains(line, \"pkg/errors\") {\n   247→\t\t\tstartIdx = i + 2 // Skip the error package frame\n   248→\t\t\tbreak\n   249→\t\t}\n   250→\t}\n   251→\n   252→\tif startIdx < len(lines) {\n   253→\t\treturn strings.Join(lines[startIdx:], \"\\n\")\n   254→\t}\n   255→\treturn stack\n   256→}\n   257→\n   258→// Is is a convenience wrapper around errors.Is\n   259→func Is(err, target error) bool {\n   260→\treturn errors.Is(err, target)\n   261→}\n   262→\n   263→// As is a convenience wrapper around errors.As\n   264→func As(err error, target interface{}) bool {\n   265→\treturn errors.As(err, target)\n   266→}\n   267→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"27058cf6-5a30-42e1-8a3a-76a99246fb22","timestamp":"2025-08-13T10:28:58.543Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/pkg/errors/errors.go","content":"// Package errors provides a structured error handling framework for the BigMeanie trading system.\n// It extends Go's standard error handling with trading-specific context, error categorization,\n// and stack trace capture for better debugging and operational visibility.\npackage errors\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"runtime\"\n\t\"strings\"\n)\n\n// ErrorType categorizes errors for proper handling and retry logic\ntype ErrorType int\n\nconst (\n\t// ErrTypeUnknown is for uncategorized errors\n\tErrTypeUnknown ErrorType = iota\n\n\t// ErrTypeRetryable indicates the operation can be retried\n\tErrTypeRetryable\n\n\t// ErrTypeFatal indicates a non-recoverable error requiring immediate attention\n\tErrTypeFatal\n\n\t// ErrTypeValidation indicates input validation failure\n\tErrTypeValidation\n\n\t// ErrTypeConfiguration indicates system configuration issues\n\tErrTypeConfiguration\n\n\t// ErrTypeMarket indicates market-related errors (e.g., market closed)\n\tErrTypeMarket\n\n\t// ErrTypeOrder indicates order-specific errors\n\tErrTypeOrder\n\n\t// ErrTypeInsufficientFunds indicates not enough balance\n\tErrTypeInsufficientFunds\n\n\t// ErrTypeRateLimit indicates API rate limit exceeded\n\tErrTypeRateLimit\n\n\t// ErrTypeConnection indicates network/connection issues\n\tErrTypeConnection\n\n\t// ErrTypeAuth indicates authentication/authorization failures\n\tErrTypeAuth\n\n\t// ErrTypeData indicates data integrity or availability issues\n\tErrTypeData\n)\n\n// String returns a human-readable error type\nfunc (t ErrorType) String() string {\n\tswitch t {\n\tcase ErrTypeUnknown:\n\t\treturn \"Unknown\"\n\tcase ErrTypeRetryable:\n\t\treturn \"Retryable\"\n\tcase ErrTypeFatal:\n\t\treturn \"Fatal\"\n\tcase ErrTypeValidation:\n\t\treturn \"Validation\"\n\tcase ErrTypeConfiguration:\n\t\treturn \"Configuration\"\n\tcase ErrTypeMarket:\n\t\treturn \"Market\"\n\tcase ErrTypeOrder:\n\t\treturn \"Order\"\n\tcase ErrTypeInsufficientFunds:\n\t\treturn \"InsufficientFunds\"\n\tcase ErrTypeRateLimit:\n\t\treturn \"RateLimit\"\n\tcase ErrTypeConnection:\n\t\treturn \"Connection\"\n\tcase ErrTypeAuth:\n\t\treturn \"Authentication\"\n\tcase ErrTypeData:\n\t\treturn \"Data\"\n\tdefault:\n\t\treturn \"Unknown\"\n\t}\n}\n\n// TradingError provides structured error information for the trading system\ntype TradingError struct {\n\tType    ErrorType              // Error category\n\tOp      string                 // Operation that failed (e.g., \"OrderExecutor.PlaceOrder\")\n\tSymbol  string                 // Trading symbol if applicable\n\tErr     error                  // Wrapped error\n\tContext map[string]interface{} // Additional context\n\tStack   string                 // Stack trace (only captured for non-retryable errors)\n}\n\n// Error implements the error interface\nfunc (e *TradingError) Error() string {\n\tvar b strings.Builder\n\tb.WriteString(e.Op)\n\tb.WriteString(\": \")\n\tb.WriteString(e.Type.String())\n\n\tif e.Symbol != \"\" {\n\t\tb.WriteString(\" [\")\n\t\tb.WriteString(e.Symbol)\n\t\tb.WriteString(\"]\")\n\t}\n\n\tif e.Err != nil {\n\t\tb.WriteString(\": \")\n\t\tb.WriteString(e.Err.Error())\n\t}\n\n\treturn b.String()\n}\n\n// Unwrap returns the wrapped error for errors.Is and errors.As\nfunc (e *TradingError) Unwrap() error {\n\treturn e.Err\n}\n\n// New creates a new trading error\nfunc New(op string, errType ErrorType, err error) *TradingError {\n\tte := &TradingError{\n\t\tType: errType,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n\n\t// Only capture stack for non-retryable errors to reduce overhead\n\tif errType == ErrTypeFatal || errType == ErrTypeConfiguration || errType == ErrTypeAuth {\n\t\tte.Stack = captureStack()\n\t}\n\n\treturn te\n}\n\n// Newf creates a new trading error with formatted message\nfunc Newf(op string, errType ErrorType, format string, args ...interface{}) *TradingError {\n\treturn New(op, errType, fmt.Errorf(format, args...))\n}\n\n// WithSymbol adds symbol context\nfunc (e *TradingError) WithSymbol(symbol string) *TradingError {\n\te.Symbol = symbol\n\treturn e\n}\n\n// WithContext adds additional context\nfunc (e *TradingError) WithContext(key string, value interface{}) *TradingError {\n\tif e.Context == nil {\n\t\te.Context = make(map[string]interface{})\n\t}\n\te.Context[key] = value\n\treturn e\n}\n\n// WithStack forces stack trace capture\nfunc (e *TradingError) WithStack() *TradingError {\n\tif e.Stack == \"\" {\n\t\te.Stack = captureStack()\n\t}\n\treturn e\n}\n\n// Wrap wraps an existing error with trading context\nfunc Wrap(op string, errType ErrorType, err error) *TradingError {\n\tif err == nil {\n\t\treturn nil\n\t}\n\n\t// If already a TradingError, preserve the original context\n\tvar te *TradingError\n\tif errors.As(err, &te) {\n\t\t// Create new error that wraps the original\n\t\tnewErr := New(op, errType, err)\n\t\t// Preserve symbol if not set\n\t\tif newErr.Symbol == \"\" && te.Symbol != \"\" {\n\t\t\tnewErr.Symbol = te.Symbol\n\t\t}\n\t\treturn newErr\n\t}\n\n\treturn New(op, errType, err)\n}\n\n// IsType checks if an error is of a specific type\nfunc IsType(err error, errType ErrorType) bool {\n\tvar te *TradingError\n\tif errors.As(err, &te) {\n\t\treturn te.Type == errType\n\t}\n\treturn false\n}\n\n// IsRetryable checks if error can be retried\nfunc IsRetryable(err error) bool {\n\tvar te *TradingError\n\tif errors.As(err, &te) {\n\t\tswitch te.Type {\n\t\tcase ErrTypeRetryable, ErrTypeConnection, ErrTypeRateLimit:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\treturn false\n}\n\n// IsFatal checks if error is fatal\nfunc IsFatal(err error) bool {\n\treturn IsType(err, ErrTypeFatal)\n}\n\n// GetType returns the error type if it's a TradingError\nfunc GetType(err error) ErrorType {\n\tvar te *TradingError\n\tif errors.As(err, &te) {\n\t\treturn te.Type\n\t}\n\treturn ErrTypeUnknown\n}\n\n// GetContext extracts context from a TradingError\nfunc GetContext(err error) map[string]interface{} {\n\tvar te *TradingError\n\tif errors.As(err, &te) {\n\t\treturn te.Context\n\t}\n\treturn nil\n}\n\n// captureStack captures the current stack trace\nfunc captureStack() string {\n\tconst maxStackSize = 4096\n\tbuf := make([]byte, maxStackSize)\n\tn := runtime.Stack(buf, false)\n\n\t// Skip the first few frames to remove error package internals\n\tstack := string(buf[:n])\n\tlines := strings.Split(stack, \"\\n\")\n\n\t// Find where to start (skip runtime and error package frames)\n\tstartIdx := 0\n\tfor i, line := range lines {\n\t\tif strings.Contains(line, \"pkg/errors\") {\n\t\t\tstartIdx = i + 2 // Skip the error package frame\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif startIdx < len(lines) {\n\t\treturn strings.Join(lines[startIdx:], \"\\n\")\n\t}\n\treturn stack\n}\n\n// Is is a convenience wrapper around errors.Is\nfunc Is(err, target error) bool {\n\treturn errors.Is(err, target)\n}\n\n// As is a convenience wrapper around errors.As\nfunc As(err error, target interface{}) bool {\n\treturn errors.As(err, target)\n}\n","numLines":267,"startLine":1,"totalLines":267}}}
{"parentUuid":"27058cf6-5a30-42e1-8a3a-76a99246fb22","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01MHsgrkJvqFXSZuxLaPGttL","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_0146NJ2c7AA5BrFetRf2qZCF","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/errors/errors_test.go"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":3086,"cache_read_input_tokens":62950,"output_tokens":75,"service_tier":"standard"}},"requestId":"req_011CS5Yxw4ZidoeGDZGPhrSn","type":"assistant","uuid":"8d45e13b-6f18-4402-8252-1c7f9a4df0b4","timestamp":"2025-08-13T10:29:01.342Z"}
{"parentUuid":"8d45e13b-6f18-4402-8252-1c7f9a4df0b4","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0146NJ2c7AA5BrFetRf2qZCF","type":"tool_result","content":"     1→package errors\n     2→\n     3→import (\n     4→\t\"errors\"\n     5→\t\"fmt\"\n     6→\t\"testing\"\n     7→\n     8→\t\"github.com/stretchr/testify/assert\"\n     9→\t\"github.com/stretchr/testify/require\"\n    10→)\n    11→\n    12→func TestErrorType_String(t *testing.T) {\n    13→\ttests := []struct {\n    14→\t\terrType  ErrorType\n    15→\t\texpected string\n    16→\t}{\n    17→\t\t{ErrTypeUnknown, \"Unknown\"},\n    18→\t\t{ErrTypeRetryable, \"Retryable\"},\n    19→\t\t{ErrTypeFatal, \"Fatal\"},\n    20→\t\t{ErrTypeValidation, \"Validation\"},\n    21→\t\t{ErrTypeConfiguration, \"Configuration\"},\n    22→\t\t{ErrTypeMarket, \"Market\"},\n    23→\t\t{ErrTypeOrder, \"Order\"},\n    24→\t\t{ErrTypeInsufficientFunds, \"InsufficientFunds\"},\n    25→\t\t{ErrTypeRateLimit, \"RateLimit\"},\n    26→\t\t{ErrTypeConnection, \"Connection\"},\n    27→\t\t{ErrTypeAuth, \"Authentication\"},\n    28→\t\t{ErrTypeData, \"Data\"},\n    29→\t\t{ErrorType(999), \"Unknown\"}, // Invalid type\n    30→\t}\n    31→\n    32→\tfor _, tt := range tests {\n    33→\t\tt.Run(tt.expected, func(t *testing.T) {\n    34→\t\t\tassert.Equal(t, tt.expected, tt.errType.String())\n    35→\t\t})\n    36→\t}\n    37→}\n    38→\n    39→func TestNew(t *testing.T) {\n    40→\tbaseErr := errors.New(\"base error\")\n    41→\n    42→\tt.Run(\"basic error creation\", func(t *testing.T) {\n    43→\t\terr := New(\"TestOp\", ErrTypeRetryable, baseErr)\n    44→\n    45→\t\tassert.NotNil(t, err)\n    46→\t\tassert.Equal(t, ErrTypeRetryable, err.Type)\n    47→\t\tassert.Equal(t, \"TestOp\", err.Op)\n    48→\t\tassert.Equal(t, baseErr, err.Err)\n    49→\t\tassert.Empty(t, err.Symbol)\n    50→\t\tassert.Empty(t, err.Context)\n    51→\t\tassert.Empty(t, err.Stack) // Retryable errors don't capture stack by default\n    52→\t})\n    53→\n    54→\tt.Run(\"fatal error captures stack\", func(t *testing.T) {\n    55→\t\terr := New(\"TestOp\", ErrTypeFatal, baseErr)\n    56→\n    57→\t\tassert.NotEmpty(t, err.Stack)\n    58→\t\tassert.Contains(t, err.Stack, \"TestNew\") // Should contain current function\n    59→\t})\n    60→\n    61→\tt.Run(\"auth error captures stack\", func(t *testing.T) {\n    62→\t\terr := New(\"TestOp\", ErrTypeAuth, baseErr)\n    63→\n    64→\t\tassert.NotEmpty(t, err.Stack)\n    65→\t})\n    66→}\n    67→\n    68→func TestNewf(t *testing.T) {\n    69→\terr := Newf(\"TestOp\", ErrTypeValidation, \"invalid value: %d\", 42)\n    70→\n    71→\tassert.NotNil(t, err)\n    72→\tassert.Equal(t, ErrTypeValidation, err.Type)\n    73→\tassert.Equal(t, \"TestOp\", err.Op)\n    74→\tassert.Equal(t, \"invalid value: 42\", err.Err.Error())\n    75→}\n    76→\n    77→func TestTradingError_Error(t *testing.T) {\n    78→\ttests := []struct {\n    79→\t\tname     string\n    80→\t\terr      *TradingError\n    81→\t\texpected string\n    82→\t}{\n    83→\t\t{\n    84→\t\t\tname: \"basic error\",\n    85→\t\t\terr: &TradingError{\n    86→\t\t\t\tType: ErrTypeRetryable,\n    87→\t\t\t\tOp:   \"TestOp\",\n    88→\t\t\t\tErr:  errors.New(\"test error\"),\n    89→\t\t\t},\n    90→\t\t\texpected: \"TestOp: Retryable: test error\",\n    91→\t\t},\n    92→\t\t{\n    93→\t\t\tname: \"error with symbol\",\n    94→\t\t\terr: &TradingError{\n    95→\t\t\t\tType:   ErrTypeOrder,\n    96→\t\t\t\tOp:     \"OrderExecutor.PlaceOrder\",\n    97→\t\t\t\tSymbol: \"BTC-USD\",\n    98→\t\t\t\tErr:    errors.New(\"insufficient balance\"),\n    99→\t\t\t},\n   100→\t\t\texpected: \"OrderExecutor.PlaceOrder: Order [BTC-USD]: insufficient balance\",\n   101→\t\t},\n   102→\t\t{\n   103→\t\t\tname: \"error without wrapped error\",\n   104→\t\t\terr: &TradingError{\n   105→\t\t\t\tType: ErrTypeConfiguration,\n   106→\t\t\t\tOp:   \"Config.Load\",\n   107→\t\t\t},\n   108→\t\t\texpected: \"Config.Load: Configuration\",\n   109→\t\t},\n   110→\t}\n   111→\n   112→\tfor _, tt := range tests {\n   113→\t\tt.Run(tt.name, func(t *testing.T) {\n   114→\t\t\tassert.Equal(t, tt.expected, tt.err.Error())\n   115→\t\t})\n   116→\t}\n   117→}\n   118→\n   119→func TestTradingError_WithMethods(t *testing.T) {\n   120→\terr := New(\"TestOp\", ErrTypeRetryable, errors.New(\"base error\"))\n   121→\n   122→\tt.Run(\"WithSymbol\", func(t *testing.T) {\n   123→\t\terr = err.WithSymbol(\"BTC-USD\")\n   124→\t\tassert.Equal(t, \"BTC-USD\", err.Symbol)\n   125→\t})\n   126→\n   127→\tt.Run(\"WithContext\", func(t *testing.T) {\n   128→\t\terr = err.WithContext(\"orderID\", \"12345\").\n   129→\t\t\tWithContext(\"size\", 0.1)\n   130→\n   131→\t\tassert.Equal(t, \"12345\", err.Context[\"orderID\"])\n   132→\t\tassert.Equal(t, 0.1, err.Context[\"size\"])\n   133→\t})\n   134→\n   135→\tt.Run(\"WithStack\", func(t *testing.T) {\n   136→\t\t// Create error without stack\n   137→\t\terr := New(\"TestOp\", ErrTypeRetryable, nil)\n   138→\t\tassert.Empty(t, err.Stack)\n   139→\n   140→\t\t// Force stack capture\n   141→\t\terr = err.WithStack()\n   142→\t\tassert.NotEmpty(t, err.Stack)\n   143→\t\tassert.Contains(t, err.Stack, \"TestTradingError_WithMethods\")\n   144→\t})\n   145→}\n   146→\n   147→func TestWrap(t *testing.T) {\n   148→\tt.Run(\"wrap nil error returns nil\", func(t *testing.T) {\n   149→\t\terr := Wrap(\"TestOp\", ErrTypeRetryable, nil)\n   150→\t\tassert.Nil(t, err)\n   151→\t})\n   152→\n   153→\tt.Run(\"wrap standard error\", func(t *testing.T) {\n   154→\t\tbaseErr := errors.New(\"base error\")\n   155→\t\terr := Wrap(\"TestOp\", ErrTypeRetryable, baseErr)\n   156→\n   157→\t\tassert.NotNil(t, err)\n   158→\t\tassert.Equal(t, \"TestOp\", err.Op)\n   159→\t\tassert.Equal(t, ErrTypeRetryable, err.Type)\n   160→\t\tassert.Equal(t, baseErr, err.Err)\n   161→\t})\n   162→\n   163→\tt.Run(\"wrap TradingError preserves context\", func(t *testing.T) {\n   164→\t\toriginalErr := New(\"OriginalOp\", ErrTypeOrder, errors.New(\"original error\")).\n   165→\t\t\tWithSymbol(\"BTC-USD\").\n   166→\t\t\tWithContext(\"orderID\", \"12345\")\n   167→\n   168→\t\twrappedErr := Wrap(\"WrapperOp\", ErrTypeRetryable, originalErr)\n   169→\n   170→\t\tassert.Equal(t, \"WrapperOp\", wrappedErr.Op)\n   171→\t\tassert.Equal(t, ErrTypeRetryable, wrappedErr.Type)\n   172→\t\tassert.Equal(t, \"BTC-USD\", wrappedErr.Symbol) // Symbol preserved\n   173→\t\tassert.Equal(t, originalErr, wrappedErr.Err)  // Original error wrapped\n   174→\t})\n   175→}\n   176→\n   177→func TestErrorChecks(t *testing.T) {\n   178→\tt.Run(\"IsType\", func(t *testing.T) {\n   179→\t\terr := New(\"TestOp\", ErrTypeRetryable, nil)\n   180→\t\tassert.True(t, IsType(err, ErrTypeRetryable))\n   181→\t\tassert.False(t, IsType(err, ErrTypeFatal))\n   182→\n   183→\t\t// Test with wrapped error\n   184→\t\twrappedErr := fmt.Errorf(\"wrapped: %w\", err)\n   185→\t\tassert.True(t, IsType(wrappedErr, ErrTypeRetryable))\n   186→\n   187→\t\t// Test with non-TradingError\n   188→\t\tstdErr := errors.New(\"standard error\")\n   189→\t\tassert.False(t, IsType(stdErr, ErrTypeRetryable))\n   190→\t})\n   191→\n   192→\tt.Run(\"IsRetryable\", func(t *testing.T) {\n   193→\t\ttests := []struct {\n   194→\t\t\terrType  ErrorType\n   195→\t\t\texpected bool\n   196→\t\t}{\n   197→\t\t\t{ErrTypeRetryable, true},\n   198→\t\t\t{ErrTypeConnection, true},\n   199→\t\t\t{ErrTypeRateLimit, true},\n   200→\t\t\t{ErrTypeFatal, false},\n   201→\t\t\t{ErrTypeValidation, false},\n   202→\t\t\t{ErrTypeAuth, false},\n   203→\t\t}\n   204→\n   205→\t\tfor _, tt := range tests {\n   206→\t\t\terr := New(\"TestOp\", tt.errType, nil)\n   207→\t\t\tassert.Equal(t, tt.expected, IsRetryable(err))\n   208→\t\t}\n   209→\n   210→\t\t// Test with non-TradingError\n   211→\t\tassert.False(t, IsRetryable(errors.New(\"standard error\")))\n   212→\t})\n   213→\n   214→\tt.Run(\"IsFatal\", func(t *testing.T) {\n   215→\t\tfatalErr := New(\"TestOp\", ErrTypeFatal, nil)\n   216→\t\tassert.True(t, IsFatal(fatalErr))\n   217→\n   218→\t\tnonFatalErr := New(\"TestOp\", ErrTypeRetryable, nil)\n   219→\t\tassert.False(t, IsFatal(nonFatalErr))\n   220→\t})\n   221→\n   222→\tt.Run(\"GetType\", func(t *testing.T) {\n   223→\t\terr := New(\"TestOp\", ErrTypeOrder, nil)\n   224→\t\tassert.Equal(t, ErrTypeOrder, GetType(err))\n   225→\n   226→\t\t// Test with non-TradingError\n   227→\t\tassert.Equal(t, ErrTypeUnknown, GetType(errors.New(\"standard error\")))\n   228→\t})\n   229→\n   230→\tt.Run(\"GetContext\", func(t *testing.T) {\n   231→\t\terr := New(\"TestOp\", ErrTypeOrder, nil).\n   232→\t\t\tWithContext(\"key\", \"value\")\n   233→\n   234→\t\tctx := GetContext(err)\n   235→\t\tassert.Equal(t, \"value\", ctx[\"key\"])\n   236→\n   237→\t\t// Test with non-TradingError\n   238→\t\tassert.Nil(t, GetContext(errors.New(\"standard error\")))\n   239→\t})\n   240→}\n   241→\n   242→func TestErrorChaining(t *testing.T) {\n   243→\tbaseErr := errors.New(\"base error\")\n   244→\ttradingErr := New(\"TestOp\", ErrTypeRetryable, baseErr)\n   245→\twrappedErr := fmt.Errorf(\"wrapped: %w\", tradingErr)\n   246→\n   247→\tt.Run(\"errors.Is\", func(t *testing.T) {\n   248→\t\tassert.True(t, errors.Is(wrappedErr, tradingErr))\n   249→\t\tassert.True(t, errors.Is(wrappedErr, baseErr))\n   250→\t\tassert.True(t, Is(wrappedErr, baseErr))\n   251→\t})\n   252→\n   253→\tt.Run(\"errors.As\", func(t *testing.T) {\n   254→\t\tvar te *TradingError\n   255→\t\tassert.True(t, errors.As(wrappedErr, &te))\n   256→\t\tassert.Equal(t, \"TestOp\", te.Op)\n   257→\n   258→\t\tassert.True(t, As(wrappedErr, &te))\n   259→\t})\n   260→}\n   261→\n   262→func TestStackTraceCapture(t *testing.T) {\n   263→\t// Test that stack trace is captured for fatal errors\n   264→\terr := New(\"TestOp\", ErrTypeFatal, nil)\n   265→\n   266→\trequire.NotEmpty(t, err.Stack)\n   267→\n   268→\t// Should contain test function\n   269→\tassert.Contains(t, err.Stack, \"TestStackTraceCapture\")\n   270→\n   271→\t// Stack should be captured\n   272→\tassert.True(t, len(err.Stack) > 100, \"Stack trace should be substantial\")\n   273→}\n   274→\n   275→func TestConcurrentAccess(t *testing.T) {\n   276→\t// Test that error creation and access is safe for concurrent use\n   277→\tdone := make(chan bool)\n   278→\n   279→\tfor i := 0; i < 10; i++ {\n   280→\t\tgo func(id int) {\n   281→\t\t\terr := Newf(\"TestOp\", ErrTypeRetryable, \"error %d\", id).\n   282→\t\t\t\tWithSymbol(\"BTC-USD\").\n   283→\t\t\t\tWithContext(\"goroutine\", id)\n   284→\n   285→\t\t\tassert.Contains(t, err.Error(), fmt.Sprintf(\"error %d\", id))\n   286→\t\t\tassert.Equal(t, id, err.Context[\"goroutine\"])\n   287→\n   288→\t\t\tdone <- true\n   289→\t\t}(i)\n   290→\t}\n   291→\n   292→\tfor i := 0; i < 10; i++ {\n   293→\t\t<-done\n   294→\t}\n   295→}\n   296→\n   297→// Benchmark error creation\n   298→func BenchmarkNew(b *testing.B) {\n   299→\tbaseErr := errors.New(\"base error\")\n   300→\n   301→\tb.Run(\"Retryable\", func(b *testing.B) {\n   302→\t\tfor i := 0; i < b.N; i++ {\n   303→\t\t\t_ = New(\"BenchOp\", ErrTypeRetryable, baseErr)\n   304→\t\t}\n   305→\t})\n   306→\n   307→\tb.Run(\"Fatal_WithStack\", func(b *testing.B) {\n   308→\t\tfor i := 0; i < b.N; i++ {\n   309→\t\t\t_ = New(\"BenchOp\", ErrTypeFatal, baseErr)\n   310→\t\t}\n   311→\t})\n   312→\n   313→\tb.Run(\"WithContext\", func(b *testing.B) {\n   314→\t\tfor i := 0; i < b.N; i++ {\n   315→\t\t\t_ = New(\"BenchOp\", ErrTypeRetryable, baseErr).\n   316→\t\t\t\tWithSymbol(\"BTC-USD\").\n   317→\t\t\t\tWithContext(\"orderID\", \"12345\").\n   318→\t\t\t\tWithContext(\"size\", 0.1)\n   319→\t\t}\n   320→\t})\n   321→}\n   322→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"52d40f84-7fa7-43ba-b2d5-28eb8121618a","timestamp":"2025-08-13T10:29:01.381Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/pkg/errors/errors_test.go","content":"package errors\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestErrorType_String(t *testing.T) {\n\ttests := []struct {\n\t\terrType  ErrorType\n\t\texpected string\n\t}{\n\t\t{ErrTypeUnknown, \"Unknown\"},\n\t\t{ErrTypeRetryable, \"Retryable\"},\n\t\t{ErrTypeFatal, \"Fatal\"},\n\t\t{ErrTypeValidation, \"Validation\"},\n\t\t{ErrTypeConfiguration, \"Configuration\"},\n\t\t{ErrTypeMarket, \"Market\"},\n\t\t{ErrTypeOrder, \"Order\"},\n\t\t{ErrTypeInsufficientFunds, \"InsufficientFunds\"},\n\t\t{ErrTypeRateLimit, \"RateLimit\"},\n\t\t{ErrTypeConnection, \"Connection\"},\n\t\t{ErrTypeAuth, \"Authentication\"},\n\t\t{ErrTypeData, \"Data\"},\n\t\t{ErrorType(999), \"Unknown\"}, // Invalid type\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.expected, func(t *testing.T) {\n\t\t\tassert.Equal(t, tt.expected, tt.errType.String())\n\t\t})\n\t}\n}\n\nfunc TestNew(t *testing.T) {\n\tbaseErr := errors.New(\"base error\")\n\n\tt.Run(\"basic error creation\", func(t *testing.T) {\n\t\terr := New(\"TestOp\", ErrTypeRetryable, baseErr)\n\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, ErrTypeRetryable, err.Type)\n\t\tassert.Equal(t, \"TestOp\", err.Op)\n\t\tassert.Equal(t, baseErr, err.Err)\n\t\tassert.Empty(t, err.Symbol)\n\t\tassert.Empty(t, err.Context)\n\t\tassert.Empty(t, err.Stack) // Retryable errors don't capture stack by default\n\t})\n\n\tt.Run(\"fatal error captures stack\", func(t *testing.T) {\n\t\terr := New(\"TestOp\", ErrTypeFatal, baseErr)\n\n\t\tassert.NotEmpty(t, err.Stack)\n\t\tassert.Contains(t, err.Stack, \"TestNew\") // Should contain current function\n\t})\n\n\tt.Run(\"auth error captures stack\", func(t *testing.T) {\n\t\terr := New(\"TestOp\", ErrTypeAuth, baseErr)\n\n\t\tassert.NotEmpty(t, err.Stack)\n\t})\n}\n\nfunc TestNewf(t *testing.T) {\n\terr := Newf(\"TestOp\", ErrTypeValidation, \"invalid value: %d\", 42)\n\n\tassert.NotNil(t, err)\n\tassert.Equal(t, ErrTypeValidation, err.Type)\n\tassert.Equal(t, \"TestOp\", err.Op)\n\tassert.Equal(t, \"invalid value: 42\", err.Err.Error())\n}\n\nfunc TestTradingError_Error(t *testing.T) {\n\ttests := []struct {\n\t\tname     string\n\t\terr      *TradingError\n\t\texpected string\n\t}{\n\t\t{\n\t\t\tname: \"basic error\",\n\t\t\terr: &TradingError{\n\t\t\t\tType: ErrTypeRetryable,\n\t\t\t\tOp:   \"TestOp\",\n\t\t\t\tErr:  errors.New(\"test error\"),\n\t\t\t},\n\t\t\texpected: \"TestOp: Retryable: test error\",\n\t\t},\n\t\t{\n\t\t\tname: \"error with symbol\",\n\t\t\terr: &TradingError{\n\t\t\t\tType:   ErrTypeOrder,\n\t\t\t\tOp:     \"OrderExecutor.PlaceOrder\",\n\t\t\t\tSymbol: \"BTC-USD\",\n\t\t\t\tErr:    errors.New(\"insufficient balance\"),\n\t\t\t},\n\t\t\texpected: \"OrderExecutor.PlaceOrder: Order [BTC-USD]: insufficient balance\",\n\t\t},\n\t\t{\n\t\t\tname: \"error without wrapped error\",\n\t\t\terr: &TradingError{\n\t\t\t\tType: ErrTypeConfiguration,\n\t\t\t\tOp:   \"Config.Load\",\n\t\t\t},\n\t\t\texpected: \"Config.Load: Configuration\",\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tassert.Equal(t, tt.expected, tt.err.Error())\n\t\t})\n\t}\n}\n\nfunc TestTradingError_WithMethods(t *testing.T) {\n\terr := New(\"TestOp\", ErrTypeRetryable, errors.New(\"base error\"))\n\n\tt.Run(\"WithSymbol\", func(t *testing.T) {\n\t\terr = err.WithSymbol(\"BTC-USD\")\n\t\tassert.Equal(t, \"BTC-USD\", err.Symbol)\n\t})\n\n\tt.Run(\"WithContext\", func(t *testing.T) {\n\t\terr = err.WithContext(\"orderID\", \"12345\").\n\t\t\tWithContext(\"size\", 0.1)\n\n\t\tassert.Equal(t, \"12345\", err.Context[\"orderID\"])\n\t\tassert.Equal(t, 0.1, err.Context[\"size\"])\n\t})\n\n\tt.Run(\"WithStack\", func(t *testing.T) {\n\t\t// Create error without stack\n\t\terr := New(\"TestOp\", ErrTypeRetryable, nil)\n\t\tassert.Empty(t, err.Stack)\n\n\t\t// Force stack capture\n\t\terr = err.WithStack()\n\t\tassert.NotEmpty(t, err.Stack)\n\t\tassert.Contains(t, err.Stack, \"TestTradingError_WithMethods\")\n\t})\n}\n\nfunc TestWrap(t *testing.T) {\n\tt.Run(\"wrap nil error returns nil\", func(t *testing.T) {\n\t\terr := Wrap(\"TestOp\", ErrTypeRetryable, nil)\n\t\tassert.Nil(t, err)\n\t})\n\n\tt.Run(\"wrap standard error\", func(t *testing.T) {\n\t\tbaseErr := errors.New(\"base error\")\n\t\terr := Wrap(\"TestOp\", ErrTypeRetryable, baseErr)\n\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, \"TestOp\", err.Op)\n\t\tassert.Equal(t, ErrTypeRetryable, err.Type)\n\t\tassert.Equal(t, baseErr, err.Err)\n\t})\n\n\tt.Run(\"wrap TradingError preserves context\", func(t *testing.T) {\n\t\toriginalErr := New(\"OriginalOp\", ErrTypeOrder, errors.New(\"original error\")).\n\t\t\tWithSymbol(\"BTC-USD\").\n\t\t\tWithContext(\"orderID\", \"12345\")\n\n\t\twrappedErr := Wrap(\"WrapperOp\", ErrTypeRetryable, originalErr)\n\n\t\tassert.Equal(t, \"WrapperOp\", wrappedErr.Op)\n\t\tassert.Equal(t, ErrTypeRetryable, wrappedErr.Type)\n\t\tassert.Equal(t, \"BTC-USD\", wrappedErr.Symbol) // Symbol preserved\n\t\tassert.Equal(t, originalErr, wrappedErr.Err)  // Original error wrapped\n\t})\n}\n\nfunc TestErrorChecks(t *testing.T) {\n\tt.Run(\"IsType\", func(t *testing.T) {\n\t\terr := New(\"TestOp\", ErrTypeRetryable, nil)\n\t\tassert.True(t, IsType(err, ErrTypeRetryable))\n\t\tassert.False(t, IsType(err, ErrTypeFatal))\n\n\t\t// Test with wrapped error\n\t\twrappedErr := fmt.Errorf(\"wrapped: %w\", err)\n\t\tassert.True(t, IsType(wrappedErr, ErrTypeRetryable))\n\n\t\t// Test with non-TradingError\n\t\tstdErr := errors.New(\"standard error\")\n\t\tassert.False(t, IsType(stdErr, ErrTypeRetryable))\n\t})\n\n\tt.Run(\"IsRetryable\", func(t *testing.T) {\n\t\ttests := []struct {\n\t\t\terrType  ErrorType\n\t\t\texpected bool\n\t\t}{\n\t\t\t{ErrTypeRetryable, true},\n\t\t\t{ErrTypeConnection, true},\n\t\t\t{ErrTypeRateLimit, true},\n\t\t\t{ErrTypeFatal, false},\n\t\t\t{ErrTypeValidation, false},\n\t\t\t{ErrTypeAuth, false},\n\t\t}\n\n\t\tfor _, tt := range tests {\n\t\t\terr := New(\"TestOp\", tt.errType, nil)\n\t\t\tassert.Equal(t, tt.expected, IsRetryable(err))\n\t\t}\n\n\t\t// Test with non-TradingError\n\t\tassert.False(t, IsRetryable(errors.New(\"standard error\")))\n\t})\n\n\tt.Run(\"IsFatal\", func(t *testing.T) {\n\t\tfatalErr := New(\"TestOp\", ErrTypeFatal, nil)\n\t\tassert.True(t, IsFatal(fatalErr))\n\n\t\tnonFatalErr := New(\"TestOp\", ErrTypeRetryable, nil)\n\t\tassert.False(t, IsFatal(nonFatalErr))\n\t})\n\n\tt.Run(\"GetType\", func(t *testing.T) {\n\t\terr := New(\"TestOp\", ErrTypeOrder, nil)\n\t\tassert.Equal(t, ErrTypeOrder, GetType(err))\n\n\t\t// Test with non-TradingError\n\t\tassert.Equal(t, ErrTypeUnknown, GetType(errors.New(\"standard error\")))\n\t})\n\n\tt.Run(\"GetContext\", func(t *testing.T) {\n\t\terr := New(\"TestOp\", ErrTypeOrder, nil).\n\t\t\tWithContext(\"key\", \"value\")\n\n\t\tctx := GetContext(err)\n\t\tassert.Equal(t, \"value\", ctx[\"key\"])\n\n\t\t// Test with non-TradingError\n\t\tassert.Nil(t, GetContext(errors.New(\"standard error\")))\n\t})\n}\n\nfunc TestErrorChaining(t *testing.T) {\n\tbaseErr := errors.New(\"base error\")\n\ttradingErr := New(\"TestOp\", ErrTypeRetryable, baseErr)\n\twrappedErr := fmt.Errorf(\"wrapped: %w\", tradingErr)\n\n\tt.Run(\"errors.Is\", func(t *testing.T) {\n\t\tassert.True(t, errors.Is(wrappedErr, tradingErr))\n\t\tassert.True(t, errors.Is(wrappedErr, baseErr))\n\t\tassert.True(t, Is(wrappedErr, baseErr))\n\t})\n\n\tt.Run(\"errors.As\", func(t *testing.T) {\n\t\tvar te *TradingError\n\t\tassert.True(t, errors.As(wrappedErr, &te))\n\t\tassert.Equal(t, \"TestOp\", te.Op)\n\n\t\tassert.True(t, As(wrappedErr, &te))\n\t})\n}\n\nfunc TestStackTraceCapture(t *testing.T) {\n\t// Test that stack trace is captured for fatal errors\n\terr := New(\"TestOp\", ErrTypeFatal, nil)\n\n\trequire.NotEmpty(t, err.Stack)\n\n\t// Should contain test function\n\tassert.Contains(t, err.Stack, \"TestStackTraceCapture\")\n\n\t// Stack should be captured\n\tassert.True(t, len(err.Stack) > 100, \"Stack trace should be substantial\")\n}\n\nfunc TestConcurrentAccess(t *testing.T) {\n\t// Test that error creation and access is safe for concurrent use\n\tdone := make(chan bool)\n\n\tfor i := 0; i < 10; i++ {\n\t\tgo func(id int) {\n\t\t\terr := Newf(\"TestOp\", ErrTypeRetryable, \"error %d\", id).\n\t\t\t\tWithSymbol(\"BTC-USD\").\n\t\t\t\tWithContext(\"goroutine\", id)\n\n\t\t\tassert.Contains(t, err.Error(), fmt.Sprintf(\"error %d\", id))\n\t\t\tassert.Equal(t, id, err.Context[\"goroutine\"])\n\n\t\t\tdone <- true\n\t\t}(i)\n\t}\n\n\tfor i := 0; i < 10; i++ {\n\t\t<-done\n\t}\n}\n\n// Benchmark error creation\nfunc BenchmarkNew(b *testing.B) {\n\tbaseErr := errors.New(\"base error\")\n\n\tb.Run(\"Retryable\", func(b *testing.B) {\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\t_ = New(\"BenchOp\", ErrTypeRetryable, baseErr)\n\t\t}\n\t})\n\n\tb.Run(\"Fatal_WithStack\", func(b *testing.B) {\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\t_ = New(\"BenchOp\", ErrTypeFatal, baseErr)\n\t\t}\n\t})\n\n\tb.Run(\"WithContext\", func(b *testing.B) {\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\t_ = New(\"BenchOp\", ErrTypeRetryable, baseErr).\n\t\t\t\tWithSymbol(\"BTC-USD\").\n\t\t\t\tWithContext(\"orderID\", \"12345\").\n\t\t\t\tWithContext(\"size\", 0.1)\n\t\t}\n\t})\n}\n","numLines":322,"startLine":1,"totalLines":322}}}
{"parentUuid":"52d40f84-7fa7-43ba-b2d5-28eb8121618a","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01SyRZx2pJDR6H6caFJsMMZi","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01AWRBkeSf1tEfUxRF1MjZKb","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/math/decimal_math.go"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":4421,"cache_read_input_tokens":66036,"output_tokens":75,"service_tier":"standard"}},"requestId":"req_011CS5Yy84MMmTsqQrjf6vXA","type":"assistant","uuid":"91103c6d-3ec5-4c1d-9c78-e32f2b8de5e6","timestamp":"2025-08-13T10:29:05.458Z"}
{"parentUuid":"91103c6d-3ec5-4c1d-9c78-e32f2b8de5e6","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"<tool_use_error>File does not exist.</tool_use_error>","is_error":true,"tool_use_id":"toolu_01AWRBkeSf1tEfUxRF1MjZKb"}]},"uuid":"340dceb3-cc95-4fa2-9960-7b22ceef90da","timestamp":"2025-08-13T10:29:05.524Z","toolUseResult":"Error: File does not exist."}
{"parentUuid":"340dceb3-cc95-4fa2-9960-7b22ceef90da","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_013DpnsV2i9Z2MDd1AsELkTu","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01Mg7RkXWoLtVTEbnFsmL5q6","name":"Glob","input":{"pattern":"back/pkg/*/decimal*"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":110,"cache_read_input_tokens":70457,"output_tokens":58,"service_tier":"standard"}},"requestId":"req_011CS5YyShXBuJYRhS5pRizy","type":"assistant","uuid":"c3d688f4-ac25-4363-a8aa-9c39cd271b2e","timestamp":"2025-08-13T10:29:08.484Z"}
{"parentUuid":"c3d688f4-ac25-4363-a8aa-9c39cd271b2e","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Mg7RkXWoLtVTEbnFsmL5q6","type":"tool_result","content":"/home/aural/Code/bigmeanie/back/pkg/decimal_math/decimal_math.go"}]},"uuid":"9627989a-c469-4c43-bde8-40a3a71c75d0","timestamp":"2025-08-13T10:29:08.533Z","toolUseResult":{"filenames":["/home/aural/Code/bigmeanie/back/pkg/decimal_math/decimal_math.go"],"durationMs":10,"numFiles":1,"truncated":false}}
{"parentUuid":"9627989a-c469-4c43-bde8-40a3a71c75d0","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01LWHydKy59asXTZtfeJhX1x","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01AQ3WSJEg1TySyDtAUcHTF2","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/decimal_math/decimal_math.go"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":95,"cache_read_input_tokens":70567,"output_tokens":77,"service_tier":"standard"}},"requestId":"req_011CS5YyefMgS6xiqyNVD412","type":"assistant","uuid":"82786361-0ba7-4ffa-b01b-7a07d074af8a","timestamp":"2025-08-13T10:29:10.506Z"}
{"parentUuid":"82786361-0ba7-4ffa-b01b-7a07d074af8a","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01AQ3WSJEg1TySyDtAUcHTF2","type":"tool_result","content":"     1→// Package math provides mathematical utilities for decimal operations used throughout the trading system.\n     2→// It includes functions for complex calculations like square roots that aren't provided by the decimal library.\n     3→package math\n     4→\n     5→import (\n     6→\t\"github.com/shopspring/decimal\"\n     7→)\n     8→\n     9→// DecimalSqrt calculates the square root of a decimal number using Newton's method\n    10→// with configurable precision iterations\n    11→func DecimalSqrt(d decimal.Decimal) decimal.Decimal {\n    12→\t// Handle special cases\n    13→\tif d.IsZero() {\n    14→\t\treturn decimal.Zero\n    15→\t}\n    16→\tif d.IsNegative() {\n    17→\t\t// Return zero for negative numbers (could panic or return error instead)\n    18→\t\treturn decimal.Zero\n    19→\t}\n    20→\t\n    21→\t// Use Newton's method: x_{n+1} = (x_n + d/x_n) / 2\n    22→\t// Start with a reasonable initial guess\n    23→\tx := d.Div(decimal.NewFromInt(2))\n    24→\ttwo := decimal.NewFromInt(2)\n    25→\t\n    26→\t// Precision threshold - stop when change is less than this\n    27→\tepsilon := decimal.NewFromFloat(1e-15)\n    28→\t\n    29→\t// Maximum iterations to prevent infinite loops\n    30→\tmaxIterations := 50\n    31→\t\n    32→\tfor i := 0; i < maxIterations; i++ {\n    33→\t\t// Calculate next approximation\n    34→\t\tnextX := x.Add(d.Div(x)).Div(two)\n    35→\t\t\n    36→\t\t// Check if we've converged\n    37→\t\tdiff := nextX.Sub(x).Abs()\n    38→\t\tif diff.LessThan(epsilon) {\n    39→\t\t\treturn nextX\n    40→\t\t}\n    41→\t\t\n    42→\t\tx = nextX\n    43→\t}\n    44→\t\n    45→\treturn x\n    46→}\n    47→\n    48→// DecimalStdDev calculates the standard deviation of a slice of decimals\n    49→// maintaining decimal precision throughout\n    50→func DecimalStdDev(values []decimal.Decimal) decimal.Decimal {\n    51→\tif len(values) < 2 {\n    52→\t\treturn decimal.Zero\n    53→\t}\n    54→\t\n    55→\t// Calculate mean\n    56→\tsum := decimal.Zero\n    57→\tfor _, v := range values {\n    58→\t\tsum = sum.Add(v)\n    59→\t}\n    60→\tmean := sum.Div(decimal.NewFromInt(int64(len(values))))\n    61→\t\n    62→\t// Calculate variance\n    63→\tvarianceSum := decimal.Zero\n    64→\tfor _, v := range values {\n    65→\t\tdiff := v.Sub(mean)\n    66→\t\tvarianceSum = varianceSum.Add(diff.Pow(decimal.NewFromInt(2)))\n    67→\t}\n    68→\tvariance := varianceSum.Div(decimal.NewFromInt(int64(len(values) - 1)))\n    69→\t\n    70→\t// Return standard deviation\n    71→\treturn DecimalSqrt(variance)\n    72→}\n    73→\n    74→// DecimalDownsideDeviation calculates the downside deviation (semi-deviation)\n    75→// for risk metrics like Sortino ratio\n    76→func DecimalDownsideDeviation(returns []decimal.Decimal, target decimal.Decimal) decimal.Decimal {\n    77→\tif len(returns) < 2 {\n    78→\t\treturn decimal.Zero\n    79→\t}\n    80→\t\n    81→\t// Calculate downside variance (only negative deviations)\n    82→\tdownsideSum := decimal.Zero\n    83→\tdownsideCount := 0\n    84→\t\n    85→\tfor _, ret := range returns {\n    86→\t\tif ret.LessThan(target) {\n    87→\t\t\tdiff := target.Sub(ret)\n    88→\t\t\tdownsideSum = downsideSum.Add(diff.Pow(decimal.NewFromInt(2)))\n    89→\t\t\tdownsideCount++\n    90→\t\t}\n    91→\t}\n    92→\t\n    93→\tif downsideCount < 2 {\n    94→\t\treturn decimal.Zero\n    95→\t}\n    96→\t\n    97→\tdownsideVariance := downsideSum.Div(decimal.NewFromInt(int64(downsideCount - 1)))\n    98→\treturn DecimalSqrt(downsideVariance)\n    99→}\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"c8e13616-8e20-44e2-9008-6d7b08884805","timestamp":"2025-08-13T10:29:10.554Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/pkg/decimal_math/decimal_math.go","content":"// Package math provides mathematical utilities for decimal operations used throughout the trading system.\n// It includes functions for complex calculations like square roots that aren't provided by the decimal library.\npackage math\n\nimport (\n\t\"github.com/shopspring/decimal\"\n)\n\n// DecimalSqrt calculates the square root of a decimal number using Newton's method\n// with configurable precision iterations\nfunc DecimalSqrt(d decimal.Decimal) decimal.Decimal {\n\t// Handle special cases\n\tif d.IsZero() {\n\t\treturn decimal.Zero\n\t}\n\tif d.IsNegative() {\n\t\t// Return zero for negative numbers (could panic or return error instead)\n\t\treturn decimal.Zero\n\t}\n\t\n\t// Use Newton's method: x_{n+1} = (x_n + d/x_n) / 2\n\t// Start with a reasonable initial guess\n\tx := d.Div(decimal.NewFromInt(2))\n\ttwo := decimal.NewFromInt(2)\n\t\n\t// Precision threshold - stop when change is less than this\n\tepsilon := decimal.NewFromFloat(1e-15)\n\t\n\t// Maximum iterations to prevent infinite loops\n\tmaxIterations := 50\n\t\n\tfor i := 0; i < maxIterations; i++ {\n\t\t// Calculate next approximation\n\t\tnextX := x.Add(d.Div(x)).Div(two)\n\t\t\n\t\t// Check if we've converged\n\t\tdiff := nextX.Sub(x).Abs()\n\t\tif diff.LessThan(epsilon) {\n\t\t\treturn nextX\n\t\t}\n\t\t\n\t\tx = nextX\n\t}\n\t\n\treturn x\n}\n\n// DecimalStdDev calculates the standard deviation of a slice of decimals\n// maintaining decimal precision throughout\nfunc DecimalStdDev(values []decimal.Decimal) decimal.Decimal {\n\tif len(values) < 2 {\n\t\treturn decimal.Zero\n\t}\n\t\n\t// Calculate mean\n\tsum := decimal.Zero\n\tfor _, v := range values {\n\t\tsum = sum.Add(v)\n\t}\n\tmean := sum.Div(decimal.NewFromInt(int64(len(values))))\n\t\n\t// Calculate variance\n\tvarianceSum := decimal.Zero\n\tfor _, v := range values {\n\t\tdiff := v.Sub(mean)\n\t\tvarianceSum = varianceSum.Add(diff.Pow(decimal.NewFromInt(2)))\n\t}\n\tvariance := varianceSum.Div(decimal.NewFromInt(int64(len(values) - 1)))\n\t\n\t// Return standard deviation\n\treturn DecimalSqrt(variance)\n}\n\n// DecimalDownsideDeviation calculates the downside deviation (semi-deviation)\n// for risk metrics like Sortino ratio\nfunc DecimalDownsideDeviation(returns []decimal.Decimal, target decimal.Decimal) decimal.Decimal {\n\tif len(returns) < 2 {\n\t\treturn decimal.Zero\n\t}\n\t\n\t// Calculate downside variance (only negative deviations)\n\tdownsideSum := decimal.Zero\n\tdownsideCount := 0\n\t\n\tfor _, ret := range returns {\n\t\tif ret.LessThan(target) {\n\t\t\tdiff := target.Sub(ret)\n\t\t\tdownsideSum = downsideSum.Add(diff.Pow(decimal.NewFromInt(2)))\n\t\t\tdownsideCount++\n\t\t}\n\t}\n\t\n\tif downsideCount < 2 {\n\t\treturn decimal.Zero\n\t}\n\t\n\tdownsideVariance := downsideSum.Div(decimal.NewFromInt(int64(downsideCount - 1)))\n\treturn DecimalSqrt(downsideVariance)\n}","numLines":99,"startLine":1,"totalLines":99}}}
{"parentUuid":"c8e13616-8e20-44e2-9008-6d7b08884805","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01FeUQV8m6vW2y4TgiCYz33W","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01SweqxAuPcFbJLDuWExmD35","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/clock/clock.go"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1350,"cache_read_input_tokens":70662,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5YyoK1QPYaoQ8zVXBmL","type":"assistant","uuid":"be461d80-7a95-4a26-bc7f-cccd0a22118b","timestamp":"2025-08-13T10:29:13.467Z"}
{"parentUuid":"be461d80-7a95-4a26-bc7f-cccd0a22118b","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SweqxAuPcFbJLDuWExmD35","type":"tool_result","content":"     1→package clock\n     2→\n     3→import \"time\"\n     4→\n     5→// Clock provides an interface for time operations to enable testing.\n     6→type Clock interface {\n     7→\tNow() time.Time\n     8→\tSince(t time.Time) time.Duration\n     9→\tUntil(t time.Time) time.Duration\n    10→}\n    11→\n    12→// RealClock implements Clock using the real time functions.\n    13→type RealClock struct{}\n    14→\n    15→// NewRealClock creates a new real clock.\n    16→func NewRealClock() *RealClock {\n    17→\treturn &RealClock{}\n    18→}\n    19→\n    20→// Now returns the current time.\n    21→func (c *RealClock) Now() time.Time {\n    22→\treturn time.Now()\n    23→}\n    24→\n    25→// Since returns the time elapsed since t.\n    26→func (c *RealClock) Since(t time.Time) time.Duration {\n    27→\treturn time.Since(t)\n    28→}\n    29→\n    30→// Until returns the duration until t.\n    31→func (c *RealClock) Until(t time.Time) time.Duration {\n    32→\treturn time.Until(t)\n    33→}\n    34→\n    35→// Verify that RealClock implements Clock\n    36→var _ Clock = (*RealClock)(nil)\n    37→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"12121ab6-261d-45a6-89cd-70cf60944625","timestamp":"2025-08-13T10:29:13.510Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/pkg/clock/clock.go","content":"package clock\n\nimport \"time\"\n\n// Clock provides an interface for time operations to enable testing.\ntype Clock interface {\n\tNow() time.Time\n\tSince(t time.Time) time.Duration\n\tUntil(t time.Time) time.Duration\n}\n\n// RealClock implements Clock using the real time functions.\ntype RealClock struct{}\n\n// NewRealClock creates a new real clock.\nfunc NewRealClock() *RealClock {\n\treturn &RealClock{}\n}\n\n// Now returns the current time.\nfunc (c *RealClock) Now() time.Time {\n\treturn time.Now()\n}\n\n// Since returns the time elapsed since t.\nfunc (c *RealClock) Since(t time.Time) time.Duration {\n\treturn time.Since(t)\n}\n\n// Until returns the duration until t.\nfunc (c *RealClock) Until(t time.Time) time.Duration {\n\treturn time.Until(t)\n}\n\n// Verify that RealClock implements Clock\nvar _ Clock = (*RealClock)(nil)\n","numLines":37,"startLine":1,"totalLines":37}}}
{"parentUuid":"12121ab6-261d-45a6-89cd-70cf60944625","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01CfXreZ8zAHW854Q6H2eHZW","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_017HwXuihPfZgncA4pxxaAzC","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/clock/mock.go"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":530,"cache_read_input_tokens":72012,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5Yz1uo3DxrwSe6SmunR","type":"assistant","uuid":"6ae805e8-9e81-4cd8-ba2e-570dc6be0d5d","timestamp":"2025-08-13T10:29:15.999Z"}
{"parentUuid":"6ae805e8-9e81-4cd8-ba2e-570dc6be0d5d","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017HwXuihPfZgncA4pxxaAzC","type":"tool_result","content":"     1→package clock\n     2→\n     3→import (\n     4→\t\"sync\"\n     5→\t\"time\"\n     6→)\n     7→\n     8→// MockClock is a clock that can be controlled for testing.\n     9→type MockClock struct {\n    10→\tmu          sync.RWMutex\n    11→\tcurrentTime time.Time\n    12→}\n    13→\n    14→// NewMockClock creates a new mock clock with the given time.\n    15→func NewMockClock(t time.Time) *MockClock {\n    16→\treturn &MockClock{\n    17→\t\tcurrentTime: t,\n    18→\t}\n    19→}\n    20→\n    21→// Now returns the current mock time.\n    22→func (c *MockClock) Now() time.Time {\n    23→\tc.mu.RLock()\n    24→\tdefer c.mu.RUnlock()\n    25→\treturn c.currentTime\n    26→}\n    27→\n    28→// Since returns the time elapsed since t.\n    29→func (c *MockClock) Since(t time.Time) time.Duration {\n    30→\tc.mu.RLock()\n    31→\tdefer c.mu.RUnlock()\n    32→\treturn c.currentTime.Sub(t)\n    33→}\n    34→\n    35→// Until returns the duration until t.\n    36→func (c *MockClock) Until(t time.Time) time.Duration {\n    37→\tc.mu.RLock()\n    38→\tdefer c.mu.RUnlock()\n    39→\treturn t.Sub(c.currentTime)\n    40→}\n    41→\n    42→// Set sets the current time.\n    43→func (c *MockClock) Set(t time.Time) {\n    44→\tc.mu.Lock()\n    45→\tdefer c.mu.Unlock()\n    46→\tc.currentTime = t\n    47→}\n    48→\n    49→// Add adds a duration to the current time.\n    50→func (c *MockClock) Add(d time.Duration) {\n    51→\tc.mu.Lock()\n    52→\tdefer c.mu.Unlock()\n    53→\tc.currentTime = c.currentTime.Add(d)\n    54→}\n    55→\n    56→// AddDate adds years, months, and days to the current time.\n    57→func (c *MockClock) AddDate(years, months, days int) {\n    58→\tc.mu.Lock()\n    59→\tdefer c.mu.Unlock()\n    60→\tc.currentTime = c.currentTime.AddDate(years, months, days)\n    61→}\n    62→\n    63→// Verify that MockClock implements Clock\n    64→var _ Clock = (*MockClock)(nil)\n    65→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"218eb412-0f34-489e-acbd-a9a4c7ea12eb","timestamp":"2025-08-13T10:29:16.043Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/pkg/clock/mock.go","content":"package clock\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\n// MockClock is a clock that can be controlled for testing.\ntype MockClock struct {\n\tmu          sync.RWMutex\n\tcurrentTime time.Time\n}\n\n// NewMockClock creates a new mock clock with the given time.\nfunc NewMockClock(t time.Time) *MockClock {\n\treturn &MockClock{\n\t\tcurrentTime: t,\n\t}\n}\n\n// Now returns the current mock time.\nfunc (c *MockClock) Now() time.Time {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.currentTime\n}\n\n// Since returns the time elapsed since t.\nfunc (c *MockClock) Since(t time.Time) time.Duration {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.currentTime.Sub(t)\n}\n\n// Until returns the duration until t.\nfunc (c *MockClock) Until(t time.Time) time.Duration {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn t.Sub(c.currentTime)\n}\n\n// Set sets the current time.\nfunc (c *MockClock) Set(t time.Time) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.currentTime = t\n}\n\n// Add adds a duration to the current time.\nfunc (c *MockClock) Add(d time.Duration) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.currentTime = c.currentTime.Add(d)\n}\n\n// AddDate adds years, months, and days to the current time.\nfunc (c *MockClock) AddDate(years, months, days int) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.currentTime = c.currentTime.AddDate(years, months, days)\n}\n\n// Verify that MockClock implements Clock\nvar _ Clock = (*MockClock)(nil)\n","numLines":65,"startLine":1,"totalLines":65}}}
{"parentUuid":"218eb412-0f34-489e-acbd-a9a4c7ea12eb","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01Y6F4Xp2m99ma8Yf1d1A5cy","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01ShJvkwJgwpUYfbReavhfVf","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/indicators/common/rsi.go"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":871,"cache_read_input_tokens":72542,"output_tokens":76,"service_tier":"standard"}},"requestId":"req_011CS5YzDAhy5YppYNErk9Nd","type":"assistant","uuid":"9781e541-3936-43a3-96ed-a93584c34baa","timestamp":"2025-08-13T10:29:18.599Z"}
{"parentUuid":"9781e541-3936-43a3-96ed-a93584c34baa","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01ShJvkwJgwpUYfbReavhfVf","type":"tool_result","content":"     1→package common\n     2→\n     3→import (\n     4→\t\"fmt\"\n     5→\t\n     6→\t\"bigmeanie/pkg/indicators\"\n     7→\t\"github.com/shopspring/decimal\"\n     8→)\n     9→\n    10→// RSI implements the Relative Strength Index indicator\n    11→type RSI struct {\n    12→\tindicators.Base\n    13→\tperiod int\n    14→\n    15→\t// Pre-calculated values for efficiency\n    16→\tgains      []decimal.Decimal\n    17→\tlosses     []decimal.Decimal\n    18→\tavgGains   []decimal.Decimal\n    19→\tavgLosses  []decimal.Decimal\n    20→\trsiValues  []decimal.Decimal\n    21→\tcalculated bool\n    22→}\n    23→\n    24→// RSI is a concrete implementation of the Relative Strength Index indicator\n    25→// Consumers should define their own interfaces for what they need from RSI\n    26→\n    27→// Compile-time check that RSI satisfies analysis.RSICalculator\n    28→// This is beneficial as it's a cross-package implementation\n    29→var _ interface {\n    30→\tCalculate(index int) decimal.Decimal\n    31→\tGetOversoldLevel() decimal.Decimal\n    32→\tGetOverboughtLevel() decimal.Decimal\n    33→\tIsOversold(index int) bool\n    34→\tIsOverbought(index int) bool\n    35→} = (*RSI)(nil)\n    36→\n    37→// NewRSI creates a new RSI indicator\n    38→func NewRSI(series indicators.TimeSeries, period int) *RSI {\n    39→\trsi := &RSI{\n    40→\t\tBase: indicators.NewBase(series, fmt.Sprintf(\"RSI(%d)\", period)),\n    41→\t\tperiod:        period,\n    42→\t\tgains:         make([]decimal.Decimal, 0),\n    43→\t\tlosses:        make([]decimal.Decimal, 0),\n    44→\t\tavgGains:      make([]decimal.Decimal, 0),\n    45→\t\tavgLosses:     make([]decimal.Decimal, 0),\n    46→\t\trsiValues:     make([]decimal.Decimal, 0),\n    47→\t\tcalculated:    false,\n    48→\t}\n    49→\n    50→\t// Pre-calculate all values\n    51→\trsi.precalculate()\n    52→\n    53→\treturn rsi\n    54→}\n    55→\n    56→// precalculate computes all RSI values upfront\n    57→func (r *RSI) precalculate() {\n    58→\tif r.calculated || r.Series() == nil || r.Series().Len() < 2 {\n    59→\t\treturn\n    60→\t}\n    61→\n    62→\t// Calculate gains and losses for each period\n    63→\tfor i := 1; i < r.Series().Len(); i++ {\n    64→\t\tprevCandle := r.Series().GetCandle(i - 1)\n    65→\t\tcurrCandle := r.Series().GetCandle(i)\n    66→\n    67→\t\tif prevCandle == nil || currCandle == nil {\n    68→\t\t\tr.gains = append(r.gains, decimal.Zero)\n    69→\t\t\tr.losses = append(r.losses, decimal.Zero)\n    70→\t\t\tcontinue\n    71→\t\t}\n    72→\n    73→\t\tchange := currCandle.Close.Sub(prevCandle.Close)\n    74→\n    75→\t\tif change.IsPositive() {\n    76→\t\t\tr.gains = append(r.gains, change)\n    77→\t\t\tr.losses = append(r.losses, decimal.Zero)\n    78→\t\t} else if change.IsNegative() {\n    79→\t\t\tr.gains = append(r.gains, decimal.Zero)\n    80→\t\t\tr.losses = append(r.losses, change.Abs())\n    81→\t\t} else {\n    82→\t\t\tr.gains = append(r.gains, decimal.Zero)\n    83→\t\t\tr.losses = append(r.losses, decimal.Zero)\n    84→\t\t}\n    85→\t}\n    86→\n    87→\t// Calculate average gains and losses\n    88→\tfor i := 0; i < r.Series().Len(); i++ {\n    89→\t\tif i < r.period {\n    90→\t\t\t// Not enough data yet\n    91→\t\t\tr.avgGains = append(r.avgGains, decimal.Zero)\n    92→\t\t\tr.avgLosses = append(r.avgLosses, decimal.Zero)\n    93→\t\t\tr.rsiValues = append(r.rsiValues, decimal.NewFromInt(50)) // Neutral RSI\n    94→\t\t} else if i == r.period {\n    95→\t\t\t// First average: simple average of first 'period' values\n    96→\t\t\tsumGains := decimal.Zero\n    97→\t\t\tsumLosses := decimal.Zero\n    98→\n    99→\t\t\t// Calculate sum over the period (last 'period' changes)\n   100→\t\t\tfor j := i - r.period; j < i; j++ {\n   101→\t\t\t\tif j-1 >= 0 && j-1 < len(r.gains) {\n   102→\t\t\t\t\tsumGains = sumGains.Add(r.gains[j-1])\n   103→\t\t\t\t\tsumLosses = sumLosses.Add(r.losses[j-1])\n   104→\t\t\t\t}\n   105→\t\t\t}\n   106→\n   107→\t\t\tavgGain := sumGains.Div(decimal.NewFromInt(int64(r.period)))\n   108→\t\t\tavgLoss := sumLosses.Div(decimal.NewFromInt(int64(r.period)))\n   109→\n   110→\t\t\tr.avgGains = append(r.avgGains, avgGain)\n   111→\t\t\tr.avgLosses = append(r.avgLosses, avgLoss)\n   112→\n   113→\t\t\t// Calculate RSI\n   114→\t\t\trsi := r.calculateRSI(avgGain, avgLoss)\n   115→\t\t\tr.rsiValues = append(r.rsiValues, rsi)\n   116→\t\t} else {\n   117→\t\t\t// Wilder's smoothing: avg = (prev_avg * (period-1) + current) / period\n   118→\t\t\tprevAvgGain := r.avgGains[i-1]\n   119→\t\t\tprevAvgLoss := r.avgLosses[i-1]\n   120→\n   121→\t\t\t// Current gain/loss is at index i-1 in gains/losses arrays\n   122→\t\t\tcurrentGain := decimal.Zero\n   123→\t\t\tcurrentLoss := decimal.Zero\n   124→\t\t\tif i-1 < len(r.gains) {\n   125→\t\t\t\tcurrentGain = r.gains[i-1]\n   126→\t\t\t\tcurrentLoss = r.losses[i-1]\n   127→\t\t\t}\n   128→\n   129→\t\t\t// Use Wilder's smoothing method\n   130→\t\t\tperiodDec := decimal.NewFromInt(int64(r.period))\n   131→\t\t\tperiodMinus1 := decimal.NewFromInt(int64(r.period - 1))\n   132→\n   133→\t\t\tavgGain := prevAvgGain.Mul(periodMinus1).Add(currentGain).Div(periodDec)\n   134→\t\t\tavgLoss := prevAvgLoss.Mul(periodMinus1).Add(currentLoss).Div(periodDec)\n   135→\n   136→\t\t\tr.avgGains = append(r.avgGains, avgGain)\n   137→\t\t\tr.avgLosses = append(r.avgLosses, avgLoss)\n   138→\n   139→\t\t\t// Calculate RSI\n   140→\t\t\trsi := r.calculateRSI(avgGain, avgLoss)\n   141→\t\t\tr.rsiValues = append(r.rsiValues, rsi)\n   142→\t\t}\n   143→\t}\n   144→\n   145→\tr.calculated = true\n   146→}\n   147→\n   148→// calculateRSI computes RSI from average gain and loss\n   149→func (r *RSI) calculateRSI(avgGain, avgLoss decimal.Decimal) decimal.Decimal {\n   150→\tif avgLoss.IsZero() {\n   151→\t\t// All gains, RSI = 100\n   152→\t\tif avgGain.IsPositive() {\n   153→\t\t\treturn decimal.NewFromInt(100)\n   154→\t\t}\n   155→\t\t// No movement, RSI = 50\n   156→\t\treturn decimal.NewFromInt(50)\n   157→\t}\n   158→\n   159→\tif avgGain.IsZero() && avgLoss.IsPositive() {\n   160→\t\t// All losses, RSI = 0\n   161→\t\treturn decimal.Zero\n   162→\t}\n   163→\n   164→\t// RS = Average Gain / Average Loss\n   165→\trs := avgGain.Div(avgLoss)\n   166→\n   167→\t// RSI = 100 - (100 / (1 + RS))\n   168→\tone := decimal.NewFromInt(1)\n   169→\thundred := decimal.NewFromInt(100)\n   170→\n   171→\trsi := hundred.Sub(hundred.Div(one.Add(rs)))\n   172→\n   173→\t// Ensure RSI is between 0 and 100\n   174→\tif rsi.LessThan(decimal.Zero) {\n   175→\t\treturn decimal.Zero\n   176→\t}\n   177→\tif rsi.GreaterThan(hundred) {\n   178→\t\treturn hundred\n   179→\t}\n   180→\n   181→\treturn rsi\n   182→}\n   183→\n   184→// Calculate returns the RSI value at the given index\n   185→func (r *RSI) Calculate(index int) decimal.Decimal {\n   186→\tif !r.ValidIndex(index) {\n   187→\t\treturn decimal.NewFromInt(50) // Return neutral RSI for invalid index\n   188→\t}\n   189→\n   190→\t// Ensure we have calculated values\n   191→\tif !r.calculated {\n   192→\t\tr.precalculate()\n   193→\t}\n   194→\n   195→\tif index >= len(r.rsiValues) {\n   196→\t\treturn decimal.NewFromInt(50) // Return neutral RSI if not enough data\n   197→\t}\n   198→\n   199→\treturn r.rsiValues[index]\n   200→}\n   201→\n   202→// RequiredBars returns the minimum number of bars needed for calculation\n   203→func (r *RSI) RequiredBars() int {\n   204→\treturn r.period\n   205→}\n   206→\n   207→// GetOversoldLevel returns the default oversold level (30)\n   208→func (r *RSI) GetOversoldLevel() decimal.Decimal {\n   209→\treturn decimal.NewFromInt(30)\n   210→}\n   211→\n   212→// GetOverboughtLevel returns the default overbought level (70)\n   213→func (r *RSI) GetOverboughtLevel() decimal.Decimal {\n   214→\treturn decimal.NewFromInt(70)\n   215→}\n   216→\n   217→// IsOversold checks if the RSI indicates oversold conditions\n   218→func (r *RSI) IsOversold(index int) bool {\n   219→\trsi := r.Calculate(index)\n   220→\treturn rsi.LessThan(r.GetOversoldLevel())\n   221→}\n   222→\n   223→// IsOverbought checks if the RSI indicates overbought conditions\n   224→func (r *RSI) IsOverbought(index int) bool {\n   225→\trsi := r.Calculate(index)\n   226→\treturn rsi.GreaterThan(r.GetOverboughtLevel())\n   227→}\n   228→\n   229→// GetDivergence checks for divergence between price and RSI\n   230→// Returns: 1 for bullish divergence, -1 for bearish divergence, 0 for no divergence\n   231→func (r *RSI) GetDivergence(index int, lookback int) int {\n   232→\tif index < lookback || index >= r.Series().Len() {\n   233→\t\treturn 0\n   234→\t}\n   235→\n   236→\t// Get current and past prices\n   237→\tcurrentCandle := r.Series().GetCandle(index)\n   238→\tpastCandle := r.Series().GetCandle(index - lookback)\n   239→\tif currentCandle == nil || pastCandle == nil {\n   240→\t\treturn 0\n   241→\t}\n   242→\n   243→\tcurrentPrice := currentCandle.Close\n   244→\tpastPrice := pastCandle.Close\n   245→\n   246→\t// Get current and past RSI\n   247→\tcurrentRSI := r.Calculate(index)\n   248→\tpastRSI := r.Calculate(index - lookback)\n   249→\n   250→\t// Check for divergence\n   251→\tpriceUp := currentPrice.GreaterThan(pastPrice)\n   252→\trsiUp := currentRSI.GreaterThan(pastRSI)\n   253→\n   254→\t// Bearish divergence: price up, RSI down\n   255→\tif priceUp && !rsiUp {\n   256→\t\treturn -1\n   257→\t}\n   258→\n   259→\t// Bullish divergence: price down, RSI up\n   260→\tif !priceUp && rsiUp {\n   261→\t\treturn 1\n   262→\t}\n   263→\n   264→\treturn 0\n   265→}\n   266→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"4aa75546-f06b-4267-82bd-c93aa9b3163d","timestamp":"2025-08-13T10:29:18.652Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/pkg/indicators/common/rsi.go","content":"package common\n\nimport (\n\t\"fmt\"\n\t\n\t\"bigmeanie/pkg/indicators\"\n\t\"github.com/shopspring/decimal\"\n)\n\n// RSI implements the Relative Strength Index indicator\ntype RSI struct {\n\tindicators.Base\n\tperiod int\n\n\t// Pre-calculated values for efficiency\n\tgains      []decimal.Decimal\n\tlosses     []decimal.Decimal\n\tavgGains   []decimal.Decimal\n\tavgLosses  []decimal.Decimal\n\trsiValues  []decimal.Decimal\n\tcalculated bool\n}\n\n// RSI is a concrete implementation of the Relative Strength Index indicator\n// Consumers should define their own interfaces for what they need from RSI\n\n// Compile-time check that RSI satisfies analysis.RSICalculator\n// This is beneficial as it's a cross-package implementation\nvar _ interface {\n\tCalculate(index int) decimal.Decimal\n\tGetOversoldLevel() decimal.Decimal\n\tGetOverboughtLevel() decimal.Decimal\n\tIsOversold(index int) bool\n\tIsOverbought(index int) bool\n} = (*RSI)(nil)\n\n// NewRSI creates a new RSI indicator\nfunc NewRSI(series indicators.TimeSeries, period int) *RSI {\n\trsi := &RSI{\n\t\tBase: indicators.NewBase(series, fmt.Sprintf(\"RSI(%d)\", period)),\n\t\tperiod:        period,\n\t\tgains:         make([]decimal.Decimal, 0),\n\t\tlosses:        make([]decimal.Decimal, 0),\n\t\tavgGains:      make([]decimal.Decimal, 0),\n\t\tavgLosses:     make([]decimal.Decimal, 0),\n\t\trsiValues:     make([]decimal.Decimal, 0),\n\t\tcalculated:    false,\n\t}\n\n\t// Pre-calculate all values\n\trsi.precalculate()\n\n\treturn rsi\n}\n\n// precalculate computes all RSI values upfront\nfunc (r *RSI) precalculate() {\n\tif r.calculated || r.Series() == nil || r.Series().Len() < 2 {\n\t\treturn\n\t}\n\n\t// Calculate gains and losses for each period\n\tfor i := 1; i < r.Series().Len(); i++ {\n\t\tprevCandle := r.Series().GetCandle(i - 1)\n\t\tcurrCandle := r.Series().GetCandle(i)\n\n\t\tif prevCandle == nil || currCandle == nil {\n\t\t\tr.gains = append(r.gains, decimal.Zero)\n\t\t\tr.losses = append(r.losses, decimal.Zero)\n\t\t\tcontinue\n\t\t}\n\n\t\tchange := currCandle.Close.Sub(prevCandle.Close)\n\n\t\tif change.IsPositive() {\n\t\t\tr.gains = append(r.gains, change)\n\t\t\tr.losses = append(r.losses, decimal.Zero)\n\t\t} else if change.IsNegative() {\n\t\t\tr.gains = append(r.gains, decimal.Zero)\n\t\t\tr.losses = append(r.losses, change.Abs())\n\t\t} else {\n\t\t\tr.gains = append(r.gains, decimal.Zero)\n\t\t\tr.losses = append(r.losses, decimal.Zero)\n\t\t}\n\t}\n\n\t// Calculate average gains and losses\n\tfor i := 0; i < r.Series().Len(); i++ {\n\t\tif i < r.period {\n\t\t\t// Not enough data yet\n\t\t\tr.avgGains = append(r.avgGains, decimal.Zero)\n\t\t\tr.avgLosses = append(r.avgLosses, decimal.Zero)\n\t\t\tr.rsiValues = append(r.rsiValues, decimal.NewFromInt(50)) // Neutral RSI\n\t\t} else if i == r.period {\n\t\t\t// First average: simple average of first 'period' values\n\t\t\tsumGains := decimal.Zero\n\t\t\tsumLosses := decimal.Zero\n\n\t\t\t// Calculate sum over the period (last 'period' changes)\n\t\t\tfor j := i - r.period; j < i; j++ {\n\t\t\t\tif j-1 >= 0 && j-1 < len(r.gains) {\n\t\t\t\t\tsumGains = sumGains.Add(r.gains[j-1])\n\t\t\t\t\tsumLosses = sumLosses.Add(r.losses[j-1])\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tavgGain := sumGains.Div(decimal.NewFromInt(int64(r.period)))\n\t\t\tavgLoss := sumLosses.Div(decimal.NewFromInt(int64(r.period)))\n\n\t\t\tr.avgGains = append(r.avgGains, avgGain)\n\t\t\tr.avgLosses = append(r.avgLosses, avgLoss)\n\n\t\t\t// Calculate RSI\n\t\t\trsi := r.calculateRSI(avgGain, avgLoss)\n\t\t\tr.rsiValues = append(r.rsiValues, rsi)\n\t\t} else {\n\t\t\t// Wilder's smoothing: avg = (prev_avg * (period-1) + current) / period\n\t\t\tprevAvgGain := r.avgGains[i-1]\n\t\t\tprevAvgLoss := r.avgLosses[i-1]\n\n\t\t\t// Current gain/loss is at index i-1 in gains/losses arrays\n\t\t\tcurrentGain := decimal.Zero\n\t\t\tcurrentLoss := decimal.Zero\n\t\t\tif i-1 < len(r.gains) {\n\t\t\t\tcurrentGain = r.gains[i-1]\n\t\t\t\tcurrentLoss = r.losses[i-1]\n\t\t\t}\n\n\t\t\t// Use Wilder's smoothing method\n\t\t\tperiodDec := decimal.NewFromInt(int64(r.period))\n\t\t\tperiodMinus1 := decimal.NewFromInt(int64(r.period - 1))\n\n\t\t\tavgGain := prevAvgGain.Mul(periodMinus1).Add(currentGain).Div(periodDec)\n\t\t\tavgLoss := prevAvgLoss.Mul(periodMinus1).Add(currentLoss).Div(periodDec)\n\n\t\t\tr.avgGains = append(r.avgGains, avgGain)\n\t\t\tr.avgLosses = append(r.avgLosses, avgLoss)\n\n\t\t\t// Calculate RSI\n\t\t\trsi := r.calculateRSI(avgGain, avgLoss)\n\t\t\tr.rsiValues = append(r.rsiValues, rsi)\n\t\t}\n\t}\n\n\tr.calculated = true\n}\n\n// calculateRSI computes RSI from average gain and loss\nfunc (r *RSI) calculateRSI(avgGain, avgLoss decimal.Decimal) decimal.Decimal {\n\tif avgLoss.IsZero() {\n\t\t// All gains, RSI = 100\n\t\tif avgGain.IsPositive() {\n\t\t\treturn decimal.NewFromInt(100)\n\t\t}\n\t\t// No movement, RSI = 50\n\t\treturn decimal.NewFromInt(50)\n\t}\n\n\tif avgGain.IsZero() && avgLoss.IsPositive() {\n\t\t// All losses, RSI = 0\n\t\treturn decimal.Zero\n\t}\n\n\t// RS = Average Gain / Average Loss\n\trs := avgGain.Div(avgLoss)\n\n\t// RSI = 100 - (100 / (1 + RS))\n\tone := decimal.NewFromInt(1)\n\thundred := decimal.NewFromInt(100)\n\n\trsi := hundred.Sub(hundred.Div(one.Add(rs)))\n\n\t// Ensure RSI is between 0 and 100\n\tif rsi.LessThan(decimal.Zero) {\n\t\treturn decimal.Zero\n\t}\n\tif rsi.GreaterThan(hundred) {\n\t\treturn hundred\n\t}\n\n\treturn rsi\n}\n\n// Calculate returns the RSI value at the given index\nfunc (r *RSI) Calculate(index int) decimal.Decimal {\n\tif !r.ValidIndex(index) {\n\t\treturn decimal.NewFromInt(50) // Return neutral RSI for invalid index\n\t}\n\n\t// Ensure we have calculated values\n\tif !r.calculated {\n\t\tr.precalculate()\n\t}\n\n\tif index >= len(r.rsiValues) {\n\t\treturn decimal.NewFromInt(50) // Return neutral RSI if not enough data\n\t}\n\n\treturn r.rsiValues[index]\n}\n\n// RequiredBars returns the minimum number of bars needed for calculation\nfunc (r *RSI) RequiredBars() int {\n\treturn r.period\n}\n\n// GetOversoldLevel returns the default oversold level (30)\nfunc (r *RSI) GetOversoldLevel() decimal.Decimal {\n\treturn decimal.NewFromInt(30)\n}\n\n// GetOverboughtLevel returns the default overbought level (70)\nfunc (r *RSI) GetOverboughtLevel() decimal.Decimal {\n\treturn decimal.NewFromInt(70)\n}\n\n// IsOversold checks if the RSI indicates oversold conditions\nfunc (r *RSI) IsOversold(index int) bool {\n\trsi := r.Calculate(index)\n\treturn rsi.LessThan(r.GetOversoldLevel())\n}\n\n// IsOverbought checks if the RSI indicates overbought conditions\nfunc (r *RSI) IsOverbought(index int) bool {\n\trsi := r.Calculate(index)\n\treturn rsi.GreaterThan(r.GetOverboughtLevel())\n}\n\n// GetDivergence checks for divergence between price and RSI\n// Returns: 1 for bullish divergence, -1 for bearish divergence, 0 for no divergence\nfunc (r *RSI) GetDivergence(index int, lookback int) int {\n\tif index < lookback || index >= r.Series().Len() {\n\t\treturn 0\n\t}\n\n\t// Get current and past prices\n\tcurrentCandle := r.Series().GetCandle(index)\n\tpastCandle := r.Series().GetCandle(index - lookback)\n\tif currentCandle == nil || pastCandle == nil {\n\t\treturn 0\n\t}\n\n\tcurrentPrice := currentCandle.Close\n\tpastPrice := pastCandle.Close\n\n\t// Get current and past RSI\n\tcurrentRSI := r.Calculate(index)\n\tpastRSI := r.Calculate(index - lookback)\n\n\t// Check for divergence\n\tpriceUp := currentPrice.GreaterThan(pastPrice)\n\trsiUp := currentRSI.GreaterThan(pastRSI)\n\n\t// Bearish divergence: price up, RSI down\n\tif priceUp && !rsiUp {\n\t\treturn -1\n\t}\n\n\t// Bullish divergence: price down, RSI up\n\tif !priceUp && rsiUp {\n\t\treturn 1\n\t}\n\n\treturn 0\n}\n","numLines":266,"startLine":1,"totalLines":266}}}
{"parentUuid":"4aa75546-f06b-4267-82bd-c93aa9b3163d","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01U8noUM1kWHeBeWs6Wfutvk","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_016a8bjSjfqGLWPYWbzEB3CJ","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/indicators/indicator.go"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":3637,"cache_read_input_tokens":73413,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5YzPvrryWkodDbidPmN","type":"assistant","uuid":"aefc5597-5132-4bbd-ac8e-ab1d44d2882e","timestamp":"2025-08-13T10:29:21.917Z"}
{"parentUuid":"aefc5597-5132-4bbd-ac8e-ab1d44d2882e","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016a8bjSjfqGLWPYWbzEB3CJ","type":"tool_result","content":"     1→// Package indicators provides technical analysis indicators for trading strategies.\n     2→// It includes implementations of popular indicators like RSI, ATR, SMA, and custom indicators\n     3→// for mean reversion strategies. All indicators are designed to work with decimal precision.\n     4→package indicators\n     5→\n     6→import (\n     7→\t// \"bigmeanie/pkg/interfaces\" - now using local interfaces\n     8→\n     9→\t\"github.com/shopspring/decimal\"\n    10→)\n    11→\n    12→// Note: Indicator interface is defined in interfaces.go\n    13→\n    14→// Base provides common functionality for all indicators\n    15→type Base struct {\n    16→\tseries TimeSeries\n    17→\tname   string\n    18→}\n    19→\n    20→// NewBase creates a new base indicator\n    21→func NewBase(series TimeSeries, name string) Base {\n    22→\treturn Base{\n    23→\t\tseries: series,\n    24→\t\tname:   name,\n    25→\t}\n    26→}\n    27→\n    28→// Series returns the underlying time series\n    29→func (b *Base) Series() TimeSeries {\n    30→\treturn b.series\n    31→}\n    32→\n    33→// Name returns the indicator name\n    34→func (b *Base) Name() string {\n    35→\treturn b.name\n    36→}\n    37→\n    38→// ValidIndex checks if the index is valid for calculation\n    39→func (b *Base) ValidIndex(index int) bool {\n    40→\treturn index >= 0 && index <= b.series.LastIndex()\n    41→}\n    42→\n    43→// Cached wraps an indicator with caching for performance\n    44→type Cached struct {\n    45→\tindicator Indicator\n    46→\tcache     map[int]decimal.Decimal\n    47→}\n    48→\n    49→// NewCached creates a new cached indicator wrapper\n    50→func NewCached(indicator Indicator) *Cached {\n    51→\treturn &Cached{\n    52→\t\tindicator: indicator,\n    53→\t\tcache:     make(map[int]decimal.Decimal),\n    54→\t}\n    55→}\n    56→\n    57→// Calculate returns the cached value or calculates and caches it\n    58→func (c *Cached) Calculate(index int) decimal.Decimal {\n    59→\tif value, exists := c.cache[index]; exists {\n    60→\t\treturn value\n    61→\t}\n    62→\n    63→\tvalue := c.indicator.Calculate(index)\n    64→\tc.cache[index] = value\n    65→\treturn value\n    66→}\n    67→\n    68→// Name returns the wrapped indicator's name\n    69→func (c *Cached) Name() string {\n    70→\treturn c.indicator.Name()\n    71→}\n    72→\n    73→// RequiredBars returns the wrapped indicator's required bars\n    74→func (c *Cached) RequiredBars() int {\n    75→\treturn c.indicator.RequiredBars()\n    76→}\n    77→\n    78→// ClearCache removes all cached values\n    79→func (c *Cached) ClearCache() {\n    80→\tc.cache = make(map[int]decimal.Decimal)\n    81→}\n    82→\n    83→// InvalidateFrom removes cached values from the specified index onward\n    84→func (c *Cached) InvalidateFrom(index int) {\n    85→\tfor k := range c.cache {\n    86→\t\tif k >= index {\n    87→\t\t\tdelete(c.cache, k)\n    88→\t\t}\n    89→\t}\n    90→}\n    91→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"8b4f68ac-c540-4aa1-a3cf-f41b761afe92","timestamp":"2025-08-13T10:29:21.978Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/pkg/indicators/indicator.go","content":"// Package indicators provides technical analysis indicators for trading strategies.\n// It includes implementations of popular indicators like RSI, ATR, SMA, and custom indicators\n// for mean reversion strategies. All indicators are designed to work with decimal precision.\npackage indicators\n\nimport (\n\t// \"bigmeanie/pkg/interfaces\" - now using local interfaces\n\n\t\"github.com/shopspring/decimal\"\n)\n\n// Note: Indicator interface is defined in interfaces.go\n\n// Base provides common functionality for all indicators\ntype Base struct {\n\tseries TimeSeries\n\tname   string\n}\n\n// NewBase creates a new base indicator\nfunc NewBase(series TimeSeries, name string) Base {\n\treturn Base{\n\t\tseries: series,\n\t\tname:   name,\n\t}\n}\n\n// Series returns the underlying time series\nfunc (b *Base) Series() TimeSeries {\n\treturn b.series\n}\n\n// Name returns the indicator name\nfunc (b *Base) Name() string {\n\treturn b.name\n}\n\n// ValidIndex checks if the index is valid for calculation\nfunc (b *Base) ValidIndex(index int) bool {\n\treturn index >= 0 && index <= b.series.LastIndex()\n}\n\n// Cached wraps an indicator with caching for performance\ntype Cached struct {\n\tindicator Indicator\n\tcache     map[int]decimal.Decimal\n}\n\n// NewCached creates a new cached indicator wrapper\nfunc NewCached(indicator Indicator) *Cached {\n\treturn &Cached{\n\t\tindicator: indicator,\n\t\tcache:     make(map[int]decimal.Decimal),\n\t}\n}\n\n// Calculate returns the cached value or calculates and caches it\nfunc (c *Cached) Calculate(index int) decimal.Decimal {\n\tif value, exists := c.cache[index]; exists {\n\t\treturn value\n\t}\n\n\tvalue := c.indicator.Calculate(index)\n\tc.cache[index] = value\n\treturn value\n}\n\n// Name returns the wrapped indicator's name\nfunc (c *Cached) Name() string {\n\treturn c.indicator.Name()\n}\n\n// RequiredBars returns the wrapped indicator's required bars\nfunc (c *Cached) RequiredBars() int {\n\treturn c.indicator.RequiredBars()\n}\n\n// ClearCache removes all cached values\nfunc (c *Cached) ClearCache() {\n\tc.cache = make(map[int]decimal.Decimal)\n}\n\n// InvalidateFrom removes cached values from the specified index onward\nfunc (c *Cached) InvalidateFrom(index int) {\n\tfor k := range c.cache {\n\t\tif k >= index {\n\t\t\tdelete(c.cache, k)\n\t\t}\n\t}\n}\n","numLines":91,"startLine":1,"totalLines":91}}}
{"parentUuid":"8b4f68ac-c540-4aa1-a3cf-f41b761afe92","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01H1VcDp1poouzU6ueXLdL9H","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01TkpWTQJ3LPrJ9GEpSEUiGD","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/indicators/interfaces.go"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1077,"cache_read_input_tokens":77050,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5Yze8tKQYW5xAG9aMx8","type":"assistant","uuid":"e5e4bea1-5ef6-4dc4-83d1-cb6c41b77b43","timestamp":"2025-08-13T10:29:24.572Z"}
{"parentUuid":"e5e4bea1-5ef6-4dc4-83d1-cb6c41b77b43","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TkpWTQJ3LPrJ9GEpSEUiGD","type":"tool_result","content":"     1→package indicators\n     2→\n     3→import (\n     4→\t\"bigmeanie/pkg/types\"\n     5→\t\"github.com/shopspring/decimal\"\n     6→)\n     7→\n     8→// TimeSeries defines what indicators need from a time series\n     9→type TimeSeries interface {\n    10→\t// Symbol returns the symbol for this time series\n    11→\tSymbol() string\n    12→\n    13→\t// Len returns the number of candles in the series\n    14→\tLen() int\n    15→\n    16→\t// GetCandle returns the candle at the given index\n    17→\tGetCandle(index int) *types.Candle\n    18→\n    19→\t// LastCandle returns the most recent candle\n    20→\tLastCandle() *types.Candle\n    21→\n    22→\t// LastIndex returns the index of the last candle\n    23→\tLastIndex() int\n    24→}\n    25→\n    26→// Indicator is the base interface for all technical indicators\n    27→type Indicator interface {\n    28→\t// Calculate returns the indicator value at the given index\n    29→\tCalculate(index int) decimal.Decimal\n    30→\t\n    31→\t// RequiredBars returns the minimum number of bars needed for calculation\n    32→\tRequiredBars() int\n    33→\t\n    34→\t// Name returns the indicator name with parameters\n    35→\tName() string\n    36→\t\n    37→\t// Series returns the underlying time series\n    38→\tSeries() TimeSeries\n    39→}\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"b7d71ed8-aa69-4ed0-9ff4-7183521942e6","timestamp":"2025-08-13T10:29:24.621Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/pkg/indicators/interfaces.go","content":"package indicators\n\nimport (\n\t\"bigmeanie/pkg/types\"\n\t\"github.com/shopspring/decimal\"\n)\n\n// TimeSeries defines what indicators need from a time series\ntype TimeSeries interface {\n\t// Symbol returns the symbol for this time series\n\tSymbol() string\n\n\t// Len returns the number of candles in the series\n\tLen() int\n\n\t// GetCandle returns the candle at the given index\n\tGetCandle(index int) *types.Candle\n\n\t// LastCandle returns the most recent candle\n\tLastCandle() *types.Candle\n\n\t// LastIndex returns the index of the last candle\n\tLastIndex() int\n}\n\n// Indicator is the base interface for all technical indicators\ntype Indicator interface {\n\t// Calculate returns the indicator value at the given index\n\tCalculate(index int) decimal.Decimal\n\t\n\t// RequiredBars returns the minimum number of bars needed for calculation\n\tRequiredBars() int\n\t\n\t// Name returns the indicator name with parameters\n\tName() string\n\t\n\t// Series returns the underlying time series\n\tSeries() TimeSeries\n}","numLines":39,"startLine":1,"totalLines":39}}}
{"parentUuid":"b7d71ed8-aa69-4ed0-9ff4-7183521942e6","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01M4exzfZwuAQ1LkKgVT1YzF","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Now let me examine some more files to get a complete picture of the codebase patterns:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":540,"cache_read_input_tokens":78127,"output_tokens":77,"service_tier":"standard"}},"requestId":"req_011CS5YzqRHZu4QyUFGooaob","type":"assistant","uuid":"a6bff3cc-a48e-4a63-820b-7b9b2731f945","timestamp":"2025-08-13T10:29:27.154Z"}
{"parentUuid":"a6bff3cc-a48e-4a63-820b-7b9b2731f945","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01M4exzfZwuAQ1LkKgVT1YzF","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_0152wk35bLZu71VkZ8MtahXT","name":"Glob","input":{"pattern":"back/pkg/*/*.md"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":540,"cache_read_input_tokens":78127,"output_tokens":77,"service_tier":"standard"}},"requestId":"req_011CS5YzqRHZu4QyUFGooaob","type":"assistant","uuid":"68f443f9-a89f-4762-8719-fad3712e5a72","timestamp":"2025-08-13T10:29:27.387Z"}
{"parentUuid":"68f443f9-a89f-4762-8719-fad3712e5a72","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0152wk35bLZu71VkZ8MtahXT","type":"tool_result","content":"/home/aural/Code/bigmeanie/back/pkg/clock/README.md\n/home/aural/Code/bigmeanie/back/pkg/goroutine/README.md\n/home/aural/Code/bigmeanie/back/pkg/decimal_math/README.md\n/home/aural/Code/bigmeanie/back/pkg/indicators/README.md\n/home/aural/Code/bigmeanie/back/pkg/errors/README.md"}]},"uuid":"0db5f012-487e-4c3c-97f7-ba2c12210508","timestamp":"2025-08-13T10:29:27.446Z","toolUseResult":{"filenames":["/home/aural/Code/bigmeanie/back/pkg/clock/README.md","/home/aural/Code/bigmeanie/back/pkg/goroutine/README.md","/home/aural/Code/bigmeanie/back/pkg/decimal_math/README.md","/home/aural/Code/bigmeanie/back/pkg/indicators/README.md","/home/aural/Code/bigmeanie/back/pkg/errors/README.md"],"durationMs":3,"numFiles":5,"truncated":false}}
{"parentUuid":"0db5f012-487e-4c3c-97f7-ba2c12210508","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01S7FuhwyKneL3VRLy1f6bJa","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_0181xYMqdAjoqjz21VccHML7","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/errors/README.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":201,"cache_read_input_tokens":78667,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5Z13Y3sh6M3Em1Su21b","type":"assistant","uuid":"779356cc-797e-428c-a038-e0ad2fa9118b","timestamp":"2025-08-13T10:29:29.487Z"}
{"parentUuid":"779356cc-797e-428c-a038-e0ad2fa9118b","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0181xYMqdAjoqjz21VccHML7","type":"tool_result","content":"     1→# Errors Package\n     2→\n     3→Structured error handling framework designed specifically for financial trading operations, providing rich context, automatic retry detection, and comprehensive error categorization.\n     4→\n     5→## Key Features\n     6→\n     7→- **Error Categorization**: Predefined error types for consistent handling across the trading system\n     8→- **Trading Context**: Symbol, order, and operation-specific information attached to errors\n     9→- **Automatic Retry Logic**: Built-in retry detection based on error types\n    10→- **Stack Traces**: Captured for fatal errors (opt-in for others) to aid debugging\n    11→- **Zero Dependencies**: Uses only Go standard library for maximum compatibility\n    12→- **High Performance**: ~27ns basic error creation, ~45ns with context\n    13→\n    14→## Error Types\n    15→\n    16→| Type | Description | Retryable | Stack Trace | Use Case |\n    17→|------|-------------|-----------|-------------|----------|\n    18→| `ErrTypeRetryable` | Generic retryable error | ✓ | | Temporary service unavailable |\n    19→| `ErrTypeConnection` | Network/connection issues | ✓ | | Connection timeout, DNS failure |\n    20→| `ErrTypeRateLimit` | API rate limit exceeded | ✓ | | 429 Too Many Requests |\n    21→| `ErrTypeTimeout` | Operation timeout | ✓ | | Request timeout |\n    22→| `ErrTypeFatal` | Non-recoverable error | | ✓ | Critical configuration error |\n    23→| `ErrTypeConfiguration` | Config issues | | ✓ | Missing required config |\n    24→| `ErrTypeAuth` | Authentication failure | | ✓ | Invalid API credentials |\n    25→| `ErrTypeValidation` | Input validation error | | | Invalid order size |\n    26→| `ErrTypeMarket` | Market-related error | | | Market closed, halted |\n    27→| `ErrTypeOrder` | Order-specific error | | | Order rejected by exchange |\n    28→| `ErrTypeInsufficientFunds` | Not enough balance | | | Insufficient balance/margin |\n    29→| `ErrTypeData` | Data integrity issues | | | Malformed JSON response |\n    30→| `ErrTypeUnknown` | Uncategorized errors | | | Fallback for unknown errors |\n    31→\n    32→## Usage Examples\n    33→\n    34→### Creating Errors\n    35→\n    36→```go\n    37→import \"github.com/bigmeanie/trading/pkg/errors\"\n    38→\n    39→// Simple error\n    40→err := errors.New(\"OrderExecutor.PlaceOrder\", errors.ErrTypeRetryable, apiErr)\n    41→\n    42→// Error with formatting\n    43→err := errors.Newf(\"Config.Validate\", errors.ErrTypeValidation, \n    44→    \"invalid order size: %v\", size)\n    45→\n    46→// Error with context\n    47→err := errors.New(\"OrderExecutor.PlaceOrder\", errors.ErrTypeOrder, apiErr).\n    48→    WithSymbol(\"BTC-USD\").\n    49→    WithContext(\"orderType\", \"MARKET\").\n    50→    WithContext(\"size\", 0.1)\n    51→\n    52→// Force stack trace capture\n    53→err := errors.New(\"DataCollector.Fetch\", errors.ErrTypeRetryable, apiErr).\n    54→    WithStack()\n    55→```\n    56→\n    57→### Wrapping Errors\n    58→\n    59→```go\n    60→// Wrap existing error with new context\n    61→if err := api.GetOrder(orderID); err != nil {\n    62→    return errors.Wrap(\"OrderService.GetStatus\", errors.ErrTypeRetryable, err)\n    63→}\n    64→\n    65→// Wrap preserves TradingError context\n    66→originalErr := someOperation() // returns TradingError with symbol\n    67→wrappedErr := errors.Wrap(\"HigherLevel.Operation\", errors.ErrTypeRetryable, originalErr)\n    68→// wrappedErr still has the symbol from originalErr\n    69→```\n    70→\n    71→### Error Checking\n    72→\n    73→```go\n    74→// Check if error is retryable\n    75→if errors.IsRetryable(err) {\n    76→    return retryWithBackoff(operation)\n    77→}\n    78→\n    79→// Check specific error type\n    80→if errors.IsType(err, errors.ErrTypeRateLimit) {\n    81→    time.Sleep(rateLimitDelay)\n    82→    return retry(operation)\n    83→}\n    84→\n    85→// Check if fatal\n    86→if errors.IsFatal(err) {\n    87→    // Shut down gracefully\n    88→    return shutdownSystem(err)\n    89→}\n    90→\n    91→// Get error type\n    92→switch errors.GetType(err) {\n    93→case errors.ErrTypeInsufficientFunds:\n    94→    return handleInsufficientFunds()\n    95→case errors.ErrTypeAuth:\n    96→    return refreshAuthentication()\n    97→}\n    98→\n    99→// Extract context\n   100→if ctx := errors.GetContext(err); ctx != nil {\n   101→    orderID := ctx[\"orderID\"].(string)\n   102→    // Use context information\n   103→}\n   104→```\n   105→\n   106→### Integration with Standard Errors\n   107→\n   108→```go\n   109→// Works with errors.Is\n   110→var ErrOrderNotFound = errors.New(\"OrderService\", errors.ErrTypeOrder, \n   111→    fmt.Errorf(\"order not found\"))\n   112→\n   113→if errors.Is(err, ErrOrderNotFound) {\n   114→    // Handle missing order\n   115→}\n   116→\n   117→// Works with errors.As\n   118→var tradingErr *errors.TradingError\n   119→if errors.As(err, &tradingErr) {\n   120→    log.Printf(\"Operation failed: %s, Symbol: %s\", \n   121→        tradingErr.Op, tradingErr.Symbol)\n   122→}\n   123→```\n   124→\n   125→## Migration Guide\n   126→\n   127→### Before (Old Pattern)\n   128→```go\n   129→func (e *OrderExecutor) PlaceOrder(order *Order) error {\n   130→    resp, err := e.api.CreateOrder(order)\n   131→    if err != nil {\n   132→        return fmt.Errorf(\"failed to place order: %w\", err)\n   133→    }\n   134→    // ...\n   135→}\n   136→```\n   137→\n   138→### After (New Pattern)\n   139→```go\n   140→func (e *OrderExecutor) PlaceOrder(order *Order) error {\n   141→    resp, err := e.api.CreateOrder(order)\n   142→    if err != nil {\n   143→        // Determine error type based on error content\n   144→        errType := errors.ErrTypeRetryable\n   145→        if strings.Contains(err.Error(), \"insufficient funds\") {\n   146→            errType = errors.ErrTypeInsufficientFunds\n   147→        } else if strings.Contains(err.Error(), \"rate limit\") {\n   148→            errType = errors.ErrTypeRateLimit\n   149→        }\n   150→        \n   151→        return errors.New(\"OrderExecutor.PlaceOrder\", errType, err).\n   152→            WithSymbol(order.Symbol).\n   153→            WithContext(\"orderType\", order.Type).\n   154→            WithContext(\"size\", order.Size)\n   155→    }\n   156→    // ...\n   157→}\n   158→```\n   159→\n   160→## Best Practices\n   161→\n   162→1. **Operation Naming**: Use `Package.Method` or `Type.Method` format\n   163→   ```go\n   164→   errors.New(\"OrderExecutor.PlaceOrder\", ...)\n   165→   errors.New(\"Config.Validate\", ...)\n   166→   ```\n   167→\n   168→2. **Error Type Selection**: Choose the most specific error type\n   169→   ```go\n   170→   // Good: Specific error type\n   171→   errors.New(\"API.GetBalance\", errors.ErrTypeInsufficientFunds, err)\n   172→   \n   173→   // Avoid: Generic error type when specific one exists\n   174→   errors.New(\"API.GetBalance\", errors.ErrTypeRetryable, err)\n   175→   ```\n   176→\n   177→3. **Context Addition**: Add relevant context for debugging\n   178→   ```go\n   179→   err.WithSymbol(symbol).\n   180→       WithContext(\"orderID\", orderID).\n   181→       WithContext(\"attemptCount\", attempts)\n   182→   ```\n   183→\n   184→4. **Stack Traces**: Only force stack traces when needed\n   185→   ```go\n   186→   // Good: Stack trace for unexpected errors\n   187→   if unexpectedCondition {\n   188→       return errors.New(\"Service.Method\", errors.ErrTypeData, err).\n   189→           WithStack()\n   190→   }\n   191→   ```\n   192→\n   193→## Performance Considerations\n   194→\n   195→- Stack traces are only captured for Fatal, Configuration, and Auth errors by default\n   196→- Use `WithStack()` sparingly in hot paths\n   197→- Context map is lazily initialized\n   198→- Error creation is allocation-efficient\n   199→\n   200→## Logging Integration\n   201→\n   202→```go\n   203→// With structured logging\n   204→logger.Error(\"operation failed\",\n   205→    \"error\", err.Error(),\n   206→    \"errorType\", errors.GetType(err).String(),\n   207→    \"symbol\", tradingErr.Symbol,\n   208→    \"context\", errors.GetContext(err),\n   209→)\n   210→\n   211→// Extract stack trace for fatal errors\n   212→var tradingErr *errors.TradingError\n   213→if errors.As(err, &tradingErr) && tradingErr.Stack != \"\" {\n   214→    logger.Error(\"fatal error with stack\", \n   215→        \"stack\", tradingErr.Stack)\n   216→}\n   217→```\n   218→\n   219→## Examples\n   220→\n   221→### Basic Error Creation\n   222→```go\n   223→err := errors.New(\"OrderService.PlaceOrder\", errors.ErrTypeRetryable,\n   224→    fmt.Errorf(\"API timeout\"))\n   225→// Output: OrderService.PlaceOrder: Retryable: API timeout\n   226→```\n   227→\n   228→### Error with Context\n   229→```go\n   230→err := errors.New(\"OrderExecutor.Execute\", errors.ErrTypeOrder,\n   231→    fmt.Errorf(\"order rejected\")).\n   232→    WithSymbol(\"BTC-USD\").\n   233→    WithContext(\"orderID\", \"12345\").\n   234→    WithContext(\"reason\", \"insufficient balance\")\n   235→// Output: OrderExecutor.Execute: Order [BTC-USD]: order rejected\n   236→```\n   237→\n   238→### Retry Logic with Error Framework\n   239→```go\n   240→func ExecuteWithRetry(operation func() error, maxRetries int) error {\n   241→    var lastErr error\n   242→    \n   243→    for i := 0; i < maxRetries; i++ {\n   244→        err := operation()\n   245→        if err == nil {\n   246→            return nil\n   247→        }\n   248→        \n   249→        lastErr = err\n   250→        \n   251→        // Only retry if error is retryable\n   252→        if !errors.IsRetryable(err) {\n   253→            return err\n   254→        }\n   255→        \n   256→        // Exponential backoff for rate limits\n   257→        if errors.IsType(err, errors.ErrTypeRateLimit) {\n   258→            time.Sleep(time.Duration(math.Pow(2, float64(i))) * time.Second)\n   259→        } else {\n   260→            time.Sleep(time.Second * time.Duration(i+1))\n   261→        }\n   262→    }\n   263→    \n   264→    return lastErr\n   265→}\n   266→```\n   267→\n   268→### API Error Handling Pattern\n   269→```go\n   270→func (c *Client) PlaceOrder(req OrderRequest) (*OrderResponse, error) {\n   271→    resp, err := c.doRequest(\"POST\", \"/orders\", req)\n   272→    if err != nil {\n   273→        // Categorize by HTTP status or error message\n   274→        if isRateLimitError(err) {\n   275→            return nil, errors.Wrap(\"Client.PlaceOrder\", errors.ErrTypeRateLimit, err).\n   276→                WithSymbol(req.ProductID)\n   277→        }\n   278→        if isAuthError(err) {\n   279→            return nil, errors.Wrap(\"Client.PlaceOrder\", errors.ErrTypeAuth, err)\n   280→        }\n   281→        return nil, errors.Wrap(\"Client.PlaceOrder\", errors.ErrTypeConnection, err).\n   282→            WithSymbol(req.ProductID)\n   283→    }\n   284→    \n   285→    return parseOrderResponse(resp)\n   286→}\n   287→```\n   288→\n   289→### Wrapping External Errors\n   290→\n   291→```go\n   292→import (\n   293→    \"database/sql\"\n   294→    \"encoding/json\"\n   295→    \"io\"\n   296→    \"net/http\"\n   297→    \"os\"\n   298→    \"github.com/dominicnunez/bigmeanie/back/pkg/errors\"\n   299→)\n   300→\n   301→// Wrapping standard library errors\n   302→func ReadConfig(path string) (*Config, error) {\n   303→    data, err := os.ReadFile(path)\n   304→    if err != nil {\n   305→        // Wrap os package errors\n   306→        if os.IsNotExist(err) {\n   307→            return nil, errors.Wrap(\"Config.ReadConfig\", errors.ErrTypeConfiguration, err).\n   308→                WithContext(\"path\", path).\n   309→                WithContext(\"reason\", \"config file not found\")\n   310→        }\n   311→        if os.IsPermission(err) {\n   312→            return nil, errors.Wrap(\"Config.ReadConfig\", errors.ErrTypeFatal, err).\n   313→                WithContext(\"path\", path).\n   314→                WithContext(\"reason\", \"permission denied\")\n   315→        }\n   316→        return nil, errors.Wrap(\"Config.ReadConfig\", errors.ErrTypeUnknown, err).\n   317→            WithContext(\"path\", path)\n   318→    }\n   319→    \n   320→    var config Config\n   321→    if err := json.Unmarshal(data, &config); err != nil {\n   322→        // Wrap JSON errors\n   323→        return nil, errors.Wrap(\"Config.ReadConfig\", errors.ErrTypeData, err).\n   324→            WithContext(\"path\", path).\n   325→            WithContext(\"reason\", \"invalid JSON format\")\n   326→    }\n   327→    \n   328→    return &config, nil\n   329→}\n   330→\n   331→// Wrapping HTTP client errors\n   332→func (c *APIClient) MakeRequest(endpoint string) (*Response, error) {\n   333→    resp, err := http.Get(c.baseURL + endpoint)\n   334→    if err != nil {\n   335→        // Wrap network errors\n   336→        return nil, errors.Wrap(\"APIClient.MakeRequest\", errors.ErrTypeConnection, err).\n   337→            WithContext(\"endpoint\", endpoint)\n   338→    }\n   339→    defer resp.Body.Close()\n   340→    \n   341→    if resp.StatusCode == http.StatusTooManyRequests {\n   342→        return nil, errors.New(\"APIClient.MakeRequest\", errors.ErrTypeRateLimit,\n   343→            fmt.Errorf(\"rate limited: status %d\", resp.StatusCode)).\n   344→            WithContext(\"endpoint\", endpoint)\n   345→    }\n   346→    \n   347→    if resp.StatusCode >= 500 {\n   348→        return nil, errors.New(\"APIClient.MakeRequest\", errors.ErrTypeRetryable,\n   349→            fmt.Errorf(\"server error: status %d\", resp.StatusCode)).\n   350→            WithContext(\"endpoint\", endpoint)\n   351→    }\n   352→    \n   353→    body, err := io.ReadAll(resp.Body)\n   354→    if err != nil {\n   355→        // Wrap IO errors\n   356→        return nil, errors.Wrap(\"APIClient.MakeRequest\", errors.ErrTypeData, err).\n   357→            WithContext(\"endpoint\", endpoint).\n   358→            WithContext(\"reason\", \"failed to read response body\")\n   359→    }\n   360→    \n   361→    var response Response\n   362→    if err := json.Unmarshal(body, &response); err != nil {\n   363→        // Wrap JSON parsing errors\n   364→        return nil, errors.Wrap(\"APIClient.MakeRequest\", errors.ErrTypeData, err).\n   365→            WithContext(\"endpoint\", endpoint).\n   366→            WithContext(\"body\", string(body)).\n   367→            WithContext(\"reason\", \"invalid response format\")\n   368→    }\n   369→    \n   370→    return &response, nil\n   371→}\n   372→\n   373→// Wrapping database errors\n   374→func (r *OrderRepository) GetOrder(id string) (*Order, error) {\n   375→    var order Order\n   376→    err := r.db.QueryRow(\"SELECT * FROM orders WHERE id = $1\", id).Scan(&order)\n   377→    if err != nil {\n   378→        // Handle specific database errors\n   379→        if err == sql.ErrNoRows {\n   380→            return nil, errors.Wrap(\"OrderRepository.GetOrder\", errors.ErrTypeOrder, err).\n   381→                WithContext(\"orderID\", id).\n   382→                WithContext(\"reason\", \"order not found\")\n   383→        }\n   384→        \n   385→        // Connection errors are retryable\n   386→        if isConnectionError(err) {\n   387→            return nil, errors.Wrap(\"OrderRepository.GetOrder\", errors.ErrTypeConnection, err).\n   388→                WithContext(\"orderID\", id)\n   389→        }\n   390→        \n   391→        // Generic database error\n   392→        return nil, errors.Wrap(\"OrderRepository.GetOrder\", errors.ErrTypeData, err).\n   393→            WithContext(\"orderID\", id)\n   394→    }\n   395→    \n   396→    return &order, nil\n   397→}\n   398→\n   399→// Wrapping third-party library errors (example with a hypothetical exchange SDK)\n   400→func (e *ExchangeClient) CancelOrder(orderID string) error {\n   401→    err := e.sdk.CancelOrder(orderID)\n   402→    if err != nil {\n   403→        // Map third-party error codes to our error types\n   404→        switch sdkErr := err.(type) {\n   405→        case *sdk.RateLimitError:\n   406→            return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeRateLimit, err).\n   407→                WithContext(\"orderID\", orderID).\n   408→                WithContext(\"retryAfter\", sdkErr.RetryAfter)\n   409→        \n   410→        case *sdk.AuthenticationError:\n   411→            return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeAuth, err).\n   412→                WithContext(\"orderID\", orderID)\n   413→        \n   414→        case *sdk.OrderNotFoundError:\n   415→            return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeOrder, err).\n   416→                WithContext(\"orderID\", orderID).\n   417→                WithContext(\"reason\", \"order not found or already cancelled\")\n   418→        \n   419→        default:\n   420→            // Analyze error message for categorization\n   421→            errMsg := err.Error()\n   422→            if strings.Contains(errMsg, \"timeout\") {\n   423→                return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeTimeout, err).\n   424→                    WithContext(\"orderID\", orderID)\n   425→            }\n   426→            if strings.Contains(errMsg, \"connection\") {\n   427→                return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeConnection, err).\n   428→                    WithContext(\"orderID\", orderID)\n   429→            }\n   430→            \n   431→            // Default to unknown type\n   432→            return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeUnknown, err).\n   433→                WithContext(\"orderID\", orderID)\n   434→        }\n   435→    }\n   436→    \n   437→    return nil\n   438→}\n   439→```\n   440→\n   441→### Database Error Handling Pattern\n   442→```go\n   443→func (s *OrderService) SaveOrder(order *Order) error {\n   444→    if err := s.db.Create(order).Error; err != nil {\n   445→        // Check for specific database errors\n   446→        if strings.Contains(err.Error(), \"duplicate key\") {\n   447→            return errors.Wrap(\"OrderService.SaveOrder\", errors.ErrTypeValidation, err).\n   448→                WithContext(\"orderID\", order.ID).\n   449→                WithContext(\"reason\", \"duplicate order\")\n   450→        }\n   451→        \n   452→        // Connection errors are retryable\n   453→        if isConnectionError(err) {\n   454→            return errors.Wrap(\"OrderService.SaveOrder\", errors.ErrTypeConnection, err).\n   455→                WithContext(\"orderID\", order.ID)\n   456→        }\n   457→        \n   458→        // Default to data error\n   459→        return errors.Wrap(\"OrderService.SaveOrder\", errors.ErrTypeData, err).\n   460→            WithContext(\"orderID\", order.ID)\n   461→    }\n   462→    \n   463→    return nil\n   464→}\n   465→```\n   466→\n   467→## Testing\n   468→\n   469→```go\n   470→// Test error types\n   471→func TestPlaceOrder_InsufficientFunds(t *testing.T) {\n   472→    err := executor.PlaceOrder(order)\n   473→    assert.True(t, errors.IsType(err, errors.ErrTypeInsufficientFunds))\n   474→}\n   475→\n   476→// Test retry logic\n   477→func TestPlaceOrder_Retry(t *testing.T) {\n   478→    err := executor.PlaceOrder(order)\n   479→    assert.True(t, errors.IsRetryable(err))\n   480→}\n   481→\n   482→// Test error context extraction\n   483→func TestErrorContext(t *testing.T) {\n   484→    err := errors.New(\"Test\", errors.ErrTypeOrder, nil).\n   485→        WithSymbol(\"BTC-USD\").\n   486→        WithContext(\"orderID\", \"12345\")\n   487→    \n   488→    ctx := errors.GetContext(err)\n   489→    assert.Equal(t, \"12345\", ctx[\"orderID\"])\n   490→}\n   491→```\n   492→\n   493→## Performance Characteristics\n   494→\n   495→- **Basic error creation**: ~27ns overhead\n   496→- **With context**: ~45ns overhead  \n   497→- **Stack traces**: Only captured for Fatal, Configuration, and Auth errors by default\n   498→- **Zero allocations**: For basic error creation without context\n   499→- **Memory efficient**: Context stored as map[string]interface{}, lazily initialized\n   500→\n   501→## Important Notes\n   502→\n   503→1. **Stack traces are expensive** - Only force them with `WithStack()` when absolutely necessary\n   504→2. **Context is preserved** - When wrapping TradingErrors, the original context is maintained\n   505→3. **Error chains work** - Compatible with standard library `errors.Is()` and `errors.As()`\n   506→4. **Retryable types** - Connection, RateLimit, Timeout, and generic Retryable are automatically retryable\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d839c922-c9a1-4f6b-ab37-4fe8b426e33d","timestamp":"2025-08-13T10:29:29.542Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/pkg/errors/README.md","content":"# Errors Package\n\nStructured error handling framework designed specifically for financial trading operations, providing rich context, automatic retry detection, and comprehensive error categorization.\n\n## Key Features\n\n- **Error Categorization**: Predefined error types for consistent handling across the trading system\n- **Trading Context**: Symbol, order, and operation-specific information attached to errors\n- **Automatic Retry Logic**: Built-in retry detection based on error types\n- **Stack Traces**: Captured for fatal errors (opt-in for others) to aid debugging\n- **Zero Dependencies**: Uses only Go standard library for maximum compatibility\n- **High Performance**: ~27ns basic error creation, ~45ns with context\n\n## Error Types\n\n| Type | Description | Retryable | Stack Trace | Use Case |\n|------|-------------|-----------|-------------|----------|\n| `ErrTypeRetryable` | Generic retryable error | ✓ | | Temporary service unavailable |\n| `ErrTypeConnection` | Network/connection issues | ✓ | | Connection timeout, DNS failure |\n| `ErrTypeRateLimit` | API rate limit exceeded | ✓ | | 429 Too Many Requests |\n| `ErrTypeTimeout` | Operation timeout | ✓ | | Request timeout |\n| `ErrTypeFatal` | Non-recoverable error | | ✓ | Critical configuration error |\n| `ErrTypeConfiguration` | Config issues | | ✓ | Missing required config |\n| `ErrTypeAuth` | Authentication failure | | ✓ | Invalid API credentials |\n| `ErrTypeValidation` | Input validation error | | | Invalid order size |\n| `ErrTypeMarket` | Market-related error | | | Market closed, halted |\n| `ErrTypeOrder` | Order-specific error | | | Order rejected by exchange |\n| `ErrTypeInsufficientFunds` | Not enough balance | | | Insufficient balance/margin |\n| `ErrTypeData` | Data integrity issues | | | Malformed JSON response |\n| `ErrTypeUnknown` | Uncategorized errors | | | Fallback for unknown errors |\n\n## Usage Examples\n\n### Creating Errors\n\n```go\nimport \"github.com/bigmeanie/trading/pkg/errors\"\n\n// Simple error\nerr := errors.New(\"OrderExecutor.PlaceOrder\", errors.ErrTypeRetryable, apiErr)\n\n// Error with formatting\nerr := errors.Newf(\"Config.Validate\", errors.ErrTypeValidation, \n    \"invalid order size: %v\", size)\n\n// Error with context\nerr := errors.New(\"OrderExecutor.PlaceOrder\", errors.ErrTypeOrder, apiErr).\n    WithSymbol(\"BTC-USD\").\n    WithContext(\"orderType\", \"MARKET\").\n    WithContext(\"size\", 0.1)\n\n// Force stack trace capture\nerr := errors.New(\"DataCollector.Fetch\", errors.ErrTypeRetryable, apiErr).\n    WithStack()\n```\n\n### Wrapping Errors\n\n```go\n// Wrap existing error with new context\nif err := api.GetOrder(orderID); err != nil {\n    return errors.Wrap(\"OrderService.GetStatus\", errors.ErrTypeRetryable, err)\n}\n\n// Wrap preserves TradingError context\noriginalErr := someOperation() // returns TradingError with symbol\nwrappedErr := errors.Wrap(\"HigherLevel.Operation\", errors.ErrTypeRetryable, originalErr)\n// wrappedErr still has the symbol from originalErr\n```\n\n### Error Checking\n\n```go\n// Check if error is retryable\nif errors.IsRetryable(err) {\n    return retryWithBackoff(operation)\n}\n\n// Check specific error type\nif errors.IsType(err, errors.ErrTypeRateLimit) {\n    time.Sleep(rateLimitDelay)\n    return retry(operation)\n}\n\n// Check if fatal\nif errors.IsFatal(err) {\n    // Shut down gracefully\n    return shutdownSystem(err)\n}\n\n// Get error type\nswitch errors.GetType(err) {\ncase errors.ErrTypeInsufficientFunds:\n    return handleInsufficientFunds()\ncase errors.ErrTypeAuth:\n    return refreshAuthentication()\n}\n\n// Extract context\nif ctx := errors.GetContext(err); ctx != nil {\n    orderID := ctx[\"orderID\"].(string)\n    // Use context information\n}\n```\n\n### Integration with Standard Errors\n\n```go\n// Works with errors.Is\nvar ErrOrderNotFound = errors.New(\"OrderService\", errors.ErrTypeOrder, \n    fmt.Errorf(\"order not found\"))\n\nif errors.Is(err, ErrOrderNotFound) {\n    // Handle missing order\n}\n\n// Works with errors.As\nvar tradingErr *errors.TradingError\nif errors.As(err, &tradingErr) {\n    log.Printf(\"Operation failed: %s, Symbol: %s\", \n        tradingErr.Op, tradingErr.Symbol)\n}\n```\n\n## Migration Guide\n\n### Before (Old Pattern)\n```go\nfunc (e *OrderExecutor) PlaceOrder(order *Order) error {\n    resp, err := e.api.CreateOrder(order)\n    if err != nil {\n        return fmt.Errorf(\"failed to place order: %w\", err)\n    }\n    // ...\n}\n```\n\n### After (New Pattern)\n```go\nfunc (e *OrderExecutor) PlaceOrder(order *Order) error {\n    resp, err := e.api.CreateOrder(order)\n    if err != nil {\n        // Determine error type based on error content\n        errType := errors.ErrTypeRetryable\n        if strings.Contains(err.Error(), \"insufficient funds\") {\n            errType = errors.ErrTypeInsufficientFunds\n        } else if strings.Contains(err.Error(), \"rate limit\") {\n            errType = errors.ErrTypeRateLimit\n        }\n        \n        return errors.New(\"OrderExecutor.PlaceOrder\", errType, err).\n            WithSymbol(order.Symbol).\n            WithContext(\"orderType\", order.Type).\n            WithContext(\"size\", order.Size)\n    }\n    // ...\n}\n```\n\n## Best Practices\n\n1. **Operation Naming**: Use `Package.Method` or `Type.Method` format\n   ```go\n   errors.New(\"OrderExecutor.PlaceOrder\", ...)\n   errors.New(\"Config.Validate\", ...)\n   ```\n\n2. **Error Type Selection**: Choose the most specific error type\n   ```go\n   // Good: Specific error type\n   errors.New(\"API.GetBalance\", errors.ErrTypeInsufficientFunds, err)\n   \n   // Avoid: Generic error type when specific one exists\n   errors.New(\"API.GetBalance\", errors.ErrTypeRetryable, err)\n   ```\n\n3. **Context Addition**: Add relevant context for debugging\n   ```go\n   err.WithSymbol(symbol).\n       WithContext(\"orderID\", orderID).\n       WithContext(\"attemptCount\", attempts)\n   ```\n\n4. **Stack Traces**: Only force stack traces when needed\n   ```go\n   // Good: Stack trace for unexpected errors\n   if unexpectedCondition {\n       return errors.New(\"Service.Method\", errors.ErrTypeData, err).\n           WithStack()\n   }\n   ```\n\n## Performance Considerations\n\n- Stack traces are only captured for Fatal, Configuration, and Auth errors by default\n- Use `WithStack()` sparingly in hot paths\n- Context map is lazily initialized\n- Error creation is allocation-efficient\n\n## Logging Integration\n\n```go\n// With structured logging\nlogger.Error(\"operation failed\",\n    \"error\", err.Error(),\n    \"errorType\", errors.GetType(err).String(),\n    \"symbol\", tradingErr.Symbol,\n    \"context\", errors.GetContext(err),\n)\n\n// Extract stack trace for fatal errors\nvar tradingErr *errors.TradingError\nif errors.As(err, &tradingErr) && tradingErr.Stack != \"\" {\n    logger.Error(\"fatal error with stack\", \n        \"stack\", tradingErr.Stack)\n}\n```\n\n## Examples\n\n### Basic Error Creation\n```go\nerr := errors.New(\"OrderService.PlaceOrder\", errors.ErrTypeRetryable,\n    fmt.Errorf(\"API timeout\"))\n// Output: OrderService.PlaceOrder: Retryable: API timeout\n```\n\n### Error with Context\n```go\nerr := errors.New(\"OrderExecutor.Execute\", errors.ErrTypeOrder,\n    fmt.Errorf(\"order rejected\")).\n    WithSymbol(\"BTC-USD\").\n    WithContext(\"orderID\", \"12345\").\n    WithContext(\"reason\", \"insufficient balance\")\n// Output: OrderExecutor.Execute: Order [BTC-USD]: order rejected\n```\n\n### Retry Logic with Error Framework\n```go\nfunc ExecuteWithRetry(operation func() error, maxRetries int) error {\n    var lastErr error\n    \n    for i := 0; i < maxRetries; i++ {\n        err := operation()\n        if err == nil {\n            return nil\n        }\n        \n        lastErr = err\n        \n        // Only retry if error is retryable\n        if !errors.IsRetryable(err) {\n            return err\n        }\n        \n        // Exponential backoff for rate limits\n        if errors.IsType(err, errors.ErrTypeRateLimit) {\n            time.Sleep(time.Duration(math.Pow(2, float64(i))) * time.Second)\n        } else {\n            time.Sleep(time.Second * time.Duration(i+1))\n        }\n    }\n    \n    return lastErr\n}\n```\n\n### API Error Handling Pattern\n```go\nfunc (c *Client) PlaceOrder(req OrderRequest) (*OrderResponse, error) {\n    resp, err := c.doRequest(\"POST\", \"/orders\", req)\n    if err != nil {\n        // Categorize by HTTP status or error message\n        if isRateLimitError(err) {\n            return nil, errors.Wrap(\"Client.PlaceOrder\", errors.ErrTypeRateLimit, err).\n                WithSymbol(req.ProductID)\n        }\n        if isAuthError(err) {\n            return nil, errors.Wrap(\"Client.PlaceOrder\", errors.ErrTypeAuth, err)\n        }\n        return nil, errors.Wrap(\"Client.PlaceOrder\", errors.ErrTypeConnection, err).\n            WithSymbol(req.ProductID)\n    }\n    \n    return parseOrderResponse(resp)\n}\n```\n\n### Wrapping External Errors\n\n```go\nimport (\n    \"database/sql\"\n    \"encoding/json\"\n    \"io\"\n    \"net/http\"\n    \"os\"\n    \"github.com/dominicnunez/bigmeanie/back/pkg/errors\"\n)\n\n// Wrapping standard library errors\nfunc ReadConfig(path string) (*Config, error) {\n    data, err := os.ReadFile(path)\n    if err != nil {\n        // Wrap os package errors\n        if os.IsNotExist(err) {\n            return nil, errors.Wrap(\"Config.ReadConfig\", errors.ErrTypeConfiguration, err).\n                WithContext(\"path\", path).\n                WithContext(\"reason\", \"config file not found\")\n        }\n        if os.IsPermission(err) {\n            return nil, errors.Wrap(\"Config.ReadConfig\", errors.ErrTypeFatal, err).\n                WithContext(\"path\", path).\n                WithContext(\"reason\", \"permission denied\")\n        }\n        return nil, errors.Wrap(\"Config.ReadConfig\", errors.ErrTypeUnknown, err).\n            WithContext(\"path\", path)\n    }\n    \n    var config Config\n    if err := json.Unmarshal(data, &config); err != nil {\n        // Wrap JSON errors\n        return nil, errors.Wrap(\"Config.ReadConfig\", errors.ErrTypeData, err).\n            WithContext(\"path\", path).\n            WithContext(\"reason\", \"invalid JSON format\")\n    }\n    \n    return &config, nil\n}\n\n// Wrapping HTTP client errors\nfunc (c *APIClient) MakeRequest(endpoint string) (*Response, error) {\n    resp, err := http.Get(c.baseURL + endpoint)\n    if err != nil {\n        // Wrap network errors\n        return nil, errors.Wrap(\"APIClient.MakeRequest\", errors.ErrTypeConnection, err).\n            WithContext(\"endpoint\", endpoint)\n    }\n    defer resp.Body.Close()\n    \n    if resp.StatusCode == http.StatusTooManyRequests {\n        return nil, errors.New(\"APIClient.MakeRequest\", errors.ErrTypeRateLimit,\n            fmt.Errorf(\"rate limited: status %d\", resp.StatusCode)).\n            WithContext(\"endpoint\", endpoint)\n    }\n    \n    if resp.StatusCode >= 500 {\n        return nil, errors.New(\"APIClient.MakeRequest\", errors.ErrTypeRetryable,\n            fmt.Errorf(\"server error: status %d\", resp.StatusCode)).\n            WithContext(\"endpoint\", endpoint)\n    }\n    \n    body, err := io.ReadAll(resp.Body)\n    if err != nil {\n        // Wrap IO errors\n        return nil, errors.Wrap(\"APIClient.MakeRequest\", errors.ErrTypeData, err).\n            WithContext(\"endpoint\", endpoint).\n            WithContext(\"reason\", \"failed to read response body\")\n    }\n    \n    var response Response\n    if err := json.Unmarshal(body, &response); err != nil {\n        // Wrap JSON parsing errors\n        return nil, errors.Wrap(\"APIClient.MakeRequest\", errors.ErrTypeData, err).\n            WithContext(\"endpoint\", endpoint).\n            WithContext(\"body\", string(body)).\n            WithContext(\"reason\", \"invalid response format\")\n    }\n    \n    return &response, nil\n}\n\n// Wrapping database errors\nfunc (r *OrderRepository) GetOrder(id string) (*Order, error) {\n    var order Order\n    err := r.db.QueryRow(\"SELECT * FROM orders WHERE id = $1\", id).Scan(&order)\n    if err != nil {\n        // Handle specific database errors\n        if err == sql.ErrNoRows {\n            return nil, errors.Wrap(\"OrderRepository.GetOrder\", errors.ErrTypeOrder, err).\n                WithContext(\"orderID\", id).\n                WithContext(\"reason\", \"order not found\")\n        }\n        \n        // Connection errors are retryable\n        if isConnectionError(err) {\n            return nil, errors.Wrap(\"OrderRepository.GetOrder\", errors.ErrTypeConnection, err).\n                WithContext(\"orderID\", id)\n        }\n        \n        // Generic database error\n        return nil, errors.Wrap(\"OrderRepository.GetOrder\", errors.ErrTypeData, err).\n            WithContext(\"orderID\", id)\n    }\n    \n    return &order, nil\n}\n\n// Wrapping third-party library errors (example with a hypothetical exchange SDK)\nfunc (e *ExchangeClient) CancelOrder(orderID string) error {\n    err := e.sdk.CancelOrder(orderID)\n    if err != nil {\n        // Map third-party error codes to our error types\n        switch sdkErr := err.(type) {\n        case *sdk.RateLimitError:\n            return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeRateLimit, err).\n                WithContext(\"orderID\", orderID).\n                WithContext(\"retryAfter\", sdkErr.RetryAfter)\n        \n        case *sdk.AuthenticationError:\n            return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeAuth, err).\n                WithContext(\"orderID\", orderID)\n        \n        case *sdk.OrderNotFoundError:\n            return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeOrder, err).\n                WithContext(\"orderID\", orderID).\n                WithContext(\"reason\", \"order not found or already cancelled\")\n        \n        default:\n            // Analyze error message for categorization\n            errMsg := err.Error()\n            if strings.Contains(errMsg, \"timeout\") {\n                return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeTimeout, err).\n                    WithContext(\"orderID\", orderID)\n            }\n            if strings.Contains(errMsg, \"connection\") {\n                return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeConnection, err).\n                    WithContext(\"orderID\", orderID)\n            }\n            \n            // Default to unknown type\n            return errors.Wrap(\"ExchangeClient.CancelOrder\", errors.ErrTypeUnknown, err).\n                WithContext(\"orderID\", orderID)\n        }\n    }\n    \n    return nil\n}\n```\n\n### Database Error Handling Pattern\n```go\nfunc (s *OrderService) SaveOrder(order *Order) error {\n    if err := s.db.Create(order).Error; err != nil {\n        // Check for specific database errors\n        if strings.Contains(err.Error(), \"duplicate key\") {\n            return errors.Wrap(\"OrderService.SaveOrder\", errors.ErrTypeValidation, err).\n                WithContext(\"orderID\", order.ID).\n                WithContext(\"reason\", \"duplicate order\")\n        }\n        \n        // Connection errors are retryable\n        if isConnectionError(err) {\n            return errors.Wrap(\"OrderService.SaveOrder\", errors.ErrTypeConnection, err).\n                WithContext(\"orderID\", order.ID)\n        }\n        \n        // Default to data error\n        return errors.Wrap(\"OrderService.SaveOrder\", errors.ErrTypeData, err).\n            WithContext(\"orderID\", order.ID)\n    }\n    \n    return nil\n}\n```\n\n## Testing\n\n```go\n// Test error types\nfunc TestPlaceOrder_InsufficientFunds(t *testing.T) {\n    err := executor.PlaceOrder(order)\n    assert.True(t, errors.IsType(err, errors.ErrTypeInsufficientFunds))\n}\n\n// Test retry logic\nfunc TestPlaceOrder_Retry(t *testing.T) {\n    err := executor.PlaceOrder(order)\n    assert.True(t, errors.IsRetryable(err))\n}\n\n// Test error context extraction\nfunc TestErrorContext(t *testing.T) {\n    err := errors.New(\"Test\", errors.ErrTypeOrder, nil).\n        WithSymbol(\"BTC-USD\").\n        WithContext(\"orderID\", \"12345\")\n    \n    ctx := errors.GetContext(err)\n    assert.Equal(t, \"12345\", ctx[\"orderID\"])\n}\n```\n\n## Performance Characteristics\n\n- **Basic error creation**: ~27ns overhead\n- **With context**: ~45ns overhead  \n- **Stack traces**: Only captured for Fatal, Configuration, and Auth errors by default\n- **Zero allocations**: For basic error creation without context\n- **Memory efficient**: Context stored as map[string]interface{}, lazily initialized\n\n## Important Notes\n\n1. **Stack traces are expensive** - Only force them with `WithStack()` when absolutely necessary\n2. **Context is preserved** - When wrapping TradingErrors, the original context is maintained\n3. **Error chains work** - Compatible with standard library `errors.Is()` and `errors.As()`\n4. **Retryable types** - Connection, RateLimit, Timeout, and generic Retryable are automatically retryable","numLines":506,"startLine":1,"totalLines":506}}}
{"parentUuid":"d839c922-c9a1-4f6b-ab37-4fe8b426e33d","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01UF6FfVxo3pNtmhDSizDWNc","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Now let me check one more package to get a complete comparison view:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":6450,"cache_read_input_tokens":78868,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5Z1CeytEjxqrNS3RPEi","type":"assistant","uuid":"9f4f74ab-af64-46b3-ae78-ef6f7432105b","timestamp":"2025-08-13T10:29:32.711Z"}
{"parentUuid":"9f4f74ab-af64-46b3-ae78-ef6f7432105b","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01UF6FfVxo3pNtmhDSizDWNc","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01QAJubq4iqLs9doLV5F42ZZ","name":"Glob","input":{"pattern":"back/pkg/testutil/*"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":6450,"cache_read_input_tokens":78868,"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CS5Z1CeytEjxqrNS3RPEi","type":"assistant","uuid":"1a28b5e1-e8a0-4b87-bc28-5bd08d2e99f9","timestamp":"2025-08-13T10:29:32.951Z"}
{"parentUuid":"1a28b5e1-e8a0-4b87-bc28-5bd08d2e99f9","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QAJubq4iqLs9doLV5F42ZZ","type":"tool_result","content":"No files found"}]},"uuid":"1df6e271-f416-456c-91e5-75151f1c690c","timestamp":"2025-08-13T10:29:33.065Z","toolUseResult":{"filenames":[],"durationMs":2,"numFiles":0,"truncated":false}}
{"parentUuid":"1df6e271-f416-456c-91e5-75151f1c690c","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01RxWg2V1sgtadBgXwkZxK5R","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01AjGcZ2kRjXFsRY51gZEzC3","name":"Glob","input":{"pattern":"back/pkg/*/test*"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":88,"cache_read_input_tokens":85318,"output_tokens":58,"service_tier":"standard"}},"requestId":"req_011CS5Z1TXwBxxgrnvkF3DzB","type":"assistant","uuid":"9e46e05d-a5f8-4af9-8476-fe0cf56df256","timestamp":"2025-08-13T10:29:35.698Z"}
{"parentUuid":"9e46e05d-a5f8-4af9-8476-fe0cf56df256","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01AjGcZ2kRjXFsRY51gZEzC3","type":"tool_result","content":"No files found"}]},"uuid":"a30e94ba-4e0e-42c4-b307-91277b135705","timestamp":"2025-08-13T10:29:35.736Z","toolUseResult":{"filenames":[],"durationMs":2,"numFiles":0,"truncated":false}}
{"parentUuid":"a30e94ba-4e0e-42c4-b307-91277b135705","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01QpdGJ6Z1vtcWn3AhLAiWuW","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01MfJYrbHLqGLBdcqp6BPHys","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/pkg/goroutine/safe.go"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":73,"cache_read_input_tokens":85406,"output_tokens":75,"service_tier":"standard"}},"requestId":"req_011CS5Z1f6x8N9kTLsrTuNn6","type":"assistant","uuid":"dce4ee07-7363-4303-b79f-1e90a748dd6f","timestamp":"2025-08-13T10:29:38.673Z"}
{"parentUuid":"dce4ee07-7363-4303-b79f-1e90a748dd6f","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MfJYrbHLqGLBdcqp6BPHys","type":"tool_result","content":"     1→package goroutine\n     2→\n     3→import (\n     4→\t\"context\"\n     5→\t\"fmt\"\n     6→\t\"runtime/debug\"\n     7→\t\"sync\"\n     8→\t\"sync/atomic\"\n     9→\t\"time\"\n    10→\n    11→\t\"bigmeanie/pkg/logger\"\n    12→)\n    13→\n    14→// RecoveryHandler is a function that handles panics\n    15→type RecoveryHandler func(recovered interface{}, stack []byte)\n    16→\n    17→// Package logger instance\n    18→var log = logger.Component(\"goroutine\")\n    19→\n    20→// Global metrics for monitoring\n    21→var (\n    22→\tactiveGoroutines  atomic.Int64\n    23→\ttotalPanics       atomic.Int64\n    24→\ttotalRestarts     atomic.Int64\n    25→\ttotalGoroutines   atomic.Int64\n    26→)\n    27→\n    28→// Metrics provides goroutine metrics\n    29→type Metrics struct {\n    30→\tActive        int64\n    31→\tTotalPanics   int64\n    32→\tTotalRestarts int64\n    33→\tTotal         int64\n    34→}\n    35→\n    36→// GetMetrics returns current goroutine metrics\n    37→func GetMetrics() Metrics {\n    38→\treturn Metrics{\n    39→\t\tActive:        activeGoroutines.Load(),\n    40→\t\tTotalPanics:   totalPanics.Load(),\n    41→\t\tTotalRestarts: totalRestarts.Load(),\n    42→\t\tTotal:         totalGoroutines.Load(),\n    43→\t}\n    44→}\n    45→\n    46→// defaultRecoveryHandler logs the panic and stack trace\n    47→func defaultRecoveryHandler(recovered interface{}, stack []byte) {\n    48→\ttotalPanics.Add(1)\n    49→\tlog.Errorf(\"PANIC RECOVERED: %v\\nStack trace:\\n%s\", recovered, stack)\n    50→}\n    51→\n    52→// BackoffStrategy defines how to calculate restart delays\n    53→type BackoffStrategy interface {\n    54→\tNextDelay(attempt int) time.Duration\n    55→\tReset()\n    56→}\n    57→\n    58→// ExponentialBackoff implements exponential backoff with jitter\n    59→type ExponentialBackoff struct {\n    60→\tInitialDelay time.Duration\n    61→\tMaxDelay     time.Duration\n    62→\tMultiplier   float64\n    63→}\n    64→\n    65→// NextDelay returns the next delay duration\n    66→func (e *ExponentialBackoff) NextDelay(attempt int) time.Duration {\n    67→\tif attempt <= 0 {\n    68→\t\treturn e.InitialDelay\n    69→\t}\n    70→\t\n    71→\tdelay := e.InitialDelay\n    72→\tfor i := 0; i < attempt; i++ {\n    73→\t\tdelay = time.Duration(float64(delay) * e.Multiplier)\n    74→\t\tif delay > e.MaxDelay {\n    75→\t\t\treturn e.MaxDelay\n    76→\t\t}\n    77→\t}\n    78→\treturn delay\n    79→}\n    80→\n    81→// Reset resets the backoff state (no-op for exponential)\n    82→func (e *ExponentialBackoff) Reset() {}\n    83→\n    84→// LinearBackoff implements linear backoff\n    85→type LinearBackoff struct {\n    86→\tInitialDelay time.Duration\n    87→\tIncrement    time.Duration\n    88→\tMaxDelay     time.Duration\n    89→}\n    90→\n    91→// NextDelay returns the next delay duration\n    92→func (l *LinearBackoff) NextDelay(attempt int) time.Duration {\n    93→\tdelay := l.InitialDelay + time.Duration(attempt)*l.Increment\n    94→\tif delay > l.MaxDelay {\n    95→\t\treturn l.MaxDelay\n    96→\t}\n    97→\treturn delay\n    98→}\n    99→\n   100→// Reset resets the backoff state (no-op for linear)\n   101→func (l *LinearBackoff) Reset() {}\n   102→\n   103→// DefaultBackoff returns a sensible default backoff strategy\n   104→func DefaultBackoff() BackoffStrategy {\n   105→\treturn &ExponentialBackoff{\n   106→\t\tInitialDelay: 100 * time.Millisecond,\n   107→\t\tMaxDelay:     30 * time.Second,\n   108→\t\tMultiplier:   2.0,\n   109→\t}\n   110→}\n   111→\n   112→// SafeGo runs a function in a goroutine with panic recovery\n   113→func SafeGo(name string, fn func(), handlers ...RecoveryHandler) {\n   114→\thandler := defaultRecoveryHandler\n   115→\tif len(handlers) > 0 {\n   116→\t\thandler = handlers[0]\n   117→\t}\n   118→\n   119→\ttotalGoroutines.Add(1)\n   120→\tactiveGoroutines.Add(1)\n   121→\t\n   122→\tgo func() {\n   123→\t\tdefer activeGoroutines.Add(-1)\n   124→\t\tdefer func() {\n   125→\t\t\tif r := recover(); r != nil {\n   126→\t\t\t\tstack := debug.Stack()\n   127→\t\t\t\thandler(r, stack)\n   128→\t\t\t\tlog.Errorf(\"Goroutine '%s' panicked and was recovered\", name)\n   129→\t\t\t}\n   130→\t\t}()\n   131→\n   132→\t\tlog.Debugf(\"Starting goroutine: %s\", name)\n   133→\t\tfn()\n   134→\t\tlog.Debugf(\"Goroutine completed: %s\", name)\n   135→\t}()\n   136→}\n   137→\n   138→// SafeGoContext runs a function with context support and panic recovery\n   139→func SafeGoContext(ctx context.Context, name string, fn func(context.Context), handlers ...RecoveryHandler) {\n   140→\thandler := defaultRecoveryHandler\n   141→\tif len(handlers) > 0 {\n   142→\t\thandler = handlers[0]\n   143→\t}\n   144→\n   145→\ttotalGoroutines.Add(1)\n   146→\tactiveGoroutines.Add(1)\n   147→\t\n   148→\tgo func() {\n   149→\t\tdefer activeGoroutines.Add(-1)\n   150→\t\tdefer func() {\n   151→\t\t\tif r := recover(); r != nil {\n   152→\t\t\t\tstack := debug.Stack()\n   153→\t\t\t\thandler(r, stack)\n   154→\t\t\t\tlog.Errorf(\"Goroutine '%s' panicked and was recovered\", name)\n   155→\t\t\t}\n   156→\t\t}()\n   157→\n   158→\t\tlog.Debugf(\"Starting goroutine: %s\", name)\n   159→\t\tfn(ctx)\n   160→\t\tlog.Debugf(\"Goroutine completed: %s\", name)\n   161→\t}()\n   162→}\n   163→\n   164→// SafeGoWithRestart runs a function with automatic restart on panic\n   165→// Uses iterative approach to prevent goroutine accumulation\n   166→func SafeGoWithRestart(ctx context.Context, name string, fn func(context.Context) error, maxRestarts int, backoff BackoffStrategy, handlers ...RecoveryHandler) {\n   167→\thandler := defaultRecoveryHandler\n   168→\tif len(handlers) > 0 {\n   169→\t\thandler = handlers[0]\n   170→\t}\n   171→\n   172→\tif backoff == nil {\n   173→\t\tbackoff = DefaultBackoff()\n   174→\t}\n   175→\n   176→\ttotalGoroutines.Add(1)\n   177→\tactiveGoroutines.Add(1)\n   178→\t\n   179→\tgo func() {\n   180→\t\tdefer activeGoroutines.Add(-1)\n   181→\t\trestartCount := 0\n   182→\t\t\n   183→\t\tfor {\n   184→\t\t\t// Check if context is cancelled\n   185→\t\t\tselect {\n   186→\t\t\tcase <-ctx.Done():\n   187→\t\t\t\tlog.Infof(\"Goroutine '%s' stopped due to context cancellation\", name)\n   188→\t\t\t\treturn\n   189→\t\t\tdefault:\n   190→\t\t\t}\n   191→\t\t\t\n   192→\t\t\t// Run the function with panic recovery\n   193→\t\t\tpanicked := false\n   194→\t\t\tfunc() {\n   195→\t\t\t\tdefer func() {\n   196→\t\t\t\t\tif r := recover(); r != nil {\n   197→\t\t\t\t\t\tpanicked = true\n   198→\t\t\t\t\t\tstack := debug.Stack()\n   199→\t\t\t\t\t\thandler(r, stack)\n   200→\t\t\t\t\t\tlog.Errorf(\"Goroutine '%s' panicked (restart %d/%d)\", name, restartCount, maxRestarts)\n   201→\t\t\t\t\t}\n   202→\t\t\t\t}()\n   203→\t\t\t\t\n   204→\t\t\t\tif restartCount == 0 {\n   205→\t\t\t\t\tlog.Debugf(\"Starting goroutine: %s\", name)\n   206→\t\t\t\t} else {\n   207→\t\t\t\t\tlog.Debugf(\"Restarting goroutine: %s (attempt %d/%d)\", name, restartCount, maxRestarts)\n   208→\t\t\t\t}\n   209→\t\t\t\t\n   210→\t\t\t\tif err := fn(ctx); err != nil {\n   211→\t\t\t\t\tlog.Errorf(\"Goroutine '%s' returned error: %v\", name, err)\n   212→\t\t\t\t}\n   213→\t\t\t}()\n   214→\t\t\t\n   215→\t\t\t// If function completed without panic, we're done\n   216→\t\t\tif !panicked {\n   217→\t\t\t\tlog.Debugf(\"Goroutine completed: %s\", name)\n   218→\t\t\t\treturn\n   219→\t\t\t}\n   220→\t\t\t\n   221→\t\t\t// Check if we should restart\n   222→\t\t\tif restartCount >= maxRestarts {\n   223→\t\t\t\tlog.Errorf(\"Goroutine '%s' exceeded max restarts (%d), stopping\", name, maxRestarts)\n   224→\t\t\t\treturn\n   225→\t\t\t}\n   226→\t\t\t\n   227→\t\t\t// Calculate backoff delay\n   228→\t\t\tdelay := backoff.NextDelay(restartCount)\n   229→\t\t\trestartCount++\n   230→\t\t\ttotalRestarts.Add(1)\n   231→\t\t\t\n   232→\t\t\tlog.Warnf(\"Restarting goroutine '%s' after %v delay (attempt %d/%d)\", name, delay, restartCount, maxRestarts)\n   233→\t\t\t\n   234→\t\t\t// Wait with context cancellation support\n   235→\t\t\tselect {\n   236→\t\t\tcase <-ctx.Done():\n   237→\t\t\t\tlog.Infof(\"Goroutine '%s' stopped during restart delay due to context cancellation\", name)\n   238→\t\t\t\treturn\n   239→\t\t\tcase <-time.After(delay):\n   240→\t\t\t\t// Continue to restart\n   241→\t\t\t}\n   242→\t\t}\n   243→\t}()\n   244→}\n   245→\n   246→// Group manages a group of goroutines with panic recovery and context support\n   247→type Group struct {\n   248→\tctx     context.Context\n   249→\tcancel  context.CancelFunc\n   250→\twg      sync.WaitGroup\n   251→\tname    string\n   252→\thandler RecoveryHandler\n   253→\tmu      sync.RWMutex\n   254→\ttasks   map[string]bool // Track active tasks\n   255→}\n   256→\n   257→// NewGroup creates a new goroutine group with context\n   258→func NewGroup(ctx context.Context, name string, handlers ...RecoveryHandler) *Group {\n   259→\thandler := defaultRecoveryHandler\n   260→\tif len(handlers) > 0 {\n   261→\t\thandler = handlers[0]\n   262→\t}\n   263→\n   264→\tgroupCtx, cancel := context.WithCancel(ctx)\n   265→\t\n   266→\treturn &Group{\n   267→\t\tctx:     groupCtx,\n   268→\t\tcancel:  cancel,\n   269→\t\tname:    name,\n   270→\t\thandler: handler,\n   271→\t\ttasks:   make(map[string]bool),\n   272→\t}\n   273→}\n   274→\n   275→// Go runs a function in the group with panic recovery\n   276→func (g *Group) Go(taskName string, fn func(context.Context)) {\n   277→\tg.wg.Add(1)\n   278→\t\n   279→\tg.mu.Lock()\n   280→\tg.tasks[taskName] = true\n   281→\tg.mu.Unlock()\n   282→\t\n   283→\ttotalGoroutines.Add(1)\n   284→\tactiveGoroutines.Add(1)\n   285→\n   286→\tgo func() {\n   287→\t\tdefer g.wg.Done()\n   288→\t\tdefer activeGoroutines.Add(-1)\n   289→\t\tdefer func() {\n   290→\t\t\tg.mu.Lock()\n   291→\t\t\tdelete(g.tasks, taskName)\n   292→\t\t\tg.mu.Unlock()\n   293→\t\t}()\n   294→\t\tdefer func() {\n   295→\t\t\tif r := recover(); r != nil {\n   296→\t\t\t\tstack := debug.Stack()\n   297→\t\t\t\tg.handler(r, stack)\n   298→\t\t\t\tlog.Errorf(\"Task '%s' in group '%s' panicked and was recovered\", taskName, g.name)\n   299→\t\t\t}\n   300→\t\t}()\n   301→\n   302→\t\tlog.Debugf(\"Starting task '%s' in group '%s'\", taskName, g.name)\n   303→\t\tfn(g.ctx)\n   304→\t\tlog.Debugf(\"Task '%s' in group '%s' completed\", taskName, g.name)\n   305→\t}()\n   306→}\n   307→\n   308→// Wait waits for all goroutines in the group to complete\n   309→func (g *Group) Wait() {\n   310→\tg.wg.Wait()\n   311→}\n   312→\n   313→// Stop cancels the group's context and waits for all tasks to complete\n   314→func (g *Group) Stop() {\n   315→\tg.cancel()\n   316→\tg.wg.Wait()\n   317→}\n   318→\n   319→// ActiveTasks returns the names of currently active tasks\n   320→func (g *Group) ActiveTasks() []string {\n   321→\tg.mu.RLock()\n   322→\tdefer g.mu.RUnlock()\n   323→\t\n   324→\ttasks := make([]string, 0, len(g.tasks))\n   325→\tfor task := range g.tasks {\n   326→\t\ttasks = append(tasks, task)\n   327→\t}\n   328→\treturn tasks\n   329→}\n   330→\n   331→// SafeAsync runs an async operation with panic recovery and error handling\n   332→func SafeAsync(ctx context.Context, name string, fn func(context.Context) error, errHandler func(error)) {\n   333→\tSafeGoContext(ctx, name, func(ctx context.Context) {\n   334→\t\tif err := fn(ctx); err != nil {\n   335→\t\t\tlog.Errorf(\"Async operation '%s' failed: %v\", name, err)\n   336→\t\t\tif errHandler != nil {\n   337→\t\t\t\terrHandler(err)\n   338→\t\t\t}\n   339→\t\t}\n   340→\t})\n   341→}\n   342→\n   343→// Monitor provides continuous monitoring with panic recovery and proper cleanup\n   344→type Monitor struct {\n   345→\tname       string\n   346→\tfn         func(context.Context) error\n   347→\tinterval   time.Duration\n   348→\thandler    RecoveryHandler\n   349→\terrHandler func(error)\n   350→\tctx        context.Context\n   351→\tcancel     context.CancelFunc\n   352→\trunning    atomic.Bool\n   353→\tdone       chan struct{}\n   354→\tbackoff    BackoffStrategy\n   355→}\n   356→\n   357→// NewMonitor creates a new monitor with fixed interval\n   358→func NewMonitor(ctx context.Context, name string, fn func(context.Context) error, interval time.Duration) *Monitor {\n   359→\tmonitorCtx, cancel := context.WithCancel(ctx)\n   360→\treturn &Monitor{\n   361→\t\tname:     name,\n   362→\t\tfn:       fn,\n   363→\t\tinterval: interval,\n   364→\t\thandler:  defaultRecoveryHandler,\n   365→\t\tctx:      monitorCtx,\n   366→\t\tcancel:   cancel,\n   367→\t\tdone:     make(chan struct{}),\n   368→\t\tbackoff:  DefaultBackoff(),\n   369→\t}\n   370→}\n   371→\n   372→// SetRecoveryHandler sets a custom panic recovery handler\n   373→func (m *Monitor) SetRecoveryHandler(handler RecoveryHandler) *Monitor {\n   374→\tm.handler = handler\n   375→\treturn m\n   376→}\n   377→\n   378→// SetErrorHandler sets a custom error handler\n   379→func (m *Monitor) SetErrorHandler(handler func(error)) *Monitor {\n   380→\tm.errHandler = handler\n   381→\treturn m\n   382→}\n   383→\n   384→// SetBackoff sets a custom backoff strategy for error recovery\n   385→func (m *Monitor) SetBackoff(backoff BackoffStrategy) *Monitor {\n   386→\tm.backoff = backoff\n   387→\treturn m\n   388→}\n   389→\n   390→// Start starts the monitor\n   391→func (m *Monitor) Start() error {\n   392→\tif !m.running.CompareAndSwap(false, true) {\n   393→\t\treturn fmt.Errorf(\"monitor '%s' is already running\", m.name)\n   394→\t}\n   395→\t\n   396→\ttotalGoroutines.Add(1)\n   397→\tactiveGoroutines.Add(1)\n   398→\t\n   399→\tgo func() {\n   400→\t\tdefer close(m.done)\n   401→\t\tdefer m.running.Store(false)\n   402→\t\tdefer activeGoroutines.Add(-1)\n   403→\t\tdefer func() {\n   404→\t\t\tif r := recover(); r != nil {\n   405→\t\t\t\tstack := debug.Stack()\n   406→\t\t\t\tm.handler(r, stack)\n   407→\t\t\t\tlog.Errorf(\"Monitor '%s' panicked and stopped\", m.name)\n   408→\t\t\t}\n   409→\t\t}()\n   410→\n   411→\t\tlog.Infof(\"Starting monitor: %s\", m.name)\n   412→\t\t\n   413→\t\tticker := time.NewTicker(m.interval)\n   414→\t\tdefer ticker.Stop()\n   415→\t\t\n   416→\t\tconsecutiveErrors := 0\n   417→\t\t\n   418→\t\tfor {\n   419→\t\t\tselect {\n   420→\t\t\tcase <-m.ctx.Done():\n   421→\t\t\t\tlog.Infof(\"Stopping monitor '%s': context cancelled\", m.name)\n   422→\t\t\t\treturn\n   423→\t\t\tcase <-ticker.C:\n   424→\t\t\t\t// Run the monitored function with panic recovery\n   425→\t\t\t\terr := func() (err error) {\n   426→\t\t\t\t\tdefer func() {\n   427→\t\t\t\t\t\tif r := recover(); r != nil {\n   428→\t\t\t\t\t\t\tstack := debug.Stack()\n   429→\t\t\t\t\t\t\tm.handler(r, stack)\n   430→\t\t\t\t\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n   431→\t\t\t\t\t\t}\n   432→\t\t\t\t\t}()\n   433→\t\t\t\t\treturn m.fn(m.ctx)\n   434→\t\t\t\t}()\n   435→\t\t\t\t\n   436→\t\t\t\tif err != nil {\n   437→\t\t\t\t\tconsecutiveErrors++\n   438→\t\t\t\t\tlog.Errorf(\"Monitor '%s' error (consecutive: %d): %v\", m.name, consecutiveErrors, err)\n   439→\t\t\t\t\tif m.errHandler != nil {\n   440→\t\t\t\t\t\tm.errHandler(err)\n   441→\t\t\t\t\t}\n   442→\t\t\t\t\t\n   443→\t\t\t\t\t// Apply backoff for consecutive errors\n   444→\t\t\t\t\tif consecutiveErrors > 1 {\n   445→\t\t\t\t\t\tbackoffDelay := m.backoff.NextDelay(consecutiveErrors - 1)\n   446→\t\t\t\t\t\tlog.Warnf(\"Monitor '%s' backing off for %v due to consecutive errors\", m.name, backoffDelay)\n   447→\t\t\t\t\t\t\n   448→\t\t\t\t\t\tselect {\n   449→\t\t\t\t\t\tcase <-m.ctx.Done():\n   450→\t\t\t\t\t\t\treturn\n   451→\t\t\t\t\t\tcase <-time.After(backoffDelay):\n   452→\t\t\t\t\t\t\t// Continue after backoff\n   453→\t\t\t\t\t\t}\n   454→\t\t\t\t\t}\n   455→\t\t\t\t} else {\n   456→\t\t\t\t\t// Reset on success\n   457→\t\t\t\t\tif consecutiveErrors > 0 {\n   458→\t\t\t\t\t\tlog.Infof(\"Monitor '%s' recovered after %d consecutive errors\", m.name, consecutiveErrors)\n   459→\t\t\t\t\t\tconsecutiveErrors = 0\n   460→\t\t\t\t\t\tm.backoff.Reset()\n   461→\t\t\t\t\t}\n   462→\t\t\t\t}\n   463→\t\t\t}\n   464→\t\t}\n   465→\t}()\n   466→\t\n   467→\treturn nil\n   468→}\n   469→\n   470→// Stop stops the monitor and waits for it to complete\n   471→func (m *Monitor) Stop() {\n   472→\tif m.running.Load() {\n   473→\t\tlog.Infof(\"Stopping monitor: %s\", m.name)\n   474→\t\tm.cancel()\n   475→\t\t<-m.done\n   476→\t}\n   477→}\n   478→\n   479→// IsRunning returns whether the monitor is currently running\n   480→func (m *Monitor) IsRunning() bool {\n   481→\treturn m.running.Load()\n   482→}\n   483→\n   484→// RunSafe is a helper that runs a function with panic recovery and returns any panic as an error\n   485→func RunSafe(fn func() error) (err error) {\n   486→\tdefer func() {\n   487→\t\tif r := recover(); r != nil {\n   488→\t\t\tstack := debug.Stack()\n   489→\t\t\terr = fmt.Errorf(\"panic: %v\\nStack:\\n%s\", r, stack)\n   490→\t\t\ttotalPanics.Add(1)\n   491→\t\t}\n   492→\t}()\n   493→\n   494→\treturn fn()\n   495→}\n   496→\n   497→// RunSafeContext is like RunSafe but with context support\n   498→func RunSafeContext(ctx context.Context, fn func(context.Context) error) (err error) {\n   499→\tdefer func() {\n   500→\t\tif r := recover(); r != nil {\n   501→\t\t\tstack := debug.Stack()\n   502→\t\t\terr = fmt.Errorf(\"panic: %v\\nStack:\\n%s\", r, stack)\n   503→\t\t\ttotalPanics.Add(1)\n   504→\t\t}\n   505→\t}()\n   506→\n   507→\treturn fn(ctx)\n   508→}\n   509→\n   510→// Registry tracks all active goroutines for lifecycle management\n   511→type Registry struct {\n   512→\tmu       sync.RWMutex\n   513→\troutines map[string]*RegisteredRoutine\n   514→}\n   515→\n   516→// RegisteredRoutine represents a tracked goroutine\n   517→type RegisteredRoutine struct {\n   518→\tName      string\n   519→\tStartTime time.Time\n   520→\tContext   context.Context\n   521→\tCancel    context.CancelFunc\n   522→}\n   523→\n   524→// globalRegistry is the singleton registry instance\n   525→var globalRegistry = &Registry{\n   526→\troutines: make(map[string]*RegisteredRoutine),\n   527→}\n   528→\n   529→// Register adds a goroutine to the registry\n   530→func Register(name string, ctx context.Context, cancel context.CancelFunc) {\n   531→\tglobalRegistry.mu.Lock()\n   532→\tdefer globalRegistry.mu.Unlock()\n   533→\t\n   534→\tglobalRegistry.routines[name] = &RegisteredRoutine{\n   535→\t\tName:      name,\n   536→\t\tStartTime: time.Now(),\n   537→\t\tContext:   ctx,\n   538→\t\tCancel:    cancel,\n   539→\t}\n   540→}\n   541→\n   542→// Unregister removes a goroutine from the registry\n   543→func Unregister(name string) {\n   544→\tglobalRegistry.mu.Lock()\n   545→\tdefer globalRegistry.mu.Unlock()\n   546→\t\n   547→\tdelete(globalRegistry.routines, name)\n   548→}\n   549→\n   550→// StopAll cancels all registered goroutines\n   551→func StopAll() {\n   552→\tglobalRegistry.mu.RLock()\n   553→\tdefer globalRegistry.mu.RUnlock()\n   554→\t\n   555→\tfor name, routine := range globalRegistry.routines {\n   556→\t\tlog.Infof(\"Cancelling registered goroutine: %s\", name)\n   557→\t\troutine.Cancel()\n   558→\t}\n   559→}\n   560→\n   561→// ListActive returns all active registered goroutines\n   562→func ListActive() []string {\n   563→\tglobalRegistry.mu.RLock()\n   564→\tdefer globalRegistry.mu.RUnlock()\n   565→\t\n   566→\tnames := make([]string, 0, len(globalRegistry.routines))\n   567→\tfor name := range globalRegistry.routines {\n   568→\t\tnames = append(names, name)\n   569→\t}\n   570→\treturn names\n   571→}\n   572→\n   573→// TrackedGo runs a goroutine with registration and automatic cleanup\n   574→func TrackedGo(ctx context.Context, name string, fn func(context.Context), handlers ...RecoveryHandler) {\n   575→\troutineCtx, cancel := context.WithCancel(ctx)\n   576→\tRegister(name, routineCtx, cancel)\n   577→\t\n   578→\thandler := defaultRecoveryHandler\n   579→\tif len(handlers) > 0 {\n   580→\t\thandler = handlers[0]\n   581→\t}\n   582→\t\n   583→\ttotalGoroutines.Add(1)\n   584→\tactiveGoroutines.Add(1)\n   585→\t\n   586→\tgo func() {\n   587→\t\tdefer Unregister(name)\n   588→\t\tdefer cancel()\n   589→\t\tdefer activeGoroutines.Add(-1)\n   590→\t\tdefer func() {\n   591→\t\t\tif r := recover(); r != nil {\n   592→\t\t\t\tstack := debug.Stack()\n   593→\t\t\t\thandler(r, stack)\n   594→\t\t\t\tlog.Errorf(\"Tracked goroutine '%s' panicked and was recovered\", name)\n   595→\t\t\t}\n   596→\t\t}()\n   597→\t\t\n   598→\t\tlog.Debugf(\"Starting tracked goroutine: %s\", name)\n   599→\t\tfn(routineCtx)\n   600→\t\tlog.Debugf(\"Tracked goroutine completed: %s\", name)\n   601→\t}()\n   602→}\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"be9a751b-f52c-4c49-9230-ed64b7a4041a","timestamp":"2025-08-13T10:29:38.717Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/pkg/goroutine/safe.go","content":"package goroutine\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"runtime/debug\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"bigmeanie/pkg/logger\"\n)\n\n// RecoveryHandler is a function that handles panics\ntype RecoveryHandler func(recovered interface{}, stack []byte)\n\n// Package logger instance\nvar log = logger.Component(\"goroutine\")\n\n// Global metrics for monitoring\nvar (\n\tactiveGoroutines  atomic.Int64\n\ttotalPanics       atomic.Int64\n\ttotalRestarts     atomic.Int64\n\ttotalGoroutines   atomic.Int64\n)\n\n// Metrics provides goroutine metrics\ntype Metrics struct {\n\tActive        int64\n\tTotalPanics   int64\n\tTotalRestarts int64\n\tTotal         int64\n}\n\n// GetMetrics returns current goroutine metrics\nfunc GetMetrics() Metrics {\n\treturn Metrics{\n\t\tActive:        activeGoroutines.Load(),\n\t\tTotalPanics:   totalPanics.Load(),\n\t\tTotalRestarts: totalRestarts.Load(),\n\t\tTotal:         totalGoroutines.Load(),\n\t}\n}\n\n// defaultRecoveryHandler logs the panic and stack trace\nfunc defaultRecoveryHandler(recovered interface{}, stack []byte) {\n\ttotalPanics.Add(1)\n\tlog.Errorf(\"PANIC RECOVERED: %v\\nStack trace:\\n%s\", recovered, stack)\n}\n\n// BackoffStrategy defines how to calculate restart delays\ntype BackoffStrategy interface {\n\tNextDelay(attempt int) time.Duration\n\tReset()\n}\n\n// ExponentialBackoff implements exponential backoff with jitter\ntype ExponentialBackoff struct {\n\tInitialDelay time.Duration\n\tMaxDelay     time.Duration\n\tMultiplier   float64\n}\n\n// NextDelay returns the next delay duration\nfunc (e *ExponentialBackoff) NextDelay(attempt int) time.Duration {\n\tif attempt <= 0 {\n\t\treturn e.InitialDelay\n\t}\n\t\n\tdelay := e.InitialDelay\n\tfor i := 0; i < attempt; i++ {\n\t\tdelay = time.Duration(float64(delay) * e.Multiplier)\n\t\tif delay > e.MaxDelay {\n\t\t\treturn e.MaxDelay\n\t\t}\n\t}\n\treturn delay\n}\n\n// Reset resets the backoff state (no-op for exponential)\nfunc (e *ExponentialBackoff) Reset() {}\n\n// LinearBackoff implements linear backoff\ntype LinearBackoff struct {\n\tInitialDelay time.Duration\n\tIncrement    time.Duration\n\tMaxDelay     time.Duration\n}\n\n// NextDelay returns the next delay duration\nfunc (l *LinearBackoff) NextDelay(attempt int) time.Duration {\n\tdelay := l.InitialDelay + time.Duration(attempt)*l.Increment\n\tif delay > l.MaxDelay {\n\t\treturn l.MaxDelay\n\t}\n\treturn delay\n}\n\n// Reset resets the backoff state (no-op for linear)\nfunc (l *LinearBackoff) Reset() {}\n\n// DefaultBackoff returns a sensible default backoff strategy\nfunc DefaultBackoff() BackoffStrategy {\n\treturn &ExponentialBackoff{\n\t\tInitialDelay: 100 * time.Millisecond,\n\t\tMaxDelay:     30 * time.Second,\n\t\tMultiplier:   2.0,\n\t}\n}\n\n// SafeGo runs a function in a goroutine with panic recovery\nfunc SafeGo(name string, fn func(), handlers ...RecoveryHandler) {\n\thandler := defaultRecoveryHandler\n\tif len(handlers) > 0 {\n\t\thandler = handlers[0]\n\t}\n\n\ttotalGoroutines.Add(1)\n\tactiveGoroutines.Add(1)\n\t\n\tgo func() {\n\t\tdefer activeGoroutines.Add(-1)\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tstack := debug.Stack()\n\t\t\t\thandler(r, stack)\n\t\t\t\tlog.Errorf(\"Goroutine '%s' panicked and was recovered\", name)\n\t\t\t}\n\t\t}()\n\n\t\tlog.Debugf(\"Starting goroutine: %s\", name)\n\t\tfn()\n\t\tlog.Debugf(\"Goroutine completed: %s\", name)\n\t}()\n}\n\n// SafeGoContext runs a function with context support and panic recovery\nfunc SafeGoContext(ctx context.Context, name string, fn func(context.Context), handlers ...RecoveryHandler) {\n\thandler := defaultRecoveryHandler\n\tif len(handlers) > 0 {\n\t\thandler = handlers[0]\n\t}\n\n\ttotalGoroutines.Add(1)\n\tactiveGoroutines.Add(1)\n\t\n\tgo func() {\n\t\tdefer activeGoroutines.Add(-1)\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tstack := debug.Stack()\n\t\t\t\thandler(r, stack)\n\t\t\t\tlog.Errorf(\"Goroutine '%s' panicked and was recovered\", name)\n\t\t\t}\n\t\t}()\n\n\t\tlog.Debugf(\"Starting goroutine: %s\", name)\n\t\tfn(ctx)\n\t\tlog.Debugf(\"Goroutine completed: %s\", name)\n\t}()\n}\n\n// SafeGoWithRestart runs a function with automatic restart on panic\n// Uses iterative approach to prevent goroutine accumulation\nfunc SafeGoWithRestart(ctx context.Context, name string, fn func(context.Context) error, maxRestarts int, backoff BackoffStrategy, handlers ...RecoveryHandler) {\n\thandler := defaultRecoveryHandler\n\tif len(handlers) > 0 {\n\t\thandler = handlers[0]\n\t}\n\n\tif backoff == nil {\n\t\tbackoff = DefaultBackoff()\n\t}\n\n\ttotalGoroutines.Add(1)\n\tactiveGoroutines.Add(1)\n\t\n\tgo func() {\n\t\tdefer activeGoroutines.Add(-1)\n\t\trestartCount := 0\n\t\t\n\t\tfor {\n\t\t\t// Check if context is cancelled\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tlog.Infof(\"Goroutine '%s' stopped due to context cancellation\", name)\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t}\n\t\t\t\n\t\t\t// Run the function with panic recovery\n\t\t\tpanicked := false\n\t\t\tfunc() {\n\t\t\t\tdefer func() {\n\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\tpanicked = true\n\t\t\t\t\t\tstack := debug.Stack()\n\t\t\t\t\t\thandler(r, stack)\n\t\t\t\t\t\tlog.Errorf(\"Goroutine '%s' panicked (restart %d/%d)\", name, restartCount, maxRestarts)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t\t\n\t\t\t\tif restartCount == 0 {\n\t\t\t\t\tlog.Debugf(\"Starting goroutine: %s\", name)\n\t\t\t\t} else {\n\t\t\t\t\tlog.Debugf(\"Restarting goroutine: %s (attempt %d/%d)\", name, restartCount, maxRestarts)\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif err := fn(ctx); err != nil {\n\t\t\t\t\tlog.Errorf(\"Goroutine '%s' returned error: %v\", name, err)\n\t\t\t\t}\n\t\t\t}()\n\t\t\t\n\t\t\t// If function completed without panic, we're done\n\t\t\tif !panicked {\n\t\t\t\tlog.Debugf(\"Goroutine completed: %s\", name)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t\n\t\t\t// Check if we should restart\n\t\t\tif restartCount >= maxRestarts {\n\t\t\t\tlog.Errorf(\"Goroutine '%s' exceeded max restarts (%d), stopping\", name, maxRestarts)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t\n\t\t\t// Calculate backoff delay\n\t\t\tdelay := backoff.NextDelay(restartCount)\n\t\t\trestartCount++\n\t\t\ttotalRestarts.Add(1)\n\t\t\t\n\t\t\tlog.Warnf(\"Restarting goroutine '%s' after %v delay (attempt %d/%d)\", name, delay, restartCount, maxRestarts)\n\t\t\t\n\t\t\t// Wait with context cancellation support\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tlog.Infof(\"Goroutine '%s' stopped during restart delay due to context cancellation\", name)\n\t\t\t\treturn\n\t\t\tcase <-time.After(delay):\n\t\t\t\t// Continue to restart\n\t\t\t}\n\t\t}\n\t}()\n}\n\n// Group manages a group of goroutines with panic recovery and context support\ntype Group struct {\n\tctx     context.Context\n\tcancel  context.CancelFunc\n\twg      sync.WaitGroup\n\tname    string\n\thandler RecoveryHandler\n\tmu      sync.RWMutex\n\ttasks   map[string]bool // Track active tasks\n}\n\n// NewGroup creates a new goroutine group with context\nfunc NewGroup(ctx context.Context, name string, handlers ...RecoveryHandler) *Group {\n\thandler := defaultRecoveryHandler\n\tif len(handlers) > 0 {\n\t\thandler = handlers[0]\n\t}\n\n\tgroupCtx, cancel := context.WithCancel(ctx)\n\t\n\treturn &Group{\n\t\tctx:     groupCtx,\n\t\tcancel:  cancel,\n\t\tname:    name,\n\t\thandler: handler,\n\t\ttasks:   make(map[string]bool),\n\t}\n}\n\n// Go runs a function in the group with panic recovery\nfunc (g *Group) Go(taskName string, fn func(context.Context)) {\n\tg.wg.Add(1)\n\t\n\tg.mu.Lock()\n\tg.tasks[taskName] = true\n\tg.mu.Unlock()\n\t\n\ttotalGoroutines.Add(1)\n\tactiveGoroutines.Add(1)\n\n\tgo func() {\n\t\tdefer g.wg.Done()\n\t\tdefer activeGoroutines.Add(-1)\n\t\tdefer func() {\n\t\t\tg.mu.Lock()\n\t\t\tdelete(g.tasks, taskName)\n\t\t\tg.mu.Unlock()\n\t\t}()\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tstack := debug.Stack()\n\t\t\t\tg.handler(r, stack)\n\t\t\t\tlog.Errorf(\"Task '%s' in group '%s' panicked and was recovered\", taskName, g.name)\n\t\t\t}\n\t\t}()\n\n\t\tlog.Debugf(\"Starting task '%s' in group '%s'\", taskName, g.name)\n\t\tfn(g.ctx)\n\t\tlog.Debugf(\"Task '%s' in group '%s' completed\", taskName, g.name)\n\t}()\n}\n\n// Wait waits for all goroutines in the group to complete\nfunc (g *Group) Wait() {\n\tg.wg.Wait()\n}\n\n// Stop cancels the group's context and waits for all tasks to complete\nfunc (g *Group) Stop() {\n\tg.cancel()\n\tg.wg.Wait()\n}\n\n// ActiveTasks returns the names of currently active tasks\nfunc (g *Group) ActiveTasks() []string {\n\tg.mu.RLock()\n\tdefer g.mu.RUnlock()\n\t\n\ttasks := make([]string, 0, len(g.tasks))\n\tfor task := range g.tasks {\n\t\ttasks = append(tasks, task)\n\t}\n\treturn tasks\n}\n\n// SafeAsync runs an async operation with panic recovery and error handling\nfunc SafeAsync(ctx context.Context, name string, fn func(context.Context) error, errHandler func(error)) {\n\tSafeGoContext(ctx, name, func(ctx context.Context) {\n\t\tif err := fn(ctx); err != nil {\n\t\t\tlog.Errorf(\"Async operation '%s' failed: %v\", name, err)\n\t\t\tif errHandler != nil {\n\t\t\t\terrHandler(err)\n\t\t\t}\n\t\t}\n\t})\n}\n\n// Monitor provides continuous monitoring with panic recovery and proper cleanup\ntype Monitor struct {\n\tname       string\n\tfn         func(context.Context) error\n\tinterval   time.Duration\n\thandler    RecoveryHandler\n\terrHandler func(error)\n\tctx        context.Context\n\tcancel     context.CancelFunc\n\trunning    atomic.Bool\n\tdone       chan struct{}\n\tbackoff    BackoffStrategy\n}\n\n// NewMonitor creates a new monitor with fixed interval\nfunc NewMonitor(ctx context.Context, name string, fn func(context.Context) error, interval time.Duration) *Monitor {\n\tmonitorCtx, cancel := context.WithCancel(ctx)\n\treturn &Monitor{\n\t\tname:     name,\n\t\tfn:       fn,\n\t\tinterval: interval,\n\t\thandler:  defaultRecoveryHandler,\n\t\tctx:      monitorCtx,\n\t\tcancel:   cancel,\n\t\tdone:     make(chan struct{}),\n\t\tbackoff:  DefaultBackoff(),\n\t}\n}\n\n// SetRecoveryHandler sets a custom panic recovery handler\nfunc (m *Monitor) SetRecoveryHandler(handler RecoveryHandler) *Monitor {\n\tm.handler = handler\n\treturn m\n}\n\n// SetErrorHandler sets a custom error handler\nfunc (m *Monitor) SetErrorHandler(handler func(error)) *Monitor {\n\tm.errHandler = handler\n\treturn m\n}\n\n// SetBackoff sets a custom backoff strategy for error recovery\nfunc (m *Monitor) SetBackoff(backoff BackoffStrategy) *Monitor {\n\tm.backoff = backoff\n\treturn m\n}\n\n// Start starts the monitor\nfunc (m *Monitor) Start() error {\n\tif !m.running.CompareAndSwap(false, true) {\n\t\treturn fmt.Errorf(\"monitor '%s' is already running\", m.name)\n\t}\n\t\n\ttotalGoroutines.Add(1)\n\tactiveGoroutines.Add(1)\n\t\n\tgo func() {\n\t\tdefer close(m.done)\n\t\tdefer m.running.Store(false)\n\t\tdefer activeGoroutines.Add(-1)\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tstack := debug.Stack()\n\t\t\t\tm.handler(r, stack)\n\t\t\t\tlog.Errorf(\"Monitor '%s' panicked and stopped\", m.name)\n\t\t\t}\n\t\t}()\n\n\t\tlog.Infof(\"Starting monitor: %s\", m.name)\n\t\t\n\t\tticker := time.NewTicker(m.interval)\n\t\tdefer ticker.Stop()\n\t\t\n\t\tconsecutiveErrors := 0\n\t\t\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-m.ctx.Done():\n\t\t\t\tlog.Infof(\"Stopping monitor '%s': context cancelled\", m.name)\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t\t// Run the monitored function with panic recovery\n\t\t\t\terr := func() (err error) {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\tstack := debug.Stack()\n\t\t\t\t\t\t\tm.handler(r, stack)\n\t\t\t\t\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\treturn m.fn(m.ctx)\n\t\t\t\t}()\n\t\t\t\t\n\t\t\t\tif err != nil {\n\t\t\t\t\tconsecutiveErrors++\n\t\t\t\t\tlog.Errorf(\"Monitor '%s' error (consecutive: %d): %v\", m.name, consecutiveErrors, err)\n\t\t\t\t\tif m.errHandler != nil {\n\t\t\t\t\t\tm.errHandler(err)\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\t// Apply backoff for consecutive errors\n\t\t\t\t\tif consecutiveErrors > 1 {\n\t\t\t\t\t\tbackoffDelay := m.backoff.NextDelay(consecutiveErrors - 1)\n\t\t\t\t\t\tlog.Warnf(\"Monitor '%s' backing off for %v due to consecutive errors\", m.name, backoffDelay)\n\t\t\t\t\t\t\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-m.ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-time.After(backoffDelay):\n\t\t\t\t\t\t\t// Continue after backoff\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\t// Reset on success\n\t\t\t\t\tif consecutiveErrors > 0 {\n\t\t\t\t\t\tlog.Infof(\"Monitor '%s' recovered after %d consecutive errors\", m.name, consecutiveErrors)\n\t\t\t\t\t\tconsecutiveErrors = 0\n\t\t\t\t\t\tm.backoff.Reset()\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\t\n\treturn nil\n}\n\n// Stop stops the monitor and waits for it to complete\nfunc (m *Monitor) Stop() {\n\tif m.running.Load() {\n\t\tlog.Infof(\"Stopping monitor: %s\", m.name)\n\t\tm.cancel()\n\t\t<-m.done\n\t}\n}\n\n// IsRunning returns whether the monitor is currently running\nfunc (m *Monitor) IsRunning() bool {\n\treturn m.running.Load()\n}\n\n// RunSafe is a helper that runs a function with panic recovery and returns any panic as an error\nfunc RunSafe(fn func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tstack := debug.Stack()\n\t\t\terr = fmt.Errorf(\"panic: %v\\nStack:\\n%s\", r, stack)\n\t\t\ttotalPanics.Add(1)\n\t\t}\n\t}()\n\n\treturn fn()\n}\n\n// RunSafeContext is like RunSafe but with context support\nfunc RunSafeContext(ctx context.Context, fn func(context.Context) error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tstack := debug.Stack()\n\t\t\terr = fmt.Errorf(\"panic: %v\\nStack:\\n%s\", r, stack)\n\t\t\ttotalPanics.Add(1)\n\t\t}\n\t}()\n\n\treturn fn(ctx)\n}\n\n// Registry tracks all active goroutines for lifecycle management\ntype Registry struct {\n\tmu       sync.RWMutex\n\troutines map[string]*RegisteredRoutine\n}\n\n// RegisteredRoutine represents a tracked goroutine\ntype RegisteredRoutine struct {\n\tName      string\n\tStartTime time.Time\n\tContext   context.Context\n\tCancel    context.CancelFunc\n}\n\n// globalRegistry is the singleton registry instance\nvar globalRegistry = &Registry{\n\troutines: make(map[string]*RegisteredRoutine),\n}\n\n// Register adds a goroutine to the registry\nfunc Register(name string, ctx context.Context, cancel context.CancelFunc) {\n\tglobalRegistry.mu.Lock()\n\tdefer globalRegistry.mu.Unlock()\n\t\n\tglobalRegistry.routines[name] = &RegisteredRoutine{\n\t\tName:      name,\n\t\tStartTime: time.Now(),\n\t\tContext:   ctx,\n\t\tCancel:    cancel,\n\t}\n}\n\n// Unregister removes a goroutine from the registry\nfunc Unregister(name string) {\n\tglobalRegistry.mu.Lock()\n\tdefer globalRegistry.mu.Unlock()\n\t\n\tdelete(globalRegistry.routines, name)\n}\n\n// StopAll cancels all registered goroutines\nfunc StopAll() {\n\tglobalRegistry.mu.RLock()\n\tdefer globalRegistry.mu.RUnlock()\n\t\n\tfor name, routine := range globalRegistry.routines {\n\t\tlog.Infof(\"Cancelling registered goroutine: %s\", name)\n\t\troutine.Cancel()\n\t}\n}\n\n// ListActive returns all active registered goroutines\nfunc ListActive() []string {\n\tglobalRegistry.mu.RLock()\n\tdefer globalRegistry.mu.RUnlock()\n\t\n\tnames := make([]string, 0, len(globalRegistry.routines))\n\tfor name := range globalRegistry.routines {\n\t\tnames = append(names, name)\n\t}\n\treturn names\n}\n\n// TrackedGo runs a goroutine with registration and automatic cleanup\nfunc TrackedGo(ctx context.Context, name string, fn func(context.Context), handlers ...RecoveryHandler) {\n\troutineCtx, cancel := context.WithCancel(ctx)\n\tRegister(name, routineCtx, cancel)\n\t\n\thandler := defaultRecoveryHandler\n\tif len(handlers) > 0 {\n\t\thandler = handlers[0]\n\t}\n\t\n\ttotalGoroutines.Add(1)\n\tactiveGoroutines.Add(1)\n\t\n\tgo func() {\n\t\tdefer Unregister(name)\n\t\tdefer cancel()\n\t\tdefer activeGoroutines.Add(-1)\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tstack := debug.Stack()\n\t\t\t\thandler(r, stack)\n\t\t\t\tlog.Errorf(\"Tracked goroutine '%s' panicked and was recovered\", name)\n\t\t\t}\n\t\t}()\n\t\t\n\t\tlog.Debugf(\"Starting tracked goroutine: %s\", name)\n\t\tfn(routineCtx)\n\t\tlog.Debugf(\"Tracked goroutine completed: %s\", name)\n\t}()\n}","numLines":602,"startLine":1,"totalLines":602}}}
{"parentUuid":"be9a751b-f52c-4c49-9230-ed64b7a4041a","isSidechain":true,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01MhuMuLxwRmB89JeFBjtFmK","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"## Documentation Review Analysis Report\n\nAfter thoroughly examining both the documentation files and the actual codebase implementation, I can provide a comprehensive analysis of how well the documentation aligns with the actual code patterns.\n\n## Key Findings\n\n### ✅ **Strong Alignments**\n\n1. **Error Handling Excellence**\n   - **Documentation**: The `errors.md` extensively covers error types, wrapping, and best practices\n   - **Implementation**: The `back/pkg/errors/errors.go` perfectly matches the documented patterns\n   - **Evidence**: TradingError struct, error types, wrapping patterns, and recovery handlers all align perfectly\n   - **Testing**: `errors_test.go` comprehensively tests all documented patterns\n\n2. **Decimal Usage Patterns**\n   - **Documentation**: `decimal-patterns.md` emphasizes shopspring/decimal for ALL financial calculations\n   - **Implementation**: All packages consistently use `decimal.Decimal` types\n   - **Evidence**: RSI indicator uses `decimal.Decimal` throughout, math package provides decimal-specific utilities\n\n3. **Testing Practices**\n   - **Documentation**: `testing.md` advocates table-driven tests, testify usage, and comprehensive coverage\n   - **Implementation**: `errors_test.go` follows exact patterns with table-driven tests and testify assertions\n   - **Evidence**: Proper use of `t.Run()`, `assert`, `require`, and benchmarking\n\n4. **Package Organization**\n   - **Documentation**: `packages.md` suggests clear package boundaries and naming conventions\n   - **Implementation**: Clean package structure with focused responsibilities (errors, clock, indicators, etc.)\n\n5. **Concurrency Best Practices**\n   - **Documentation**: `concurrency.md` covers goroutine safety, context usage, and panic recovery\n   - **Implementation**: `goroutine/safe.go` implements sophisticated goroutine management with monitoring and recovery\n\n### ⚠️ **Areas Needing Attention**\n\n1. **Project Structure Inconsistencies**\n   - **Issue**: Documentation shows `pkg/math/` but actual file is `pkg/decimal_math/`\n   - **Impact**: Minor - package name mismatch in documentation examples\n   - **Fix**: Update documentation to reference correct package path\n\n2. **Interface Documentation**\n   - **Gap**: The `design-patterns.md` shows interface patterns, but actual indicator interfaces are more specific\n   - **Evidence**: `indicators/interfaces.go` defines `TimeSeries` and `Indicator` interfaces that aren't fully documented\n   - **Impact**: Medium - developers might not understand the actual interface design\n\n3. **Import Path References**\n   - **Issue**: Some documentation examples use generic import paths while actual code uses `bigmeanie/pkg/...`\n   - **Evidence**: RSI imports `bigmeanie/pkg/indicators` but docs might show different patterns\n\n### 📋 **Missing Documentation**\n\n1. **Goroutine Package Documentation**\n   - **Gap**: No mention of the sophisticated `goroutine/safe.go` package in documentation\n   - **Missing**: Registry patterns, Monitor type, Group management, backoff strategies\n   - **Impact**: High - This is a complex, feature-rich package that developers need guidance on\n\n2. **Indicator Framework**\n   - **Gap**: Limited documentation about the indicator architecture\n   - **Missing**: Base types, caching patterns, precalculation strategies\n   - **Evidence**: RSI shows sophisticated precalculation but no docs explain this pattern\n\n3. **Clock Abstraction**\n   - **Gap**: No documentation of the clock package for testability\n   - **Missing**: Testing time-dependent code patterns\n\n### 🔧 **Specific Recommendations**\n\n1. **Add New Documentation Files**\n   ```\n   /back/.docs/code/goroutine-patterns.md  # For the goroutine package\n   /back/.docs/code/indicator-framework.md # For technical indicators\n   /back/.docs/code/time-testing.md        # For clock abstractions\n   ```\n\n2. **Update Existing Files**\n   - Fix package path references in `decimal-patterns.md`\n   - Add actual interface examples from `indicators/interfaces.go` to `design-patterns.md`\n   - Update import paths throughout documentation to match actual project structure\n\n3. **Code Examples Accuracy**\n   - All error handling examples in documentation are accurate\n   - Decimal patterns match implementation perfectly\n   - Testing patterns are correctly documented\n\n### 📊 **Documentation Coverage Assessment**\n\n| Package | Documentation Quality | Implementation Quality | Alignment Score |\n|---------|----------------------|------------------------|-----------------|\n| `errors` | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 95% |\n| `decimal_math` | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 85% |\n| `clock` | ⭐⭐ | ⭐⭐⭐⭐⭐ | 40% |\n| `indicators` | ⭐⭐ | ⭐⭐⭐⭐⭐ | 45% |\n| `goroutine` | ⭐ | ⭐⭐⭐⭐⭐ | 20% |\n\n### 🎯 **Priority Actions**\n\n**High Priority:**\n1. Create `goroutine-patterns.md` - This package has enterprise-grade features undocumented\n2. Fix package path references throughout existing documentation\n3. Document the indicator framework architecture\n\n**Medium Priority:**\n1. Add comprehensive examples for the clock testing pattern\n2. Update interface documentation with actual implementations\n3. Add cross-package integration examples\n\n**Low Priority:**\n1. Add more advanced error handling scenarios\n2. Expand on concurrent testing patterns\n3. Document performance characteristics of each package\n\n## Conclusion\n\nThe codebase demonstrates **exceptionally high quality** implementation that often exceeds what's documented. The major gap is that some of the most sophisticated packages (goroutine management, indicator framework) are barely documented despite having production-ready implementations. The error handling framework is exemplary and perfectly aligned with its comprehensive documentation.\n\nThe project follows Go best practices consistently and the existing documentation foundation is solid - it just needs expansion to cover all the implemented functionality."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":7043,"cache_read_input_tokens":85479,"output_tokens":1465,"service_tier":"standard"}},"requestId":"req_011CS5Z1tFyWbziNp4GdGXvS","type":"assistant","uuid":"72e28e03-d1ab-4933-9d7f-417d7f4c6c24","timestamp":"2025-08-13T10:30:15.347Z"}
{"parentUuid":"7f6025f4-573d-4aa6-8b58-bce7f23c1ca1","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017192VtHanSr51KikLzgA53","type":"tool_result","content":[{"type":"text","text":"## Documentation Review Analysis Report\n\nAfter thoroughly examining both the documentation files and the actual codebase implementation, I can provide a comprehensive analysis of how well the documentation aligns with the actual code patterns.\n\n## Key Findings\n\n### ✅ **Strong Alignments**\n\n1. **Error Handling Excellence**\n   - **Documentation**: The `errors.md` extensively covers error types, wrapping, and best practices\n   - **Implementation**: The `back/pkg/errors/errors.go` perfectly matches the documented patterns\n   - **Evidence**: TradingError struct, error types, wrapping patterns, and recovery handlers all align perfectly\n   - **Testing**: `errors_test.go` comprehensively tests all documented patterns\n\n2. **Decimal Usage Patterns**\n   - **Documentation**: `decimal-patterns.md` emphasizes shopspring/decimal for ALL financial calculations\n   - **Implementation**: All packages consistently use `decimal.Decimal` types\n   - **Evidence**: RSI indicator uses `decimal.Decimal` throughout, math package provides decimal-specific utilities\n\n3. **Testing Practices**\n   - **Documentation**: `testing.md` advocates table-driven tests, testify usage, and comprehensive coverage\n   - **Implementation**: `errors_test.go` follows exact patterns with table-driven tests and testify assertions\n   - **Evidence**: Proper use of `t.Run()`, `assert`, `require`, and benchmarking\n\n4. **Package Organization**\n   - **Documentation**: `packages.md` suggests clear package boundaries and naming conventions\n   - **Implementation**: Clean package structure with focused responsibilities (errors, clock, indicators, etc.)\n\n5. **Concurrency Best Practices**\n   - **Documentation**: `concurrency.md` covers goroutine safety, context usage, and panic recovery\n   - **Implementation**: `goroutine/safe.go` implements sophisticated goroutine management with monitoring and recovery\n\n### ⚠️ **Areas Needing Attention**\n\n1. **Project Structure Inconsistencies**\n   - **Issue**: Documentation shows `pkg/math/` but actual file is `pkg/decimal_math/`\n   - **Impact**: Minor - package name mismatch in documentation examples\n   - **Fix**: Update documentation to reference correct package path\n\n2. **Interface Documentation**\n   - **Gap**: The `design-patterns.md` shows interface patterns, but actual indicator interfaces are more specific\n   - **Evidence**: `indicators/interfaces.go` defines `TimeSeries` and `Indicator` interfaces that aren't fully documented\n   - **Impact**: Medium - developers might not understand the actual interface design\n\n3. **Import Path References**\n   - **Issue**: Some documentation examples use generic import paths while actual code uses `bigmeanie/pkg/...`\n   - **Evidence**: RSI imports `bigmeanie/pkg/indicators` but docs might show different patterns\n\n### 📋 **Missing Documentation**\n\n1. **Goroutine Package Documentation**\n   - **Gap**: No mention of the sophisticated `goroutine/safe.go` package in documentation\n   - **Missing**: Registry patterns, Monitor type, Group management, backoff strategies\n   - **Impact**: High - This is a complex, feature-rich package that developers need guidance on\n\n2. **Indicator Framework**\n   - **Gap**: Limited documentation about the indicator architecture\n   - **Missing**: Base types, caching patterns, precalculation strategies\n   - **Evidence**: RSI shows sophisticated precalculation but no docs explain this pattern\n\n3. **Clock Abstraction**\n   - **Gap**: No documentation of the clock package for testability\n   - **Missing**: Testing time-dependent code patterns\n\n### 🔧 **Specific Recommendations**\n\n1. **Add New Documentation Files**\n   ```\n   /back/.docs/code/goroutine-patterns.md  # For the goroutine package\n   /back/.docs/code/indicator-framework.md # For technical indicators\n   /back/.docs/code/time-testing.md        # For clock abstractions\n   ```\n\n2. **Update Existing Files**\n   - Fix package path references in `decimal-patterns.md`\n   - Add actual interface examples from `indicators/interfaces.go` to `design-patterns.md`\n   - Update import paths throughout documentation to match actual project structure\n\n3. **Code Examples Accuracy**\n   - All error handling examples in documentation are accurate\n   - Decimal patterns match implementation perfectly\n   - Testing patterns are correctly documented\n\n### 📊 **Documentation Coverage Assessment**\n\n| Package | Documentation Quality | Implementation Quality | Alignment Score |\n|---------|----------------------|------------------------|-----------------|\n| `errors` | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 95% |\n| `decimal_math` | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 85% |\n| `clock` | ⭐⭐ | ⭐⭐⭐⭐⭐ | 40% |\n| `indicators` | ⭐⭐ | ⭐⭐⭐⭐⭐ | 45% |\n| `goroutine` | ⭐ | ⭐⭐⭐⭐⭐ | 20% |\n\n### 🎯 **Priority Actions**\n\n**High Priority:**\n1. Create `goroutine-patterns.md` - This package has enterprise-grade features undocumented\n2. Fix package path references throughout existing documentation\n3. Document the indicator framework architecture\n\n**Medium Priority:**\n1. Add comprehensive examples for the clock testing pattern\n2. Update interface documentation with actual implementations\n3. Add cross-package integration examples\n\n**Low Priority:**\n1. Add more advanced error handling scenarios\n2. Expand on concurrent testing patterns\n3. Document performance characteristics of each package\n\n## Conclusion\n\nThe codebase demonstrates **exceptionally high quality** implementation that often exceeds what's documented. The major gap is that some of the most sophisticated packages (goroutine management, indicator framework) are barely documented despite having production-ready implementations. The error handling framework is exemplary and perfectly aligned with its comprehensive documentation.\n\nThe project follows Go best practices consistently and the existing documentation foundation is solid - it just needs expansion to cover all the implemented functionality."}]}]},"uuid":"483134cc-61fb-4fd6-a89b-004db79a8a0d","timestamp":"2025-08-13T10:30:15.419Z","toolUseResult":{"content":[{"type":"text","text":"## Documentation Review Analysis Report\n\nAfter thoroughly examining both the documentation files and the actual codebase implementation, I can provide a comprehensive analysis of how well the documentation aligns with the actual code patterns.\n\n## Key Findings\n\n### ✅ **Strong Alignments**\n\n1. **Error Handling Excellence**\n   - **Documentation**: The `errors.md` extensively covers error types, wrapping, and best practices\n   - **Implementation**: The `back/pkg/errors/errors.go` perfectly matches the documented patterns\n   - **Evidence**: TradingError struct, error types, wrapping patterns, and recovery handlers all align perfectly\n   - **Testing**: `errors_test.go` comprehensively tests all documented patterns\n\n2. **Decimal Usage Patterns**\n   - **Documentation**: `decimal-patterns.md` emphasizes shopspring/decimal for ALL financial calculations\n   - **Implementation**: All packages consistently use `decimal.Decimal` types\n   - **Evidence**: RSI indicator uses `decimal.Decimal` throughout, math package provides decimal-specific utilities\n\n3. **Testing Practices**\n   - **Documentation**: `testing.md` advocates table-driven tests, testify usage, and comprehensive coverage\n   - **Implementation**: `errors_test.go` follows exact patterns with table-driven tests and testify assertions\n   - **Evidence**: Proper use of `t.Run()`, `assert`, `require`, and benchmarking\n\n4. **Package Organization**\n   - **Documentation**: `packages.md` suggests clear package boundaries and naming conventions\n   - **Implementation**: Clean package structure with focused responsibilities (errors, clock, indicators, etc.)\n\n5. **Concurrency Best Practices**\n   - **Documentation**: `concurrency.md` covers goroutine safety, context usage, and panic recovery\n   - **Implementation**: `goroutine/safe.go` implements sophisticated goroutine management with monitoring and recovery\n\n### ⚠️ **Areas Needing Attention**\n\n1. **Project Structure Inconsistencies**\n   - **Issue**: Documentation shows `pkg/math/` but actual file is `pkg/decimal_math/`\n   - **Impact**: Minor - package name mismatch in documentation examples\n   - **Fix**: Update documentation to reference correct package path\n\n2. **Interface Documentation**\n   - **Gap**: The `design-patterns.md` shows interface patterns, but actual indicator interfaces are more specific\n   - **Evidence**: `indicators/interfaces.go` defines `TimeSeries` and `Indicator` interfaces that aren't fully documented\n   - **Impact**: Medium - developers might not understand the actual interface design\n\n3. **Import Path References**\n   - **Issue**: Some documentation examples use generic import paths while actual code uses `bigmeanie/pkg/...`\n   - **Evidence**: RSI imports `bigmeanie/pkg/indicators` but docs might show different patterns\n\n### 📋 **Missing Documentation**\n\n1. **Goroutine Package Documentation**\n   - **Gap**: No mention of the sophisticated `goroutine/safe.go` package in documentation\n   - **Missing**: Registry patterns, Monitor type, Group management, backoff strategies\n   - **Impact**: High - This is a complex, feature-rich package that developers need guidance on\n\n2. **Indicator Framework**\n   - **Gap**: Limited documentation about the indicator architecture\n   - **Missing**: Base types, caching patterns, precalculation strategies\n   - **Evidence**: RSI shows sophisticated precalculation but no docs explain this pattern\n\n3. **Clock Abstraction**\n   - **Gap**: No documentation of the clock package for testability\n   - **Missing**: Testing time-dependent code patterns\n\n### 🔧 **Specific Recommendations**\n\n1. **Add New Documentation Files**\n   ```\n   /back/.docs/code/goroutine-patterns.md  # For the goroutine package\n   /back/.docs/code/indicator-framework.md # For technical indicators\n   /back/.docs/code/time-testing.md        # For clock abstractions\n   ```\n\n2. **Update Existing Files**\n   - Fix package path references in `decimal-patterns.md`\n   - Add actual interface examples from `indicators/interfaces.go` to `design-patterns.md`\n   - Update import paths throughout documentation to match actual project structure\n\n3. **Code Examples Accuracy**\n   - All error handling examples in documentation are accurate\n   - Decimal patterns match implementation perfectly\n   - Testing patterns are correctly documented\n\n### 📊 **Documentation Coverage Assessment**\n\n| Package | Documentation Quality | Implementation Quality | Alignment Score |\n|---------|----------------------|------------------------|-----------------|\n| `errors` | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 95% |\n| `decimal_math` | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 85% |\n| `clock` | ⭐⭐ | ⭐⭐⭐⭐⭐ | 40% |\n| `indicators` | ⭐⭐ | ⭐⭐⭐⭐⭐ | 45% |\n| `goroutine` | ⭐ | ⭐⭐⭐⭐⭐ | 20% |\n\n### 🎯 **Priority Actions**\n\n**High Priority:**\n1. Create `goroutine-patterns.md` - This package has enterprise-grade features undocumented\n2. Fix package path references throughout existing documentation\n3. Document the indicator framework architecture\n\n**Medium Priority:**\n1. Add comprehensive examples for the clock testing pattern\n2. Update interface documentation with actual implementations\n3. Add cross-package integration examples\n\n**Low Priority:**\n1. Add more advanced error handling scenarios\n2. Expand on concurrent testing patterns\n3. Document performance characteristics of each package\n\n## Conclusion\n\nThe codebase demonstrates **exceptionally high quality** implementation that often exceeds what's documented. The major gap is that some of the most sophisticated packages (goroutine management, indicator framework) are barely documented despite having production-ready implementations. The error handling framework is exemplary and perfectly aligned with its comprehensive documentation.\n\nThe project follows Go best practices consistently and the existing documentation foundation is solid - it just needs expansion to cover all the implemented functionality."}],"totalDurationMs":151802,"totalTokens":93994,"totalToolUseCount":26,"usage":{"input_tokens":7,"cache_creation_input_tokens":7043,"cache_read_input_tokens":85479,"output_tokens":1465,"service_tier":"standard"}}}
{"parentUuid":"483134cc-61fb-4fd6-a89b-004db79a8a0d","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01UGB2C9yUmLzTPeCrdinwHx","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"**Documentation Review Summary:**\n\nThe god agent found that your code quality **exceeds documentation coverage** - you have enterprise-grade implementations that are under-documented.\n\n## Key Issues Found\n\n**Package Path Mismatches:**\n- Documentation references `pkg/math/` but actual package is `pkg/decimal_math/`\n- Import paths need standardization to `bigmeanie/pkg/...`\n\n**Major Documentation Gaps:**\n- **`goroutine` package**: Sophisticated 24/7 management system with zero documentation\n- **Indicator framework**: Complex architecture with caching/precalculation undocumented  \n- **`clock` package**: Time abstraction for testing not covered\n\n**Alignment Scores:**\n- `errors`: 95% - Excellent documentation matches implementation\n- `decimal_math`: 85% - Good coverage, minor path issues\n- `clock`: 40% - High-quality implementation, minimal docs\n- `indicators`: 45% - Complex system needs architecture docs\n- `goroutine`: 20% - Production-ready features completely undocumented\n\n## Recommended Actions\n\n**High Priority:**\n1. Create `goroutine-patterns.md` - document registry, monitoring, recovery\n2. Fix all package path references throughout docs\n3. Add `indicator-framework.md` for the technical analysis architecture\n\n**Medium Priority:** \n1. Document clock testing patterns in `time-testing.md`\n2. Update interface examples with actual implementations\n\nYour error handling documentation is exemplary and the decimal patterns are perfectly aligned. The main issue is sophisticated packages lacking any documentation coverage."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":1695,"cache_read_input_tokens":55369,"output_tokens":356,"service_tier":"standard"}},"requestId":"req_011CS5Z4bcwCQ9rT2mtMLy8A","type":"assistant","uuid":"e077345a-21b6-4980-94a3-d3ffb7126084","timestamp":"2025-08-13T10:30:25.156Z"}
{"parentUuid":"e077345a-21b6-4980-94a3-d3ffb7126084","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"system","content":"\u001b[1mStop\u001b[22m [paplay /run/current-system/sw/share/sounds/freedesktop/stereo/bell.oga] completed successfully","isMeta":false,"timestamp":"2025-08-13T10:30:25.473Z","uuid":"1a037a0c-7dca-426d-a56b-204f20ffeb72","toolUseID":"3c69bffd-9525-4f9f-856f-3a08dad269c0","level":"info"}
{"parentUuid":"1a037a0c-7dca-426d-a56b-204f20ffeb72","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":"My response:\nRecommended Actions\n\n  High Priority:\n  1. Create goroutine-patterns.md - document registry, monitoring, recovery\n\n  actual go goroutines or our /pkg/goroutine? the fact that i have to ask means we need to rename ours\n\n  2. Fix all package path references throughout docs\n\n  ok and change \"v1\" something that doesn't using a versioning naming convention.\n\n  3. Add indicator-framework.md for the technical analysis architecture\n\n  i think we need to fix this framework before we document it.\n\n  Medium Priority:\n  1. Document clock testing patterns in time-testing.md\n\n  we need to wait still we create our own test assertion framework\n\n  2. Update interface examples with actual implementations\n\n  interfaces can remain generic till we get more codebase\n\n  additionally i think the follow section in project-conventions should more accurently reflect the current state:\n\n  bigmeanie/\n├── back/                 # Backend code\n│   ├── cmd/             # Entry points\n│   │   ├── trade/       # Trading bot\n│   │   ├── backtest/    # Backtesting engine\n│   │   └── api/         # REST API server\n│   ├── internal/        # Private packages\n│   │   ├── engine/      # Trading engine\n│   │   ├── strategy/    # Trading strategies\n│   │   ├── exchange/    # Exchange integrations\n│   │   ├── portfolio/   # Portfolio management\n│   │   └── risk/        # Risk management\n│   ├── pkg/             # Public packages\n│   │   ├── indicators/  # Technical indicators\n│   │   ├── decimal/     # Decimal utilities\n│   │   └── errors/      # Error handling\n│   └── .docs/           # Documentation\n│       ├── code/        # Code patterns\n│       ├── plan.md      # Current planning\n│       └── todo.md      # Task tracking\n└── front/               # Frontend code\n    └── [React/Next.js structure]\n"},"uuid":"f8160d46-6e34-4899-bd93-c6b52bc88ae8","timestamp":"2025-08-13T10:37:16.815Z"}
{"parentUuid":"f8160d46-6e34-4899-bd93-c6b52bc88ae8","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_013eSq4uqQp2qKw96Vf5fkZU","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"I'll help address your feedback and update the documentation to reflect the current state."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":57905,"cache_read_input_tokens":0,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CS5Zbg6vrrLNVRwL9cEiK","type":"assistant","uuid":"d9e76429-4216-403b-8306-85b305e2064f","timestamp":"2025-08-13T10:37:20.733Z"}
{"parentUuid":"d9e76429-4216-403b-8306-85b305e2064f","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_013eSq4uqQp2qKw96Vf5fkZU","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01BS1pbD9C1n13tkwJNUENZx","name":"TodoWrite","input":{"todos":[{"id":"1","content":"Rename pkg/goroutine to pkg/concurrent or pkg/workers to avoid confusion with Go's native goroutines","status":"pending"},{"id":"2","content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending"},{"id":"3","content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"pending"},{"id":"4","content":"Defer indicator-framework.md until framework is redesigned","status":"pending"},{"id":"5","content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":57905,"cache_read_input_tokens":0,"output_tokens":299,"service_tier":"standard"}},"requestId":"req_011CS5Zbg6vrrLNVRwL9cEiK","type":"assistant","uuid":"2f6310c7-11ae-475b-9e1c-47d27fc3337b","timestamp":"2025-08-13T10:37:24.517Z"}
{"parentUuid":"2f6310c7-11ae-475b-9e1c-47d27fc3337b","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BS1pbD9C1n13tkwJNUENZx","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"ade51993-97fe-4a50-b0f4-9821bc4ccfac","timestamp":"2025-08-13T10:37:24.577Z","toolUseResult":{"oldTodos":[{"content":"Create decimal-patterns.md for shopspring/decimal usage","status":"completed","id":"1"},{"content":"Create project-conventions.md for Big Meanie specific rules","status":"completed","id":"2"},{"content":"Fix unsafe string conversions in performance.md","status":"completed","id":"3"},{"content":"Create database-patterns.md for PostgreSQL patterns","status":"completed","id":"4"},{"content":"Create api-patterns.md for REST/HTTP patterns","status":"completed","id":"5"}],"newTodos":[{"content":"Rename pkg/goroutine to pkg/concurrent or pkg/workers to avoid confusion with Go's native goroutines","status":"pending","id":"1"},{"content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending","id":"2"},{"content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"pending","id":"3"},{"content":"Defer indicator-framework.md until framework is redesigned","status":"pending","id":"4"},{"content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending","id":"5"}]}}
{"parentUuid":"ade51993-97fe-4a50-b0f4-9821bc4ccfac","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_018gPMKsCzLibfYGrjQs6Vhf","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01Cf1HiNv528D9McKpFfhL2D","name":"Read","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":280,"cache_read_input_tokens":57905,"output_tokens":75,"service_tier":"standard"}},"requestId":"req_011CS5ZcEmxGAgRodmpkiiMu","type":"assistant","uuid":"242487a0-b3e3-4d56-971f-1543764f4470","timestamp":"2025-08-13T10:37:27.621Z"}
{"parentUuid":"242487a0-b3e3-4d56-971f-1543764f4470","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Cf1HiNv528D9McKpFfhL2D","type":"tool_result","content":"     1→# Big Meanie Project Conventions\n     2→\n     3→## Philosophy\n     4→\n     5→Big Meanie follows a radical simplicity approach: **break fast, fix immediately**. We prioritize clean breaks over compatibility layers because hidden issues compound exponentially. A breaking change that forces immediate fixes is better than subtle bugs that surface months later in production.\n     6→\n     7→## Table of Contents\n     8→1. [Core Philosophy](#core-philosophy)\n     9→2. [Naming Conventions](#naming-conventions)\n    10→3. [No Backwards Compatibility](#no-backwards-compatibility)\n    11→4. [Project Structure](#project-structure)\n    12→5. [File Management](#file-management)\n    13→6. [Code Organization](#code-organization)\n    14→7. [Testing Standards](#testing-standards)\n    15→8. [Documentation Rules](#documentation-rules)\n    16→\n    17→## Core Philosophy\n    18→\n    19→### The Big Meanie Way\n    20→\n    21→```go\n    22→// We value:\n    23→// 1. Clarity over cleverness\n    24→// 2. Breaking changes over hidden complexity\n    25→// 3. Direct solutions over abstractions\n    26→// 4. Fast failures over graceful degradation\n    27→// 5. Today's correctness over tomorrow's flexibility\n    28→```\n    29→\n    30→### Design Principles\n    31→\n    32→```go\n    33→// BAD: Maintaining compatibility\n    34→type OrderService interface {\n    35→    PlaceOrder(order Order) error\n    36→    PlaceOrderV2(order OrderV2) error  // NEVER DO THIS\n    37→}\n    38→\n    39→// GOOD: Clean break\n    40→type OrderService interface {\n    41→    PlaceOrder(order Order) error  // Just change it\n    42→}\n    43→\n    44→// BAD: Migration code\n    45→func MigrateData() {\n    46→    if isOldFormat() {\n    47→        convertToNew()  // NEVER DO THIS\n    48→    }\n    49→}\n    50→\n    51→// GOOD: Direct cutover\n    52→func LoadData() {\n    53→    // Assume new format only\n    54→    // Old format fails fast\n    55→}\n    56→```\n    57→\n    58→## Naming Conventions\n    59→\n    60→### Concise Names\n    61→\n    62→Big Meanie uses ultra-concise naming. We prefer short, clear names over verbose descriptions.\n    63→\n    64→```go\n    65→// BAD: Verbose naming\n    66→type SupportResistanceCalculator struct {\n    67→    maximumLookbackPeriod int\n    68→    minimumVolumeThreshold decimal.Decimal\n    69→}\n    70→\n    71→func CalculateSupportAndResistanceLevels() {}\n    72→func GetMovingAverageConvergenceDivergence() {}\n    73→\n    74→// GOOD: Concise\n    75→type SRCalculator struct {  // Support/Resistance\n    76→    maxLookback int\n    77→    minVol decimal.Decimal\n    78→}\n    79→\n    80→func CalcSR() {}\n    81→func MACD() {}\n    82→```\n    83→\n    84→### Standard Abbreviations\n    85→\n    86→```go\n    87→// Common trading abbreviations\n    88→SR   // Support/Resistance\n    89→MA   // Moving Average\n    90→EMA  // Exponential Moving Average\n    91→RSI  // Relative Strength Index\n    92→MACD // Moving Average Convergence Divergence\n    93→BB   // Bollinger Bands\n    94→ATR  // Average True Range\n    95→OBV  // On-Balance Volume\n    96→MFI  // Money Flow Index\n    97→\n    98→// System abbreviations\n    99→cfg  // config\n   100→ctx  // context\n   101→conn // connection\n   102→db   // database\n   103→err  // error\n   104→msg  // message\n   105→req  // request\n   106→res  // response/result\n   107→tx   // transaction\n   108→\n   109→// Trading specific\n   110→qty  // quantity\n   111→vol  // volume\n   112→pos  // position\n   113→pnl  // profit and loss\n   114→nav  // net asset value\n   115→liq  // liquidation/liquidity\n   116→```\n   117→\n   118→### Method Names\n   119→\n   120→```go\n   121→// Prefer short verbs\n   122→Calc()  not  Calculate()\n   123→Exec()  not  Execute()\n   124→Init()  not  Initialize()\n   125→Proc()  not  Process()\n   126→Gen()   not  Generate()\n   127→\n   128→// Getters don't use Get\n   129→Price()     not  GetPrice()\n   130→Quantity()  not  GetQuantity()\n   131→\n   132→// Setters use Set\n   133→SetPrice()\n   134→SetQuantity()\n   135→\n   136→// Boolean methods\n   137→IsValid()   not  CheckIfValid()\n   138→HasData()   not  CheckHasData()\n   139→CanTrade()  not  CheckCanTrade()\n   140→```\n   141→\n   142→## No Backwards Compatibility\n   143→\n   144→### Breaking Changes Are Good\n   145→\n   146→```go\n   147→// BAD: Versioned APIs\n   148→func (api *API) RegisterHandlers() {\n   149→    api.HandleFunc(\"/v1/orders\", ordersV1Handler)\n   150→    api.HandleFunc(\"/v2/orders\", ordersV2Handler)  // NEVER\n   151→}\n   152→\n   153→// GOOD: One version only\n   154→func (api *API) RegisterHandlers() {\n   155→    api.HandleFunc(\"/orders\", ordersHandler)  // Break it, fix it\n   156→}\n   157→\n   158→// BAD: Compatibility fields\n   159→type Order struct {\n   160→    ID       string\n   161→    Price    decimal.Decimal\n   162→\n   163→    // Deprecated: Use Price instead\n   164→    PriceStr string  // NEVER KEEP THIS\n   165→}\n   166→\n   167→// GOOD: Clean structure\n   168→type Order struct {\n   169→    ID    string\n   170→    Price decimal.Decimal  // Changed? Fix all usages\n   171→}\n   172→```\n   173→\n   174→### Migration Anti-Patterns to Avoid\n   175→\n   176→```go\n   177→// NEVER: Gradual migration\n   178→func LoadConfig() Config {\n   179→    if FileExists(\"config.yaml\") {\n   180→        return LoadYAML()\n   181→    }\n   182→    // Fallback to old format\n   183→    return LoadJSON()  // NEVER DO THIS\n   184→}\n   185→\n   186→// ALWAYS: Direct cutover\n   187→func LoadConfig() Config {\n   188→    return LoadYAML()  // Old format fails immediately\n   189→}\n   190→\n   191→// NEVER: Adapter patterns\n   192→type LegacyAdapter struct {\n   193→    newService *Service\n   194→}\n   195→\n   196→func (a *LegacyAdapter) OldMethod() {\n   197→    a.newService.NewMethod()  // NEVER BUILD ADAPTERS\n   198→}\n   199→\n   200→// ALWAYS: Direct replacement\n   201→// Just change OldMethod to NewMethod everywhere\n   202→```\n   203→\n   204→### Database Migration Rules\n   205→\n   206→```sql\n   207→-- BAD: Maintaining old columns\n   208→ALTER TABLE orders ADD COLUMN price_decimal DECIMAL(20,8);\n   209→UPDATE orders SET price_decimal = CAST(price_string AS DECIMAL);\n   210→-- Keep both columns during \"transition\" - NEVER\n   211→\n   212→-- GOOD: Direct replacement\n   213→ALTER TABLE orders DROP COLUMN price_string;\n   214→ALTER TABLE orders ADD COLUMN price DECIMAL(20,8) NOT NULL;\n   215→-- Breaks immediately, forces data migration\n   216→```\n   217→\n   218→## Project Structure\n   219→\n   220→### Directory Layout\n   221→\n   222→```\n   223→bigmeanie/\n   224→├── back/                 # Backend code\n   225→│   ├── cmd/             # Entry points\n   226→│   │   ├── trade/       # Trading bot\n   227→│   │   ├── backtest/    # Backtesting engine\n   228→│   │   └── api/         # REST API server\n   229→│   ├── internal/        # Private packages\n   230→│   │   ├── engine/      # Trading engine\n   231→│   │   ├── strategy/    # Trading strategies\n   232→│   │   ├── exchange/    # Exchange integrations\n   233→│   │   ├── portfolio/   # Portfolio management\n   234→│   │   └── risk/        # Risk management\n   235→│   ├── pkg/             # Public packages\n   236→│   │   ├── indicators/  # Technical indicators\n   237→│   │   ├── decimal/     # Decimal utilities\n   238→│   │   └── errors/      # Error handling\n   239→│   └── .docs/           # Documentation\n   240→│       ├── code/        # Code patterns\n   241→│       ├── plan.md      # Current planning\n   242→│       └── todo.md      # Task tracking\n   243→└── front/               # Frontend code\n   244→    └── [React/Next.js structure]\n   245→```\n   246→\n   247→### Package Organization\n   248→\n   249→```go\n   250→// Each package has single responsibility\n   251→// internal/engine/engine.go\n   252→package engine\n   253→\n   254→type Engine struct {\n   255→    // Only engine-related fields\n   256→}\n   257→\n   258→// internal/strategy/strategy.go\n   259→package strategy\n   260→\n   261→type Strategy interface {\n   262→    // Only strategy methods\n   263→}\n   264→\n   265→// Never mix concerns in one package\n   266→// BAD: internal/trading/everything.go\n   267→// GOOD: Separate packages for separate concerns\n   268→```\n   269→\n   270→## File Management\n   271→\n   272→### No Variant Files\n   273→\n   274→```go\n   275→// NEVER create these files:\n   276→order.go\n   277→order_v2.go      // NEVER\n   278→order_new.go     // NEVER\n   279→order_enhanced.go // NEVER\n   280→order_refactored.go // NEVER\n   281→\n   282→// ALWAYS update the original:\n   283→order.go  // Just change this file\n   284→```\n   285→\n   286→### File Naming\n   287→\n   288→```go\n   289→// Standard Go conventions\n   290→order.go        // Types and methods\n   291→order_test.go   // Tests\n   292→doc.go         // Package documentation\n   293→\n   294→// Group by feature, not by type\n   295→// BAD structure:\n   296→types.go       // All types\n   297→methods.go     // All methods\n   298→interfaces.go  // All interfaces\n   299→\n   300→// GOOD structure:\n   301→order.go       // Order type and methods\n   302→trade.go       // Trade type and methods\n   303→portfolio.go   // Portfolio type and methods\n   304→```\n   305→\n   306→### Import Organization\n   307→\n   308→```go\n   309→import (\n   310→    // Standard library\n   311→    \"context\"\n   312→    \"fmt\"\n   313→\n   314→    // External dependencies\n   315→    \"github.com/shopspring/decimal\"\n   316→\n   317→    // Internal packages\n   318→    \"bigmeanie/internal/engine\"\n   319→    \"bigmeanie/pkg/indicators\"\n   320→)\n   321→\n   322→// Never use relative imports\n   323→// BAD:  import \"../engine\"\n   324→// GOOD: import \"bigmeanie/internal/engine\"\n   325→```\n   326→\n   327→## Code Organization\n   328→\n   329→### Interface Design\n   330→\n   331→```go\n   332→// Small, focused interfaces\n   333→type Trader interface {\n   334→    Trade(ctx context.Context, signal Signal) error\n   335→}\n   336→\n   337→// Not large, kitchen-sink interfaces\n   338→type BadTrader interface {\n   339→    Trade() error\n   340→    GetBalance() decimal.Decimal\n   341→    GetHistory() []Trade\n   342→    Configure(Config) error\n   343→    // ... 20 more methods - NO!\n   344→}\n   345→\n   346→// Compose interfaces when needed\n   347→type FullTrader interface {\n   348→    Trader\n   349→    Backtester\n   350→    Reporter\n   351→}\n   352→```\n   353→\n   354→### Error Handling\n   355→\n   356→```go\n   357→// Always wrap errors with context\n   358→if err != nil {\n   359→    return fmt.Errorf(\"engine.Start: %w\", err)\n   360→}\n   361→\n   362→// Define sentinel errors\n   363→var (\n   364→    ErrInsufficientFunds = errors.New(\"insufficient funds\")\n   365→    ErrOrderTooSmall     = errors.New(\"order below minimum\")\n   366→    ErrExchangeDown      = errors.New(\"exchange unavailable\")\n   367→)\n   368→\n   369→// Use errors.Is for checking\n   370→if errors.Is(err, ErrInsufficientFunds) {\n   371→    // Handle specific error\n   372→}\n   373→```\n   374→\n   375→### Concurrency Patterns\n   376→\n   377→```go\n   378→// Always use context for cancellation\n   379→func (e *Engine) Run(ctx context.Context) error {\n   380→    for {\n   381→        select {\n   382→        case <-ctx.Done():\n   383→            return ctx.Err()\n   384→        case signal := <-e.signals:\n   385→            e.process(signal)\n   386→        }\n   387→    }\n   388→}\n   389→\n   390→// Protect shared state\n   391→type Portfolio struct {\n   392→    mu       sync.RWMutex\n   393→    balances map[string]decimal.Decimal\n   394→}\n   395→\n   396→func (p *Portfolio) Balance(asset string) decimal.Decimal {\n   397→    p.mu.RLock()\n   398→    defer p.mu.RUnlock()\n   399→    return p.balances[asset]\n   400→}\n   401→```\n   402→\n   403→## Testing Standards\n   404→\n   405→### Test Organization\n   406→\n   407→```go\n   408→// Table-driven tests always\n   409→func TestCalcSR(t *testing.T) {\n   410→    tests := []struct {\n   411→        name string\n   412→        data []decimal.Decimal\n   413→        want []Level\n   414→    }{\n   415→        {\n   416→            name: \"basic support\",\n   417→            data: []decimal.Decimal{...},\n   418→            want: []Level{...},\n   419→        },\n   420→    }\n   421→\n   422→    for _, tt := range tests {\n   423→        t.Run(tt.name, func(t *testing.T) {\n   424→            got := CalcSR(tt.data)\n   425→            require.Equal(t, tt.want, got)\n   426→        })\n   427→    }\n   428→}\n   429→\n   430→// NEVER use t.Skip()\n   431→// BAD:\n   432→func TestBrokenFeature(t *testing.T) {\n   433→    t.Skip(\"Fix later\")  // NEVER\n   434→}\n   435→\n   436→// GOOD: Fix it or delete it\n   437→```\n   438→\n   439→### Test Coverage\n   440→\n   441→```go\n   442→// Test edge cases\n   443→func TestDivision(t *testing.T) {\n   444→    // Test zero division\n   445→    _, err := Divide(decimal.NewFromInt(1), decimal.Zero)\n   446→    require.Error(t, err)\n   447→\n   448→    // Test negative values\n   449→    result := Divide(decimal.NewFromInt(-10), decimal.NewFromInt(2))\n   450→    require.Equal(t, decimal.NewFromInt(-5), result)\n   451→}\n   452→\n   453→// Benchmark hot paths\n   454→func BenchmarkCalcSR(b *testing.B) {\n   455→    data := generatePriceData(1000)\n   456→    b.ResetTimer()\n   457→\n   458→    for i := 0; i < b.N; i++ {\n   459→        CalcSR(data)\n   460→    }\n   461→}\n   462→```\n   463→\n   464→## Documentation Rules\n   465→\n   466→### Code Comments\n   467→\n   468→```go\n   469→// Document WHY, not WHAT\n   470→// BAD:\n   471→// Increment counter by 1\n   472→counter++\n   473→\n   474→// GOOD:\n   475→// Retry count for exchange rate limiting\n   476→counter++\n   477→\n   478→// Document edge cases\n   479→// Returns -1 if no valid price found\n   480→func FindPrice(prices []decimal.Decimal) decimal.Decimal {\n   481→    // ...\n   482→}\n   483→\n   484→// Document assumptions\n   485→// Assumes prices are sorted in ascending order\n   486→func BinarySearch(prices []decimal.Decimal, target decimal.Decimal) int {\n   487→    // ...\n   488→}\n   489→```\n   490→\n   491→### Package Documentation\n   492→\n   493→```go\n   494→// Package engine implements the core trading engine for Big Meanie.\n   495→//\n   496→// The engine coordinates between strategy signals, risk management,\n   497→// and exchange execution. It runs continuously, processing signals\n   498→// and managing positions according to configured strategies.\n   499→//\n   500→// Basic usage:\n   501→//\n   502→//\tcfg := engine.DefaultConfig()\n   503→//\teng := engine.New(cfg)\n   504→//\terr := eng.Run(ctx)\n   505→//\n   506→package engine\n   507→```\n   508→\n   509→### README Files\n   510→\n   511→```markdown\n   512→# Component Name\n   513→\n   514→## Purpose\n   515→One paragraph explaining what this does and why it exists.\n   516→\n   517→## Usage\n   518→Code examples showing common usage patterns.\n   519→\n   520→## Configuration\n   521→Environment variables or config files needed.\n   522→\n   523→## Testing\n   524→How to run tests for this component.\n   525→\n   526→Never create documentation unless explicitly requested.\n   527→Document in code, not in separate files.\n   528→```\n   529→\n   530→## Anti-Patterns to Avoid\n   531→\n   532→### Never Do These\n   533→\n   534→```go\n   535→// 1. Backwards compatibility layers\n   536→type Service struct {\n   537→    v1Client *ClientV1\n   538→    v2Client *ClientV2  // NEVER\n   539→}\n   540→\n   541→// 2. Gradual migrations\n   542→if useNewSystem {\n   543→    processNew()\n   544→} else {\n   545→    processOld()  // NEVER\n   546→}\n   547→\n   548→// 3. Deprecation warnings\n   549→// Deprecated: Use NewMethod instead\n   550→func OldMethod() {  // Just delete it\n   551→}\n   552→\n   553→// 4. Feature flags for old behavior\n   554→if featureFlag(\"use-old-algorithm\") {  // NEVER\n   555→    oldAlgorithm()\n   556→}\n   557→\n   558→// 5. Compatibility shims\n   559→func shimOldToNew(old Old) New {  // NEVER\n   560→    // Convert old format to new\n   561→}\n   562→\n   563→// 6. Variant files\n   564→order_v2.go      // NEVER\n   565→order_new.go     // NEVER\n   566→order_temp.go    // NEVER\n   567→\n   568→// 7. TODO comments for compatibility\n   569→// TODO: Remove after all clients updated  // NEVER\n   570→```\n   571→\n   572→## Summary of Conventions\n   573→\n   574→1. **Ultra-concise naming** - SR not SupportResistance\n   575→2. **No backwards compatibility** - Break it cleanly\n   576→3. **No migration code** - Direct cutover only\n   577→4. **No variant files** - Update the original\n   578→5. **Fast failures** - Errors surface immediately\n   579→6. **Single version** - No v1, v2 APIs\n   580→7. **Clean breaks** - Force immediate fixes\n   581→8. **Direct solutions** - No adapter patterns\n   582→9. **Test everything** - Never skip tests\n   583→10. **Document WHY** - Code explains what, comments explain why\n   584→\n   585→Remember: **Every line of compatibility code is technical debt.** Break fast, fix immediately, move forward.\n   586→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"6b87d6ec-b5c1-468e-a7e8-542c06908846","timestamp":"2025-08-13T10:37:27.667Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md","content":"# Big Meanie Project Conventions\n\n## Philosophy\n\nBig Meanie follows a radical simplicity approach: **break fast, fix immediately**. We prioritize clean breaks over compatibility layers because hidden issues compound exponentially. A breaking change that forces immediate fixes is better than subtle bugs that surface months later in production.\n\n## Table of Contents\n1. [Core Philosophy](#core-philosophy)\n2. [Naming Conventions](#naming-conventions)\n3. [No Backwards Compatibility](#no-backwards-compatibility)\n4. [Project Structure](#project-structure)\n5. [File Management](#file-management)\n6. [Code Organization](#code-organization)\n7. [Testing Standards](#testing-standards)\n8. [Documentation Rules](#documentation-rules)\n\n## Core Philosophy\n\n### The Big Meanie Way\n\n```go\n// We value:\n// 1. Clarity over cleverness\n// 2. Breaking changes over hidden complexity\n// 3. Direct solutions over abstractions\n// 4. Fast failures over graceful degradation\n// 5. Today's correctness over tomorrow's flexibility\n```\n\n### Design Principles\n\n```go\n// BAD: Maintaining compatibility\ntype OrderService interface {\n    PlaceOrder(order Order) error\n    PlaceOrderV2(order OrderV2) error  // NEVER DO THIS\n}\n\n// GOOD: Clean break\ntype OrderService interface {\n    PlaceOrder(order Order) error  // Just change it\n}\n\n// BAD: Migration code\nfunc MigrateData() {\n    if isOldFormat() {\n        convertToNew()  // NEVER DO THIS\n    }\n}\n\n// GOOD: Direct cutover\nfunc LoadData() {\n    // Assume new format only\n    // Old format fails fast\n}\n```\n\n## Naming Conventions\n\n### Concise Names\n\nBig Meanie uses ultra-concise naming. We prefer short, clear names over verbose descriptions.\n\n```go\n// BAD: Verbose naming\ntype SupportResistanceCalculator struct {\n    maximumLookbackPeriod int\n    minimumVolumeThreshold decimal.Decimal\n}\n\nfunc CalculateSupportAndResistanceLevels() {}\nfunc GetMovingAverageConvergenceDivergence() {}\n\n// GOOD: Concise\ntype SRCalculator struct {  // Support/Resistance\n    maxLookback int\n    minVol decimal.Decimal\n}\n\nfunc CalcSR() {}\nfunc MACD() {}\n```\n\n### Standard Abbreviations\n\n```go\n// Common trading abbreviations\nSR   // Support/Resistance\nMA   // Moving Average\nEMA  // Exponential Moving Average\nRSI  // Relative Strength Index\nMACD // Moving Average Convergence Divergence\nBB   // Bollinger Bands\nATR  // Average True Range\nOBV  // On-Balance Volume\nMFI  // Money Flow Index\n\n// System abbreviations\ncfg  // config\nctx  // context\nconn // connection\ndb   // database\nerr  // error\nmsg  // message\nreq  // request\nres  // response/result\ntx   // transaction\n\n// Trading specific\nqty  // quantity\nvol  // volume\npos  // position\npnl  // profit and loss\nnav  // net asset value\nliq  // liquidation/liquidity\n```\n\n### Method Names\n\n```go\n// Prefer short verbs\nCalc()  not  Calculate()\nExec()  not  Execute()\nInit()  not  Initialize()\nProc()  not  Process()\nGen()   not  Generate()\n\n// Getters don't use Get\nPrice()     not  GetPrice()\nQuantity()  not  GetQuantity()\n\n// Setters use Set\nSetPrice()\nSetQuantity()\n\n// Boolean methods\nIsValid()   not  CheckIfValid()\nHasData()   not  CheckHasData()\nCanTrade()  not  CheckCanTrade()\n```\n\n## No Backwards Compatibility\n\n### Breaking Changes Are Good\n\n```go\n// BAD: Versioned APIs\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/v1/orders\", ordersV1Handler)\n    api.HandleFunc(\"/v2/orders\", ordersV2Handler)  // NEVER\n}\n\n// GOOD: One version only\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/orders\", ordersHandler)  // Break it, fix it\n}\n\n// BAD: Compatibility fields\ntype Order struct {\n    ID       string\n    Price    decimal.Decimal\n\n    // Deprecated: Use Price instead\n    PriceStr string  // NEVER KEEP THIS\n}\n\n// GOOD: Clean structure\ntype Order struct {\n    ID    string\n    Price decimal.Decimal  // Changed? Fix all usages\n}\n```\n\n### Migration Anti-Patterns to Avoid\n\n```go\n// NEVER: Gradual migration\nfunc LoadConfig() Config {\n    if FileExists(\"config.yaml\") {\n        return LoadYAML()\n    }\n    // Fallback to old format\n    return LoadJSON()  // NEVER DO THIS\n}\n\n// ALWAYS: Direct cutover\nfunc LoadConfig() Config {\n    return LoadYAML()  // Old format fails immediately\n}\n\n// NEVER: Adapter patterns\ntype LegacyAdapter struct {\n    newService *Service\n}\n\nfunc (a *LegacyAdapter) OldMethod() {\n    a.newService.NewMethod()  // NEVER BUILD ADAPTERS\n}\n\n// ALWAYS: Direct replacement\n// Just change OldMethod to NewMethod everywhere\n```\n\n### Database Migration Rules\n\n```sql\n-- BAD: Maintaining old columns\nALTER TABLE orders ADD COLUMN price_decimal DECIMAL(20,8);\nUPDATE orders SET price_decimal = CAST(price_string AS DECIMAL);\n-- Keep both columns during \"transition\" - NEVER\n\n-- GOOD: Direct replacement\nALTER TABLE orders DROP COLUMN price_string;\nALTER TABLE orders ADD COLUMN price DECIMAL(20,8) NOT NULL;\n-- Breaks immediately, forces data migration\n```\n\n## Project Structure\n\n### Directory Layout\n\n```\nbigmeanie/\n├── back/                 # Backend code\n│   ├── cmd/             # Entry points\n│   │   ├── trade/       # Trading bot\n│   │   ├── backtest/    # Backtesting engine\n│   │   └── api/         # REST API server\n│   ├── internal/        # Private packages\n│   │   ├── engine/      # Trading engine\n│   │   ├── strategy/    # Trading strategies\n│   │   ├── exchange/    # Exchange integrations\n│   │   ├── portfolio/   # Portfolio management\n│   │   └── risk/        # Risk management\n│   ├── pkg/             # Public packages\n│   │   ├── indicators/  # Technical indicators\n│   │   ├── decimal/     # Decimal utilities\n│   │   └── errors/      # Error handling\n│   └── .docs/           # Documentation\n│       ├── code/        # Code patterns\n│       ├── plan.md      # Current planning\n│       └── todo.md      # Task tracking\n└── front/               # Frontend code\n    └── [React/Next.js structure]\n```\n\n### Package Organization\n\n```go\n// Each package has single responsibility\n// internal/engine/engine.go\npackage engine\n\ntype Engine struct {\n    // Only engine-related fields\n}\n\n// internal/strategy/strategy.go\npackage strategy\n\ntype Strategy interface {\n    // Only strategy methods\n}\n\n// Never mix concerns in one package\n// BAD: internal/trading/everything.go\n// GOOD: Separate packages for separate concerns\n```\n\n## File Management\n\n### No Variant Files\n\n```go\n// NEVER create these files:\norder.go\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_enhanced.go // NEVER\norder_refactored.go // NEVER\n\n// ALWAYS update the original:\norder.go  // Just change this file\n```\n\n### File Naming\n\n```go\n// Standard Go conventions\norder.go        // Types and methods\norder_test.go   // Tests\ndoc.go         // Package documentation\n\n// Group by feature, not by type\n// BAD structure:\ntypes.go       // All types\nmethods.go     // All methods\ninterfaces.go  // All interfaces\n\n// GOOD structure:\norder.go       // Order type and methods\ntrade.go       // Trade type and methods\nportfolio.go   // Portfolio type and methods\n```\n\n### Import Organization\n\n```go\nimport (\n    // Standard library\n    \"context\"\n    \"fmt\"\n\n    // External dependencies\n    \"github.com/shopspring/decimal\"\n\n    // Internal packages\n    \"bigmeanie/internal/engine\"\n    \"bigmeanie/pkg/indicators\"\n)\n\n// Never use relative imports\n// BAD:  import \"../engine\"\n// GOOD: import \"bigmeanie/internal/engine\"\n```\n\n## Code Organization\n\n### Interface Design\n\n```go\n// Small, focused interfaces\ntype Trader interface {\n    Trade(ctx context.Context, signal Signal) error\n}\n\n// Not large, kitchen-sink interfaces\ntype BadTrader interface {\n    Trade() error\n    GetBalance() decimal.Decimal\n    GetHistory() []Trade\n    Configure(Config) error\n    // ... 20 more methods - NO!\n}\n\n// Compose interfaces when needed\ntype FullTrader interface {\n    Trader\n    Backtester\n    Reporter\n}\n```\n\n### Error Handling\n\n```go\n// Always wrap errors with context\nif err != nil {\n    return fmt.Errorf(\"engine.Start: %w\", err)\n}\n\n// Define sentinel errors\nvar (\n    ErrInsufficientFunds = errors.New(\"insufficient funds\")\n    ErrOrderTooSmall     = errors.New(\"order below minimum\")\n    ErrExchangeDown      = errors.New(\"exchange unavailable\")\n)\n\n// Use errors.Is for checking\nif errors.Is(err, ErrInsufficientFunds) {\n    // Handle specific error\n}\n```\n\n### Concurrency Patterns\n\n```go\n// Always use context for cancellation\nfunc (e *Engine) Run(ctx context.Context) error {\n    for {\n        select {\n        case <-ctx.Done():\n            return ctx.Err()\n        case signal := <-e.signals:\n            e.process(signal)\n        }\n    }\n}\n\n// Protect shared state\ntype Portfolio struct {\n    mu       sync.RWMutex\n    balances map[string]decimal.Decimal\n}\n\nfunc (p *Portfolio) Balance(asset string) decimal.Decimal {\n    p.mu.RLock()\n    defer p.mu.RUnlock()\n    return p.balances[asset]\n}\n```\n\n## Testing Standards\n\n### Test Organization\n\n```go\n// Table-driven tests always\nfunc TestCalcSR(t *testing.T) {\n    tests := []struct {\n        name string\n        data []decimal.Decimal\n        want []Level\n    }{\n        {\n            name: \"basic support\",\n            data: []decimal.Decimal{...},\n            want: []Level{...},\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := CalcSR(tt.data)\n            require.Equal(t, tt.want, got)\n        })\n    }\n}\n\n// NEVER use t.Skip()\n// BAD:\nfunc TestBrokenFeature(t *testing.T) {\n    t.Skip(\"Fix later\")  // NEVER\n}\n\n// GOOD: Fix it or delete it\n```\n\n### Test Coverage\n\n```go\n// Test edge cases\nfunc TestDivision(t *testing.T) {\n    // Test zero division\n    _, err := Divide(decimal.NewFromInt(1), decimal.Zero)\n    require.Error(t, err)\n\n    // Test negative values\n    result := Divide(decimal.NewFromInt(-10), decimal.NewFromInt(2))\n    require.Equal(t, decimal.NewFromInt(-5), result)\n}\n\n// Benchmark hot paths\nfunc BenchmarkCalcSR(b *testing.B) {\n    data := generatePriceData(1000)\n    b.ResetTimer()\n\n    for i := 0; i < b.N; i++ {\n        CalcSR(data)\n    }\n}\n```\n\n## Documentation Rules\n\n### Code Comments\n\n```go\n// Document WHY, not WHAT\n// BAD:\n// Increment counter by 1\ncounter++\n\n// GOOD:\n// Retry count for exchange rate limiting\ncounter++\n\n// Document edge cases\n// Returns -1 if no valid price found\nfunc FindPrice(prices []decimal.Decimal) decimal.Decimal {\n    // ...\n}\n\n// Document assumptions\n// Assumes prices are sorted in ascending order\nfunc BinarySearch(prices []decimal.Decimal, target decimal.Decimal) int {\n    // ...\n}\n```\n\n### Package Documentation\n\n```go\n// Package engine implements the core trading engine for Big Meanie.\n//\n// The engine coordinates between strategy signals, risk management,\n// and exchange execution. It runs continuously, processing signals\n// and managing positions according to configured strategies.\n//\n// Basic usage:\n//\n//\tcfg := engine.DefaultConfig()\n//\teng := engine.New(cfg)\n//\terr := eng.Run(ctx)\n//\npackage engine\n```\n\n### README Files\n\n```markdown\n# Component Name\n\n## Purpose\nOne paragraph explaining what this does and why it exists.\n\n## Usage\nCode examples showing common usage patterns.\n\n## Configuration\nEnvironment variables or config files needed.\n\n## Testing\nHow to run tests for this component.\n\nNever create documentation unless explicitly requested.\nDocument in code, not in separate files.\n```\n\n## Anti-Patterns to Avoid\n\n### Never Do These\n\n```go\n// 1. Backwards compatibility layers\ntype Service struct {\n    v1Client *ClientV1\n    v2Client *ClientV2  // NEVER\n}\n\n// 2. Gradual migrations\nif useNewSystem {\n    processNew()\n} else {\n    processOld()  // NEVER\n}\n\n// 3. Deprecation warnings\n// Deprecated: Use NewMethod instead\nfunc OldMethod() {  // Just delete it\n}\n\n// 4. Feature flags for old behavior\nif featureFlag(\"use-old-algorithm\") {  // NEVER\n    oldAlgorithm()\n}\n\n// 5. Compatibility shims\nfunc shimOldToNew(old Old) New {  // NEVER\n    // Convert old format to new\n}\n\n// 6. Variant files\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_temp.go    // NEVER\n\n// 7. TODO comments for compatibility\n// TODO: Remove after all clients updated  // NEVER\n```\n\n## Summary of Conventions\n\n1. **Ultra-concise naming** - SR not SupportResistance\n2. **No backwards compatibility** - Break it cleanly\n3. **No migration code** - Direct cutover only\n4. **No variant files** - Update the original\n5. **Fast failures** - Errors surface immediately\n6. **Single version** - No v1, v2 APIs\n7. **Clean breaks** - Force immediate fixes\n8. **Direct solutions** - No adapter patterns\n9. **Test everything** - Never skip tests\n10. **Document WHY** - Code explains what, comments explain why\n\nRemember: **Every line of compatibility code is technical debt.** Break fast, fix immediately, move forward.\n","numLines":586,"startLine":1,"totalLines":586}}}
{"parentUuid":"6b87d6ec-b5c1-468e-a7e8-542c06908846","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_019mU87BPtErjDcQ1WaZM227","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Perfect! Your feedback is spot on. Let me update the documentation to address these issues:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":5736,"cache_read_input_tokens":58185,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CS5ZcSfKf8P8v3qK4R7zb","type":"assistant","uuid":"16bff3bf-9c04-44d1-b918-7efcc2be1bde","timestamp":"2025-08-13T10:37:31.123Z"}
{"parentUuid":"16bff3bf-9c04-44d1-b918-7efcc2be1bde","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_019mU87BPtErjDcQ1WaZM227","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_011ineoUesiCo8o7QcQwsiN5","name":"TodoWrite","input":{"todos":[{"id":"1","content":"Rename pkg/goroutine to pkg/concurrent or pkg/workers to avoid confusion with Go's native goroutines","status":"in_progress"},{"id":"2","content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending"},{"id":"3","content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"in_progress"},{"id":"4","content":"Defer indicator-framework.md until framework is redesigned","status":"pending"},{"id":"5","content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":5736,"cache_read_input_tokens":58185,"output_tokens":247,"service_tier":"standard"}},"requestId":"req_011CS5ZcSfKf8P8v3qK4R7zb","type":"assistant","uuid":"111f5a1f-abe7-40ef-affc-f2b93717c533","timestamp":"2025-08-13T10:37:35.007Z"}
{"parentUuid":"111f5a1f-abe7-40ef-affc-f2b93717c533","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011ineoUesiCo8o7QcQwsiN5","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"4fcdff29-0377-4f6e-8c69-bc0c60d5a29d","timestamp":"2025-08-13T10:37:35.045Z","toolUseResult":{"oldTodos":[{"content":"Rename pkg/goroutine to pkg/concurrent or pkg/workers to avoid confusion with Go's native goroutines","status":"pending","id":"1"},{"content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending","id":"2"},{"content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"pending","id":"3"},{"content":"Defer indicator-framework.md until framework is redesigned","status":"pending","id":"4"},{"content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending","id":"5"}],"newTodos":[{"content":"Rename pkg/goroutine to pkg/concurrent or pkg/workers to avoid confusion with Go's native goroutines","status":"in_progress","id":"1"},{"content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"in_progress","id":"3"},{"content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending","id":"2"},{"content":"Defer indicator-framework.md until framework is redesigned","status":"pending","id":"4"},{"content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending","id":"5"}]}}
{"parentUuid":"4fcdff29-0377-4f6e-8c69-bc0c60d5a29d","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01AqgPZ4NgfdyLBrsTC2nNhu","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01EiU4cH6pJkXHHbeeqFTDLF","name":"Edit","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md","old_string":"```\nbigmeanie/\n├── back/                 # Backend code\n│   ├── cmd/             # Entry points\n│   │   ├── trade/       # Trading bot\n│   │   ├── backtest/    # Backtesting engine\n│   │   └── api/         # REST API server\n│   ├── internal/        # Private packages\n│   │   ├── engine/      # Trading engine\n│   │   ├── strategy/    # Trading strategies\n│   │   ├── exchange/    # Exchange integrations\n│   │   ├── portfolio/   # Portfolio management\n│   │   └── risk/        # Risk management\n│   ├── pkg/             # Public packages\n│   │   ├── indicators/  # Technical indicators\n│   │   ├── decimal/     # Decimal utilities\n│   │   └── errors/      # Error handling\n│   └── .docs/           # Documentation\n│       ├── code/        # Code patterns\n│       ├── plan.md      # Current planning\n│       └── todo.md      # Task tracking\n└── front/               # Frontend code\n    └── [React/Next.js structure]\n```","new_string":"```\nbigmeanie/\n├── back/                 # Backend code\n│   ├── .docs/           # Documentation (hidden)\n│   │   ├── archive/     # Historical docs (DO NOT REFERENCE)\n│   │   ├── code/        # Developer guidelines\n│   │   ├── pinescripts/ # TradingView source scripts\n│   │   ├── plan.md      # Current planning\n│   │   └── todo.md      # Task tracking\n│   ├── .snippets/       # Code patterns and examples (hidden)\n│   ├── internal/        # Private packages (future)\n│   ├── pkg/             # Public packages\n│   │   ├── clock/       # Time abstraction for testing\n│   │   ├── decimal_math/# High-precision math utilities\n│   │   ├── errors/      # Structured error handling framework\n│   │   ├── goroutine/   # Safe goroutine management (to be renamed)\n│   │   └── indicators/  # Technical analysis indicators\n│   │       ├── common/  # Standard indicators (RSI, ATR, VWAP)\n│   │       ├── pinescript/# Advanced indicators (ZLTS, MTO, AVOP)\n│   │       └── vol_delta/# Volume delta calculations\n│   ├── go.mod\n│   └── README.md\n└── front/               # Frontend code\n    └── README.md        # Currently empty - backend focus\n```"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":289,"cache_read_input_tokens":63921,"output_tokens":750,"service_tier":"standard"}},"requestId":"req_011CS5Zd1JMpnNnJD2NC4A8M","type":"assistant","uuid":"dc762986-2786-4d3b-b2ee-7240722a3158","timestamp":"2025-08-13T10:37:47.524Z"}
{"parentUuid":"dc762986-2786-4d3b-b2ee-7240722a3158","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EiU4cH6pJkXHHbeeqFTDLF","type":"tool_result","content":"The file /home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n   218→## Project Structure\n   219→\n   220→### Directory Layout\n   221→\n   222→```\n   223→bigmeanie/\n   224→├── back/                 # Backend code\n   225→│   ├── .docs/           # Documentation (hidden)\n   226→│   │   ├── archive/     # Historical docs (DO NOT REFERENCE)\n   227→│   │   ├── code/        # Developer guidelines\n   228→│   │   ├── pinescripts/ # TradingView source scripts\n   229→│   │   ├── plan.md      # Current planning\n   230→│   │   └── todo.md      # Task tracking\n   231→│   ├── .snippets/       # Code patterns and examples (hidden)\n   232→│   ├── internal/        # Private packages (future)\n   233→│   ├── pkg/             # Public packages\n   234→│   │   ├── clock/       # Time abstraction for testing\n   235→│   │   ├── decimal_math/# High-precision math utilities\n   236→│   │   ├── errors/      # Structured error handling framework\n   237→│   │   ├── goroutine/   # Safe goroutine management (to be renamed)\n   238→│   │   └── indicators/  # Technical analysis indicators\n   239→│   │       ├── common/  # Standard indicators (RSI, ATR, VWAP)\n   240→│   │       ├── pinescript/# Advanced indicators (ZLTS, MTO, AVOP)\n   241→│   │       └── vol_delta/# Volume delta calculations\n   242→│   ├── go.mod\n   243→│   └── README.md\n   244→└── front/               # Frontend code\n   245→    └── README.md        # Currently empty - backend focus\n   246→```\n   247→\n   248→### Package Organization\n   249→\n   250→```go"}]},"uuid":"fe584051-a261-417c-bd0b-1e900ac3945d","timestamp":"2025-08-13T10:38:01.348Z","toolUseResult":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md","oldString":"```\nbigmeanie/\n├── back/                 # Backend code\n│   ├── cmd/             # Entry points\n│   │   ├── trade/       # Trading bot\n│   │   ├── backtest/    # Backtesting engine\n│   │   └── api/         # REST API server\n│   ├── internal/        # Private packages\n│   │   ├── engine/      # Trading engine\n│   │   ├── strategy/    # Trading strategies\n│   │   ├── exchange/    # Exchange integrations\n│   │   ├── portfolio/   # Portfolio management\n│   │   └── risk/        # Risk management\n│   ├── pkg/             # Public packages\n│   │   ├── indicators/  # Technical indicators\n│   │   ├── decimal/     # Decimal utilities\n│   │   └── errors/      # Error handling\n│   └── .docs/           # Documentation\n│       ├── code/        # Code patterns\n│       ├── plan.md      # Current planning\n│       └── todo.md      # Task tracking\n└── front/               # Frontend code\n    └── [React/Next.js structure]\n```","newString":"```\nbigmeanie/\n├── back/                 # Backend code\n│   ├── .docs/           # Documentation (hidden)\n│   │   ├── archive/     # Historical docs (DO NOT REFERENCE)\n│   │   ├── code/        # Developer guidelines\n│   │   ├── pinescripts/ # TradingView source scripts\n│   │   ├── plan.md      # Current planning\n│   │   └── todo.md      # Task tracking\n│   ├── .snippets/       # Code patterns and examples (hidden)\n│   ├── internal/        # Private packages (future)\n│   ├── pkg/             # Public packages\n│   │   ├── clock/       # Time abstraction for testing\n│   │   ├── decimal_math/# High-precision math utilities\n│   │   ├── errors/      # Structured error handling framework\n│   │   ├── goroutine/   # Safe goroutine management (to be renamed)\n│   │   └── indicators/  # Technical analysis indicators\n│   │       ├── common/  # Standard indicators (RSI, ATR, VWAP)\n│   │       ├── pinescript/# Advanced indicators (ZLTS, MTO, AVOP)\n│   │       └── vol_delta/# Volume delta calculations\n│   ├── go.mod\n│   └── README.md\n└── front/               # Frontend code\n    └── README.md        # Currently empty - backend focus\n```","originalFile":"# Big Meanie Project Conventions\n\n## Philosophy\n\nBig Meanie follows a radical simplicity approach: **break fast, fix immediately**. We prioritize clean breaks over compatibility layers because hidden issues compound exponentially. A breaking change that forces immediate fixes is better than subtle bugs that surface months later in production.\n\n## Table of Contents\n1. [Core Philosophy](#core-philosophy)\n2. [Naming Conventions](#naming-conventions)\n3. [No Backwards Compatibility](#no-backwards-compatibility)\n4. [Project Structure](#project-structure)\n5. [File Management](#file-management)\n6. [Code Organization](#code-organization)\n7. [Testing Standards](#testing-standards)\n8. [Documentation Rules](#documentation-rules)\n\n## Core Philosophy\n\n### The Big Meanie Way\n\n```go\n// We value:\n// 1. Clarity over cleverness\n// 2. Breaking changes over hidden complexity\n// 3. Direct solutions over abstractions\n// 4. Fast failures over graceful degradation\n// 5. Today's correctness over tomorrow's flexibility\n```\n\n### Design Principles\n\n```go\n// BAD: Maintaining compatibility\ntype OrderService interface {\n    PlaceOrder(order Order) error\n    PlaceOrderV2(order OrderV2) error  // NEVER DO THIS\n}\n\n// GOOD: Clean break\ntype OrderService interface {\n    PlaceOrder(order Order) error  // Just change it\n}\n\n// BAD: Migration code\nfunc MigrateData() {\n    if isOldFormat() {\n        convertToNew()  // NEVER DO THIS\n    }\n}\n\n// GOOD: Direct cutover\nfunc LoadData() {\n    // Assume new format only\n    // Old format fails fast\n}\n```\n\n## Naming Conventions\n\n### Concise Names\n\nBig Meanie uses ultra-concise naming. We prefer short, clear names over verbose descriptions.\n\n```go\n// BAD: Verbose naming\ntype SupportResistanceCalculator struct {\n    maximumLookbackPeriod int\n    minimumVolumeThreshold decimal.Decimal\n}\n\nfunc CalculateSupportAndResistanceLevels() {}\nfunc GetMovingAverageConvergenceDivergence() {}\n\n// GOOD: Concise\ntype SRCalculator struct {  // Support/Resistance\n    maxLookback int\n    minVol decimal.Decimal\n}\n\nfunc CalcSR() {}\nfunc MACD() {}\n```\n\n### Standard Abbreviations\n\n```go\n// Common trading abbreviations\nSR   // Support/Resistance\nMA   // Moving Average\nEMA  // Exponential Moving Average\nRSI  // Relative Strength Index\nMACD // Moving Average Convergence Divergence\nBB   // Bollinger Bands\nATR  // Average True Range\nOBV  // On-Balance Volume\nMFI  // Money Flow Index\n\n// System abbreviations\ncfg  // config\nctx  // context\nconn // connection\ndb   // database\nerr  // error\nmsg  // message\nreq  // request\nres  // response/result\ntx   // transaction\n\n// Trading specific\nqty  // quantity\nvol  // volume\npos  // position\npnl  // profit and loss\nnav  // net asset value\nliq  // liquidation/liquidity\n```\n\n### Method Names\n\n```go\n// Prefer short verbs\nCalc()  not  Calculate()\nExec()  not  Execute()\nInit()  not  Initialize()\nProc()  not  Process()\nGen()   not  Generate()\n\n// Getters don't use Get\nPrice()     not  GetPrice()\nQuantity()  not  GetQuantity()\n\n// Setters use Set\nSetPrice()\nSetQuantity()\n\n// Boolean methods\nIsValid()   not  CheckIfValid()\nHasData()   not  CheckHasData()\nCanTrade()  not  CheckCanTrade()\n```\n\n## No Backwards Compatibility\n\n### Breaking Changes Are Good\n\n```go\n// BAD: Versioned APIs\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/v1/orders\", ordersV1Handler)\n    api.HandleFunc(\"/v2/orders\", ordersV2Handler)  // NEVER\n}\n\n// GOOD: One version only\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/orders\", ordersHandler)  // Break it, fix it\n}\n\n// BAD: Compatibility fields\ntype Order struct {\n    ID       string\n    Price    decimal.Decimal\n\n    // Deprecated: Use Price instead\n    PriceStr string  // NEVER KEEP THIS\n}\n\n// GOOD: Clean structure\ntype Order struct {\n    ID    string\n    Price decimal.Decimal  // Changed? Fix all usages\n}\n```\n\n### Migration Anti-Patterns to Avoid\n\n```go\n// NEVER: Gradual migration\nfunc LoadConfig() Config {\n    if FileExists(\"config.yaml\") {\n        return LoadYAML()\n    }\n    // Fallback to old format\n    return LoadJSON()  // NEVER DO THIS\n}\n\n// ALWAYS: Direct cutover\nfunc LoadConfig() Config {\n    return LoadYAML()  // Old format fails immediately\n}\n\n// NEVER: Adapter patterns\ntype LegacyAdapter struct {\n    newService *Service\n}\n\nfunc (a *LegacyAdapter) OldMethod() {\n    a.newService.NewMethod()  // NEVER BUILD ADAPTERS\n}\n\n// ALWAYS: Direct replacement\n// Just change OldMethod to NewMethod everywhere\n```\n\n### Database Migration Rules\n\n```sql\n-- BAD: Maintaining old columns\nALTER TABLE orders ADD COLUMN price_decimal DECIMAL(20,8);\nUPDATE orders SET price_decimal = CAST(price_string AS DECIMAL);\n-- Keep both columns during \"transition\" - NEVER\n\n-- GOOD: Direct replacement\nALTER TABLE orders DROP COLUMN price_string;\nALTER TABLE orders ADD COLUMN price DECIMAL(20,8) NOT NULL;\n-- Breaks immediately, forces data migration\n```\n\n## Project Structure\n\n### Directory Layout\n\n```\nbigmeanie/\n├── back/                 # Backend code\n│   ├── cmd/             # Entry points\n│   │   ├── trade/       # Trading bot\n│   │   ├── backtest/    # Backtesting engine\n│   │   └── api/         # REST API server\n│   ├── internal/        # Private packages\n│   │   ├── engine/      # Trading engine\n│   │   ├── strategy/    # Trading strategies\n│   │   ├── exchange/    # Exchange integrations\n│   │   ├── portfolio/   # Portfolio management\n│   │   └── risk/        # Risk management\n│   ├── pkg/             # Public packages\n│   │   ├── indicators/  # Technical indicators\n│   │   ├── decimal/     # Decimal utilities\n│   │   └── errors/      # Error handling\n│   └── .docs/           # Documentation\n│       ├── code/        # Code patterns\n│       ├── plan.md      # Current planning\n│       └── todo.md      # Task tracking\n└── front/               # Frontend code\n    └── [React/Next.js structure]\n```\n\n### Package Organization\n\n```go\n// Each package has single responsibility\n// internal/engine/engine.go\npackage engine\n\ntype Engine struct {\n    // Only engine-related fields\n}\n\n// internal/strategy/strategy.go\npackage strategy\n\ntype Strategy interface {\n    // Only strategy methods\n}\n\n// Never mix concerns in one package\n// BAD: internal/trading/everything.go\n// GOOD: Separate packages for separate concerns\n```\n\n## File Management\n\n### No Variant Files\n\n```go\n// NEVER create these files:\norder.go\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_enhanced.go // NEVER\norder_refactored.go // NEVER\n\n// ALWAYS update the original:\norder.go  // Just change this file\n```\n\n### File Naming\n\n```go\n// Standard Go conventions\norder.go        // Types and methods\norder_test.go   // Tests\ndoc.go         // Package documentation\n\n// Group by feature, not by type\n// BAD structure:\ntypes.go       // All types\nmethods.go     // All methods\ninterfaces.go  // All interfaces\n\n// GOOD structure:\norder.go       // Order type and methods\ntrade.go       // Trade type and methods\nportfolio.go   // Portfolio type and methods\n```\n\n### Import Organization\n\n```go\nimport (\n    // Standard library\n    \"context\"\n    \"fmt\"\n\n    // External dependencies\n    \"github.com/shopspring/decimal\"\n\n    // Internal packages\n    \"bigmeanie/internal/engine\"\n    \"bigmeanie/pkg/indicators\"\n)\n\n// Never use relative imports\n// BAD:  import \"../engine\"\n// GOOD: import \"bigmeanie/internal/engine\"\n```\n\n## Code Organization\n\n### Interface Design\n\n```go\n// Small, focused interfaces\ntype Trader interface {\n    Trade(ctx context.Context, signal Signal) error\n}\n\n// Not large, kitchen-sink interfaces\ntype BadTrader interface {\n    Trade() error\n    GetBalance() decimal.Decimal\n    GetHistory() []Trade\n    Configure(Config) error\n    // ... 20 more methods - NO!\n}\n\n// Compose interfaces when needed\ntype FullTrader interface {\n    Trader\n    Backtester\n    Reporter\n}\n```\n\n### Error Handling\n\n```go\n// Always wrap errors with context\nif err != nil {\n    return fmt.Errorf(\"engine.Start: %w\", err)\n}\n\n// Define sentinel errors\nvar (\n    ErrInsufficientFunds = errors.New(\"insufficient funds\")\n    ErrOrderTooSmall     = errors.New(\"order below minimum\")\n    ErrExchangeDown      = errors.New(\"exchange unavailable\")\n)\n\n// Use errors.Is for checking\nif errors.Is(err, ErrInsufficientFunds) {\n    // Handle specific error\n}\n```\n\n### Concurrency Patterns\n\n```go\n// Always use context for cancellation\nfunc (e *Engine) Run(ctx context.Context) error {\n    for {\n        select {\n        case <-ctx.Done():\n            return ctx.Err()\n        case signal := <-e.signals:\n            e.process(signal)\n        }\n    }\n}\n\n// Protect shared state\ntype Portfolio struct {\n    mu       sync.RWMutex\n    balances map[string]decimal.Decimal\n}\n\nfunc (p *Portfolio) Balance(asset string) decimal.Decimal {\n    p.mu.RLock()\n    defer p.mu.RUnlock()\n    return p.balances[asset]\n}\n```\n\n## Testing Standards\n\n### Test Organization\n\n```go\n// Table-driven tests always\nfunc TestCalcSR(t *testing.T) {\n    tests := []struct {\n        name string\n        data []decimal.Decimal\n        want []Level\n    }{\n        {\n            name: \"basic support\",\n            data: []decimal.Decimal{...},\n            want: []Level{...},\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := CalcSR(tt.data)\n            require.Equal(t, tt.want, got)\n        })\n    }\n}\n\n// NEVER use t.Skip()\n// BAD:\nfunc TestBrokenFeature(t *testing.T) {\n    t.Skip(\"Fix later\")  // NEVER\n}\n\n// GOOD: Fix it or delete it\n```\n\n### Test Coverage\n\n```go\n// Test edge cases\nfunc TestDivision(t *testing.T) {\n    // Test zero division\n    _, err := Divide(decimal.NewFromInt(1), decimal.Zero)\n    require.Error(t, err)\n\n    // Test negative values\n    result := Divide(decimal.NewFromInt(-10), decimal.NewFromInt(2))\n    require.Equal(t, decimal.NewFromInt(-5), result)\n}\n\n// Benchmark hot paths\nfunc BenchmarkCalcSR(b *testing.B) {\n    data := generatePriceData(1000)\n    b.ResetTimer()\n\n    for i := 0; i < b.N; i++ {\n        CalcSR(data)\n    }\n}\n```\n\n## Documentation Rules\n\n### Code Comments\n\n```go\n// Document WHY, not WHAT\n// BAD:\n// Increment counter by 1\ncounter++\n\n// GOOD:\n// Retry count for exchange rate limiting\ncounter++\n\n// Document edge cases\n// Returns -1 if no valid price found\nfunc FindPrice(prices []decimal.Decimal) decimal.Decimal {\n    // ...\n}\n\n// Document assumptions\n// Assumes prices are sorted in ascending order\nfunc BinarySearch(prices []decimal.Decimal, target decimal.Decimal) int {\n    // ...\n}\n```\n\n### Package Documentation\n\n```go\n// Package engine implements the core trading engine for Big Meanie.\n//\n// The engine coordinates between strategy signals, risk management,\n// and exchange execution. It runs continuously, processing signals\n// and managing positions according to configured strategies.\n//\n// Basic usage:\n//\n//\tcfg := engine.DefaultConfig()\n//\teng := engine.New(cfg)\n//\terr := eng.Run(ctx)\n//\npackage engine\n```\n\n### README Files\n\n```markdown\n# Component Name\n\n## Purpose\nOne paragraph explaining what this does and why it exists.\n\n## Usage\nCode examples showing common usage patterns.\n\n## Configuration\nEnvironment variables or config files needed.\n\n## Testing\nHow to run tests for this component.\n\nNever create documentation unless explicitly requested.\nDocument in code, not in separate files.\n```\n\n## Anti-Patterns to Avoid\n\n### Never Do These\n\n```go\n// 1. Backwards compatibility layers\ntype Service struct {\n    v1Client *ClientV1\n    v2Client *ClientV2  // NEVER\n}\n\n// 2. Gradual migrations\nif useNewSystem {\n    processNew()\n} else {\n    processOld()  // NEVER\n}\n\n// 3. Deprecation warnings\n// Deprecated: Use NewMethod instead\nfunc OldMethod() {  // Just delete it\n}\n\n// 4. Feature flags for old behavior\nif featureFlag(\"use-old-algorithm\") {  // NEVER\n    oldAlgorithm()\n}\n\n// 5. Compatibility shims\nfunc shimOldToNew(old Old) New {  // NEVER\n    // Convert old format to new\n}\n\n// 6. Variant files\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_temp.go    // NEVER\n\n// 7. TODO comments for compatibility\n// TODO: Remove after all clients updated  // NEVER\n```\n\n## Summary of Conventions\n\n1. **Ultra-concise naming** - SR not SupportResistance\n2. **No backwards compatibility** - Break it cleanly\n3. **No migration code** - Direct cutover only\n4. **No variant files** - Update the original\n5. **Fast failures** - Errors surface immediately\n6. **Single version** - No v1, v2 APIs\n7. **Clean breaks** - Force immediate fixes\n8. **Direct solutions** - No adapter patterns\n9. **Test everything** - Never skip tests\n10. **Document WHY** - Code explains what, comments explain why\n\nRemember: **Every line of compatibility code is technical debt.** Break fast, fix immediately, move forward.\n","structuredPatch":[{"oldStart":222,"oldLines":26,"newStart":222,"newLines":27,"lines":[" ```"," bigmeanie/"," ├── back/                 # Backend code","-│   ├── cmd/             # Entry points","-│   │   ├── trade/       # Trading bot","-│   │   ├── backtest/    # Backtesting engine","-│   │   └── api/         # REST API server","-│   ├── internal/        # Private packages","-│   │   ├── engine/      # Trading engine","-│   │   ├── strategy/    # Trading strategies","-│   │   ├── exchange/    # Exchange integrations","-│   │   ├── portfolio/   # Portfolio management","-│   │   └── risk/        # Risk management","+│   ├── .docs/           # Documentation (hidden)","+│   │   ├── archive/     # Historical docs (DO NOT REFERENCE)","+│   │   ├── code/        # Developer guidelines","+│   │   ├── pinescripts/ # TradingView source scripts","+│   │   ├── plan.md      # Current planning","+│   │   └── todo.md      # Task tracking","+│   ├── .snippets/       # Code patterns and examples (hidden)","+│   ├── internal/        # Private packages (future)"," │   ├── pkg/             # Public packages","-│   │   ├── indicators/  # Technical indicators","-│   │   ├── decimal/     # Decimal utilities","-│   │   └── errors/      # Error handling","-│   └── .docs/           # Documentation","-│       ├── code/        # Code patterns","-│       ├── plan.md      # Current planning","-│       └── todo.md      # Task tracking","+│   │   ├── clock/       # Time abstraction for testing","+│   │   ├── decimal_math/# High-precision math utilities","+│   │   ├── errors/      # Structured error handling framework","+│   │   ├── goroutine/   # Safe goroutine management (to be renamed)","+│   │   └── indicators/  # Technical analysis indicators","+│   │       ├── common/  # Standard indicators (RSI, ATR, VWAP)","+│   │       ├── pinescript/# Advanced indicators (ZLTS, MTO, AVOP)","+│   │       └── vol_delta/# Volume delta calculations","+│   ├── go.mod","+│   └── README.md"," └── front/               # Frontend code","-    └── [React/Next.js structure]","+    └── README.md        # Currently empty - backend focus"," ```"," "," ### Package Organization"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"fe584051-a261-417c-bd0b-1e900ac3945d","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01T9pBxxkroLb1KVrEhn2ExZ","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_018mXdXrvL8cMiEGmMhe6YT4","name":"TodoWrite","input":{"todos":[{"id":"1","content":"Rename pkg/goroutine to pkg/concurrent or pkg/workers to avoid confusion with Go's native goroutines","status":"pending"},{"id":"2","content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending"},{"id":"3","content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"completed"},{"id":"4","content":"Defer indicator-framework.md until framework is redesigned","status":"pending"},{"id":"5","content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":1287,"cache_read_input_tokens":64210,"output_tokens":224,"service_tier":"standard"}},"requestId":"req_011CS5Zews3qbHtM8HBdMcVN","type":"assistant","uuid":"25ee44a7-8f04-4e0b-b0de-92c148fab073","timestamp":"2025-08-13T10:38:05.459Z"}
{"parentUuid":"25ee44a7-8f04-4e0b-b0de-92c148fab073","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018mXdXrvL8cMiEGmMhe6YT4","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"53114efd-ae02-4429-a3a1-25a5c41e9019","timestamp":"2025-08-13T10:38:05.520Z","toolUseResult":{"oldTodos":[{"content":"Rename pkg/goroutine to pkg/concurrent or pkg/workers to avoid confusion with Go's native goroutines","status":"in_progress","id":"1"},{"content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending","id":"2"},{"content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"in_progress","id":"3"},{"content":"Defer indicator-framework.md until framework is redesigned","status":"pending","id":"4"},{"content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending","id":"5"}],"newTodos":[{"content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"completed","id":"3"},{"content":"Rename pkg/goroutine to pkg/concurrent or pkg/workers to avoid confusion with Go's native goroutines","status":"pending","id":"1"},{"content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending","id":"2"},{"content":"Defer indicator-framework.md until framework is redesigned","status":"pending","id":"4"},{"content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending","id":"5"}]}}
{"parentUuid":"53114efd-ae02-4429-a3a1-25a5c41e9019","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01Muv5RHGzALm6w9Ga8YT7BF","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"**Updated project-conventions.md** to reflect the current `/back` structure accurately.\n\n**Your feedback addresses key issues:**\n\n1. **Package naming clarity** - You're absolutely right that having to ask \"actual Go goroutines or our pkg/goroutine\" proves the naming is confusing. `pkg/concurrent` or `pkg/workers` would be much clearer.\n\n2. **Version naming convention** - Removing \"v1\" references is important since your philosophy explicitly rejects versioning.\n\n3. **Framework timing** - Smart to fix the indicator framework before documenting it, since documentation should reflect stable patterns.\n\n4. **Test framework dependency** - Waiting for your custom assertion framework before documenting testing patterns ensures consistency.\n\n5. **Interface generics** - Keeping interfaces generic until more codebase exists makes sense for flexibility.\n\n**Next priority actions:**\n- Rename `pkg/goroutine` → `pkg/concurrent` (or `pkg/workers`) \n- Clean up \"v1\" references throughout docs\n- Package renaming will need updates to imports across the codebase\n\nThe project structure is now accurately documented and matches your current reality."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":266,"cache_read_input_tokens":65497,"output_tokens":256,"service_tier":"standard"}},"requestId":"req_011CS5ZfEmHfPYFq3MsRUvSN","type":"assistant","uuid":"c5a38975-0a54-42ed-a3b0-8807c40fa2db","timestamp":"2025-08-13T10:38:14.203Z"}
{"parentUuid":"c5a38975-0a54-42ed-a3b0-8807c40fa2db","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"system","content":"\u001b[1mStop\u001b[22m [paplay /run/current-system/sw/share/sounds/freedesktop/stereo/bell.oga] completed successfully","isMeta":false,"timestamp":"2025-08-13T10:38:14.550Z","uuid":"6d55ffe9-bd33-4b91-b92e-e3a4c5f7cef5","toolUseID":"631997d5-6205-4240-8568-bf91d67ef7e3","level":"info"}
{"parentUuid":"6d55ffe9-bd33-4b91-b92e-e3a4c5f7cef5","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":"why can't we just call it /pkg/safego?"},"uuid":"12bd8e41-72c0-4325-b79c-fb76c3ec9424","timestamp":"2025-08-13T10:40:37.591Z"}
{"parentUuid":"12bd8e41-72c0-4325-b79c-fb76c3ec9424","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01QTXbfYn4WZ1QpMvvgf9vaG","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Absolutely! `pkg/safego` is perfect - it's:\n\n- **Crystal clear**: Immediately conveys \"safe goroutine operations\"\n- **Concise**: Fits your ultra-concise naming philosophy \n- **Unambiguous**: No confusion with native Go goroutines\n- **Descriptive**: Tells you exactly what it does - safe Go concurrency"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":275,"cache_read_input_tokens":65763,"output_tokens":12,"service_tier":"standard"}},"requestId":"req_011CS5ZrTqA4SCuCMicDqBx8","type":"assistant","uuid":"d44907ff-7b6c-4f31-b3d6-102f4cdb6e04","timestamp":"2025-08-13T10:40:41.682Z"}
{"parentUuid":"d44907ff-7b6c-4f31-b3d6-102f4cdb6e04","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01QTXbfYn4WZ1QpMvvgf9vaG","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01SH9WKitHaufP7qk6v7Pr6i","name":"TodoWrite","input":{"todos":[{"id":"1","content":"Rename pkg/goroutine to pkg/safego for clarity and conciseness","status":"pending"},{"id":"2","content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending"},{"id":"3","content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"completed"},{"id":"4","content":"Defer indicator-framework.md until framework is redesigned","status":"pending"},{"id":"5","content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":275,"cache_read_input_tokens":65763,"output_tokens":302,"service_tier":"standard"}},"requestId":"req_011CS5ZrTqA4SCuCMicDqBx8","type":"assistant","uuid":"76bb48bb-2008-4bee-ab5c-f2f73b2eb17e","timestamp":"2025-08-13T10:40:43.142Z"}
{"parentUuid":"76bb48bb-2008-4bee-ab5c-f2f73b2eb17e","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SH9WKitHaufP7qk6v7Pr6i","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"36dc9275-77f0-4d24-ab57-bcf07556dc07","timestamp":"2025-08-13T10:40:43.233Z","toolUseResult":{"oldTodos":[{"content":"Rename pkg/goroutine to pkg/concurrent or pkg/workers to avoid confusion with Go's native goroutines","status":"pending","id":"1"},{"content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending","id":"2"},{"content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"completed","id":"3"},{"content":"Defer indicator-framework.md until framework is redesigned","status":"pending","id":"4"},{"content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending","id":"5"}],"newTodos":[{"content":"Update project structure section in project-conventions.md to reflect current /back structure","status":"completed","id":"3"},{"content":"Rename pkg/goroutine to pkg/safego for clarity and conciseness","status":"pending","id":"1"},{"content":"Fix all package path references in documentation and remove 'v1' versioning convention","status":"pending","id":"2"},{"content":"Defer indicator-framework.md until framework is redesigned","status":"pending","id":"4"},{"content":"Defer clock testing documentation until custom test assertion framework is created","status":"pending","id":"5"}]}}
{"parentUuid":"36dc9275-77f0-4d24-ab57-bcf07556dc07","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01C35kmHJgMVXc4t3c6qg4dX","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01P2KfmGuFVPBxLDTZaYXYzW","name":"Edit","input":{"file_path":"/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md","old_string":"│   │   ├── goroutine/   # Safe goroutine management (to be renamed)","new_string":"│   │   ├── safego/      # Safe goroutine management for 24/7 operations"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":341,"cache_read_input_tokens":66038,"output_tokens":157,"service_tier":"standard"}},"requestId":"req_011CS5Zrsf7yCTA4iSSqgMFb","type":"assistant","uuid":"ed98a5e8-831f-4d5e-be27-dd76765a216f","timestamp":"2025-08-13T10:40:46.662Z"}
{"parentUuid":"ed98a5e8-831f-4d5e-be27-dd76765a216f","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01P2KfmGuFVPBxLDTZaYXYzW","type":"tool_result","content":"The file /home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n   233→│   ├── pkg/             # Public packages\n   234→│   │   ├── clock/       # Time abstraction for testing\n   235→│   │   ├── decimal_math/# High-precision math utilities\n   236→│   │   ├── errors/      # Structured error handling framework\n   237→│   │   ├── safego/      # Safe goroutine management for 24/7 operations\n   238→│   │   └── indicators/  # Technical analysis indicators\n   239→│   │       ├── common/  # Standard indicators (RSI, ATR, VWAP)\n   240→│   │       ├── pinescript/# Advanced indicators (ZLTS, MTO, AVOP)\n   241→│   │       └── vol_delta/# Volume delta calculations"}]},"uuid":"2989bb80-4907-44fe-9918-a641e1965cb9","timestamp":"2025-08-13T10:41:21.826Z","toolUseResult":{"filePath":"/home/aural/Code/bigmeanie/back/.docs/code/project-conventions.md","oldString":"│   │   ├── goroutine/   # Safe goroutine management (to be renamed)","newString":"│   │   ├── safego/      # Safe goroutine management for 24/7 operations","originalFile":"# Big Meanie Project Conventions\n\n## Philosophy\n\nBig Meanie follows a radical simplicity approach: **break fast, fix immediately**. We prioritize clean breaks over compatibility layers because hidden issues compound exponentially. A breaking change that forces immediate fixes is better than subtle bugs that surface months later in production.\n\n## Table of Contents\n1. [Core Philosophy](#core-philosophy)\n2. [Naming Conventions](#naming-conventions)\n3. [No Backwards Compatibility](#no-backwards-compatibility)\n4. [Project Structure](#project-structure)\n5. [File Management](#file-management)\n6. [Code Organization](#code-organization)\n7. [Testing Standards](#testing-standards)\n8. [Documentation Rules](#documentation-rules)\n\n## Core Philosophy\n\n### The Big Meanie Way\n\n```go\n// We value:\n// 1. Clarity over cleverness\n// 2. Breaking changes over hidden complexity\n// 3. Direct solutions over abstractions\n// 4. Fast failures over graceful degradation\n// 5. Today's correctness over tomorrow's flexibility\n```\n\n### Design Principles\n\n```go\n// BAD: Maintaining compatibility\ntype OrderService interface {\n    PlaceOrder(order Order) error\n    PlaceOrderV2(order OrderV2) error  // NEVER DO THIS\n}\n\n// GOOD: Clean break\ntype OrderService interface {\n    PlaceOrder(order Order) error  // Just change it\n}\n\n// BAD: Migration code\nfunc MigrateData() {\n    if isOldFormat() {\n        convertToNew()  // NEVER DO THIS\n    }\n}\n\n// GOOD: Direct cutover\nfunc LoadData() {\n    // Assume new format only\n    // Old format fails fast\n}\n```\n\n## Naming Conventions\n\n### Concise Names\n\nBig Meanie uses ultra-concise naming. We prefer short, clear names over verbose descriptions.\n\n```go\n// BAD: Verbose naming\ntype SupportResistanceCalculator struct {\n    maximumLookbackPeriod int\n    minimumVolumeThreshold decimal.Decimal\n}\n\nfunc CalculateSupportAndResistanceLevels() {}\nfunc GetMovingAverageConvergenceDivergence() {}\n\n// GOOD: Concise\ntype SRCalculator struct {  // Support/Resistance\n    maxLookback int\n    minVol decimal.Decimal\n}\n\nfunc CalcSR() {}\nfunc MACD() {}\n```\n\n### Standard Abbreviations\n\n```go\n// Common trading abbreviations\nSR   // Support/Resistance\nMA   // Moving Average\nEMA  // Exponential Moving Average\nRSI  // Relative Strength Index\nMACD // Moving Average Convergence Divergence\nBB   // Bollinger Bands\nATR  // Average True Range\nOBV  // On-Balance Volume\nMFI  // Money Flow Index\n\n// System abbreviations\ncfg  // config\nctx  // context\nconn // connection\ndb   // database\nerr  // error\nmsg  // message\nreq  // request\nres  // response/result\ntx   // transaction\n\n// Trading specific\nqty  // quantity\nvol  // volume\npos  // position\npnl  // profit and loss\nnav  // net asset value\nliq  // liquidation/liquidity\n```\n\n### Method Names\n\n```go\n// Prefer short verbs\nCalc()  not  Calculate()\nExec()  not  Execute()\nInit()  not  Initialize()\nProc()  not  Process()\nGen()   not  Generate()\n\n// Getters don't use Get\nPrice()     not  GetPrice()\nQuantity()  not  GetQuantity()\n\n// Setters use Set\nSetPrice()\nSetQuantity()\n\n// Boolean methods\nIsValid()   not  CheckIfValid()\nHasData()   not  CheckHasData()\nCanTrade()  not  CheckCanTrade()\n```\n\n## No Backwards Compatibility\n\n### Breaking Changes Are Good\n\n```go\n// BAD: Versioned APIs\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/v1/orders\", ordersV1Handler)\n    api.HandleFunc(\"/v2/orders\", ordersV2Handler)  // NEVER\n}\n\n// GOOD: One version only\nfunc (api *API) RegisterHandlers() {\n    api.HandleFunc(\"/orders\", ordersHandler)  // Break it, fix it\n}\n\n// BAD: Compatibility fields\ntype Order struct {\n    ID       string\n    Price    decimal.Decimal\n\n    // Deprecated: Use Price instead\n    PriceStr string  // NEVER KEEP THIS\n}\n\n// GOOD: Clean structure\ntype Order struct {\n    ID    string\n    Price decimal.Decimal  // Changed? Fix all usages\n}\n```\n\n### Migration Anti-Patterns to Avoid\n\n```go\n// NEVER: Gradual migration\nfunc LoadConfig() Config {\n    if FileExists(\"config.yaml\") {\n        return LoadYAML()\n    }\n    // Fallback to old format\n    return LoadJSON()  // NEVER DO THIS\n}\n\n// ALWAYS: Direct cutover\nfunc LoadConfig() Config {\n    return LoadYAML()  // Old format fails immediately\n}\n\n// NEVER: Adapter patterns\ntype LegacyAdapter struct {\n    newService *Service\n}\n\nfunc (a *LegacyAdapter) OldMethod() {\n    a.newService.NewMethod()  // NEVER BUILD ADAPTERS\n}\n\n// ALWAYS: Direct replacement\n// Just change OldMethod to NewMethod everywhere\n```\n\n### Database Migration Rules\n\n```sql\n-- BAD: Maintaining old columns\nALTER TABLE orders ADD COLUMN price_decimal DECIMAL(20,8);\nUPDATE orders SET price_decimal = CAST(price_string AS DECIMAL);\n-- Keep both columns during \"transition\" - NEVER\n\n-- GOOD: Direct replacement\nALTER TABLE orders DROP COLUMN price_string;\nALTER TABLE orders ADD COLUMN price DECIMAL(20,8) NOT NULL;\n-- Breaks immediately, forces data migration\n```\n\n## Project Structure\n\n### Directory Layout\n\n```\nbigmeanie/\n├── back/                 # Backend code\n│   ├── .docs/           # Documentation (hidden)\n│   │   ├── archive/     # Historical docs (DO NOT REFERENCE)\n│   │   ├── code/        # Developer guidelines\n│   │   ├── pinescripts/ # TradingView source scripts\n│   │   ├── plan.md      # Current planning\n│   │   └── todo.md      # Task tracking\n│   ├── .snippets/       # Code patterns and examples (hidden)\n│   ├── internal/        # Private packages (future)\n│   ├── pkg/             # Public packages\n│   │   ├── clock/       # Time abstraction for testing\n│   │   ├── decimal_math/# High-precision math utilities\n│   │   ├── errors/      # Structured error handling framework\n│   │   ├── goroutine/   # Safe goroutine management (to be renamed)\n│   │   └── indicators/  # Technical analysis indicators\n│   │       ├── common/  # Standard indicators (RSI, ATR, VWAP)\n│   │       ├── pinescript/# Advanced indicators (ZLTS, MTO, AVOP)\n│   │       └── vol_delta/# Volume delta calculations\n│   ├── go.mod\n│   └── README.md\n└── front/               # Frontend code\n    └── README.md        # Currently empty - backend focus\n```\n\n### Package Organization\n\n```go\n// Each package has single responsibility\n// internal/engine/engine.go\npackage engine\n\ntype Engine struct {\n    // Only engine-related fields\n}\n\n// internal/strategy/strategy.go\npackage strategy\n\ntype Strategy interface {\n    // Only strategy methods\n}\n\n// Never mix concerns in one package\n// BAD: internal/trading/everything.go\n// GOOD: Separate packages for separate concerns\n```\n\n## File Management\n\n### No Variant Files\n\n```go\n// NEVER create these files:\norder.go\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_enhanced.go // NEVER\norder_refactored.go // NEVER\n\n// ALWAYS update the original:\norder.go  // Just change this file\n```\n\n### File Naming\n\n```go\n// Standard Go conventions\norder.go        // Types and methods\norder_test.go   // Tests\ndoc.go         // Package documentation\n\n// Group by feature, not by type\n// BAD structure:\ntypes.go       // All types\nmethods.go     // All methods\ninterfaces.go  // All interfaces\n\n// GOOD structure:\norder.go       // Order type and methods\ntrade.go       // Trade type and methods\nportfolio.go   // Portfolio type and methods\n```\n\n### Import Organization\n\n```go\nimport (\n    // Standard library\n    \"context\"\n    \"fmt\"\n\n    // External dependencies\n    \"github.com/shopspring/decimal\"\n\n    // Internal packages\n    \"bigmeanie/internal/engine\"\n    \"bigmeanie/pkg/indicators\"\n)\n\n// Never use relative imports\n// BAD:  import \"../engine\"\n// GOOD: import \"bigmeanie/internal/engine\"\n```\n\n## Code Organization\n\n### Interface Design\n\n```go\n// Small, focused interfaces\ntype Trader interface {\n    Trade(ctx context.Context, signal Signal) error\n}\n\n// Not large, kitchen-sink interfaces\ntype BadTrader interface {\n    Trade() error\n    GetBalance() decimal.Decimal\n    GetHistory() []Trade\n    Configure(Config) error\n    // ... 20 more methods - NO!\n}\n\n// Compose interfaces when needed\ntype FullTrader interface {\n    Trader\n    Backtester\n    Reporter\n}\n```\n\n### Error Handling\n\n```go\n// Always wrap errors with context\nif err != nil {\n    return fmt.Errorf(\"engine.Start: %w\", err)\n}\n\n// Define sentinel errors\nvar (\n    ErrInsufficientFunds = errors.New(\"insufficient funds\")\n    ErrOrderTooSmall     = errors.New(\"order below minimum\")\n    ErrExchangeDown      = errors.New(\"exchange unavailable\")\n)\n\n// Use errors.Is for checking\nif errors.Is(err, ErrInsufficientFunds) {\n    // Handle specific error\n}\n```\n\n### Concurrency Patterns\n\n```go\n// Always use context for cancellation\nfunc (e *Engine) Run(ctx context.Context) error {\n    for {\n        select {\n        case <-ctx.Done():\n            return ctx.Err()\n        case signal := <-e.signals:\n            e.process(signal)\n        }\n    }\n}\n\n// Protect shared state\ntype Portfolio struct {\n    mu       sync.RWMutex\n    balances map[string]decimal.Decimal\n}\n\nfunc (p *Portfolio) Balance(asset string) decimal.Decimal {\n    p.mu.RLock()\n    defer p.mu.RUnlock()\n    return p.balances[asset]\n}\n```\n\n## Testing Standards\n\n### Test Organization\n\n```go\n// Table-driven tests always\nfunc TestCalcSR(t *testing.T) {\n    tests := []struct {\n        name string\n        data []decimal.Decimal\n        want []Level\n    }{\n        {\n            name: \"basic support\",\n            data: []decimal.Decimal{...},\n            want: []Level{...},\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got := CalcSR(tt.data)\n            require.Equal(t, tt.want, got)\n        })\n    }\n}\n\n// NEVER use t.Skip()\n// BAD:\nfunc TestBrokenFeature(t *testing.T) {\n    t.Skip(\"Fix later\")  // NEVER\n}\n\n// GOOD: Fix it or delete it\n```\n\n### Test Coverage\n\n```go\n// Test edge cases\nfunc TestDivision(t *testing.T) {\n    // Test zero division\n    _, err := Divide(decimal.NewFromInt(1), decimal.Zero)\n    require.Error(t, err)\n\n    // Test negative values\n    result := Divide(decimal.NewFromInt(-10), decimal.NewFromInt(2))\n    require.Equal(t, decimal.NewFromInt(-5), result)\n}\n\n// Benchmark hot paths\nfunc BenchmarkCalcSR(b *testing.B) {\n    data := generatePriceData(1000)\n    b.ResetTimer()\n\n    for i := 0; i < b.N; i++ {\n        CalcSR(data)\n    }\n}\n```\n\n## Documentation Rules\n\n### Code Comments\n\n```go\n// Document WHY, not WHAT\n// BAD:\n// Increment counter by 1\ncounter++\n\n// GOOD:\n// Retry count for exchange rate limiting\ncounter++\n\n// Document edge cases\n// Returns -1 if no valid price found\nfunc FindPrice(prices []decimal.Decimal) decimal.Decimal {\n    // ...\n}\n\n// Document assumptions\n// Assumes prices are sorted in ascending order\nfunc BinarySearch(prices []decimal.Decimal, target decimal.Decimal) int {\n    // ...\n}\n```\n\n### Package Documentation\n\n```go\n// Package engine implements the core trading engine for Big Meanie.\n//\n// The engine coordinates between strategy signals, risk management,\n// and exchange execution. It runs continuously, processing signals\n// and managing positions according to configured strategies.\n//\n// Basic usage:\n//\n//\tcfg := engine.DefaultConfig()\n//\teng := engine.New(cfg)\n//\terr := eng.Run(ctx)\n//\npackage engine\n```\n\n### README Files\n\n```markdown\n# Component Name\n\n## Purpose\nOne paragraph explaining what this does and why it exists.\n\n## Usage\nCode examples showing common usage patterns.\n\n## Configuration\nEnvironment variables or config files needed.\n\n## Testing\nHow to run tests for this component.\n\nNever create documentation unless explicitly requested.\nDocument in code, not in separate files.\n```\n\n## Anti-Patterns to Avoid\n\n### Never Do These\n\n```go\n// 1. Backwards compatibility layers\ntype Service struct {\n    v1Client *ClientV1\n    v2Client *ClientV2  // NEVER\n}\n\n// 2. Gradual migrations\nif useNewSystem {\n    processNew()\n} else {\n    processOld()  // NEVER\n}\n\n// 3. Deprecation warnings\n// Deprecated: Use NewMethod instead\nfunc OldMethod() {  // Just delete it\n}\n\n// 4. Feature flags for old behavior\nif featureFlag(\"use-old-algorithm\") {  // NEVER\n    oldAlgorithm()\n}\n\n// 5. Compatibility shims\nfunc shimOldToNew(old Old) New {  // NEVER\n    // Convert old format to new\n}\n\n// 6. Variant files\norder_v2.go      // NEVER\norder_new.go     // NEVER\norder_temp.go    // NEVER\n\n// 7. TODO comments for compatibility\n// TODO: Remove after all clients updated  // NEVER\n```\n\n## Summary of Conventions\n\n1. **Ultra-concise naming** - SR not SupportResistance\n2. **No backwards compatibility** - Break it cleanly\n3. **No migration code** - Direct cutover only\n4. **No variant files** - Update the original\n5. **Fast failures** - Errors surface immediately\n6. **Single version** - No v1, v2 APIs\n7. **Clean breaks** - Force immediate fixes\n8. **Direct solutions** - No adapter patterns\n9. **Test everything** - Never skip tests\n10. **Document WHY** - Code explains what, comments explain why\n\nRemember: **Every line of compatibility code is technical debt.** Break fast, fix immediately, move forward.\n","structuredPatch":[{"oldStart":234,"oldLines":7,"newStart":234,"newLines":7,"lines":[" │   │   ├── clock/       # Time abstraction for testing"," │   │   ├── decimal_math/# High-precision math utilities"," │   │   ├── errors/      # Structured error handling framework","-│   │   ├── goroutine/   # Safe goroutine management (to be renamed)","+│   │   ├── safego/      # Safe goroutine management for 24/7 operations"," │   │   └── indicators/  # Technical analysis indicators"," │   │       ├── common/  # Standard indicators (RSI, ATR, VWAP)"," │   │       ├── pinescript/# Advanced indicators (ZLTS, MTO, AVOP)"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"2989bb80-4907-44fe-9918-a641e1965cb9","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","message":{"id":"msg_01YHaUy4LMiAmoqjq1ciBZnp","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Perfect! `pkg/safego` is much better - it's exactly what you need:\n\n- **safego.Go()** - launch safe goroutine\n- **safego.Monitor()** - monitor goroutines  \n- **safego.Registry** - global registry\n- **safego.Group** - group management\n\nFits perfectly with your concise naming convention (like `sr` for Support/Resistance). When you're ready to rename the package, the documentation is already updated to reflect the new name."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":414,"cache_read_input_tokens":66379,"output_tokens":115,"service_tier":"standard"}},"requestId":"req_011CS5Zuiwb2xATqpctvGTi3","type":"assistant","uuid":"fca1297c-6ece-4252-9141-8397e8cbeb69","timestamp":"2025-08-13T10:41:25.838Z"}
{"parentUuid":"fca1297c-6ece-4252-9141-8397e8cbeb69","isSidechain":false,"userType":"external","cwd":"/home/aural/Code/bigmeanie","sessionId":"d3f34135-c0bd-4e30-a5db-033c111deda0","version":"1.0.69","gitBranch":"dev","type":"system","content":"\u001b[1mStop\u001b[22m [paplay /run/current-system/sw/share/sounds/freedesktop/stereo/bell.oga] completed successfully","isMeta":false,"timestamp":"2025-08-13T10:41:26.167Z","uuid":"2a2d0689-e41c-431f-bd65-cc6d5404b2a2","toolUseID":"89e88d44-edc5-4393-a5cf-799b8f97c664","level":"info"}
